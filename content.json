{"posts":[{"title":"Learn Vim Efficiently 1","text":"前言：学linux时接触了vim这个编辑器，当时只知道三种模式转换，并不觉得vim有多好用。看南大蒋炎岩操作系统课程时，jyy在shell上键指如飞，我就思考为什么他能够编辑得这么快。我想到的一个点就是光标的移动。在没有接触vim之前，我都是通过键盘右下角的上下左右键进行光标的移动，这意味着右手需要移动一段距离。而接触vim之后，hjkl的移动映射只能说真香。现在我恨不得接触到的每个文本编辑器都有vim工作模式。 推荐阅读： https://github.com/iggredible/Learn-Vim https://missing.csail.mit.edu/2020/editors/ 快速体验：力扣刷题设置绑定vim键位，快速体验vim。 三种工作模式知道vim的三种工作模式 ：编辑模式（insert mode）、命令行模式（command line mode）、正常模式（normal mode） 编辑模式：最一般的文本编辑 按i进入，&lt;Esc&gt;退出 命令行模式：保存文件，离开，读入文件，显示行号等 按:显示，&lt;Esc&gt;退出 正常模式：光标移动、删除、复制粘贴、查找替换 初始模式，&lt;Esc&gt;总能返回normal mode 推荐将&lt;Esc&gt;键位映射至&lt;Caps&gt;键位。 hjkl光标移动与插入模式在normal mode下，可以通过hjkl键进行光标的移动，练会以后很香。 光标移动： 123456h Leftj Downk Upl Rightw 移动到下一个单词（挖坑、w和W区别）b 反向移动到下一个单词 插入模式： i 光标之前 I 本行开头 a 光标之后 A 本行结尾 o 本行之后新增一行插入 O 本行之前新增一行插入 s 删除当前字符插入 S 删除当前行插入 复制粘贴撤销删除在normal mode下可以进行以下操作： yy 复制当前行 （y代表 yank） dd 剪切当前行 p 粘贴 paste u 撤销 undo （挖坑，u撤销的到底是什么？） &lt;ctrl-r&gt; 重做 redo 可视化编辑 v 文本块编辑 V 行块编辑 Ctrl-v 块编辑 123y Yank text (copy)d Delete text and save to registerc Delete text, save to register, and start insert mode 后序： 本文以学windows文本编辑器的逻辑介绍了vim。学vim重要的是提高效率，如何快速入门vim？我想是掌握最常用的操作，抛弃那些看起来效率很高但是使用频率低的操作（比如e、E、ge、gE），这些只会徒增记忆的烦恼。待到使用这些命令成为肌肉记忆时，再学习也不迟。 好了，学会以上这些就算简单入门了，实际上vim还有更多命令，能带来效率质的提高。看不如动手，去力扣刷题吧，感受vim的魅力。 更多材料： vim-commands-cheat-sheet vim-cheet-sheet","link":"/2023/11/22/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/Vim/Vim-1/"},{"title":"Learn Vim Efficiently 2","text":"这里将介绍vim的语法和光标浏览，这几乎是vim最重要的部分。 一、语法强烈推荐阅读： https://github.com/iggredible/Learn-Vim/blob/master/ch04_vim_grammar.md 不同于其他文本编辑器的快捷键（需要同时按下两个键或者三个键），vim的命令更像是编程，有一套特定的语法。 在vim中只有一个语法规则： 1动词+名词 1.1 动词所谓动词就是Operator，操作符。 用:h operator可以查看16种操作符，这里列举三种最常用的操作符。 123y Yank text (copy)d Delete text and save to registerc Delete text, save to register, and start insert mode 1.2 名词所谓名词就是motions，你用来在vim中移动的符号。这里是一些motions。 1234567h Leftj Downk Upl Rightw 移动到下一个单词b 反向移动到下一个单词$ 移动到本行末尾 1.3 动词+名词的语法体现假设你有如下文本： 1cosnt string learn = “vim”; 在正常模式下，你的光标在字母c上。 复制一整行:y$ y是复制，$是移动到一行末尾 删除const：dw d删除w一个单词 向左拷贝3个字母：y3h 删除2个单词：d2w 所以vim的命令不需要刻意记忆，就像自然语言。 以行为单位的操作很频繁，所以vim将准备了一些行操作的快捷方式：yy,dd和cc 1.4 更加快捷的操作假设你有如下文本： 1234int print(){ console.log(&quot;hello vim&quot;); int a[15];} 快速删除括号内的内容di( 快速删除双引号里的内容di&quot; 快速删除中括号内的内容di[ 这将是vim的必杀技。di代表着delete inner。对于结构化的文本，特别是代码。 12i + object Inner text objecta + object Outer text object da(将会连括号一起删除。 1234567891011w A wordp A paragraphs A sentence( or ) A pair of ( ){ or } A pair of { }[ or ] A pair of [ ]&lt; or &gt; A pair of &lt; &gt;t XML tags&quot; A pair of &quot; &quot;' A Pair of ' '` A pair of ` ` 二、光标移动强烈推荐阅读： https://github.com/iggredible/Learn-Vim/blob/master/ch05_moving_in_file.md 光标移动是很基础且重要的内容，一般我们退出编辑模式就是进行光标的移动。 2.1 字符移动12345hjklN + Motion 比如说5H向左移动5个字符。 2.2 单词间移动顾名思义，在单词间移动。 12345w Move forward to the beginning of the next worde Move forward one word to the end of the next wordb Move backward to beginning of the previous word 一般命令都会有大写和小写两个版本，或者代表着两个方向，或者代表着两个不同的意思。 123456W Move forward to the beginning of the next WORDE Move forward one word to the end of the next WORDB Move backward to beginning of the previous WORDge Move backward to end of the previous wordgE Move backward to end of the previous WORD 那么大写的单词和小写的单词有什么区别呢？单词都是被空白字符分隔的字符串。 小写单词只包括字母和数字 大写单词包括任何字符除了空格、制表符和 EOL 2.3 行间移动或者叫行内水平移动更佳。 1230 Go to the first character in the current line$ Go to the last char in the current linen| Go the column n in the current line 值得说是n|，在代码的报警信息中经常能看到第几行第几列报错，使用这个命令能快速定位到出错列。n代表任意数字。 快捷的操作：行内搜索。我认为这是vim的第二个必杀技。 12f Search forward for a match in the same linet Search forward for a match in the same line, stopping before match 利用f可以快速到达你想要的字符面前。比如说fa，快速将光标定位到第一个a的位置。 快速记住f和t的区别：f代表find，找到。t代表till，直到。 同样大小写两个版本代表着两个方向。 12345F Search backward for a match in the same lineT Search backward for a match in the same line, stopping before match; Repeat the last search in the same line using the same direction, Repeat the last search in the same line using the opposite direction 使用;和.能避免重复劳动。记住上次的 行内查找操作。 2.4 行号移动这才是名副其实的行间移动。比如说你想到第7行，命令7G 1234gg Go to the first lineG Go to the last linenG Go to line nn% Go to n% in file 2.5 搜索与替换终于来了，全文搜索与替换。 1234/ Search forward for a match? Search backward for a matchn Repeat last search in same direction of previous searchN Repeat last search in opposite direction of previous search 比如说，现在我们有这样一段文本： 123const int a = 1;const int b = 2;int c = 3; 现在我们想要将所有的int都替换为float： \\int&lt;Enter&gt; 这时你将定位到第一个int cwfloat&lt;Esc&gt; change word改变一个单词，然后输入float n. 继续下一个搜索，然后用点命令重复改变 这时你就能发现vim的快捷了。 还有一些快捷命令： 1234* Search for whole word under cursor forward# Search for whole word under cursor backwardg* Search for word under cursor forwardg# Search for word under cursor backward g*和*的作用，客观自行搜索。 2.6 窗口与浏览To scroll, you have 3 speed increments: full-screen (Ctrl-F/Ctrl-B), half-screen (Ctrl-D/Ctrl-U), and line (Ctrl-E/Ctrl-Y). 123456* Ctrl-E Scroll down a lineCtrl-D Scroll down half screenCtrl-F Scroll down whole screen* Ctrl-Y Scroll up a lineCtrl-U Scroll up half screenCtrl-B Scroll up whole screen You can also scroll relatively to the current line (zoom screen sight): 123zt Bring the current line near the top of your screen* zz Bring the current line to the middle of your screenzb Bring the current line near the bottom of your screen 这里留下作者的话： Finally, realize that you do not need to know every single Vim command to be productive. Most Vim users don’t. I don’t. Learn the commands that will help you accomplish your task at that moment. Take your time. Navigation skill is a very important skill in Vim. Learn one small thing every day and learn it well. 三、Vimrc3.1 是什么？vimrc是vim的配置文件。 3.2 有什么用？它能将某些设置永久保存。什么意思呢？比如说，你现在打开vim设置了行号:set number，当你下一次打开vim时，这个设置就失效了。通过vimrc就能永久保存设置。 一般vimrc在用户目录下， ~/.vimrc. 3.3 它有哪些内容？一般来说，vimrc主要配置以下内容： Plugins Settings Custom Funcitons Custom Commands Mappings 我们只挑常用的讲，设置settings和映射mappings。 当你改变vimrc时，记得source it。 Save it (:w), then source it (:source %). 3.4 设置你可以准备一些常用的设置： 12set numberset nocompatible Since we are learning about Vim and not Vi, a setting that you must have is the nocompatible option. Add set nocompatible in your vimrc. Many Vim-specific features are disabled when it is running on compatible option. 3.5 映射你可以将一些键位映射成一系列命令的组合。这是个非常有用的功能。比方说，你如果不习惯vim的hjkl你可以映射为类似方向键布局的jkli。 语法为： 1nnoremap &lt;key&gt; &lt;key&gt; n意味着normal模式 nore意味着non-recursive，不递归的 map就是映射 如何理解non-recursive呢？让我们来看一个例子： 你现在想要实现这样一个功能：按B就能在每一行的末尾加一个分号，然后退回到上一个单词。你写出这样： 1nmap B A;&lt;esc&gt;B 注意，A行末尾插入，分号，esc退回到normal模式，B回退一个单词。 这看起来很美好，但实际上这个命令会加无限多的分号。除非你按Ctrl-C停止。 为什么？因为没有设置不递归，最后一个B也被解释为映射后的B，而不是映射前的B（回退单词）。 所以，最好在平常中都使用不递归的映射。 好了，现在你可以实现一些快捷的功能了。 1inoremap jk &lt;esc&gt; 这个命令在插入模式下，同时按住jk就能退出插入模式。 map命令的首字母对应不同的模式，这里留给大家探索。 四、后序多用，多折腾。 这里留下作者的话： Vimrc is an important component of Vim customization. A good way to start building your vimrc is by reading other people’s vimrcs and gradually build it over time. The best vimrc is not the one that developer X uses, but the one that is tailored exactly to fit your thinking framework and editing style.","link":"/2023/11/22/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/Vim/VIm-2/"},{"title":"Learn Vim Efficiently 3","text":"这里介绍点命令、寄存器和宏。点命令比较有用，寄存器和宏比较鸡肋。 一、 点命令点命令 . 可以重复你在vim中的改变。 1.1 change in vim在vim中，究竟什么被视为一个改变？ 简单的来说，从进入插入模式到退出之间的所有操作！ 1.2 一个点命令的快捷使用方式比如说，现在我们有这样一段文本： 123const int a = 1;const int b = 2;int c = 3; 现在我们想要将所有的int都替换为float： \\int&lt;Enter&gt; 这时你将定位到第一个int cwfloat&lt;Esc&gt; change word改变一个单词，然后输入float n. 继续下一个搜索，然后用点命令重复改变 点命令的最佳使用场景就是变量更名，当你修改完一个变量的名字，移动光标到下一个变量，然后应用点命令。 二、寄存器在vim中有10种类型的寄存器，不过我并不打算全部介绍它们。 关于寄存器，我们要知道： 有哪些？ 怎么往寄存器里存值？ 怎么从寄存器里取值？ 2.1 start by 4 types register 匿名寄存器：&quot;&quot; 拷贝寄存器：&quot;0 数字寄存器：&quot;1-9 和字母寄存器：&quot;a-z small delete register：&quot;- 寄存器总是以双引号开头，后面跟着一个符号。 匿名寄存器，是我们最常用的寄存器。这里的常用，是它被vim使用，而不是我们主动显式地调用。之前讲的dd,yy,p快捷方式都是往匿名寄存器里存值或取值。 拷贝寄存器，是我们使用y操作符时关联的寄存器。注意yy命令会同时拷贝匿名寄存器和拷贝寄存器，利用这点我们就能得到一个缓存。比如说先用yy再用dd，此时匿名寄存器被更新，如果想用第一次复制的内容，需要从拷贝寄存器拉值&quot;0p。 数字寄存器和字母寄存器都是常规寄存器，主要是往里面存值和取值。 samll ddelete register主要用于小单词的存取。当你diw一个单词的时候，这个单词就会存在这个寄存器中。 2.2 寄存器存取值对寄存器的操作都很简单，用双引号来调用一个寄存器，后面跟上你的命令。 比如，现在你有以下文本： 1const int a = 1; &quot;ad3l&lt;esc&gt; 向左删除3个字符，存在寄存器a中 j 移动到下一行 &quot;ap 从寄存器a中取值 三、宏3.1 是什么？宏可以看作一系列操作的录制，它能帮助你避免许多的重复劳动，在你需要的时候自动执行预先录制好的操作。 3.2 录制宏如果要录制宏，当然需要一个能存储的宏的容器，在vim中，自然就是寄存器了。 录制宏 1q&lt;寄存器名&gt; 结束录制 1q 比如说，录制宏到寄存器4 1q4 之后，寄存器4会记录下你的每一个按键操作。 记得结束录制。 3.3 使用宏使用宏也很简单，用@调用存在寄存器里的宏。 1@&lt;寄存器名&gt; 或者 1@@ Execute the last executed macros 这个命令直接执行上一次录制的宏。 举一个例子：我们想要大写每一个单词 12345hellovimmacrosareawesome With your cursor at the start of the line “hello”, run: 1qa0gU$jq The breakdown: qa starts recording a macro in the a register. 0 goes to beginning of the line. gU$ uppercases the text from your current location to the end of the line. j goes down one line. q stops recording. To replay it, run @a. Just like many other Vim commands, you can pass a count argument to macros. For example, running 3@a executes the macro three times.","link":"/2023/11/22/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/Vim/vim-3/"},{"title":"Git快速入门","text":"Git是一个版本控制工具，通常配合远程代码仓库多人协作开发。上手Git并不难，用过之后就会觉得真香。我入门的方式就是给一个项目提Pull Request。 git学习思路：单链 -&gt; 树 -&gt; 多棵树 本地版本控制（利用状态机的思想学习Git） 分支版本控制（利用树的思想） 远程仓库控制（两颗树之间的对应！） 最后学习学习git相关的配置文件，git就算简单入门了。 推荐阅读：https://www.progit.cn/#_pro_git 在线Git闯关-图形化学GIt：https://learngitbranching.js.org/?locale=zh_CN 一、git基础工作目录下的每一个文件都不外乎这两种状态：已跟踪或未跟踪 已跟踪的文件是指那些被纳入了版本控制的文件，在上一次快照中有它们的记录。 未跟踪文件是工作目录中除已跟踪文件以外的所有其它文件，它们既不存在于上次快照的记录中，也没有放入暂存区。 经过Git追踪的文件，在工作一段时间后，它们可能处于其中之一的状态： committed 已经提交，数据在本地仓库中 modified 已经修改，没有保存在数据库中 staged 已经暂存，包含在下次提交的快照中 引入Git项目三个工作区域的概念：Git仓库、工作目录、暂存区域 基本的 Git 工作流程如下： 在工作目录中修改文件。 暂存文件，将文件的快照放入暂存区域。 提交更新，找到暂存区域的文件，将快照永久性存储到 Git 仓库目录。 如果 Git 目录中保存着的特定版本文件，就属于已提交状态。 如果作了修改并已放入暂存区域，就属于已暂存状态。 如果自上次取出后，作了修改但还没有放到暂存区域，就是已修改状态。 二、本地版本控制2.1 获取仓库获取仓库的方法： 现有目录初始化仓库 克隆仓库 （1）现有目录初始化仓库 1234git init git add your_filegit add LISCENSEgit commit -m 'initial project version' （2）克隆仓库 1git clone [url] 比如 1git clone https://github.com/libgit2/libgit2 这会在当前目录下创建一个名为 “libgit2” 的目录，并在这个目录下初始化一个 .git 文件夹。 如果你想在克隆远程仓库的时候自定义本地仓库的名字， 在上条命令后面跟着你自定义的名字： 1git clone https://github.com/libgit2/libgit2 your_local_name 2.2 git状态工作目录下的每一个文件都不外乎这两种状态：已跟踪或未跟踪 已跟踪的文件是指那些被纳入了版本控制的文件，在上一次快照中有它们的记录，在工作一段时间后，它们的状态可能处于未修改，已修改或已放入暂存区。 未跟踪文件是工作目录中除已跟踪文件以外的所有其它文件，它们既不存在于上次快照的记录中，也没有放入暂存区。 初次克隆某个仓库的时候，工作目录中的所有文件都属于已跟踪文件，并处于未修改状态。 编辑过某些文件之后，由于自上次提交后你对它们做了修改，Git 将它们标记为已修改文件。 我们逐步将这些修改过的文件放入暂存区，然后提交所有暂存了的修改，如此反复。这就是Git本地工作的思想。 2.3 git操作（1）查看文件状态1$ git status （2）跟踪新文件（untracked -&gt; staged)1$ git add yourfile 这是个多功能命令：可以用它开始跟踪新文件，或者把已跟踪的文件放到暂存区，还能用于合并时把有冲突的文件标记为已解决状态等。 （3）暂存已修改文件 (modified -&gt; staged)1$ git add yourfile （4）忽略文件在这种情况下，我们可以创建一个名为 .gitignore 的文件，列出要忽略的文件模式。这些文件不会被提交。 （5）提交更新12$ git commit//另外，你也可以在 commit 命令后添加 -m 选项，将提交信息与命令放在同一行 可以看到，提交后它会告诉你，当前是在哪个分支（master）提交的，本次提交的完整 SHA-1 校验和是什么（463dc4f），以及在本次提交中，有多少文件修订过，多少行添加和删改过。 在提交前，请一定要确认还有什么修改过的或新建的文件还没有 git add 过，否则提交的时候不会记录这些还没暂存起来的变化。 这些修改过的文件只保留在本地磁盘。 每次准备提交前用 git status 看下，是不是都已暂存起来了。 （6）跳过暂存1git commit -a 跳过暂存步骤，将已跟踪的文件（若已经修改）提交。 （7）移除文件xx （8）版本回滚首先查看提交的各个版本提交的 SHA-1 标识符。两个命令都行，不过第二个显示的信息更加简洁。 12$ git log --pretty=oneline$ git log --oneline 使用 git revert 命令可以创建一个新的提交，它撤销了指定的提交内容，但是保留了原来的提交记录。 1git revert SHA-1 使用 git reset 命令可以回滚提交，但这种方式是破坏性的，因为它会更改 Git 历史记录，从而删除要回滚的提交以及回滚之后的提交。 1git reset --hard SHA-1 使用reset后就不能恢复了！ （9）放弃暂存区的修改，回到上次提交要放弃本次代码修改并将工作区回到上次提交的状态，可以使用命令： 1git checkout -- . 该命令会将工作区中所有文件的修改全部还原到上次提交的状态，注意命令中的点号”.”表示当前目录，也可以替换成具体的文件或目录名。 此外，如果你只是想还原某个特定文件的修改，可以使用： 1git checkout -- 文件名 注意，这个命令并不会从版本库中删除已经提交的修改记录，只是还原到上次提交。 如果需要完全撤销某个提交，使用 git reset 命令。 三、分支版本控制3.0 查看分支1git branch 这个命令可以查看当前的所有分支。 1234$ git branch iss53* master testing 注意 master 分支前的 * 字符：它代表现在位于的分支（当前 HEAD 指针所指向的分支）。 3.1 查看分支指向的对象分支指向的对象指commit的文件对象。 123git log --oneline --decorategit log --decorate git log --oneline --decorate 输出效果： 123位于分支 master2348425 (HEAD -&gt; master, testing) v265cd212 initial commit!# 当前 HEAD 指针所指向的分支是master，代表当前所在分支。 3.2 创建分支1git branch your_name 这会在当前提交对象上创建your_name的一个指针，代表创建了一个分支。 3.3 切换分支1git checkout branch_name 切换到branch_name这条分支。实际上会将head指针指向branch_name上。输出效果： 122348425 (HEAD -&gt; testing, master) v265cd212 initial commit!# （1）当你在testing分支提交时，会像现在这样： 123dcd85fe (HEAD -&gt; testing) add file a.c2348425 (master) v265cd212 initial commit!# （2）当你切换回mater分支时,head指针会指向master。 注意：你的工作目录恢复成 master 分支所指向的快照内容。 也就是说，你现在做修改的话，项目将始于一个较旧的版本。 本质上来讲，这就是忽略 testing 分支所做的修改，以便于向另一个方向进行开发。 （3）当你在master分支上再次提交修改时，你的项目就会产生分叉！ 1git log --oneline --decorate --graph --all 它会输出你的提交历史、各个分支的指向以及项目的分支分叉情况。 12345* c8f77ad (HEAD -&gt; master) somethign fixed| * dcd85fe (testing) add file a.c|/* 2348425 v2* 65cd212 initial commit!# Git 的分支实质上仅是包含所指对象校验和（长度为 40 的 SHA-1 值字符串）的文件，所以它的创建和销毁都异常高效。 3.3 分支工作流（1）创建并切换到新分支 1git checkout -b issue54 （2）删除分支 1git branch -d hostfix （3）合并分支 12345678//先切换到master分支$ git checkout masterSwitched to branch 'master'//然后将iss53分支合并到master分支$ git merge iss53Merge made by the 'recursive' strategy.index.html | 1 +1 file changed, 1 insertion(+) 和之前将分支指针向前推进所不同的是，Git 将此次三方合并的结果做了一个新的快照并且自动创建一个新的提交指向它。 这个被称作一次合并提交，它的特别之处在于他有不止一个父提交。 3.4 遇到冲突时的合并如果两次合并都涉及同一个文件的同一处修改，在合并它们的时候就会产生冲突。 此时需要手动排除冲突。步骤： git status 查看冲突的文件 逐一打开冲突文件修改 git add将修改完的文件放入暂存区 git commit提交修改 3.5 放弃合并1git merge --abort 有时候冲突太多了，直接放弃合并吧。 3.6 分支开发工作流比如只在 master 分支上保留完全稳定的代码——有可能仅仅是已经发布或即将发布的代码。 他们还有一些名为 develop 或者 next 的平行分支，被用来做后续开发或者测试稳定性——这些分支不必保持绝对稳定，但是一旦达到稳定状态，它们就可以被合并入 master 分支。 稳定分支的指针总是在提交历史中落后一大截，而前沿分支的指针往往比较靠前。 四、远程仓库控制4.1 查看远程仓库12$ git remoteorigin 它会列出你指定的每一个远程服务器的简写。默认情况下就只有一个origin。 使用选项 -v，会显示远程仓库使用的 Git 保存的简写与其对应的 URL。 123$ git remote -vorigin https://github.com/schacon/ticgit (fetch)origin https://github.com/schacon/ticgit (push) 4.2 添加远程仓库1git remote add &lt;shortname&gt; &lt;url&gt; 添加一个新的远程 Git 仓库，同时指定一个你可以引用的简写。 比如： 12345678$ git remoteorigin$ git remote add pb https://github.com/paulboone/ticgit$ git remote -vorigin https://github.com/schacon/ticgit (fetch)origin https://github.com/schacon/ticgit (push)pb https://github.com/paulboone/ticgit (fetch)pb https://github.com/paulboone/ticgit (push) 先查看现在有远程仓库，只有一个origin。然后添加一个简写为pb的远程仓库。再此查看对应的远程仓库，发现pb已经添加上了。 4.3 从远程仓库抓取fetch1$ git fetch [remote-name] 这个命令会访问远程仓库，拉取所有你还没有的数据（包括新的分支）。 git fetch 命令会将数据拉取到你的本地仓库 - 它并不会自动合并或修改你当前的工作。 如果你使用 clone 命令克隆了一个仓库，命令会自动将其添加为远程仓库并默认以 “origin” 为简写。 所以，git fetch origin 会抓取克隆（或上一次抓取）后新推送的所有工作。 4.4 推送到远程仓库push1git push &lt;远程仓库名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt; 将你本地的某个分支推送到远程的某个分支。两个分支名可以不相同。 如果一个本地分支和远程分支建立了联系（下节会讲，所谓联系就是一一对应），直接 git push就能推送到对应的远程分支。 4.5 跟踪分支track跟踪实际上意味着将本地分支与远程分支建立联系。 (1) 查看本地分支与远程分支之间的关系1git branch -vv 样例输出： 123 develop 3e7f1c3 [origin/develop: ahead 2] Fix bug #123 feature-abc 12a8ee2 [origin/feature-abc] New feature implementation* main 4d59b46 [origin/main: ahead 1, behind 2] Merge pull request #456 这个输出列出了本地仓库中的三个分支：develop、feature-abc和main。其中，星号(*)表示当前所在的分支是main。 对于每个分支，输出显示了以下信息： 分支名称 分支所依据的提交哈希值 与之对应的远程分支名称及其状态信息 在这个示例中，develop分支有两个本地提交尚未推送到远程，而feature-abc分支只有与远程分支同步的提交。同时，main分支有一个本地提交，需要将其推送给远程，并且还需要从远程拉取两个提交。 1、当克隆一个仓库时，git通常会自动地创建一个跟踪 origin/master 的 master 分支。 2、需要重点注意的是这个命令并没有连接服务器，它只会告诉你关于本地缓存的服务器数据。 如果想要统计最新的领先与落后数字，需要在运行此命令前抓取所有的远程仓库。 git fetch --all (2) 跟踪一个远程分支（重要）1git checkout -b [local_branch] [remote_name]/[remote_branch] 这个命令会自动创建一个本地分支并跟踪远程分支。 这是一个十分常用的操作，所以 Git 提供了 --track 快捷方式： 1$ git checkout --track origin/[remote_branch] 直接创建本地的同名分支，跟踪远程分支。比如： 1git checkout --track origin/bugfix-update-v1.1 这会建立一个本地分支origin/bugfix-update-v1.1，它会自动与远程同名分支建立联系。 (3) 修改本地分支跟踪的远程分支1$ git branch -u [remotename]/[remote_branch] 这条命令将设置当前分支跟踪的远程分支。 或者这条命令也有同样效果。 1$ git branch --set-upstream-to=[remotename]/[branch] 4.6 拉取分支pull1git pull git pull是指将远程仓库的代码更新到本地仓库，并合并到本地分支上。 具体来说，git pull命令相当于执行了两个命令： git fetch：从远程仓库拉取最新的代码，并将其存放在本地的“FETCH_HEAD”引用中，但不会修改本地分支。 git merge：将“FETCH_HEAD”引用合并到当前分支上，从而将最新的代码更新到本地仓库。 当执行git pull命令时，会自动执行以上两个步骤，从远程仓库拉取最新的代码，并合并到本地分支上，以使本地代码与远程仓库保持同步。 4.6 查看远程仓库查看某一个远程仓库的更多信息 1git remote show [remote-name] 重命名引用的名字 1git remote rename [old_name] [new_name] 比如将pb远程引用的仓库名称改为paul 1234$ git remote rename pb paul$ git remoteoriginpaul 五、打标签Git 可以给历史中的某一个提交打上标签，以示重要。 比较有代表性的是人们会使用这个功能来标记发布结点（v1.0 等等）。 5.0 为什么要打标签（1）A tag is immutable！ Tag是不可变的，在合入主分支与发布的期间，不必担心任何非预期的改变。 （2）便于管理 标签可比提交带有更多的信息。 5.1 列出标签123$ git tagv0.1v1.3 也可以使用特定的模式查找标签。 1$ git tag -l 'v1.8.5*' 六、git的配置6.1 gitconifg文件（1）是什么？ .gitconfig 文件是 Git 的配置文件，在系统上一般位于用户主目录下。这个文件包含了 Git 的一些全局配置，例如 Git 用户名、邮箱地址、文本编辑器等。 （2）怎么用？ 通过修改 .gitconfig 文件，可以定制 Git 的行为。下面是一些可以在 .gitconfig 文件中设置的常用配置： user.name：设置 Git 的用户名，例如git config --global user.name &quot;Your Name&quot;。 user.email： 设置 Git 的邮箱地址，例如 git config --global user.email &quot;youremail@example.com&quot;。 core.editor：设置 Git 使用的文本编辑器，例如 git config --global core.editor &quot;vim&quot;。 core.autocrlf：将文本文件在 Windows 和 Unix 之间自动进行换行符转换，以便在不同平台之间协作，例如git config --global core.autocrlf true。 alias：自定义 Git 命令别名，例如 git config --global alias.st status 将 git status 命令设置为 git st 命令的别名。 可以通过运行以下命令打开 .gitconfig 文件： 1git config --global --edit 这将在系统中打开 Git 配置文件，可以进行编辑。在 .gitconfig 文件中进行修改后，新的设置会对所有 Git 仓库生效。 6.2 gitignore_global文件（1）是什么？ .gitignore_global 文件是 Git 的全局忽略文件。在这个文件中写入的文件或文件夹将不会被 Git 追踪或提交到远程仓库中。这个文件不同于普通的 .gitignore 文件，它适用于所有的 Git 仓库，而不仅仅是单个项目。 .gitignore_global 文件的作用是防止 Git 追踪某些类型的文件或目录。例如，Windows 系统自动生成的 Thumbs.db 文件、macOS 下的 .DS_Store 文件以及 Python 等语言生成的 .pyc、.pyo 文件等都可以在这个文件中被忽略。当对多个 Git 仓库工作时，这是非常有用的，可以避免在未意识到的情况下提交不必要的文件，从而节省仓库的空间和管理工作。 （2）怎么用？ 要在 Git 中启用全局忽略文件，请在命令行中运行以下命令： 1git config --global core.excludesfile ~/.gitignore_global 其中 ~/.gitignore_global 是 .gitignore_global 文件的路径，可以根据实际情况修改路径。运行此命令后，Git 将不再追踪或提交 .gitignore_global 文件中列出的任何文件或目录。 （3）文件怎么配置？ 在 ~/.gitignore_global 文件中，您可以放置您希望在所有 Git 仓库中忽略的文件或文件夹的模式（通配符格式）。这将使 Git 忽略这些文件或文件夹，即使它们没有被放入 .gitignore 文件中。 例如，如果您希望 Git 在所有仓库中忽略 .DS_Store 文件和 __pycache__ 文件夹，可以创建一个 ~/.gitignore_global 文件，并在其中添加以下内容： 1234# Ignore all .DS_Store files.DS_Store# Ignore pycache directory__pycache__/ 然后，使用 git config 命令将路径添加到 Git 全局配置中，使其生效： 1git config --global core.excludesfile ~/.gitignore_global 这样，在任何 Git 仓库中，都将忽略 .DS_Store 文件和 __pycache__ 文件夹。","link":"/2023/12/01/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/Git/Git-fast-learning/"},{"title":"Missing Semmster Learning 学习笔记","text":"计算机教学中缺失的一课 ：https://missing.csail.mit.edu/ 笔记很丑，不想再改。 一、Course overview + the shell认识shell。shell直译为壳，比喻为操作系统内核外面的一层，是我们同内核对话的一个界面。 推荐阅读：https://wangdoc.com/bash/intro bash是最常用的shell，可以把它当作一种编程语言，命令解释器。以下学习的就是bash的相关命令。 1.1 shell命令入门123echo &quot;hello world&quot;echo 'hello world'echo hello\\ world echo的字符用双引号或单引号包含。也可以不用它们，但遇到空格时要用反斜杠转译空格。（因为空格默认为分隔符） 1.2 how system can find echo?123echo $PATHwhich echo/bin/echo &quot;hello world&quot; echo其实是一段小程序，它也有自己的代码。通过$PATH这个系统变量，就能知道操作系统在哪里寻找echo的可执行文件。 也可以通过指定可执行文件的路径的方式来执行特定的可执行文件。 1.3 navigting in the shell1234cdpwdls和ls -l绝对路径和相对路径 理解linux的路径是一颗树，根路径从/开始。绝对路径从根开始，相对路径是相对于当前目录。 1.4 connecting programsprograms always associated with tow stream: input stream and output streamredirection &lt; file and &gt; filewhen cat is not given any arguments, it prints contents from its input stream to its output stream 12cat &lt; hello.txt| pipe command unix系统设计的哲学： 程序默认从键盘接受输入，输出到屏幕。（即每个程序关联标准输入流，标准输出流） 通过左右箭头符号可以重定向输入输出 管道可以将上一个程序的输出导入到下一个程序的输入 二、Shell Tools and Scriptingshell scripting, about learning a new language: basic data type Control flow If case while for syntax shell编程就是学新的编程语言，你需要知道： 数据类型 程序控制流 具体语法 2.1 variable如何定义变量？直接写出变量名，紧跟着等于号，最后是值。注意中间不能有空格。 1foo=bar # foo = bar is wrong 双引号和单引号在shell程序中的区别在于里面的变量是否会被解释。单引号不会解释变量。 12echo &quot;$foo&quot; # this print barecho '$foo' # this print $foo 2.2 function1234mcd () { mkdir -p &quot;$1&quot; cd &quot;$1&quot;} $0 name of program $1-9 arguments to the script $# number of arguments $$ pid $@ all the arguments $? the last command’s exit status 定义函数也非常简单，xxx。 2.3 Logical command123|| &amp;&amp;; # simplely seperate current command and the next command 或逻辑、与逻辑、单纯的分隔符。在命令行环境中也能使用。 2.4 command substitution1echo &quot;start program at $(date)&quot; 这就是先前讲的，双引号内的命令会被解释执行。前提是用$()包围。 2.5 Process substitution1234&lt;(cmd) # this will execute cmd and place the output in a temporary file and substitute the# &lt;() with that file's name 在Bash中，”&lt;(cmd)”是一种称为”Process Substitution”的特殊语法，它允许将命令的输出作为文件传递给另一个命令。 具体来说，”&lt;(cmd)”会将命令cmd的输出作为一个临时文件，并将该文件的路径作为参数传递给当前命令。 这个临时文件只存在于命令执行期间，并在命令执行完毕后自动删除。 2.6 wildcards and curly braces Wildcards - Whenever you want to perform some sort of wildcard matching, you can use ? and * to match one or any amount of characters respectively. For instance, given files foo, foo1, foo2, foo10 and bar, the command rm foo? will delete foo1 and foo2 whereas rm foo* will delete all but bar. Curly braces {} - Whenever you have a common substring in a series of commands, you can use curly braces for bash to expand this automatically. This comes in very handy when moving or converting files. 1234567891011121314151617181920212223convert image.{png,jpg}# Will expand toconvert image.png image.jpgcp /path/to/project/{foo,bar,baz}.sh /newpath# Will expand tocp /path/to/project/foo.sh /path/to/project/bar.sh /path/to/project/baz.sh /newpath# Globbing techniques can also be combinedmv *{.py,.sh} folder# Will move all *.py and *.sh filesmkdir foo bar# This creates files foo/a, foo/b, ... foo/h, bar/a, bar/b, ... bar/htouch {foo,bar}/{a..h}touch foo/x bar/y# Show differences between files in foo and bardiff &lt;(ls foo) &lt;(ls bar)# Outputs# &lt; x# ---# &gt; y 通配符的概念无需多言。？表示任意一个字符，*表示任意多个字符。 大括号的作用比较微妙。有点像for循环遍历列表，然后自动展开。 这三个符号能极大的拓展匹配，实现自动化操作。 2.7 shebang line1#!/bin/bash Shebang line是指在脚本文件的第一行中使用特定格式的注释来指定解释器的路径。Shebang（也称为 Hashbang ）是一个由井号和叹号构成的字符串行 *#!*。 Shebang line的作用是告诉系统应该使用哪个解释器来执行脚本，从而使脚本能够正确地运行。 Some differences between shell functions and scripts that you should keep in mind are: Functions have to be in the same language as the shell, while scripts can be written in any language. This is why including a shebang for scripts is important. Functions are loaded once when their definition is read. Scripts are loaded every time they are executed. This makes functions slightly faster to load, but whenever you change them you will have to reload their definition. Functions are executed in the current shell environment whereas scripts execute in their own process. Thus, functions can modify environment variables, e.g. change your current directory, whereas scripts can’t. Scripts will be passed by value environment variables that have been exported using export As with any programming language, functions are a powerful construct to achieve modularity, code reuse, and clarity of shell code. Often shell scripts will include their own function definitions. differences between shell functions and scripts functions are executed in the current shell environment scripts execute in their own process 执行shell脚本其实是另外开了一个进程执行，所以当前环境不受影响。 1source xx.sh 而source一个shell脚本其实是加载脚本内的变量，这会影响当前环境变量。 2.8 shell tools123456find grepuniqsortwcawk 一些好用的小工具： TLDR pages Tree fasd autojump nnn 五、Command-line Environment提升你的shell工作流。 5.1 job control你的shell使用一种叫做信号的机制在进程间沟通。信号是一种软中断机制。 123ctrl-c 传递SIGINT信号ctrl-\\ 传递SIGQUIT信号ctrl-z 传递SIGTSTP信号，short for Terminal Stop SIGTERM signal ask a process to exit. Using kill command to send it. kill jobs fg bg nohup 5.2 terminal multiplexerstmux教学 leading key &lt;C-b&gt; x means you press ctrl and b, then release them together, and then press x panes 123竖直分裂一个窗口 &lt;C-b&gt; %水平分裂一个窗口 &lt;C-b&gt; &quot;关闭当前窗口 exit or ctrl-d windows - equivalent to tabs in browsers(threads in process) 123&lt;C-b&gt; c 创建一个虚拟桌面&lt;C-b&gt; p 切换上一个&lt;C-b&gt; n 切换下一个 sessions - a session is an independent workspace with one or more windows 12345tmux # start a new sessiontmux new -s NAME # start a new session with nametmux ls #ls current sessionsdetach a session with &lt;C-b&gt; dattach a session `tmux a` , with -t to specify which 5.3 Aliases1alias name=&quot;command arg1 arg2&quot; 为你的常用命令设置别名，减少重复劳动。 使用alias可以查看设置的别名。 常见的别名设置： 1todo 5.4 Dotfiles隐藏文件，通常是各种程序的配置文件。 bash ~/.bashrc or~/.bash_profile git ~/.gitconfig vim ~/.vimrc tmux ~/.tmux.conf ssh~/.ssh/config 关于隐藏文件，我们需要知道三件事： 内容 位置 管理 5.5 Remote Machines（1）ssh远程登录 1ssh user@remote_server_name ssh远程登录十分重要。 1ssh user@remote_server_name command 如果只执行一条命令，不想登录远程主机。 1ls | ssh user@remote_server_name grep PATTERN 这条命令会先将本地ls的输出通过管道传送到远程机器的grep上。是不是很神奇。这就是Unix的设计哲学。 （2）如果你不想每次都输入密码，利用非对称加密算法中的公钥和私钥，就能免去麻烦。 Key generationTo generate a pair you can run ssh-keygen. 1ssh-keygen -o -a 100 -t ed25519 -f ~/.ssh/id_ed25519 You should choose a passphrase, to avoid someone who gets hold of your private key to access authorized servers. Use ssh-agent or gpg-agent so you do not have to type your passphrase every time. If you have ever configured pushing to GitHub using SSH keys, then you have probably done the steps outlined here and have a valid key pair already. To check if you have a passphrase and validate it you can run ssh-keygen -y -f /path/to/key. Key based authenticationssh will look into .ssh/authorized_keys to determine which clients it should let in. To copy a public key over you can use: 1cat .ssh/id_ed25519.pub | ssh foobar@remote 'cat &gt;&gt; ~/.ssh/authorized_keys' A simpler solution can be achieved with ssh-copy-id where available: 1ssh-copy-id -i .ssh/id_ed25519 foobar@remote （3）文件传输 ssh+tee 1cat localfile | ssh remote_server tee serverfile tee命令读标准输入到一个文件中。 scp 1scp path/local_file remote_host:path/remote_file scp可以像cp一样，将本地文件cp到远程路径 rsync 增强的scp，不过多深入。 （4）端口转发 本地端口转发：发送给本地端口的请求发送到远程机器上 远程端口转发：远程机器监听请求，将请求转发给本地机器 1ssh -L local_ip:local_port:remote_ip:remote_port user@remote_seerver 这是本地端口转发的语法，L表示本地端口转发。本地网卡端口是可以省略的，这时表示local port绑定了本地主机所有的网卡。 比如： 1$ ssh -L 9999:localhost:8888 user@remote_server 通过访问本地localhost:9999就能访问远程服务器的localhost:8888服务。 了解跳板机的概念：https://developer.aliyun.com/article/1035160 5.6 Shells &amp; FrameworksOn-my-zsh Syntax-highlighting History-substring-search 框架是件美好的事情。","link":"/2023/12/01/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/%E7%BB%88%E7%AB%AF/missing-semester-note/"},{"title":"终端基础知识","text":"命令行、终端、Shell、Promt的基础认知。 操作系统自带的终端都很丑且难用，好用的终端需要一番折腾配置（特别是国内环境网络问题），新手往往望而生畏。 【在学校没有人教你的终端基础知识】 https://www.bilibili.com/video/BV1rk4y1W7dZ 一、CLICLI is the abbreviation of Command Line Interface. It’s a text-based way of interacting with a computer. 相比于图像界面提供的按钮，你可以使用一行命令来实现你想要的功能，比如说打开、关闭文件，从而实现与计算机的交互。 那么，你在哪里输入这种文本命令？ 二、TerminalTerminal直译为终端，什么是终端？你可以理解为计算机与人们之间沟通的桥梁。通常它是一个全黑的窗口，可以输入命令并提供反馈。 终端是一款软件，许多系统都有自带的终端。也可以使用其他的终端软件。 三、ShellShell直译为壳，这里不必纠结翻译问题。 Shell运行在终端中，解释你的输入并执行它们。可以简单理解为一个命令解释器，不同的shell有不同的语法。 你输入的文本就好比日常生活中人与人沟通的话，计算机有自己的二进制语言，你有自己的一套语言，比如汉语、英语、法语、日语，Shell就在其中充当翻译官的角色。 四、Prompt命令提示符。在终端中，命令提示符用来提示你输入。比如说提示你当前所在的路径等等","link":"/2023/12/01/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/%E7%BB%88%E7%AB%AF/%E7%BB%88%E7%AB%AF%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"title":"协程理论认识","text":"笔记取自： 【协程革命】理论篇 https://www.bilibili.com/video/BV1K14y1v7cw 主旨协程是可以暂停和恢复的函数。 在一个地方暂停后，又在同样的地方恢复。 为什么需要暂停？一些场景 等待资源就绪（网络IO） UI渲染时处理业务逻辑 游戏技能计算，每一帧计算飞行轨迹然后处理其他逻辑 可以归纳为有其他优先级更高的事件发生时，交处执行权。但这不是线程的切换，协程只是一个函数，协程的切换是函数间的切换（可能切换到另一个线程内的协程）。 暂停与恢复协程暂停了，然后恢复的是哪个协程？ 普遍来说，有一个调度器控制协程切换的整个行为，它负责挑选合适的协程进行运行。 一个协程暂停，它可能返回上层调用它的函数，可能直接返回调度器，也可能切换到另一个协程。 回到调度器，协程调用链得到保存 回到上层调用，比如说python的yield产生一个数据 直接恢复其他协程而不通知调用器，这个最危险（对称式协程） 协程与线程 调度器存放了许多被暂停的协程，多线程争抢协程运行。 实现协程一个协程要做到再恢复，就必须有个地方存上次离开的信息（上下文信息），根据地方的不同，分为有栈协程和无栈协程。 无栈协程对应一个结构体，这个结构体保存了所有协程必要的信息。有栈协程对应了一个2000字节的内存空间，这2000字节的空间可以当作栈使用。 两者优缺点： 有栈申请空间浪费，空间大小不好确定。无栈内存紧凑 有栈递归快，无栈慢 协程切换为什么比线程快在用户级线程中，线程由程序通过线程库实现，线程管理由应用负责，线程切换只需要在用户态完成。 1）协程切换完全在用户空间进行，线程切换涉及特权模式切换，需要在内核空间完成； 2）协程切换相比线程切换做的事情更少。 当前协程的 CPU 寄存器状态，称之为CPU上下文 除了和协程相同基本的 CPU 上下文，还有线程私有的栈和寄存器等，说白了就是上下文比协程多一些。","link":"/2023/12/02/%E5%8D%8F%E7%A8%8B%E7%90%86%E8%AE%BA%E8%AE%A4%E8%AF%86/"},{"title":"Redis入门","text":"Redis是一款用C编写的基于内存的非关系数据库，实际开发中，Redis用作缓存数据库，用来减轻后端数据库的压力。Redis全称为：Remote Dictionary Server（远程数据服务）。 Redis官网:：http://redis.io/ 在线尝试：https://try.redis.io/ 咱认为，学习Redis的最佳方式是从项目开始。先学一点数据结构Redis的终端命令，然后再接入SpringBoot快速上手项目使用。学完基本数据使用后，再探究其原理。 基本数据类型Reids的基本数据类型是value的类型，而不是键的类型。 string类型基本读写 12set key value [EX seconds|PX milliseconds] [NX|XX] get key EX|PX 设置过期时间，单位不同； NX （Not Exist），表示键不存在才进行操作，XX相反； 多字符串存取 12mset key value [key2 value2 ...]mget key [key2 ...] 值的加减 1234incr keydecr keyincrby key numberdecrby key number key对应的数据不是字符串类型吗？怎么能进行加减操作？这里埋个坑。 hash类型redis hash 是 字符 filed 和 value 之间的映射表，所以非常适合用于存储对象。比如说key作为对象名，Field作为对象的属性字段，value则是属性字段的值。 基本读写 123hset key field value [field value ...]hget key fieldhdel key field 查看哈希表的所有field： hkeys key 查看哈希表的所有value：hvals key 查看哈希表的所有field value对：hgetall key 判断一个Key是否存在：hexists key field 应用场景hash类型一般适合用来存对象，能够独立存储每个字段，如果需要修改某个字段的值，可针对性修改。适合对象字段频繁改变的情况。 string类型也能用来存储对象，首先将对象序列化为Json字符串，再存入Redis。这样的坏处是修改字段麻烦。适合对象字段不怎么改变的情况。 List类型redis的list相当于Java中的LinkedList，是一个双向链表，可以在头部或者尾部添加元素，当列表弹出最后一个元素后，该结构自动删除。 （1）基本读写 1234lpush key element [element2]lindex key indexrpush key element [element2]rindex key index lpush 可以将一个或多个值依次插入列表的头部，rpush则将一个或多个值依次插入列表的尾部。 lindex获取指定index的值（注意index从0开始） （2）删除元素 12lpop keyrpop key （3）获取区间元素，注意区间是左闭右闭。 1lrange start stop （4）插入元素 1linsert list BEFORE|AFTER target_element new element Set类型set就是集合，集合的元素不重复无序。Redise的Set底层由哈希表实现，查询复杂度为$O(1)$。 添加一个或多个元素 1SADD key element [element2 ...] 移除一个或多个元素 1SREM key element [element2 ..] 获取集合的所有元素 1SMEMBERS key 判断是否是成员 1SISMEMBER key member 集合应用场景（1）用户点赞 用户对某条评论点赞。偶数次点赞会取消赞。这就要求用户是否对某条评论点赞的判断。 利用set的是否是成员快速判断用户是否点赞。如果点赞，就将用户id添加到评论的点赞set里。 （2）共同关注 利用集合取交集的命令，就能实现共同关注的功能。 Zset类型Set是无序集合，ZSet则是有序集合。有序性是因为ZSet中的每个元素关联了一个Score分数，依据分数进行排序。 ZSet的终端命令与Set大体相同，前缀从S换成了Z，并且额外要求一个Score参数。 有序集合应用场景（1）点赞好友显示 朋友圈点赞头像显示。利用时间戳作为Zset的score，就能以时间排序。 （2）朋友圈滚动分页 用户查看朋友圈其实是查看它的收件箱。如果有新动态发布，那一定是在最顶上。以时间戳作为排序就能实现这种情况。 通用命令（1）exists 存在命令 1exists key 判断指定的key是否存在 （2）keys 查找命令 1keys pattern 查找指定模式的键，模式匹配（通配符、正则表达式） （3）rename 重命令 1rename key newKeyName （4）del 删除key 1del key （5）ttl 获取键的生存时间 1ttl key 值得注意：在多个键时，可以用冒号为键分隔，达到更好可视化效果 底层数据结构 简单动态字符串12345struct sdshdr{ int len; //当前保存字符串长度 int free; //当前未使用字符数量 char buf[]; } SDS类似Java的ArrayList、cpp的vector，动态扩容。虽然底层使用字符数组存储字符，但配合了两个整数变量控制存储空间，这两个变量就是实际所占空间大小和剩余空间大小。 SDS采取预先分配冗余空间策略减少内存的频繁分配。当字符串所占空间小于1M时，成倍扩容。超过1M时，每次只扩容1MB，最多512MB。 压缩链表 ZipList1234567struct ziplist&lt;T&gt; { int32 zlbytes; // 全部占用字节数 int32 zltail_offset; // 最后一个元素距离压缩列表起始位置的偏移量，用于快速定位到最后一个节点 int16 zllength; // 元素个数 T[] entries; // 元素内容列表 int8 zlend; // 标志压缩列表的结束，值恒为 0xFF} ZipList与SDS结构相差无几，由连续内存块组成的顺序型数据结构，它有多个entry节点，每个entry节点可以存放整数或者字符串。另外多了几个标志符，字节数、偏移量、长度、结尾标志符。 List 使用压缩链表的情况：List中元素的数量小于或等于16个时，Redis会使用压缩链表进行存储。 hash对象只有同时满足以下条件，才会采用ziplist编码： hash对象保存的键和值字符串长度都小于64字节 hash对象保存的键值对数量小于512 当Zset中元素的数量小于或等于256个时，Redis会使用压缩列表进行存储。 当ziplist作为zset的底层存储结构时候，每个集合元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员，第二个元素保存元素的分值。 哈希表 Redis的哈希表实现其实是字典，一个字典中包含了两个哈希表。一个哈希表里面可以有多个槽，而每个槽保存了一个键值对（或者多个，取决于是否有哈希冲突）。 采用开链法解决哈希冲突，当不同key映射到同一个哈希槽时，Redis会采用链表的方式，将后来的节点链接到上一节点。 双哈希表设计：这是一种以空间换时间的技术。特别是应对ReHash过程（哈希表扩容或收缩）。 当哈希表的负载因子超过一定阈值时，就会将0号哈希表上的键值对转移到1号哈希表上。具体过程为：为1号哈希表申请空间，然后重新计算哈希值和索引，并重新插入到 ht[1] 中，插入一个删除一个。当0号哈希表所有元素转移完成时，释放0的空间，然后将1号设为0号。 注意这个数据转移过程可以是一次性操作、也可以是分批次操作（渐进式rehash）。另外因为有两个哈希表，查询时如果0号哈希表查不到，还需要在1号哈希表再查一次，牺牲了一点查询性能。 整数集合12345typedef struct intset{ uint32_t encoding; //编码方式 uint32_t length; //集合包含的元素数量 int8_t contents[]; //保存元素的数组}intset; 当set存的都是整数，且个数小于512个时，底层使用整数集合。 跳跃链表 SkipList跳表 = 单链表+随机化的多级索引。 它的基本思想是在链表的基础上，增加多级索引，从而提高数据的查找效率。在一般情况下，它的查找、插入、删除等操作的时间复杂度都为O(log n)。 跳表的核心是索引，它通过维护多级有序链表来实现。每一级索引是原始链表的一部分节点组成，每一级索引的元素数量都比它下一级索引的元素数量少一半。最上面一级索引只有两个节点，第二级索引有四个节点，以此类推。通过这种方式，跳表在空间复杂度和时间复杂度之间做到了平衡。 跳表的查找过程与二分查找类似，先在最高级的索引中查找目标节点，然后通过下降到更低一级的索引再次查找，直到在最底层的索引中找到目标节点或者查找到整个跳表中都没有这个节点。由于跳表的结构不依赖于节点的分布情况，所以它可以用来代替平衡树，实现更高效的查找操作。","link":"/2023/12/06/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/Redis%E5%AD%A6%E4%B9%A0/"},{"title":"设计模式学习","text":"设计模式大致分为三类。 创建者模式：提供一种创建对象的方式，同时隐藏了创建对象的逻辑。而不是直接使用new创建对象。 结构型模式：结构型模式更加关注对象与对象之间的关系与组合，旨在构建灵活可复用的类和对象结构。 行为型模式：关注类或对象之间的通信、协作、职责分配。旨在对象间的责任分配和算法封装。 记住所有的设计模式是愚蠢的，关注自己所在领域常用设计模式，语言框架中默认使用的设计模式。 创建型模式创建者模式封装了创建对象的逻辑，将复杂对象的构建过程与其表示（使用）分离。代替手动用new操作符调用构造函数繁琐的过程。 优点：对象构造与表示分离，隐藏对象的内部结构。 工厂模式工厂模式提供了一种将对象的实例化过程封装在工厂类中的方式。 分类： 简单工厂模式 工厂方法模式 抽象工厂模式 缺点： 增加了系统中的类和对象的个数，复杂度增加。 需要额外工作量创建和维护工厂类和产品类，增加开发成本。 应用场景： 日志配置器：日志记录层次、记录格式、记录的存放路径 123456789101112131415public class ShapeFactory { public Shape getShape(String shapeType){ //使用 getShape 方法获取形状类型的对象 if(shapeType == null){ return null; } if(shapeType.equalsIgnoreCase(&quot;CIRCLE&quot;)){ return new Circle(); } else if(shapeType.equalsIgnoreCase(&quot;RECTANGLE&quot;)){ return new Rectangle(); } else if(shapeType.equalsIgnoreCase(&quot;SQUARE&quot;)){ return new Square(); } return null; }} 自己的应用： 深度学习中，经常需要对比不同学习模型的在相同任务上的效果。而不同的模型的创建逻辑大体相同，但部分细节不同。我自己写了一个模型工厂，根据传入的模型名称、模型层数、模块机制来自动构建模型。这样，每当我要改变一个模型训练，我就修改相应参数。 其实，这么说，整个深度学习任务的过程都可以看成工厂模式，只不过我没有做整个大任务的抽象封装。在Python代码中，我调用了一个argparse这么一个模块，它的作用就是解析命令行的参数。我训练一个任务，大体有数据集、模型、学习率、迭代次数这些个参数，每一次任务可以用参数组合表示。那么就是说我用参数组合来定义任务，这与工厂模式的思想是不谋而合的，我把要改变的地方全部提取出来，放到一起。 单例模式单例模式也就说保证一个类只有一个实例存在，整个系统中只有一个全局对象。 应用场景：当系统只需要一个实例来协调整个系统的行为时 日志记录器 配置管理器 windos中的任务管理器 单线程下实现方式： 私有化构造函数，使得构造函数无法通过外部调用； 创建一个持有字段hold，类型为对象的引用； 创建一个静态方法get，用于获得对象实例的引用。首先检查hold是否为空，为空才创建对象，否则返回引用。 多线程下实现注意点： 线程安全性，get方法得加锁 双重检查：在单例模式中，通常需要进行双重检查锁定，即先检查单例对象是否已经被创建，然后再加锁并再次检查。 饿汉式和懒汉式的选择：饿汉式在类加载时就完成了初始化，而懒汉式则在第一次调用getInstance方法时才进行初始化。 懒汉模式 12345678910111213141516public class Singleton { private static volatile Singleton instance; private Singleton() {} public static Singleton getInstance() { if (instance == null) { // 进入前检测 synchronized (Singleton.class) { // synchronized加锁 if (instance == null) { //进入后检测 instance = new Singleton(); } } } return instance; } } 饿汉模式 123456789public class Singleton { private static Singleton instance = new Singleton(); private Singleton() {} public static Singleton getInstance() { return instance; } } 建造者模式建造者模式将一个复杂对象分解成多个简单部分，对复杂对象分模块构建，一步步构建最终对象。 一般适合创建实例有多个步骤的复杂对象，比如说汽车有各个零件，每种零件的厂商是不固定的，但汽车的组装步骤是一定的。再提炼来说：一个复杂对象由各个部分的子对象组成，子对象可能会经常变化，而各个子对象的组合逻辑却不怎么变化。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class Computer { private final String cpu;//必须 private final String ram;//必须 private final int usbCount;//可选 private final String keyboard;//可选 private final String display;//可选 private Computer(Builder builder){ this.cpu=builder.cpu; this.ram=builder.ram; this.usbCount=builder.usbCount; this.keyboard=builder.keyboard; this.display=builder.display; } public static class Builder{ private String cpu;//必须 private String ram;//必须 private int usbCount;//可选 private String keyboard;//可选 private String display;//可选 public Builder(String cup,String ram){ this.cpu=cup; this.ram=ram; } public Builder setUsbCount(int usbCount) { this.usbCount = usbCount; return this; } public Builder setKeyboard(String keyboard) { this.keyboard = keyboard; return this; } public Builder setDisplay(String display) { this.display = display; return this; } public Computer build(){ return new Computer(this); } } //省略getter方法}---// 使用方式Computer computer=new Computer.Builder(&quot;因特尔&quot;,&quot;三星&quot;) .setDisplay(&quot;三星24寸&quot;) .setKeyboard(&quot;罗技&quot;) .setUsbCount(2) .build(); 结构型模式类与类之间的关系与组合，关注的是类间的布局。 装饰器模式装饰器模式允许向一个对象添加新的功能，同时却不改变其原有代码。 应用： Java中的注解 python里装饰器 Spring框架的注解AOP Java中可以自定义注解，然后通过反射的方式获取注解（注解拦截），然后进行功能增强。 适配器模式适配器模式允许你将不兼容的对象包装成一个适配器类，使它们能够与其他对象一起工作。适配器模式通常用于处理与现有类库或框架不兼容的类或接口。 在STL里，栈和队列都是适配器，它们底层使用Deque作为容器存储，对外却表现为栈或队列的特性。 代理模式unix系统调用中，错误包装函数。 我们需要从概念上了解代理和装饰的区别： 代理是全权代理，目标根本不对外，全部由代理类来完成。 装饰是增强，是辅助，目标仍然可以自行对外提供服务，装饰器只起增强作用。 行为型模式行为型模式关注的是对象间的通信、写作、职责分配等。 责任链模式将处理对象连成一条链，请求沿着链传递，直到有一个对象处理为止。 状态模式对象的行为跟随着状态而改变。【状态机】 迭代器模式提供一个方法顺序访问对象的各个元素，但不暴露对象的内部表示。 CPP的STL库里的迭代器就很好体现这一点。原生指针不足以支持元素的顺序访问，譬如链表节点、树的节点。迭代器的出现使得容器和算法分离，算法通过迭代器访问容器元素却不用知晓其实现，换句话说，算法更加通用。","link":"/2023/12/01/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"title":"链表总结","text":"链表的题目多涉及指针操作，需要画图显示步骤，不然容易搞混。 常用的套路有： 双指针（前驱后继指针、快慢指针、奇偶指针） 虚拟头节点（好处：需要前驱节点时，总能找到前驱节点。比如在删除头节点时，我们可以找到头节点的前驱。） 设计链表 https://leetcode.cn/problems/design-linked-list/description/ 从0开始设计一个链表，实现get、add、delete方法 链表首先要声明链表节点 123456789class ListNode { int val; ListNode next; ListNode(){} ListNode(int val) { this.val = val; this.next = null; }} 再设计链表类 123456789101112131415161718192021class MyLinkedList { int size; //长度 ListNode head; //虚拟头节点 public MyLinkedList() { //假设链表中的所有节点下标从 0 开始。 size = 0; head = new ListNode(-1); } public int get(int index) { //如果下标无效，则返回 -1 } public void addAtIndex(int index, int val) { //将一个值为 val 的节点插入到链表中下标为 index 的节点之前 } public void deleteAtIndex(int index) { //如果下标有效，则删除链表中下标为 index 的节点 }} 我们首先实现get方法。 123456789public int get(int index) { //如果下标无效，则返回 -1 if(index&lt;0 || index&gt;=size) return -1; ListNode cur = head; //链表下标从0开始计算 for(int i=0; i&lt;=index; ++i) cur = cur.next; return cur.val;} 再看delete方法，这里就能看到虚拟头节点的好处了。删除一个节点需要知道它的前驱节点，让它的前驱指向它的后继；如果要删除0号节点即头节点，没有虚拟头节需要额外判断； 12345678910111213public void deleteAtIndex(int index) { //如果下标有效，则删除链表中下标为 index 的节点 if (index &lt; 0 || index &gt;= size) return; ListNode cur = head; //注意要让cur指向index的前驱 //所以判断i&lt;index for(int i=0; i&lt;index; ++i) cur = cur.next; //跳过cur的next cur.next = cur.next.next; //这里需要注意java的自动回收机制，不需要delete --size;} 最后看add方法。 1234567891011121314public void addAtIndex(int index, int val) { //将一个值为 val 的节点插入到链表中下标为 index 的节点之前 if (index &gt; size) return; if (index &lt; 0) index = 0; ListNode cur = head; //注意要让cur指向index的前驱 for(int i=0; i&lt;index; ++i){ cur = cur.next; } ListNode tmp = new ListNode(val); tmp.next = cur.next; cur.next = tmp; ++size;} 双指针应用移除特定链表元素 https://leetcode.cn/problems/remove-linked-list-elements/ 1234567891011121314151617181920class Solution { public ListNode removeElements(ListNode head, int val) { ListNode dummyNode = new ListNode(-1); dummyNode.next = head; ListNode pre = dummyNode; ListNode cur = dummyNode.next; while(cur != null){ // 对cur进行 遍历 if(cur.val == val){ pre.next = cur.next; cur = pre.next; continue; //找下一个 } //找下一个 pre = cur; cur = cur.next; } return dummyNode.next; }} 移除链表中某个特定节点需要知道它的前驱和后继，所以设立前后指针；虚拟头节点方便删除。 删除链表的倒数第N个节点 https://leetcode.cn/problems/remove-nth-node-from-end-of-list/ 123456789101112131415161718class Solution { public ListNode removeNthFromEnd(ListNode head, int n) { ListNode dummyNode = new ListNode(-1); dummyNode.next = head; ListNode first = dummyNode; ListNode second = dummyNode; // second run n step for(int i=0; i&lt;n; ++i){ second = second.next; } while(second != null &amp;&amp; second.next !=null) { //删除节点需要找到它的前驱 second = second.next; first = first.next; } first.next = first.next.next; return dummyNode.next; }} 快慢指针应用，快指针先走N步，然后再走到底。 相交链表https://leetcode.cn/problems/intersection-of-two-linked-lists/ 12345678910111213public class Solution { public ListNode getIntersectionNode(ListNode headA, ListNode headB) { if(headA==null || headB==null) return null; ListNode x=headA, y =headB; while(x!=y) { if (x==null) x = headB; else x = x.next; if (y==null) y = headA; else y = y.next; } return x; }} 双指针的比较巧妙应用，利用 $x+y = y+x $的思想，走到底之后还可以重头再走一遍。 环形链表https://assets.leetcode-cn.com/aliyun-lc-upload/uploads/2018/12/14/160_statement.png 123456789101112public class Solution { public boolean hasCycle(ListNode head) { if(head==null||head.next==null)return false; ListNode slow=head, fast=head; while(fast!=null){ fast = (fast.next==null)?fast.next:fast.next.next; slow = slow.next; if(fast==slow)return true; } return false; }} 快慢指针的典型应用，判断链表中是否有环。 环形链表入口节点https://leetcode.cn/problems/linked-list-cycle-ii/ 1234567891011121314151617181920212223public class Solution { public ListNode detectCycle(ListNode head) { if(head == null) return head; ListNode slow = head; ListNode fast = head; while(fast!=null){ if(fast.next != null) fast = fast.next.next; else fast = fast.next; slow = slow.next; if(fast == slow) break; } if(fast == null) return null; //相遇点 fast = head; while(fast != slow){ fast = fast.next; slow = slow.next; } return fast; }} 这道题难点在于找出环入口节点。解体的关键在于两个点： 假设head到环入口节点的长度为a，环的长度为len，相遇时距离环入口的偏移为offset 当一个指针走 a + k*len步时，它一定在环入口处 推理： f = 2*s s = a + offset + k1*len f = a + offset + k2*len 得到 f-s = k3*len = s 即 s 走了整数倍len，f走了整数倍len。 因此只要相遇后，将fast移到头节点，一步一步走再走a步，一定和slow碰面在入口之处。 迭代法（复杂指针操作）翻转链表 https://leetcode.cn/problems/reverse-linked-list/ (1) 迭代方式反转 123456789101112131415class Solution { public ListNode reverseList(ListNode head) { // 迭代法 ListNode prev = null; ListNode cur = head; ListNode tmp = null; while(cur != null){ tmp = cur.next; cur.next = prev; prev = cur; cur = tmp; } return prev; }} 迭代方式翻转，自然需要两个指针; 需要注意的是翻转前后的尾巴null处理 pre指向已经翻转的链表头节点，初始为null； cur指向下一个要翻转的节点，初始为head （2）递归方式反转 1234567891011121314class Solution { public ListNode reverseList(ListNode head) { //空链表和单个链表无需反转，直接返回 if(head==null) return null; if(head.next==null) return head; //这里假设head.next的开头的链表完成了反转，返回反转后的头节点 ListNode prev = reverseList(head.next); //now we have to do is //reverse head.next and head head.next.next = head; head.next = null; return prev; }} 翻转部分链表 https://leetcode.cn/problems/reverse-linked-list-ii/ 123456789101112131415161718192021222324252627class Solution { public ListNode reverseBetween(ListNode head, int left, int right) { //o(n)的算法 ListNode dummyHead = new ListNode(-1); dummyHead.next = head; ListNode pre = dummyHead; //1 找到left的前驱 for(int i=0; i&lt;left-1; ++i){ pre = pre.next; } ListNode tmp1 = pre; ListNode tmp2 = pre.next; // 2 反转部分 ListNode prev = null; ListNode curr = pre.next; //注意这里多反转一单位长度 for(int i=0; i&lt;= right-left; ++i){ ListNode tmp = curr.next; curr.next = prev; prev = curr; curr = tmp; } tmp1.next = prev; tmp2.next = curr; return dummyHead.next; }} 反转特定范围内的链表，需要注意边界条件。 两两交换链表节点 迭代方式自然需要保存多个指针，修改互相的引用，然后顺序遍历下去。 为了使得处理更加顺畅，引入虚拟头节点 如果被指针指向的顺序搞懵，不如多声明几个变量，保存节点 两两反转需要两个变量 迭代处理，需要前驱和后继，又要两个变量 总共四个变量 12345678910111213141516171819202122232425class Solution { public ListNode swapPairs(ListNode head) { ListNode dummyHead = new ListNode(-1); dummyHead.next = head; ListNode prev = dummyHead; ListNode curr = prev.next; if(curr==null || curr.next==null) return head; ListNode nest = curr.next; ListNode tmp = nest.next; while(curr!=null){ // reverse nest.next = curr; curr.next = tmp; prev.next = nest; // iteration prev = curr; if(prev.next==null) break; curr = prev.next; if(curr==null||curr.next==null) break; nest = curr.next; tmp = nest.next; } return dummyHead.next; }} 简洁写法 12345678910111213141516171819class Solution { public ListNode swapPairs(ListNode head) { ListNode dummyHead = new ListNode(-1); dummyHead.next = head; ListNode prev = dummyHead; while(prev.next!=null &amp;&amp; prev.next.next!=null){ ListNode curr = prev.next; ListNode nest = curr.next; ListNode tmp = nest.next; // reverse nest.next = curr; curr.next = tmp; prev.next = nest; // iteration prev = curr; } return dummyHead.next; }} 巧妙递归翻转部分链表 https://leetcode.cn/problems/reverse-linked-list-ii/ 12345678910111213141516171819class Solution { // 反转head开头的N个节点 ListNode reverseN(ListNode head, int N){ if(head==null || N==1) return head; ListNode rHead = reverseN(head.next, N-1); ListNode tmp = head.next.next; head.next.next = head; head.next = tmp; return rHead; } public ListNode reverseBetween(ListNode head, int left, int right) { if(left == 1){ return reverseN(head, right); } // 索引减1 ListNode rHead = reverseBetween(head.next, left-1, right-1); head.next = rHead; return head; } 主要思想：将left和right堪称相对于头节点的索引。当left为1时，题目归化为反转开头N个节点。 K个一组翻转链表 https://leetcode.cn/problems/reverse-nodes-in-k-group/description/ 123456789101112131415161718192021222324class Solution { // 反转开头N个节点，并返回反转后的头节点 public ListNode reverseN(ListNode head, int N){ if(N==1) return head; ListNode rHead = reverseN(head.next, N-1); ListNode tmp = head.next.next; head.next.next = head; head.next = tmp; return rHead; } public ListNode reverseKGroup(ListNode head, int k) { // 不足N个直接返回 ListNode count = head; for(int i=0; i&lt;k; ++i){ if(count!=null) count = count.next; else return head; } // 先反转开头N个 ListNode rHead = reverseN(head, k); // 递归反转 head.next = reverseKGroup(head.next, k); return rHead; }} 思想：反转前K个后，第K+1个节点还是一样处理。 两两交换链表中的节点 https://leetcode.cn/problems/swap-nodes-in-pairs/ 1234567891011class Solution { public ListNode swapPairs(ListNode head) { if(head==null||head.next==null) return head; ListNode headNext = head.next; ListNode tmp = swapPairs(headNext.next); headNext.next = head; head.next = tmp; return headNext; }} 其实就是K一组翻转链表，K=2的情形。 判断回文链表123456789101112131415class Solution { public ListNode left; public boolean isPalindrome(ListNode head) { left = head; return traverse(head); } public boolean traverse(ListNode head){ if(head == null) return true; boolean res = traverse(head.next); if(left.val != head.val) return false; left = left.next; return res; }} 这个写法比较邪门，将链表想象成一颗退化的树，借助left存储最左端的点，递归一直到最右端，然后判断左右是否相等。 合并链表合并两个有序链表https://leetcode.cn/problems/merge-two-sorted-lists 1234567891011121314151617181920212223class Solution { public ListNode mergeTwoLists(ListNode list1, ListNode list2) { if(list1==null) return list2; if(list2==null) return list1; ListNode dummyHead = new ListNode(-1); ListNode op = dummyHead; while(list1!=null &amp;&amp; list2!=null){ ListNode tmp = new ListNode(-1); if(list1.val &lt; list2.val){ tmp.val = list1.val; list1 = list1.next; }else{ tmp.val = list2.val; list2 = list2.next; } op.next = tmp; op = op.next; } if(list1!=null) op.next =list1; if(list2!=null) op.next =list2; return dummyHead.next; }} 合并K个有序链表https://leetcode.cn/problems/vvXgSW/ 1234567891011121314151617181920212223242526272829303132class Solution { public ListNode meregeTowListInplace(ListNode head1, ListNode head2){ ListNode op1 = head1; ListNode op2 = head2; ListNode dummyHead = new ListNode(-1); ListNode op3 = dummyHead; while(op1!=null &amp;&amp; op2!=null){ if(op1.val &lt; op2.val){ op3.next = op1; op1=op1.next; }else{ op3.next = op2; op2=op2.next; } op3 = op3.next; } if(op1!=null) op3.next = op1; if(op2!=null) op3.next = op2; return dummyHead.next; } public ListNode MergeSort(ListNode[] lists, int start, int end){ if(start&gt;=end) return lists[start]; int mid = (end-start)/2 + start; ListNode head1 = MergeSort(lists, start, mid); ListNode head2 = MergeSort(lists, mid+1, end); return meregeTowListInplace(head1, head2); } public ListNode mergeKLists(ListNode[] lists) { if(lists.length==0) return null; return MergeSort(lists, 0, lists.length-1); }} 链表合并，天然适合二路归并算法。合并两条链表算法很简单，并且原地操作。合并2条链表后，可以再合并4条链表，8条链条，最终合并全部链表！ 解法二：堆 12345678910111213141516171819202122232425class Solution { public ListNode mergeKLists(ListNode[] lists) { if (lists == null || lists.length == 0) return null; PriorityQueue&lt;ListNode&gt; pq = new PriorityQueue&lt;&gt;(lists.length, new Comparator&lt;ListNode&gt;() { @Override public int compare(ListNode o1, ListNode o2) { if (o1.val &lt; o2.val) return -1; else if (o1.val == o2.val) return 0; else return 1; } }); for(ListNode node: lists){ if(node!=null) pq.offer(node); } ListNode dummyHead = new ListNode(-1); ListNode op = dummyHead; while(!pq.isEmpty()){ op.next = pq.poll(); op = op.next; if(op.next!=null) pq.add(op.next); } return dummyHead.next; }} 想清楚操作的顺序，再写代码，不然逻辑混乱，越改越错！ 算法思想：K个升序链表，每次我们都要取最小的。利用升序的特性，我们可以知道最小元素只在每个链表的头部产生。 这个过程抽象为从一个候选集合中取最小值，自然想到堆数据结构。 算法步骤： 1、先取K个链表头部元素建立堆； 2、从堆中取一个，那下一个最小的元素，只可能从取中节点所在的链表产生。所以从那个链表头部取一个节点。 3、不断取一个补一个，最后再将堆中的元素全部取出的即可。 排序链表https://leetcode.cn/problems/sort-list 1234567891011121314151617181920212223242526272829303132333435363738394041class Solution { public ListNode meregeTowListInplace(ListNode head1, ListNode head2){ ListNode op1 = head1; ListNode op2 = head2; ListNode dummyHead = new ListNode(-1); ListNode op3 = dummyHead; while(op1!=null &amp;&amp; op2!=null){ if(op1.val &lt; op2.val){ op3.next = op1; op1=op1.next; }else{ op3.next = op2; op2=op2.next; } op3 = op3.next; } if(op1!=null) op3.next = op1; if(op2!=null) op3.next = op2; return dummyHead.next; } public ListNode mergeSort(ListNode head){ if(head==null||head.next==null) return head; // 首先将一条链表分为前后两半链表 // 偶数长度链表的中间节点在后一半的第一个节点上 ListNode slow =head, fast =head.next; while(fast!=null &amp;&amp; fast.next!=null){ fast = fast.next.next; slow = slow.next; } // 此时slow指向前一半的最后个节点 // 根据slow将链表分为两半 ListNode secondHead = slow.next; slow.next=null; ListNode head1 = mergeSort(head); ListNode head2 = mergeSort(secondHead); return meregeTowListInplace(head1, head2); } public ListNode sortList(ListNode head) { return mergeSort(head); }} 重排链表https://leetcode.cn/problems/reorder-list/description/ 123456789101112131415161718192021222324252627282930313233class Solution { public ListNode reverse(ListNode head){ if(head==null || head.next ==null) return head; ListNode tmp = reverse(head.next); head.next.next = head; head.next =null; return tmp; } public void reorderList(ListNode head) { // 获取后一半链表 if(head==null || head.next ==null) return ; ListNode slow = head; ListNode fast = head.next; while(fast!=null &amp;&amp; fast.next!=null){ slow = slow.next; fast = fast.next.next; } // 反转后一半 ListNode head2 = reverse(slow.next); slow.next =null; // 合并两条链表 ListNode head1 = head; while(head2!=null){ ListNode tmp1 = head1.next; ListNode tmp2 = head2.next; head1.next = head2; head2.next = tmp1; head1 = tmp1; head2 = tmp2; } return ; }} 技术细节：快慢指针+反转链表 其他判断回文链表 https://leetcode.cn/problems/palindrome-linked-list/ 123456789101112131415161718192021222324252627class Solution { public ListNode reverseList(ListNode head){ if(head==null || head.next==null) return head; ListNode tmp = reverseList(head.next); head.next.next = head; head.next =null; return tmp; } public boolean isPalindrome(ListNode head) { if(head==null || head.next==null) return true; ListNode slow =head, fast = head; // 排除了空节点和单节点的情况后，剩下至少两个节点 while(fast!=null &amp;&amp; fast.next!=null){ fast = (fast.next==null)? fast.next:fast.next.next; slow = slow.next; } ListNode LastHalfNode = reverseList(slow); while(LastHalfNode!=null &amp;&amp; head!=null){ if (LastHalfNode.val != head.val){ return false; } LastHalfNode = LastHalfNode.next; head = head.next; } return true; }} 暴力的做法是开辟额外空间存储遍历后数组的值，再用双指针前后夹击判断。思考空间复杂读O（1）的算法，自然的想法是翻转一半的链表，然后比较两条链表。 （1）获取中间节点 方法是快慢指针。问题来了，奇数长度中间节点是确定的，偶数长度链表的中间节点是哪一个？答案是取决于快慢指针的具体实现，有可能是前一半的最后一个节点，也有可能是后一半的第一个节点。 12345ListNode slow =head, fast = head;while(fast!=null &amp;&amp; fast.next!=null){ fast = (fast.next==null)? fast.next:fast.next.next; slow = slow.next;} （2）偷懒的一个技巧 直接比较两条链表，不比较长度，奇数长度情况下最后一个节点不会被比较。 升序矩阵寻找第K个大小的元素https://leetcode.cn/problems/kth-smallest-element-in-a-sorted-matrix/description/ 12345678910111213141516171819202122232425262728293031323334353637class Solution { class Status implements Comparable&lt;Status&gt;{ public int val; public int x; public int y; Status(int val, int x, int y){ this.val = val; this.x = x; this.y = y; } @Override public int compareTo(Status st){ if(this.val &lt; st.val) return -1; if(this.val &gt; st.val) return 1; return 0; } } public int kthSmallest(int[][] matrix, int k) { PriorityQueue&lt;Status&gt; pq = new PriorityQueue&lt;&gt;(); int N = matrix.length; //添加第一列 for(int i=0; i&lt;N; ++i) pq.offer(new Status(matrix[i][0], i, 0)); //然后每次取一个，加一个 while(k&gt;1){ Status st = pq.poll(); if(st.y &lt; N-1){ // 如果这一行还没取完，就继续取 int new_x = st.x; int new_y = st.y+1; pq.offer(new Status(matrix[new_x][new_y], new_x, new_y)); } k--; } Status st = pq.poll(); return st.val; }} 这道题的思想和合并K个升序链表一摸一样。但是忽略了列间的单调上升关系。","link":"/2023/12/12/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/Java%E9%93%BE%E8%A1%A8%E6%80%BB%E7%BB%93/"},{"title":"MIT6.824笔记一 绪论与MapReduce","text":"MIT 6.824 课程第一节笔记，主要介绍了分布式系统的驱动力、难点、类型等，还介绍了MapReduce。 分布式系统介绍（1）驱动力 更高的计算性能（并行计算、大CPU、大内存、大磁盘） 容错机制（两台计算机运行相同的任务，一台失败可到另外一台） 问题的分布特性（比如说银行转账） RPC与代码隔离，只通过网络通信 这门课程主要研究性能与容错。 （2）困难 并行 容错 兼顾性能 （3）分布式系统的类型 基础架构的类型主要是存储，通信（网络）和计算。 实际上我们最关注的是存储，构建一种多副本，容错的，高性能分布式存储实现。 会讨论一些计算系统，比如MapReduce。 也会说一些关于通信的问题，但是主要的出发点是通信是我们建立分布式系统所用的工具。 对于存储和计算，我们的目标是为了能够设计一些简单接口，让第三方应用能够使用这些分布式的存储和计算，这样才能简单的在这些基础架构之上，构建第三方应用程序。 （4）工具 RPC（Remote Procedure Call）。RPC的目标就是掩盖我们正在不可靠网络上通信的事实。 线程。这是一种编程技术，使得我们可以利用多核心计算机。对于本课程而言，更重要的是，线程提供了一种结构化的并发操作方式，这样，从程序员角度来说可以简化并发操作。 并发控制，比如锁。 （5）其他特性 可拓展性：N倍的机器能否带来N倍的性能提升？ 可用性：容错、故障应对 一致性：读写一致性，系统正确的行为 Map Reduce背景Google （2003 年左右）面对巨量（数十 T）的索引数据和全网结构的数据，需要找到最重要的网页。这可以简化为一个排序问题，但如此数量级的排序，单机不是一个可选项。 MapReduce的思想是，应用程序设计人员和分布式运算的使用者，只需要写简单的Map函数和Reduce函数，而不需要知道任何有关分布式的事情，MapReduce框架会处理剩下的事情。 工作原理 两类任务：Map和Reduce一个主节点分配任务，若干个worker节点干活。 看起来很简单的架构，但在分布式环境下，需要考虑： worker节点崩溃，需要任务完成确认机制以及崩溃后临时文件的清理 网络通信不可靠，发送任务和确认任务的消息均可能丢失","link":"/2023/11/25/MIT6.824/%E7%AC%94%E8%AE%B01%E7%BB%AA%E8%AE%BA/"},{"title":"MIT6.824笔记二 Go与RPC","text":"这节课主要介绍Go语言以及用Go实现爬虫的例子。 GOGO的优势 语法层面支持线程和管道 垃圾回收机制，不需要手动管理内存 类型安全（内存安全） //关于内存安全还需要再深刻认识 线程协调方式 channels：go 中比较推荐的方式，分阻塞和带缓冲。 sync.Cond：信号机制。 waitGroup：阻塞知道一组 goroutine 执行完毕，后面还会提到。 爬虫例子 从一个种子网页 URL 开始 通过 HTTP 请求，获取其内容文本 解析其内容包含的所有 URL，针对所有 URL 重复过程 2，3 为了避免重复抓取，需要记下所有抓取过的 URL。 串行爬取（1）串行爬取的主要逻辑 12fmt.Printf(&quot;=== Serial===\\n&quot;)Serial(&quot;http://golang.org/&quot;, fetcher, make(map[string]bool)) 1234567891011121314func Serial(url string, fetcher Fetcher, fetched map[string]bool) { if fetched[url] { return } fetched[url] = true urls, err := fetcher.Fetch(url) if err != nil { return } for _, u := range urls { Serial(u, fetcher, fetched) } return} 深度优先遍历（DFS ）全部网页构成的图结构，利用一个名为 fetched 的 set 来保存所有已经抓取过的 URL。 （2）爬取函数的主要逻辑 Fetcher接口，里面定义了一个Fetch方法 fakeFetcher自定义类型，是一个string到fakeResult的map fakeResult结构体，包括body和urls 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859//// Fetcher//type Fetcher interface { // Fetch returns a slice of URLs found on the page. Fetch(url string) (urls []string, err error)}// fakeFetcher is Fetcher that returns canned results.type fakeFetcher map[string]*fakeResult //自定义类型type fakeResult struct { body string urls []string}func (f fakeFetcher) Fetch(url string) ([]string, error) { if res, ok := f[url]; ok { fmt.Printf(&quot;found: %s\\n&quot;, url) return res.urls, nil } fmt.Printf(&quot;missing: %s\\n&quot;, url) return nil, fmt.Errorf(&quot;not found: %s&quot;, url)}// fetcher is a populated fakeFetcher.var fetcher = fakeFetcher{ &quot;http://golang.org/&quot;: &amp;fakeResult{ &quot;The Go Programming Language&quot;, []string{ &quot;http://golang.org/pkg/&quot;, &quot;http://golang.org/cmd/&quot;, }, }, &quot;http://golang.org/pkg/&quot;: &amp;fakeResult{ &quot;Packages&quot;, []string{ &quot;http://golang.org/&quot;, &quot;http://golang.org/cmd/&quot;, &quot;http://golang.org/pkg/fmt/&quot;, &quot;http://golang.org/pkg/os/&quot;, }, }, &quot;http://golang.org/pkg/fmt/&quot;: &amp;fakeResult{ &quot;Package fmt&quot;, []string{ &quot;http://golang.org/&quot;, &quot;http://golang.org/pkg/&quot;, }, }, &quot;http://golang.org/pkg/os/&quot;: &amp;fakeResult{ &quot;Package os&quot;, []string{ &quot;http://golang.org/&quot;, &quot;http://golang.org/pkg/&quot;, }, },} 并行爬取（1）思考并行的方法 简单将抓取部分用go关键并行。 但如果仅这么改造，不利用某些手段（sync.WaitGroup）等待子 goroutine，而直接返回，那么可能只会抓取到种子 URL，同时造成子 goroutine 的泄露。 如果访问已经抓取的 URL 集合 fetched 不加锁，很可能造成多次拉取同一个网页（两个线程都访问fetched，这个url访问过了吗，结果都是未访问） （2）并行实现——利用锁和共享变量 12fmt.Printf(&quot;=== ConcurrentMutex ===\\n&quot;)ConcurrentMutex(&quot;http://golang.org/&quot;, fetcher, makeState()) 1234567891011121314151617181920212223242526272829303132333435363738394041//// Concurrent crawler with shared state and Mutex//type fetchState struct { mu sync.Mutex fetched map[string]bool}func makeState() *fetchState { return &amp;fetchState{fetched: make(map[string]bool)}}func (fs *fetchState) testAndSet(url string) bool { fs.mu.Lock() defer fs.mu.Unlock() r := fs.fetched[url] fs.fetched[url] = true //已经访问过 return r}func ConcurrentMutex(url string, fetcher Fetcher, fs *fetchState) { if fs.testAndSet(url) { //这里其实就是用锁保护map的更新 return } urls, err := fetcher.Fetch(url) if err != nil { return } var done sync.WaitGroup for _, u := range urls { done.Add(1) go func(u string) { defer done.Done() ConcurrentMutex(u, fetcher, fs) }(u) } done.Wait() return} 其中，关键部分为：sync.WaitGroup 123456789var done sync.WaitGroupfor _, u := range urls { done.Add(1) go func(u string) { defer done.Done() ConcurrentMutex(u, fetcher, fs) }(u)}done.Wait() WaitGroup 内部维护了一个计数器：调用 wg.Add(n) 时候会增加 n；调用 wait.Done() 时候会减少 1。调用 wg.Wait() 会一直阻塞直到当计数器变为 0 所以 WaitGroup 适合等待一组 goroutine 都结束的场景。 利用channel实现并行爬取我们可以实现一个新的爬虫版本，不用锁 + 共享变量，而用 go 中内置的语法：channel 来通信。具体做法类似实现一个生产者消费者模型，使用 channel 做消息队列。 初始将种子 url 塞进 channel。 消费者：master 不断从 channel 中取出 urls，判断是否抓取过，然后启动新的 worker goroutine 去抓取。 生产者：worker goroutine 抓取到给定的任务 url，并将解析出的结果 urls 塞回 channel。 master 使用一个变量 n 来追踪发出的任务数；往发出一份任务增加一；从 channel 中获取并处理完一份结果（即将其再安排给 worker）减掉一；当所有任务都处理完时，退出程序。 12fmt.Printf(&quot;=== ConcurrentChannel ===\\n&quot;)ConcurrentChannel(&quot;http://golang.org/&quot;, fetcher) 1234567891011121314151617181920212223242526272829303132333435363738//// Concurrent crawler with channels//func worker(url string, ch chan []string, fetcher Fetcher) { urls, err := fetcher.Fetch(url) if err != nil { ch &lt;- []string{} } else { ch &lt;- urls }}func coordinator(ch chan []string, fetcher Fetcher) { n := 1 fetched := make(map[string]bool) for urls := range ch { for _, u := range urls { if fetched[u] == false { fetched[u] = true n += 1 go worker(u, ch, fetcher) } } n -= 1 if n == 0 { break } }}func ConcurrentChannel(url string, fetcher Fetcher) { ch := make(chan []string) go func() { ch &lt;- []string{url} }() coordinator(ch, fetcher)} Q&amp;A: master 读 channel，多 worker 写 channel，不会有竞争问题吗？channel 是线程安全的。 channel 不需要最后 close 吗？我们用 n 追踪了所有执行中的任务数，因此当 n 为 0 退出时，channel 中不存在任何任务 / 结果，因此 master/worker 都不会对 channel 存在引用，稍后 gc collector 会将其回收。 为什么在 ConcurrentChannel 需要用 goroutine 往 channel 中写一个 url？否则 master 在读取的时候会一直阻塞。并且 channel 是一个非缓冲 channel，如果不用 goroutine，将会永远阻塞在写的时候。第3个问题，如果不用goroutine，并且是非缓冲管道情况下，发送方会阻塞在发送代码，直到有接收放接收消息。","link":"/2023/11/25/MIT6.824/%E7%AC%94%E8%AE%B02RPC%E4%B8%8E%E7%BA%BF%E7%A8%8B/"},{"title":"MIT6.824笔记三 分布式存储系统GFS","text":"这节课主要介绍分布式存储系统的难点以及论文GFS。 分布式系统出现的原因是人们想要利用更多的机器实现更好的性能，但更多的机器意味着故障的期望上升。解决单台机器故障最简单的办法就是多副本的容错机制，但多副本间需要时间同步。一致性难题意味着牺牲性能，这是个闭环，人们必须在性能和一致性上做取舍。 对于GFS的学习，我觉得首先要明白GFS应对的需求，整体的架构设计，然后就是读写过程，数据一致性，这是从使用层面上来说的。在高可用方面，GFS的备份管理、文件快照、崩溃恢复等细节需要再深入研究。 分布式存储系统的难点从一种角度出发理解分布式储存的难点： 性能 一开始，人们想用大量机器提供更高的性能，这称之为分片（sharding）。但分片一多，故障率就上来了。 故障 故障：单台计算机出错概率小，多台计算机出错的期望就上来了。上千台计算机总有一台失效停机。我们需要一种容错机制（fault torlance）。 容错 实现容错机制最简单的办法就是提供多个副本（replication、backup），一旦一个副本失败，就马上用另一个副本顶替。 副本 有了复制，也还需要注意副本之间的同步，或者说一致型。 一致性 维护一致性通常需要精心设计的手段，比如说主从之间定期通信，传快照或者状态改变。但无论如何设计，一致性的存在或多或少会损害性能。这就是分布式存储系统/分布式系统的难点所在。 如果构建强一致系统会付出相应代价，如果不想付出很多代价，就得忍受不确定的行为。在实践中，要根据场景设计合理的系统，适当取舍。 尽管我们会通过数百台计算机构建一个系统，但是对于一个理想的强一致模型，你看到的就像是只有一台服务器，一份数据，并且系统一次只做一件事情。这是一种直观的理解强一致的方式。 Google File SystemGFS 是谷歌最早开发应用的分布式存储框架。GFS的可贵之处在于它的应用性，尽管学界研究了数十年的分布式系统，但GFS是第一个应用到上千台计算机的分布式系统。论文写得很棒，推荐读英文原文。 论文中的一些思想在当时都不是特别新颖，比如分布式，分片，容错这些在当时已经知道如何实现了。这篇论文的特点是，它描述了一个真正运行在成百上千台计算机上的系统，这个规模远远超过了学术界建立的系统。并且由于GFS被用于工业界，它反映了现实世界的经验，例如对于一个系统来说，怎样才能正常工作，怎样才能节省成本，这些内容也极其有价值。 GFS 可贵之处是经过实践检验、部署过上千台机器的工业级系统，颠覆了之前学术界中很多的经典设计认知，比如： 为了保证数据访问不出错，需要提供强一致性保证（GFS 仅提供某种弱一致性） 为了系统的可靠性，用多机来保证主节点的可靠性（GFS 使用了单点 Master） GFS的设计场景对于任何一种分布式系统，都要明确它应用的场景需求，然后才能对此作出相应设计保障。 大文件存储，GB级别大小 大量顺序读和少量随机读 大量追加写和少量随机写 能够应对多客户端并发写入 部署在普通计算机上，有较高故障率，需要好的容错机制 GFS的总体设计 一个GFS集群包括若干个客户端、一个主节点、若干个从节点（分片服务器成，chunkserver）。 文件被分为64MB大小的块，每个块对应一个唯一64bit的块标识（chunk handle）并分散存储在从节点上。从节点就只是个运行LInux系统的普通机器。 主节点维护命名空间（文件系统的路径）、访问控制信息、文件与块的对应信息、块的存储信息（每个块存储在哪个从节点上）。 客户端与主节点的交互只有文件的元信息。客户端得到它想要的文件存储的真实信息后，就直接向从节点索要数据。 GFS读过程// 略 GFS写过程// 略 GFS的一致性GFS 把自己的一致性称为松弛的一致性模型（relaxed consistency model）。 元数据（命名空间）的操作都是由单一的 master 处理的，并且操作通过锁来保护，保证了原子性，也保证了正确性。 文件的数据修改则相对复杂。在讲述接下来的内容前，首先我们先明确，在文件的某一部分被修改后，它可能进入以下三种状态的其中之一： 客户端读取不同的 Replica 时可能会读取到不同的内容，那这部分文件是不一致的（Inconsistent） 所有客户端无论读取哪个 Replica 都会读取到相同的内容，那这部分文件就是一致的（Consistent） 所有客户端都能看到上一次修改的所有完整内容，且这部分文件是一致的，那么我们说这部分文件是确定的（Defined） 在修改后，一个文件的当前状态将取决于此次修改的类型以及修改是否成功。具体来说： 如果一次写入操作成功且没有与其他并发的写入操作发生重叠，那这部分的文件是确定的（同时也是一致的） 如果有若干个写入操作并发地执行成功，那么这部分文件会是一致的但会是不确定的：在这种情况下，客户端所能看到的数据通常不能直接体现出其中的任何一次修改 失败的写入操作会让文件进入不一致的状态 适应 GFS 的松弛一致性GFS 的松弛一致性模型，实际上是一种不一致的模型，或者更准确地说，在一致的数据中间夹杂着不一致的数据。这就要求上层应用在使用 GFS 时能够适应 GFS 所提供的一致性语义。 论文中给出了几条使用 GFS 的建议：依赖追加（append）而不是依赖覆盖（overwrite）、设立检查点（checkpoint）、写入自校验（write self-validating）、自记录标识（self-identifying record）。 简单来讲，上层应用可以通过两种方式来做到这一点：更多使用追加操作而不是覆写操作；写入包含校验信息的数据。 青睐追加操作而不是覆写操作的原因是明显的：GFS 针对追加操作做出了显著的优化，这使得这种数据写入方式的性能更高，而且也能提供更强的一致性语义。 对于不一致的数据，为每条记录添加校验数，读取方通过校验数识别出不一致的数据，并且丢弃不一致的数据。 对于重复数据，可以采用数据幂等处理。具体来说，可以采用两种方式处理。第一种，对于同一份数据处理多次，这并无负面影响；第二种，如果执行多次处理带来不同的结果，那么应用就需要过滤掉不一致的数据。写入方写入记录时额外写入一个唯一的标识（identifier），读取方读取数据后，通过标识辨别之前是否已经处理过该数据。 GFS的设计哲学前面讲解了基于GFS的应用，需要通过一些特殊手段来应对GFS的松弛一致性模型带来的各种问题。对于使用者来说，GFS的一致性保证是非常不友好的，很多人第一次看到这样的一致性保证都是比较吃惊的。 GFS在架构上选择这样的设计，有它自己的设计哲学。GFS追求的是简单、够用的原则。GFS主要解决的问题是如何使用廉价的服务器存储海量的数据，且达到非常高的吞吐量（GFS非常好地做到了这两点，但这不是本书的主题，这里就不展开介绍了），并且文件系统本身要简单，能够快速地实现出来（GFS的开发者在开发完GFS之后，很快就去开发BigTable了[2]）。 GFS很好地完成了这样的目标，但是留下了一致性问题，给使用者带来了负担。这个问题在GFS推广应用的初期阶段不明显，因为GFS的主要使用者（BigTable系统是GFS系统的主要调用方）就是GFS的开发者，他们深知应该如何使用GFS。这种不一致性在BigTable中被屏蔽掉（采用上面所说的方法），BigTable提供了很好的一致性保证。 但是随着GFS推广应用的不断深入，GFS简单、够用的架构开始带来很多问题，一致性问题仅仅是其中之一。Sean Quinlan作为Leader主导GFS的研发很长时间，在一次采访中，他详细说明了在GFS渡过推广应用的初期阶段之后，这种简单的架构带来的各种问题[2]。 在清晰地看到GFS的一致性模型给使用者带来的不便后，开源的HDFS（Hadoop分布式文件系统）坚定地摒弃了GFS的一致性模型，提供了更好的一致性保证（第3章将介绍HDFS的实现方式）。 参考资料： Google File System 论文详析 https://zhuanlan.zhihu.com/p/33944479 GFS的分布式哲学 https://mp.weixin.qq.com/s/ut8Q7vXa5Lm0auNaN2_Emg [1] Ghemawat S, Gobioff H, Leung S T. The Google File System. ACM SIGOPS Operating Systems Review, 2003. [2] Marshall, Kirk, McKusick, et al. GFS: Evolution on Fast-forward. Communications of the ACM, 2009.","link":"/2023/11/25/MIT6.824/%E7%AC%94%E8%AE%B03GFS/"},{"title":"MIT6.824笔记四 容错与FTVM","text":"这节课主要介绍容错的主要手段——复制以及相应的论文：Fautl-Tolerant Virtual Machines。 复制与容错关系容错本身是为了提供高可用性。例如，当你想构建一个服务时，尽管计算机硬件总是有可能故障，但是我们还是希望能稳定的提供服务。 容错的简单手段就是复制。复制能应对什么样的故障？ 最简单的描述就是单台计算机的fail-stop故障。Fail-stop是一种容错领域的通用术语。它是指，如果某些东西出了故障，比如说计算机，那么它会单纯的停止运行。当任何地方出现故障时，就停止运行，而不是运算出错误结果。 但是复制不能处理软件中的bug和硬件设计中的缺陷，关联性错误（同一批次产品的生产设计缺陷）。 Fautl-Tolerant Virtual MachinesINTRODUCTION论文的introduction写得很简练，直接放原文。 A common approach to implementing fault-tolerant servers is the primary / backup approach [1], where a backup server is always available to take over if the primary server fails. The state of the backup server must be kept nearly identical to the primary server at all times, so that the backup server can take over immediately when the primary fails, and in such a way that the failure is hidden to external clients and no data is lost. 应对容错的主要方式就是主从复制。主节点崩溃时，从节点能够马上接管，并且从节点的状态要与主节点尽可能一致。 One way of replicating the state on the backup server is to ship changes to all state of the primary, including CPU, memory, and I/O devices, to the backup nearly continuously. However, the bandwidth needed to send this state, particular changes in memory, can be very large. 在备份服务器上复制状态的一种方法是将对主服务器的所有状态（包括 CPU、内存和 I/O 设备）的更改几乎连续地传送到备份中。但是，发送此状态所需的带宽（特别是内存中的更改）可能非常大。 A different method for replicating servers that can use much less bandwidth is sometimes referred to as the state-machine approach [13]. The idea is to model the servers as deterministic state machines that are kept in sync by starting them from the same initial state and ensuring that they receive the same input requests in the same order. Since most servers or services have some operations that are not deterministic, extra coordination must be used to ensure that a primary and backup are kept in sync. However, the amount of extra information need to keep the primary and backup in sync is far less than the amount of state (mainly memory updates) that is changing in the primary. 另一种方法基于状态机。这个想法是通过从相同的初始状态启动服务器并确保它们以相同的顺序接收相同的输入请求来将服务器建模为保持同步的确定性状态机。由于大多数服务器或服务都具有一些不确定的操作，因此必须使用额外的协调来确保主服务器和备份服务器保持同步。但是，保持主数据库和备份数据库同步所需的额外信息量远远小于主数据库中更改的状态（主要是内存更新）量。 BASIC FT DESIGN 所有的输入（网络输入、鼠标键盘输入）由主节点接收。主节点和从节点间通过网络的方式通信，称之为logging channel。主节点将它看见的所有输入都通过logging channel 发给从节点。另外，logging channel还传输一些其他包括非确定性行为的信息。 这样从节点就和主节点执行一模一样的的操作，但是从节点的输出被抛弃，只有主节点才能回复客户端。 非确定性事件非确定性事件：不由当前内存和寄存器直接决定的指令 比如随机数生成、事件日期、唯一ID，这些统称为Weird Instructions 客户端的网络输入：包中的数据和包到达的中断触发位置。 FT Protocoloutput requirement if the backup VM ever takes over after a failure of the primary, the backup VM will continue executing in a way that is entirely consistent with all outputs that the primary VM has sent to the external world. 如果备份虚拟机在主虚拟机发生故障后接管，则备份虚拟机将继续以与主虚拟机发送到外部世界的所有输出完全一致的方式执行。 感觉这句话就是脱裤子放屁，多此一举。从状态机肯定要与主状态机状态一致，这样才能在故障时进行主从切换。可以通过延迟任何外部输出（通常是网络数据包）来确保输出要求，直到备份 VM 收到所有信息，使其至少可以重播到该输出操作的点。这就引出来第二个点 output rule the primary VM may not send an out put to the external world, until the backup VM has received and acknowledged the log entry associated with the operation producing the output. 只有主节点收到日志复制完成的回复，它才向外部输出。这意味着从节点收到了日志（此时日志可能堆在缓冲区，尚未执行） Test-and-Set服务一种常见的场景就是主从间网络不可用，此时它们都以为对方挂了，从而各自掌权回复客户端，也就是脑裂问题。 这篇论文解决这个问题的方法是，向一个外部的第三方权威机构求证，来决定Primary还是Backup允许上线。这里的第三方就是Test-and-Set服务。 VM通过网络请求Test-and-Set服务，这个服务会在内存中保留一些标志位，当你向它发送一个Test-and-Set请求，它会设置标志位，并且返回旧的值。这有点像锁，保证了原子操作。任何情况下，想要上线掌权的副本都需要获取Test-and-Set服务。 持有锁的服务挂了怎么办？一般锁都是设置一个租约，有一些心跳机制来续约。","link":"/2023/11/25/MIT6.824/%E7%AC%94%E8%AE%B04VMwareFT/"},{"title":"MIT6.824笔记五 Raft","text":"Raft是一个分布式共识算法/协议，即让多台机器达成一致的算法。 Raft将共识问题分解为三部分：Leader选举、Log复制以及安全性设置(一致性设置）。 由于实验2完整复现了Raft协议，这里只挑一些重点讲。复现时应该着重考虑：节点崩溃又上线、不可靠网络。 Leader选举角色转变 server有三种状态：follower、candidate、leader。分别经过如图所示的过程进行状态转变。 follower和candidate的任务就是等定时器过期发起投票，leader则是发起心跳请求。 当followers选举时间间隔到期后转变为candidate，增加自己的任期号，发起一轮投票； 当leader时，心跳时间间隔开启，选举时间间隔关闭，每隔一段时间向所有node发送空的AppendEntry。 任期机制 发送和回复RPC都要带上自己的任期。任何时刻（收到请求和处理回复）发现自己的任期旧，都要转变身份为follower。 一期一票制度：一个机器在一个任期只能投一票，投票对象VotedFor应该作持久化，避免节点崩溃再次上线重新投票。 投票过程想明白几个问题： 什么时候才能发起投票？ 发起投票的步骤？ 收到过半选票后的处理？ 什么条件下才能为candidate投出自己的选票？ 选举定时器重置的时间点？ 过半票决的好处： 在一机一票的场景下，只会产生一个leader节点 出现网络分区的时候，只可能有一个分区会有超过一半的服务器互相通信 旧leader的过半服务器必然与新leader的过半服务器有重叠，那么就有一个服务器经历过两个任期，它收集了完整的log信息 响应投票： 收到投票RPC消息后，需要比较任期号，驳回旧的任期号投票请求； 如果任期号校验通过，重置选举时间； 当且仅当自己的votedFor为空或为消息中的candidateId时，并且比较自己的log与RPC中的lastLog信息后，才同意投票，并设置自己的votedFor为candidateId。 日志复制想明白几个问题： nextIndex和matchIndex的作用？ 日志不一致时的回退算法？ 什么时候日志能提交？怎么避免日志重复提交？ leader只能提交当前任期内的日志。","link":"/2023/12/13/MIT6.824/%E7%AC%94%E8%AE%B05Raft/"},{"title":"MIT6.824笔记六 线性一致与Zookeeper","text":"这节课主要介绍了线性一致的概念与Zookeeper论文。 线性一致描述的是系统的行为，正确的行为是客户端发送了一个写请求并且收到服务端答复后，这个写请求能被之后的读请求看到。每个读请求看到的都是最新的写请求所作的更改。 Zookeeper论文是我接触到的最抽象的一篇论文。首先它的功能就很抽象：分布式协调内核。它提供的两个保证：线性写和FIFO客户端请求也费时间理解。最后则是它的API调用以及具体实现。 读这篇论文的原因我想一是Zookeeper的广泛使用，证明了其实用性；二是其“线性一致”的设计，契合课程。收获就是其API的设计、Watch模式。 线性一致（1）例子 12345example history 1: |-Wx1-| |-Wx2-| |---Rx2---| |-Rx1-|is this history linearizable? 满足以下两个要求： 线性后的序列要与实际请求时间相匹配（一个请求的结束时间在另一个请求的开启时间之前，那么线性序列也必须遵守） 每个读请求看到都是序列中前一个写请求的值 （2）线性一致 线性一致更多描述的是关于系统行为的定义，我们只能通过一系列请求以及返回值来推测一个系统是否是线性一致的。 在一个线性一致的系统中，读请求不允许返回旧的数据。也就是说，如果我发起了一个写请求，然后再读，如果读到的不是上次写的值，那这个系统就不是线性一致的。 ZooKeeper 参考了个人笔记：https://zhuanlan.zhihu.com/p/363396366 介绍ZookeeperZookeeper是一个通用的分布式协调服务（General-Purpose Coordination Service），通过提供协调内核/客户端API的形式，让开发者自己实现诸多原语/功能，包括统一命名、配置管理、成员管理、分布式锁、双重屏障等。 Zookeeper基于Zab（类似Raft的基于领导者的原子广播协议）实现了多副本容错机制，但不同于Raft，Zookper的所有副本都能接受读请求。这得益于Zookeeper的两个设计：线性写和FIFO客户端请求。 Zookeeper为客户端提供了一组数据节点（称之为Znode），Znode根据分层名称空间进行组织，记法上类似于Unix的文件系统。客户端通过Zookeeper提供的API能对数据节点进行创建、删除、读取、写入、获取目录下所有文件等操作。Zookeeper还实现了一种Watch机制，通过此机制，客户端能够监听某个Znode的变化（更新、删除），Zookeeper会在Znode发生变化时向客户端发送一条通知消息。 Zookeeper API Zookeeper的API某种程度上来说像是一个文件系统。它有一个层级化的目录结构，有一个根目录（root），之后每个应用程序有自己的子目录。文件和目录都被称为znodes。 1234567891011`CREATE(PATH，DATA，FLAG)`。入参分别是文件的全路径名PATH，数据DATA，和表明znode类型的FLAG。这里有意思的是，CREATE的语义是排他的。`DELETE(PATH，VERSION)`。入参分别是文件的全路径名PATH，和版本号VERSION。有一件事情我之前没有提到，每一个znode都有一个表示当前版本号的version，当znode有更新时，version也会随之增加`EXIST(PATH，WATCH)`。入参分别是文件的全路径名PATH，和一个有趣的额外参数WATCH。通过指定watch，你可以监听对应文件的变化。`GETDATA(PATH，WATCH)`。入参分别是文件的全路径名PATH，和WATCH标志位。这里的watch监听的是文件的内容的变化。`SETDATA(PATH，DATA，VERSION)`。入参分别是文件的全路径名PATH，数据DATA，和版本号VERSION。如果你传入了version，那么Zookeeper当且仅当文件的版本号与传入的version一致时，才会更新文件。`LIST(PATH)`。入参是目录的路径名，返回的是路径下的所有文件。 Znode有两种基本类型：Regular和Ephemeral。创建的api还包括一个sequential flag。 Znode还关联了时间戳、版本信息。 更新方法都带有一个版本号，只有版本号与Znode的版本号一致时，更新操作才能成功。 配置管理如何利用Zookeeper实现动态配置管理？非常简单。 配置管理器将配置写在一个Znode中，其他进程读这个Znode，同时设置Watch标志位。如果Znode中的配置改变了，那么其他进程将会收到通知，并且会再次读取最新配置。 集合点Rendezvous我理解为进程同步。客户端创建Znode，然后将Zode的full path作为参数传递给master process和worker process。如果master process先创建完成，那么它就将它的信息（addresses and ports）写入到Znode中；如果是worker process先创建完成，它照样读取Znode并设置Watch标志位，后续mater改变Znode后，worker就能读取信息。 组成员管理利用一个Znode 表示组。当组成员创建时，只需创建一个对应的Znode的Child Znode。如果需要唯一的对应，可设置Sequentail标志位。如果需要获取一个Group的信息，只需要简单调用list api查看Znode的所有Child。如果一个进程要监视组信息的变化，为每一个组成员设置Watch标志位即可。 ephemeral node有一个好处是能代表会话的状态，当进程失败或结束时，ephemeral node会自动移除。 分布式锁1234WHILE TRUE: IF CREATE(&quot;f&quot;, data, ephemeral=TRUE): RETURN IF EXIST(&quot;f&quot;, watch=TRUE): WAIT 总的来说，先是通过CREATE创建锁文件，或许可以直接成功。如果失败了，我们需要等待持有锁的客户端释放锁。通过Zookeeper的watch机制，我们会在锁文件删除的时候得到一个watch通知。收到通知之后，我们回到最开始，尝试重新创建锁文件，如果运气足够好，那么这次是能创建成功的。 Herd Effect如果有1000个客户端同时要获得锁文件，为1000个客户端分发锁所需要的时间也是N方。因为每一次锁文件的释放，所有剩下的客户端都会收到WATCH的通知，并且回到循环的开始，再次尝试创建锁文件。 为了获得锁，要通知一大群的线程，也就是惊群，最会只有一个线程能获得锁。 123456CREATE(&quot;f&quot;, data, sequential=TRUE, ephemeral=TRUE)WHILE TRUE: LIST(&quot;f*&quot;) IF NO LOWER #FILE: RETURN IF EXIST(NEXT LOWER #FILE, watch=TRUE): WAIT 代码第4行，如果现存的Sequential文件的序列号都不小于我们在代码第1行得到的序列号，那么表明我们在并发竞争中赢了，我们获得了锁。所以当我们的Sequential文件对应的序列号在所有序列号中最小时，我们获得了锁，直接RETURN。序列号代表了不同客户端创建Sequential文件的顺序。在这种锁方案中，会使用这个顺序来向客户端分发锁。当存在更低序列号的Sequential文件时，我们要做的是等待拥有更低序列号的客户端释放锁。在这个方案中，释放锁的方式是删除文件。所以接下来，我们需要做的是等待序列号更低的锁文件删除，之后我们才能获得锁。 所以，在代码的第5行，我们调用EXIST，并设置WATCH，等待比自己序列号更小的下一个锁文件删除。如果等到了，我们回到循环的最开始。但是这次，我们不会再创建锁文件，代码从LIST开始执行。这是获得锁的过程，释放就是删除创建的锁文件。 学生提问：为什么这种锁不会受羊群效应（Herd Effect）的影响？ Robert教授：假设我们有1000个客户端在等待获取锁，每个客户端都会在代码的第6行等待锁释放。但是每个客户端等待的锁文件都不一样，比如序列号为500的锁只会被序列号为501的客户端等待，而序列号500的客户端只会等待序列号499的锁文件。 每个客户端只会等待一个锁文件，当一个锁文件被释放，只有下一个序列号对应的客户端才会收到通知，也只有这一个客户端会回到循环的开始，也就是代码的第3行，之后这个客户端会获得锁。所以，不管有多少个客户端在等待锁，每一次锁释放再被其他客户端获取的代价是一个常数。而在非扩展锁中，锁释放时，每个等待的客户端都会被通知到，之后，每个等待的客户端都会发送CREATE请求给Zookeeper，所以每一次锁释放再被其他客户端获取的代价与客户端数量成正比。 双重屏障// todo 计数器第一个很简单的例子是计数器，假设我们在Zookeeper中有一个文件，我们想要在那个文件存储一个统计数字，例如，统计客户端的请求次数，当收到了一个来自客户端的请求时，我们需要增加存储的数字。 1234WHILE TRUE: X, V = GETDATA(&quot;F&quot;) IF SETDATA(&quot;f&quot;, X + 1, V): BREAK 这个例子，其实就是大家常说的mini-transaction。这里之所以是事务的，是因为一旦我们操作成功了，我们对计数器达成了_读-更改-写_的原子操作。 之所以称之为mini-transaction，是因为这里并不是一个完整的数据库事务（transaction）。一个真正的数据库可以使用完整的通用的事务，你可以指定事务的开始，然后执行任意的数据读写，之后结束事务。一个真实的事务可能会非常复杂，而Zookeeper支持这种非常简单的事务，使得我们可以对于一份数据实现原子操作。这对于计数器或者其他的一些简单功能足够了。所以，这里的事务并不通用，但是的确也提供了原子性，所以它被称为mini-transaction。 Zookeeper的保证Zookeeper基于Raft框架，是容错的，在发生网络分区的时候，也能有正确的行为。Zookeeper有一些性能增强，使得读请求可以在任何副本被处理，因此，可能会返回旧数据。 为什么Zookeeper在允许多副本读的情况下还能保证正确的行为？ 这得益于ZooKeeper 两个基本的一致性保证：线性写和先进先出(FIFO)的客户端请求。 写请求是线性一致的 All requests that update the state of ZooKeeper are serializable and respect precedence. Leader 保证写操作的顺序，并且该顺序在所有 Follower 上保持一致。 客户端可以并发的发送写请求，然后Zookeeper表现的就像以某种顺序，一次只执行一个写请求，并且也符合写请求的实际时间。所以如果一个写请求在另一个写请求开始前就结束了，那么Zookeeper实际上也会先执行第一个写请求，再执行第二个写请求。 所有更改Zookeeper状态的请求都是线性的，那么这就保证了主从状态一致性。 先进先出的客户端请求 All requests from a given client are executed in the order that they were sent by the client. 每个客户端可以为其操指定一个顺序，ZooKeeper 会按照客户端指定的顺序来执行。即zookeeper为每个单独的客户端提供了线性一致性。 这里的线性一致性只对于单个客户端的请求。比如说，客户端先发了一个写请求，然后再发读请求到落后的副本，那么这个读请求得看到它自己之前的写更新。 所以，如果我发送一个写请求给Leader，在Leader commit这个请求之前需要消耗一些时间，所以我现在给Leader发了一个写请求，而Leader还没有处理完它，或者commit它。之后，我发送了一个读请求给某个副本。这个读请求需要暂缓一下，以确保FIFO客户端请求序列。读请求需要暂缓，直到这个副本发现之前的写请求已经执行了。这是FIFO客户端请求序列的必然结果，（对于某个特定的客户端）读写请求是线性一致的。 ZooKeeper 通过 zxid 来实现，zxid 是最后一个事务的标记，当客户端发出一个请求到一个相同或者不同的副本时，会在请求带上 zxid 标记，副本通过检查客户端的 zxid 和自己的 zxid，保证读到的是更新的 zxid 的数据(没有具体说怎么处理，是阻塞等待还是拒绝请求) 更进一步，如果同一个客户端发送一个写请求&lt;X, 17&gt;，然后立即去某个副本服务器读 X，这里会暂缓一下读请求，直到这个副本发现写请求的 zxid 已经执行了，即客户端将会读到 &lt;X, 17&gt;，不会读到过期的数据。 同步操作 sync尽管有了Zookeeper的两个保证，但这还不是线性一致性。Zookeeper提供了另外一种弥补线性一致的方法：sync。 To handle this scenario more efficiently ZooKeeper provides the sync request: when followed by a read, constitutes a slow read. sync causes a server to apply all pending write requests before processing the read without the overhead of a full write. This primitive is similar in idea to the flush primitive of ISIS。 可以简单认为sync操作等于原子的写+读。这样客户端的读操作一定能看到最新的写入操作。因为FIFO的客户端请求使得它看到了自己的写请求，而写请求又是线性的，于是之前的写请求一定也被看见。 Zookeeper的实现//todo","link":"/2023/11/27/MIT6.824/%E7%AC%94%E8%AE%B06Zookeeper/"},{"title":"MIT6.824笔记七 链式复制","text":"这节课主要介绍了链复制的基本思想。CRAQ将读操作分散到各个节点，提升了读性能。 链复制基本方法![image-20231213135524616](/Users/mac/Library/Application Support/typora-user-images/image-20231213135524616.png) 为了保持线性一致的语义，链复制的基本思想是将服务器组成链表，请求从头部开始，一直链式传递到尾部。 写请求发往头部，读请求发往尾部。不同的是，写请求要经过完整的链传递复制，读请求不需要。 具体而言，当链表头部的服务器收到写请求时，它应用写请求，然后传递给下一个服务器。下一个服务器同样应用写请求，再传递下一个服务器。当尾部服务器应用完写请求时，它才回复客户端写请求已经完成。 读请求则十分简单，直接根据尾部服务器的状态读取。没有完成的写请求要么没有传递到尾服务器，要么就是回复丢失。而链复制一次只处理一个请求。所以读请求能看到最新的写请求状态，自然就是线性一致。 故障恢复链复制的写请求出现故障只有两种情况：要么写请求被所有服务器看到（commited），要么写请求只传递到中间某个服务器。 （1）Head故障 写请求在Head转发前，Head就故障了。那么没有服务器能看到这个写请求，第二个节点成为新的Head。 写请求在Head转发后，Head故障了，那么这个写请求还是会被持续转发下去，所有live服务器都看到这个写请求。 （2）Tail故障 如果TAIL出现故障，处理流程也非常相似，TAIL的前一个节点可以接手成为新的TAIL。所有TAIL知道的信息，TAIL的前一个节点必然都知道，因为TAIL的所有信息都是其前一个节点告知的。 （3）中间节点故障 或许有一些写请求被故障节点接收了，但是还没有被故障节点之后的节点接收，所以，当我们将其从链中移除时，故障节点的前一个节点或许需要重发最近的一些写请求给它的新后继节点。这是恢复中间节点流程的简单版本。 对比Raft（1）性能 对于Raft，如果我们有一个Leader和一些Follower。Leader需要直接将数据发送给所有的Follower 然而在Chain Replication中，HEAD只需要将写请求发送到一个其他节点。 所以Raft Leader的负担会比Chain Replication中HEAD的负担更高。当客户端请求变多时，Raft Leader会到达一个瓶颈，而不能在单位时间内处理更多的请求。 （2）读写分离 另一个与Raft相比的有趣的差别是，Raft中读请求同样也需要在Raft Leader中处理，所以Raft Leader可以看到所有的请求。而在Chain Replication中，每一个节点都可以看到写请求，但是只有TAIL可以看到读请求。所以负载在一定程度上，在HEAD和TAIL之间分担了，而不是集中在单个Leader节点。 （3）故障恢复 Chain Replication故障恢复更加简单。 配置管理器Chain Replication并不能抵御网络分区，也不能抵御脑裂。在实际场景中，这意味它不能单独使用。总是会有一个外部的权威（External Authority）来决定谁是活的，谁挂了，并确保所有参与者都认可由哪些节点组成一条链，这样在链的组成上就不会有分歧。这个外部的权威通常称为Configuration Manager。 Configuration Manager的工作就是监测节点存活性，一旦Configuration Manager认为一个节点挂了，它会生成并送出一个新的配置，在这个新的配置中，描述了链的新的定义，包含了链中所有的节点，HEAD和TAIL。Configuration Manager认为挂了的节点，或许真的挂了也或许没有，但是我们并不关心。因为所有节点都会遵从新的配置内容，所以现在不存在分歧了。 现在只有一个角色（Configuration Manager）在做决定，它不可能否认自己，所以可以解决脑裂的问题。 当然，你是如何使得一个服务是容错的，不否认自己，同时当有网络分区时不会出现脑裂呢？答案是，Configuration Manager通常会基于Raft或者Paxos。在CRAQ的场景下，它会基于Zookeeper。而Zookeeper本身又是基于类似Raft的方案。 所以，你的数据中心内的设置通常是，你有一个基于Raft或者Paxos的Configuration Manager，它是容错的，也不会受脑裂的影响。之后，通过一系列的配置更新通知，Configuration Manager将数据中心内的服务器分成多个链。 CRAQ论文：https://pdos.csail.mit.edu/6.824/papers/craq.pdf // todo","link":"/2023/12/13/MIT6.824/%E7%AC%94%E8%AE%B07CRAQ/"},{"title":"滑动窗口法","text":"滑动窗口是一种解题技巧，一句话说明就是维护一个窗口，不断滑动，更新答案。 滑动窗口适合的一维情况，比如数组、字符串；同时，拓展到二维也不是不可能。 根据问题求解的特性，可分为最小滑动窗口和最大滑动窗口两种解题模版。 滑动窗口大致逻辑12345678910111213int left = 0, right = 0;while (right &lt; x) { // 增大窗口 right++; // 更新窗口内的性质 window.add(s[right]); //当窗口内满足xx条件时，缩小窗口 while (window needs shrink) { window.remove(s[left]); left++; } //更新答案} 通过双指针维护窗口，right指针扩大窗口，left指针缩小窗口。滑动窗口射击两个过程，扩大窗口以及缩小窗口。需要注意一些细节，比如说如何向窗口中添加新元素，如何缩小窗口，在窗口滑动的哪个阶段更新结果。 （1）窗口内状态收集一般通过容器进行，比如map、queue（单调队列）等。 （2）两种模型 如果在扩大阶段收集答案，那么就是最大窗口模型，但注意同时要满足题目特定条件。背后的思想与贪心类似。 如果在窗口缩小阶段收集答案，那么就是最小窗口模型。 那么这两种模型到底有什么区别？滑动窗口法都有窗口扩张和窗口缩小的过程。最大窗口模型，窗口缩小是使条件满足的过程，然后收集答案；最小窗口模型，只有在满足条件时才能进行窗口缩小，窗口缩小的目的是使得条件不满足，在每一次窗口缩小过程中收集答案。 最小滑动窗口1234567891011121314151617181920void slidingWindow(string s, string t) { int left = 0, right = 0; int valid = 0; while (right &lt; s.size()) { //取数据 char c = s[right]; // 将数据加入窗口 // your code here while (窗口满足条件) { //记录结果 // your code here //缩小窗口，使之不满足条件 } //此时窗口不满足条件，继续扩大 right++; }} 可以看出来，最小滑动窗口的条件是在while循环内更新的，因为一旦满足了条件就要马上更新，取最小。 最大滑动窗口1234567891011121314151617181920void slidingWindow(string s, string t) { int left = 0, right = 0; int valid = 0; while (right &lt; s.size()) { //取数据 char c = s[right]; // 将数据加入窗口 // your code here while (窗口不满足条件) { //缩小窗口，使之满足条件 } //记录结果 // your code here //此时窗口满足条件，继续扩大 right++; }} 最大窗口的条件更新是在while外更新的。当我们的窗口满足条件时，我们希望继续扩大窗口，期望得到最大值。一旦窗口内的数据不满足条件了，我们就缩小窗口，调整满足条件。 滑动窗口法实战字符串排列https://leetcode.cn/problems/permutation-in-string/description/ 12345678910111213141516171819class Solution { public boolean checkInclusion(String s1, String s2) { if(s1.length()&gt;s2.length()) return false; // 初始化S1大小的窗口，然后不断向右滑动 int[] winodw = new int[26]; int[] s1_hash = new int[26]; for(int i=0; i&lt;s1.length(); ++i){ s1_hash[s1.charAt(i)-'a'] += 1; winodw[s2.charAt(i)-'a'] += 1; } if(Arrays.equals(s1_hash, winodw)) return true; for(int i=s1.length(); i&lt;s2.length(); ++i){ winodw[s2.charAt(i-s1.length()) -'a']--; winodw[s2.charAt(i)-'a']++; if(Arrays.equals(s1_hash, winodw)) return true; } return false; }} 很简单的思路，用哈希表映射窗口每个字母的个数，然后不断向右滑动。 字符串中的所有字母异位词https://leetcode.cn/problems/find-all-anagrams-in-a-string/ 12345678910111213141516171819class Solution { public List&lt;Integer&gt; findAnagrams(String s, String p) { List&lt;Integer&gt; ans = new ArrayList&lt;&gt;(); if (p.length() &gt; s.length() ) return ans; int[] p_map = new int[26]; int[] win_map = new int[26]; for(int i=0; i&lt;p.length(); ++i){ p_map[p.charAt(i)-'a'] +=1; win_map[s.charAt(i)-'a'] +=1; } if (Arrays.equals(p_map, win_map)) ans.add(0); for(int i=p.length();i&lt;s.length(); ++i){ win_map[s.charAt(i-p.length())-'a']--; win_map[s.charAt(i) -'a']++; if (Arrays.equals(p_map, win_map)) ans.add(i-p.length()+1); } return ans; }} 简单改变上一题的模版，增加一个容器收集答案。 最小窗口实战长度最小子数组https://leetcode.cn/problems/minimum-size-subarray-sum/ 1234567891011121314151617class Solution { public int minSubArrayLen(int target, int[] nums) { int windowCount = 0; int ans = Integer.MAX_VALUE; int l =0, r=0; while(r&lt;nums.length){ windowCount += nums[r]; while(windowCount&gt;=target){ ans = Math.min(ans, r-l+1); windowCount -= nums[l]; l++; } r++; } return ans==Integer.MAX_VALUE?0:ans; }} 最小滑动窗口入门题了，窗口内状态只需要用一个变量保存，然后在缩小窗口的过程中更新答案。 最小覆盖子串https://leetcode.cn/problems/minimum-window-substring/ 12345678910111213141516171819202122232425262728293031323334class Solution { public boolean isCovered(int[] s1, int[] s2){ for(int i=0; i&lt;s1.length; ++i) { if(s1[i]&lt;s2[i]) return false; } return true; } public int[] initMap(String s, int len){ int[] ret = new int[60]; for(int i=0; i&lt;len; ++i){ ret[s.charAt(i)-'A']++; } return ret; } public String minWindow(String s, String t) { if(s.length()&lt;t.length()) return &quot;&quot;; int l=0, r=0, record_l=0, record_r=s.length()+1; int[] tmap = initMap(t, t.length()); int[] window = new int[60]; while(r&lt;s.length()){ window[s.charAt(r)-'A']++; while(isCovered(window, tmap)){ if(record_r-record_l &gt; r-l){ record_l = l; record_r = r; } window[s.charAt(l)-'A']--; l++; } r++; } return record_r==1+s.length()?&quot;&quot;:s.substring(record_l, record_r+1); }} 有模版之后一切不再难。 最大窗口实战无重复字符的最长子串 https://leetcode.cn/problems/longest-substring-without-repeating-characters/ 123456789101112131415161718class Solution { public int lengthOfLongestSubstring(String s) { int i=0,j=0,ans=0; Map&lt;Character, Integer&gt; map = new HashMap&lt;&gt;(); while(j&lt;s.length()){ char ch = s.charAt(j); map.put(ch ,map.getOrDefault(ch ,0)+1); while(map.get(ch)&gt;1){ //不满足条件就缩小窗口 char d_ch = s.charAt(i); map.put(d_ch ,map.getOrDefault(d_ch ,0)-1); i++; } ans = Math.max(ans, j-i+1); //满足条件后更新 j++; } return ans; }} 参考： 作者：labuladong链接：https://leetcode.cn/problems/find-all-anagrams-in-a-string/solutions/9749/hua-dong-chuang-kou-tong-yong-si-xiang-jie-jue-zi-/ 作者：HelloPGJC链接：https://leetcode.cn/problems/fruit-into-baskets/solutions/1437444/shen-du-jie-xi-zhe-dao-ti-he-by-linzeyin-6crr/","link":"/2023/12/21/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%95%B0%E7%BB%84%E4%B8%8E%E5%AD%97%E7%AC%A6%E4%B8%B2/Java%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/"},{"title":"二分法","text":"你能很容易地写出一个work但很难bug-free的二分法。 记住二分法的思想：每次舍弃答案一定不存在的区间，保留答案存在的区间；同时注意二分区间状态转移的一致性。 题单：https://leetcode.cn/studyplan/binary-search/ 有序不重复数组简单二分单调递增数组找目标元素下标，元素不重复，目标元素不在其中则返回-1。 https://leetcode.cn/problems/binary-search/description/ 1234567891011121314class Solution { public int search(int[] nums, int target) { int l=0, r=nums.length -1; while(l &lt;= r){ int mid = (l+r)/2; if(nums[mid] == target) return mid; if(nums[mid] &lt; target) l = mid + 1; else r = mid - 1; } return -1; }} 看起来很简单，修改下题目，得到以下这题: 搜索插入位置单调递增数组找目标元素下标，元素不重复，如果元素不在其中，返回元素应该在插入的下标。 比如数组【1】，元素0返回下标0，元素1返回下标0，元素2返回下标1。 https://leetcode.cn/problems/search-insert-position/ 12345678910111213class Solution { public int searchInsert(int[] nums, int target) { int l=0, r=nums.length-1; while(l&lt;=r){ int mid=l+(r-l)/2; if(nums[mid]&gt;=target) r=mid-1; else l=mid+1; } return l; }} 这题如果沿用上题的左闭右闭区间表示法，就会发现困难重重，其根本原因就在左闭右闭区间无法包括所有答案应在的位置，比如，[1,2,3] 搜索 4 所在位置。仔细揣摩以上代码，虽然写得很精巧，但其中的逻辑转变不是很直观。 我更推荐以下写法： 12345678910111213class Solution { public int searchInsert(int[] nums, int target) { int l = 0, r = nums.length; while(l &lt; r){ int mid = (l+r)/2; if(nums[mid]&gt;=target) r = mid; else l = mid+1; } return l; }} 将每一次缩小区间的过程看成一次状态转移：从一个大区间到一个小区间，其中状态转移的一致性就是指永远保留答案在我的窗口区间内（每次舍弃答案不在的区间）。while(l &lt; r)的背后逻辑：缩小区间，直至l==r，最后检查l或r的状态。 在nums[mid]&gt;=target 时，应该往左边缩小区间，r应该为mid-1吗？不应该，因为这样答案可能不在这个区间，举例子[1,3]或[1,2]数组中搜索2所在位置。 接下来分析第一种写法： 由于第一题采用左闭右闭区间表示法，在l==r时仍然能构成小区间，那么答案是可能在这个区间内的，我们还需要继续在这个区间搜索下去。最后的状态一定是l==r+1即left比right大1，究竟是返回left还是right，具体题目具体分析。这里的逻辑是不同于前述状态机思想的，因为left会大于right，对于[1,2,3]中搜索9的情况，left会跳到3，这也跳脱了保持答案在区间内的想法。 有序重复数组排序数组寻找元素第一个和最后一个位置https://leetcode.cn/problems/find-first-and-last-position-of-element-in-sorted-array 给你一个按照非递减顺序排列的整数数组 nums，和一个目标值 target。请你找出给定目标值在数组中的开始位置和结束位置。 123456789101112131415161718192021222324252627282930313233class Solution { public int lower_bound(int[] nums, int target){ int l = 0, r = nums.length; while(l&lt;r){ int mid = (l+r)/2; if(nums[mid]&gt;=target) r = mid; else l = mid +1; } return l; } public int upper_bound(int[] nums, int target){ int l = 0, r = nums.length; while(l&lt;r){ int mid = (l+r)/2; if(nums[mid]&gt;target) r = mid; else l = mid +1; } return l; } public int[] searchRange(int[] nums, int target) { int[] ans = {-1, -1}; int l = lower_bound(nums, target); if(l==nums.length || nums[l]!=target) return ans; int r = upper_bound(nums, target); ans[0] = l; ans[1] = r-1; return ans; }} Lower_bound 的语义：有序重复数组寻找目标元素第一次出现的位置，如果不存在，返回应该插入的位置。 Upper_bound 的语义：有序重复数组寻找大于目标元素的数字第一次出现的位置，如果不存在，返回应该插入的位置。 换位思考：先求序列中第一个大于x的元素的位置，然后减1就是x最后出现的位置。 或者使用以下思路： 123456789public int[] searchRange(int[] nums, int target) { int[] ans = {-1, -1}; int l = lower_bound(nums, target); if(l==nums.length || nums[l]!=target) return ans; int r = lower_bound(nums, 1+target); ans[0] = l; ans[1] = r-1; return ans;} 注意：以上写法的upper bound对于targer极大不在数组中的情况，是要额外在返回前加一层判断的！ 模版总结通过思考可以发现，lower和upper函数都在解决这样一个问题：在一个有序序列中第一个满足某条件的元素的位置 lower-bound就是，从左到右，找第一个满足值大于等于target的元素位置； upper-bound就是，从左到右，找第一个满足值大于target的元素位置。 那么对于有序数组，我们就能总结出一个模块，从左到右，找第一个满足条件的元素位置： 12345678910int find_requirment(int left, int right){ while(left &lt; right){ int mid = (left+right)/2; if(条件成立) right = mid; else left = mid+1; } return left;} 注意点： left和right的初始值要包括所有答案可能的范围，通过缩小区间的方式，将答案位置一步步夹出来。 中点取法向下取整中点取法向下取整，这是很多人都没关注到的一个细节。这个细节决定了当left与right不相等时，$left \\le mid &lt;right$。 有什么作用？ 当你采用左闭右开的区间表示法时，最右边的索引在原来数组是不存在的，如果你采用向上取整的中点算法，那么你的中点是有机会达到最右边索引（比如搜索极大元素在升序数组中的位置），进而引发index out of range异常。当然，你也可以在每一次应用中点索引时增加判断，不过这将使得代码更加繁琐。 如何写出正确的二分法记住二分法的思想：在应用二分法时，每次缩小区间，其实是排除不符合条件的区间过程。 始终采用区间包含所有答案的写法，不管是左闭右闭还是左闭右开写法，只要能包括所有答案所在范围； 始终采用while(l&lt;r)的循环判断，夹出答案； 如果需要，我们还需要对最后夹出来的位置进行条件校验； 始终采用向下取整的中点算法，保证中点在索引范围内。 开始实践！ 题目搜索二维矩阵https://leetcode.cn/problems/search-a-2d-matrix 1234567891011121314151617class Solution { public boolean searchMatrix(int[][] matrix, int target) { int m = matrix.length, n = matrix[0].length; // 搜索target应该插入的位置 int l = 0, r = m*n; while(l &lt; r){ int mid = (l+r)/2; if(matrix[mid/n][mid%n]&gt;=target) r = mid; else l = mid+1; } // 额外检验 if(l==m*n) return false; return matrix[l/n][l%n]==target?true:false; }} 搜索插入位置一模一样的写法。只不过要注意，当target极大时，它的下标在数组中是不存在的。 keke吃香蕉https://leetcode.cn/problems/koko-eating-bananas/description/ 123456789101112131415161718192021222324252627class Solution { public int solve(int[] piles, int speed){ // 以speed的速度解决这堆香蕉需要多久 int time = 0; for(int banana: piles){ //上取整的实现 time += (banana+speed-1)/speed; } return time; } public int minEatingSpeed(int[] piles, int h) { int l =1, r = -1; for(int pile:piles){ r = Math.max(r, pile); } while(l &lt; r){ int mid = (l+r)/2; int time = solve(piles, mid); if(time&lt;=h){ //速度过快，往小的方面搜索 r = mid; }else{ l = mid+1; } } return r; }} 第一步，确定答案区间范围。最小速度可以为1，但1不保证能在h小时吃完所有香蕉，但最小值赋予1可以使得我得到的区间范围包括答案所在区间。最大速度怎么求？无限大？只要找到一个能在h小时吃完所有香蕉的速度speed就行，这个speed是个上界，但不是上确界。 编程小技巧：上取整的实现 $\\lceil p/s \\rceil = \\lfloor (p+s-1)/s \\rfloor$ 利用带余除法判断，余数是否大于0 1int time = p/s + (p%s&gt;0) ? 1:0; 货物运输https://leetcode.cn/problems/capacity-to-ship-packages-within-d-days/ 123456789101112131415161718192021222324252627282930313233343536373839class Solution { public int transit(int[] weights, int load){ int day = 0; int cur = 0; // 目前载荷 for(int weight:weights){ if(cur+weight &lt;load){ cur += weight; }else if(cur+weight ==load){ ++day; cur = 0; } else{ ++day; cur = weight; } } if(cur&gt;0) ++day; return day; } public int shipWithinDays(int[] weights, int days) { // 最小max(weights)，最大sum（weights） int l =0, r=0; for(int weight:weights){ r += weight; l = Math.max(l , weight); } System.out.println(transit(weights, 5)); while( l &lt; r){ int mid = l + (r-l)/2; int day = transit(weights, mid); if(day &lt;= days){ r = mid; }else{ l = mid+1; } } return r; }} 1、左右边界的确定 左边界是weights的最大，因为船至少能装一个货物。最大就是求和，这样能在一天运完。 2、计算当前负载需要天数的函数 用模拟方式进行，负载装满就出发。 旋转排序数组旋转排序数组中的最小值https://leetcode.cn/problems/find-minimum-in-rotated-sorted-array/description/ 1234567891011121314class Solution { public int findMin(int[] nums) { int l=0, r=nums.length-1; while(l&lt;r &amp;&amp; nums[l]&gt;nums[r]){ int mid = (l+r)&gt;&gt;1; if(nums[mid]&gt;=nums[l]){ // 与left进行比较 l = mid+1; }else{ r = mid; } } return nums[l]; }} （1）旋转排序数组，其实是分成了两个有序段，左半段和右半段，左半段的值肯定是大于右半段的值。但这题的难点在于可能只有一个段，以及应用二分法的过程中，可能从两个段跨越到一个段，导致语义错误。 那么我就应用状态机的思想，维持我left和right的区间始终为两个段的情况（nums[l]&gt;nums[r])，如果跨越到右半段，直接返回右半段的最左边的值。 至于mid究竟是要和left还是right比较，在我维护两个段的状态下，两种方向的比较均可。 123456789101112131415class Solution { public int findMin(int[] nums) { int l=0, r=nums.length-1; while(l&lt;r &amp;&amp; nums[l]&gt;nums[r]){ int mid = (l+r)&gt;&gt;1; // if(nums[mid]&lt;=nums[r]){ // 与right进行比较 if(nums[mid]&lt;nums[r]){ r = mid; }else{ l = mid+1; } } return nums[l]; }} （2）还有一个问题：比较时应该采用大于等于还是大于？？？ 我的回答是：仔细思考等于的语义。在题目的背景下，数组中的元素都是不重复的，如果两个下标指向的元素相等， 那么结果就一定是两个下标相等。在l&lt;r的背景下，$left \\le mid &lt;right$，mid是绝无可能与right相等的。所以nums[mid]&lt;=nums[r]和nums[mid]&lt;nums[r]是等价的。但是mid是有可能与left相等的，这时候两者是不等价的。 （3）下面分析不作两段保证会出现的问题： （3.1）mid和right比较没问题。 如果nums[mid]&gt;nums[right]，那么mid肯定落在左半段。如果nums[mid]&lt;=nums[right]，那么mid是落在右半段。如果落到单独段中，和right比较，只会出现nums[mid]&lt;=nums[right] 1234567891011121314class Solution { public int findMin(int[] nums) { int l=0, r=nums.length-1; while(l&lt;r){ int mid = (l+r)&gt;&gt;1; if(nums[mid] &lt; nums[r]){ r = mid; }else{ l = mid+1; } } return nums[l]; }} （3.2）mid和left比较有风险！ left可能越过最高点，整个区间从两个段变成一个段，再也不能通过nums[mid]&gt;=nums[left]来判断mid是落在左半段还是右半段（因为落到单升序区间后，nums[mid]&gt;nums[left]的条件指示我们往右走的行为已经违背了题目初衷）。 所以 while(l&lt;r &amp;&amp; nums[l]&gt;nums[r]) 这里条件中nums[l]&gt;nums[r] 必不可少的，这是要保持l，r窗口内是失序的状态，一旦打破，就达到了有序状态，直接返回最左边界的值。 那为什么mid和right比较没问题？因为即使left可能越过最高点，整个区间变成有序状态后，不会再出现nums[mid]&gt;nums[right]的情况。 搜索旋转排序数组//todo给你一个target，在旋转排序数组中找它的下标，不存在返回-1。 https://leetcode.cn/problems/search-in-rotated-sorted-array/ 123456789101112131415161718192021222324252627class Solution { public int search(int[] nums, int target) { if(nums==null||nums.length==0) return -1; int l=0, r=nums.length-1; while(l&lt;r){ int mid = (l+r)&gt;&gt;1; if(nums[mid]==target){l=mid; break;} if(nums[mid] &lt; nums[r]){ if(nums[mid]&lt;target &amp;&amp; target&lt;=nums[r]){ l = mid+1; }else{ r = mid; } continue; } if(nums[l] &lt;= nums[mid]){ if(nums[l]&lt;= target &amp;&amp; target &lt; nums[mid]){ r = mid; }else{ l = mid+1; } } } if(nums[l]==target) return l; return -1; }} 三步走：设置初始值、设定while比较、设定if比较。 先判断mid在左半段还是右半段，再判断target在段中的左右，最后夹出一个位置后还得额外作判断。 结论：在判断元素存在性时，尤其是不重复元素，直接使用左闭右闭的区间表示法会简单很多。 搜索旋转排序数组2给你一个target，在旋转排序数组（这个数组可能含有重复元素）中找它的下标，不存在返回-1。 https://leetcode.cn/problems/search-in-rotated-sorted-array-ii/ 1234567891011121314151617181920212223242526272829class Solution { public boolean search(int[] nums, int target) { if(nums==null||nums.length==0) return false; int l=0, r=nums.length-1; while(l&lt;=r){ int mid = (l+r)&gt;&gt;1; if(nums[mid] == target) return true; // 相等的情况,可能l==mid,也可能l!=mid if(nums[l] == nums[mid]) {l++;continue;} if(nums[l] &lt; nums[mid]){ if(nums[l]&lt;= target &amp;&amp; target &lt; nums[mid]){ // 左半段的左边 r = mid-1; }else{ l = mid+1; } }else{ // nums[mid] &lt; nums[r] if(nums[mid]&lt;target &amp;&amp; target&lt;=nums[r]){ // 右半段的右边 l = mid+1; }else{ r = mid-1; } } } return false; }} 这里比上题就多出了一行代码 1if(nums[l] == nums[mid]) {l++;continue;} 其他寻找两个正序数组的中位数https://leetcode.cn/problems/median-of-two-sorted-arrays 1234567891011121314151617181920212223242526272829class Solution { public double findMedianSortedArrays(int[] nums1, int[] nums2) { if(nums1.length &gt; nums2.length) return findMedianSortedArrays(nums2, nums1); int m = nums1.length, n= nums2.length; int half = (m+n)/2; int l =0, r= m; // left 存前一部分的最大值，right存后一部分的最小值 int left =0, right =0; while(l&lt;=r){ int i = (l+r)&gt;&gt;1; int j = half - i; // 从0到i-1有i个元素，0到j-1有j个元素 int nums_i_1 = (i==0)? Integer.MIN_VALUE:nums1[i-1]; int nums_i = (i==m)? Integer.MAX_VALUE:nums1[i]; int nums_j_1 = (j==0)? Integer.MIN_VALUE:nums2[j-1]; int nums_j = (j==n)? Integer.MAX_VALUE:nums2[j]; if(nums_i_1 &lt;= nums_j){ left = Math.max(nums_i_1, nums_j_1); right = Math.min(nums_i, nums_j); l = i+1; } else { r = i-1; } // System.out.println(&quot;i=&quot;+i+&quot; j=&quot;+j+&quot; l=&quot;+l+&quot; r=&quot;+r); } return (m+n)%2==0? (left+right)/2.0 : right; }} 这道题让我十分难受。如果数组长度为偶数，那么中位数是取平均的。 认识0: 在统计中，中位数定义：将一个集合划分为两个长度相等的子集，其中一个子集中的元素总是大于另一个子集中的元素。 认识1：假设数组长度为N，当数组有序时 当N为奇数时，中位数是下标为 $\\lfloor N/2\\rfloor$ 的元素； 当N为偶数时，中位数是下标为 $\\lfloor N/2\\rfloor$ 的元素和 $\\lfloor N/2\\rfloor+1$元素的平均值 。 认识2: 中位数的另一种描述：划分数组，将数组划分为左右两部分，左数组永远小于右数组 当N为奇数时，左边数组个数为 $\\lfloor N/2\\rfloor$ ，右边数组个数为$\\lfloor N/2\\rfloor$+1，中位数是右数组的最小值 当N为偶数时，左边数组个数为 $\\lfloor N/2\\rfloor$ ，右边数组个数为$\\lfloor N/2\\rfloor$，中位数是左数组最大值和右数组最小值的平均 总结在应用二分法，注意左右边界的获取。 根据区间的表示法，选择合适while循环判断条件。 在应用二分法时，每次缩小区间，其实是排除不符合条件的区间过程。 状态转移的一致性就是指永远保留答案在我的窗口区间内（每次舍弃答案不在的区间）。","link":"/2023/12/22/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%95%B0%E7%BB%84%E4%B8%8E%E5%AD%97%E7%AC%A6%E4%B8%B2/JAVA%E4%BA%8C%E5%88%86%E6%B3%95/"},{"title":"Linux命令学习","text":"学习思路： 大类相关：系统资源查看、文件操作 命令基本知识，比如选项参数、输出情况 应用场景：针对特定需求写命令 你应该知道的linux技巧 https://coolshell.cn/articles/8883.html 文件管理查看： ls head、tail less、more、cat 管理 chmod、chown 系统资源管理ps命名 a: 显示终端上的所有进程，包括其他用户的进程。 u: 显示进程的详细用户/拥有者信息。 x: 显示没有控制终端的进程。 p: 显示进程的PID（进程ID） 查询指定名称的进程pid，cpu 占用率和 memory 使用率 1ps aux | grep example 杀死指定pid进程 1kill process_pid 查看cpu使用情况 12topps -ef top命令top命令可以实时地展示系统当前的进程状态，它会不断更新，提供系统进程的动态信息。而ps命令则是系统在过去执行的进程的静态快照，它不能实时更新。 此外，top命令还具有交互性，允许用户输入控制命令，比如在top命令的模式下输入n5，就显示此时的5个最活跃的进程，top会持续运行直到用户按下“q”，退出top。 网络管理查看端口占用1lsof -i:8080 文本操作grep查找，sed编辑，awk对数据分析并生成报告。 grep更适合单纯的查找或匹配文本，sed更适合编辑匹配到的文本，awk更适合格式化文本。 grepGrep能使用正则表达式搜索文本，并把匹配的行打印出来，全称是 Global Regular Expression Print，全局正则表达式打印。grep通过返回一个状态值来说明搜索的状态，如果模板搜索成功，则返回0，如果搜索不成功，则返回1，如果搜索的文件不存在，则返回2。 命令的基本格式： 1grep [option] pattern file 常见参数： -i：忽略大小写进行匹配。 -v：反向查找，只打印不匹配的行。 -n：显示匹配行的行号。 -r：递归查找子目录中的文件。 -l：只打印匹配的文件名。 实际例子： 1、系统报警显示了时间，但是日志文件太大无法直接 cat 查看。(查询含有特定文本的文件，并拿到这些文本所在的行) 1grep -n '2019-10-24 00:01:11' *.log 2、在文件夹 dir 中递归查找所有文件中匹配正则表达式 “pattern” 的行，并打印匹配行所在的文件名和行号： 1grep -r -n pattern dir/ awkAWK是文本处理命令( pattern-directed scanning and processing language)，名称取自三位创始人首字符。awk的大致逻辑是逐行读入文件，以空格为默认分隔符将每行切片，再对切开的部分再进行各种分析处理。 基本用法： 1awk '[pattern] {action}' {filenames} # 行匹配语句 awk '' 只能用单引号 pattern 是要匹配的模式，通常是基于正则表达式； action 是当模式匹配时要执行的动作； filename 是您要处理的文件名。 过滤(1) 例子 提取第1列与第4列 1$ awk '{print $1, $4}' netstat.txt 亦可格式化输出，格式化语义与C语言的printf语义一致 1$ awk '{printf &quot;%-8s %-8s %-8s %-18s %-22s %-15s\\n&quot;,$1,$2,$3,$4,$5,$6}' netstat.tx 提取第3列为0且第6列为LISTEN的行的第1列信息 1$ awk '$3==0 &amp;&amp; $6==&quot;LISTEN&quot;{print $1} ' netstat.txt 取出文件中的第一万至两万行 1awk 'NR&gt;=10000 &amp;&amp; NR&lt;=20000' &lt;filename&gt; （2）基本知识 比较运算符：!=, &gt;, &lt;, &gt;=, &lt;=, == 内建变量 名称 作用 $0 当前记录（这个变量中存放着整个行的内容） $1~$n 当前记录的第n个字段，字段间由FS分隔 FS 输入字段分隔符 默认是空格或Tab NF 当前记录中的字段个数，就是有多少列 NR 已经读出的记录数，就是行号，从1开始，如果有多个文件话，这个值也是不断累加中。 FNR 当前记录数，与NR不同的是，这个值会是各个文件自己的行号 RS 输入的记录分隔符， 默认为换行符 OFS 输出字段分隔符， 默认也是空格 ORS 输出的记录分隔符，默认为换行符 FILENAME 当前输入文件的名字 123456789- FS(Field Separator)：输入字段分隔符， 默认为空白字符- OFS(Out of Field Separator)：输出字段分隔符， 默认为空白字符- RS(Record Separator)：输入记录分隔符(输入换行符)， 指定输入时的换行符- ORS(Output Record Separate)：输出记录分隔符（输出换行符），输出时用指定符号代替换行符- NF(Number for Field)：当前行的字段的个数(即当前行被分割成了几列)- NR(Number of Record)：行号，当前处理的文本行的行号。- FNR：各文件分别计数的行号- ARGC：命令行参数的个数- ARGV：数组，保存的是命令行所给定的各参数 使用：打印首行 1$ awk '$3==0 &amp;&amp; $6==&quot;ESTABLISHED&quot; || NR==1 {printf &quot;%s %s\\n&quot;,NR,$4}' netstat.txt 指定分割符，利用短选项-F 1$ awk -F: '{print $1,$3,$6}' /etc/passwd 统计脚本awk其实是一门脚本语言，有自己的语法结构，变量定义、条件循环等流程控制。 参考：https://www.bookstack.cn/books/junmajinlong-awk （1）BEGIN 与 END BEGIN：当awk开始处理任何输入行之前，BEGIN模式下的代码块会执行一次。 END：当awk处理完所有输入行后，END模式被触发。 BEGIN 和 END都放在要执行的代码块之前。 （2）自定义变量与流程控制 自定义变量，统计文件中含有字符串 abc 的总行数 1awk '/abc/ {count++} END {print count}' filename.txt 自定义变量，统计目录下所有的C文件，CPP文件和H文件的文件大小总和。 1$ ls -l *.cpp *.c *.h | awk '{sum+=$5} END {print sum}' 自定义数组，统计各个connection状态的个数 1awk 'NR!=1 {a[$6]++;} END { for (i in a) print i &quot;, &quot; a[i]; }' netstat.txt 自定义数组，统计每个用户的进程的占了多少内存 1ps aux | awk 'NR!=1{a[$1]+=$6;} END { for(i in a) print i &quot;, &quot; a[i]&quot;KB&quot;;}' 自定义数组，统计一个文件(IP TIME) 的每个IP出现次数，并按次数排序 1awk '{ip[$1]++} END {for (i in ip) print ip[i], i}' access.log | sort -k2 sed命令sed全称（stream editor）流式编辑器，主要逻辑也是逐行匹配，编辑。玩sed主要还得熟练正则表达式。 sed最主要的场景就是匹配并替换。 // todo","link":"/2023/12/22/Linux%E5%91%BD%E4%BB%A4/"},{"title":"MIT6.S081 xv6book chapter1","text":"第一章从操作系统接口方面认识操作系统，以摘要的形式介绍几个关键点，详情请看xv6book。 我的学习经验是：这一章的主要目的就是从整体上把握操作系统，认识几个系统调用。如果你没看懂这一章的一些细节，这是ok的，因为这些细节会逐渐在后面的章节披露，这一章只需要理解系统调用（操作系统为你提供的服务）。 前言操作系统的工作是 (1)将计算机的资源在多个程序间共享，并且给程序提供一系列比硬件本身更有用的服务。 (2)管理并抽象底层硬件，举例来说，一个文字处理软件（比如 word）不用去关心自己使用的是何种硬盘。 (3)多路复用硬件，使得多个程序可以(至少看起来是)同时运行的。 (4)最后，给程序间提供一种受控的交互方式，使得程序之间可以共享数据、共同工作。 操作系统通过接口向用户程序提供服务。一方面我们希望接口设计得简单和精准，使其易于正确地实现；另一方面，我们可能忍不住想为应用提供一些更加复杂的功能。答案是接口的组合，通过这些机制的组合提供强大、通用的功能。 然后就是认识shell、进程，内存，文件描述符，管道和文件系统。 shellThe shell is an ordinary program that reads commands from the user and executes them. The fact that the shell is a user program, and not part of the kernel, illustrates the power of the system call interface: there is nothing special about the shell. It also means that the shell is easy to replace; as a result, modern Unix systems have a variety of shells to choose from, each with its own user interface and scripting features. code design： The xv6 shell uses the above calls to run programs on behalf of users. The main structure of the shell is simple; see main (user/sh.c:145). The main loop reads a line of input from the user with getcmd. Then it calls fork, which creates a copy of the shell process. The parent calls wait, while the child runs the command. For example, if the user had typed “echo hello” to the shell, runcmd would have been called with “echo hello” as the argument. runcmd (user/sh.c:58) runs the actual command. For “echo hello”, it would call exec (user/sh.c:78). If exec succeeds then the child will execute instructions from echo instead of runcmd. At some point echo will call exit, which will cause the parent to return from wait in main (user/sh.c:145). 在shell中，经常使用fork+exec的方式执行用户程序。你可能会觉得这很浪费，毕竟fork拷贝了一份进程资源，为什么不把这两个系统调用合并在一起？ fork的好处是能够简单的实现IO重定向。 同时，为了避免拷贝进程然后马上替换它的浪费，fork采用了copy-on-write技术来优化拷贝过程。 进程和内存An xv6 process consists of user-space memory (instructions, data, and stack) and per-process state private to the kernel. Xv6 time-shares processes: it transparently switches the available CPUs among the set of processes waiting to execute. When a process is not executing, xv6 saves its CPU registers, restoring them when it next runs the process. The kernel associates a process identifier, or PID, with each process. Some system call： fork exit wait exec I/O 和文件描述符文件描述符是一个整数，它代表了一个进程可以读写的被内核管理的对象 每个进程都有一张表，而 xv6 内核就以文件描述符作为这张表的索引，所以每个进程都有一个从0开始的文件描述符空间。 按照惯例，进程从文件描述符0读入（标准输入），从文件描述符1输出（标准输出），从文件描述符2输出错误（标准错误输出）。 shell 保证在任何时候都有3个打开的文件描述符，他们是控制台（console）的默认文件描述符。 Some system call： read write close open dup user program： cat 重要概念：IO重定向，这是shell的一个思想。 File descriptors are a powerful abstraction, because they hide the details of what they are con- nected to: a process writing to file descriptor 1 may be writing to a file, to a device like the console, or to a pipe. 管道A pipe is a small kernel buffer exposed to processes as a pair of file descriptors, one for reading and one for writing 管道是一个小的内核缓冲区，它以文件描述符对的形式提供给进程，一个用于写操作，一个用于读操作。从管道的一端写的数据可以从管道的另一端读取，管道提供了一种进程间交互的方式。 user program： wc Pipes may seem no more powerful than temporary files: the pipeline 1echo hello world | wc could be implemented without pipes as 1echo hello world &gt;/tmp/xyz; wc &lt;/tmp/xyz Pipes have at least four advantages over temporary files in this situation. First, pipes automatically clean themselves up; with the file redirection, a shell would have to be careful to remove /tmp/xyz when done. Second, pipes can pass arbitrarily long streams of data, while file redirection requires enough free space on disk to store all the data. Third, pipes allow for parallel execution of pipeline stages, while the file approach requires the first program to finish before the second starts. Fourth, if you are implementing inter-process communication, pipes’ blocking reads and writes are more efficient than the non-blocking semantics of files. 文件系统文件是一个简单的字节数组，目录包含指向文件和其他目录的引用。目录是一棵树，它的根节点是一个特殊的目录 root 概念：inode、links system call： mknod fstat link unlink user program： mkdir ln rm cd 总结UNIX 将“标准”的文件描述符，管道，和便于操作它们的 shell 命令整合在一起，这是编写通用、可重用程序的重大进步，这个想法激发了 UNIX 强大和流行的“软件工具”文化，而且 shell 也是首个所谓的“脚本语言”。 UNIX 的系统调用接口在今天仍然存在于许多操作系统中，诸如 BSD，Linux，以及 Mac OS X。","link":"/2024/01/07/MIT6.S081/book/chapter1/"},{"title":"MIT6.S081 xv6book chapter2","text":"第二章以操作系统三个要求：复用、隔离和交互展开讲述了内核设计、进程设计，还描述了xv6的启动流程。 看完这一章还是很笼统抽象，一些细节还是需要等到后续披露，但这时候你大致把握到操作系统的整体设计了。 隔离的设计——用户态与内核态；复用的设计——用户进程；交互设计——进程通信。 物理资源的抽象 禁止应用程序直接访问敏感的硬件资源，而是将资源抽象为服务。 比如 open, read, write, and close系统调用，文件系统的抽象让应用程序只需提供path name就能访问资源的便利，而底层硬盘的读写全都有操作系统进行。 Unix 透明地在进程之间切换硬件 CPU，根据需要保存和恢复寄存器状态，因此应用程序不必担心共享。 用户态与内核态强隔离型要求应用程序和操作系统有一个硬边界，我们不希望一个失败的应用程序影响其他应用程序，甚至是操作系统。 那么，CPU在硬件级别上提供了强隔离型的支持：三种模态 machine mode 通常是用于系统启动，配置； supervisor mode 用于执行特权命令，内核运行在kernel space； user mode 应用程序运行在user space。 如果一个应用程序想要调用一个内核函数（比如说系统调用），那么必须切换模式到内核态（比如riscv 提供的ecall指令），有内核执行系统调用。 用户态与内核态就是一个隔离，用户进程不能直接执行特权指令，这也就避免了危险发生。 内核设计A key design question is what part of the operating system should run in supervisor mode. 操作系统的哪一部分应该常驻在内核中呢？根据设计的不同，内核设计也分为 monolithic kernel和micro kernel。 一体化内核中，操作系统全部运行在内核中，因此只要出现一个错误，操作系统整个完蛋。而微内核设计只将必要的代码运行在内核中。 微内核设计与一体化内核的不同：微内核充当消息转发者，比如shell想要读写某个文件，微内核将这个消息发送给file server。 在微内核中，内核接口由一些低级函数组成，用于启动应用程序、发送消息、访问设备硬件等。这种组织方式使内核相对简单，因为大多数操作系统都驻留在用户级服务器中。 不管微内核还是一体化内核，重要的是它们都实现一些key ideas： They implement system calls, they use page tables, they handle interrupts, they support processes, they use locks for concurrency control, they implement a file system, etc. 这些key idea是值得我们去学习借鉴的。 进程总览进程是实现隔离性的一个单元。进程抽象可防止一个进程破坏或监视另一个进程的内存、CPU、文件描述符等。它还可以防止进程破坏内核本身，因此进程无法破坏内核的隔离机制。 为了实现隔离性，进程为用户程序提供了一个幻觉，在程序看来，它好像掌握了整台机器。用户程序独占了机器一整片的地址空间，其他用户程序无法读写。用户程序还觉得自己独占了CPU来执行自己的指令。 地址空间地址空间的幻觉由页表实现（第三章将详细讲述）。简单来说，进程看到的是虚拟地址空间，通过页表映射到真实的物理空间。xv6 为每个进程维护了不同的页表，这样就能够合理地定义进程的地址空间了。 进程的地址空间从零开始，一直到最大虚拟地址。 地址空间的布局：Instructions come first, followed by global variables, then the stack, and finally a “heap” area (for malloc) that the process can expand as needed. At the top of the address space xv6 reserves a page for a trampoline and a page mapping the process’s trapframe. Xv6 uses these two pages to transition into the kernel and back; the trampoline page contains the code to transition in and out of the kernel and mapping the trapframe is necessary to save/restore the state of the user process xv6 使用结构体 struct proc 来维护一个进程的状态，其中最为重要的状态是进程的页表，内核栈，当前运行状态。 线程每个进程都有一个执行线程（或简称线程），用于执行进程的指令。线程可以挂起，以后再恢复。 为了在进程之间透明地切换，内核会挂起当前正在运行的线程并恢复另一个进程的线程。 线程的大部分状态（局部变量、函数调用返回地址）都存储在线程的堆栈中。 xv6大概是一个进程只有一个线程，因此两者的区别不大。 两个栈Each process has two stacks: a user stack and a kernel stack (p-&gt;kstack). When the process is executing user instructions, only its user stack is in use, and its kernel stack is empty. When the process enters the kernel (for a system call or interrupt), the kernel code executes on the process’s kernel stack; while a process is in the kernel, its user stack still contains saved data, but isn’t ac- tively used. 总结In summary, a process bundles two design ideas: an address space to give a process the illusion of its own memory, and, a thread, to give the process the illusion of its own CPU. In xv6, a process consists of one address space and one thread. In real operating systems a process may have more than one thread to take advantage of multiple CPUs. 总之，进程捆绑了两个设计思想：一个是地址空间，用于为进程提供其自身内存的错觉，另一个是线程，用于为进程提供其自身 CPU 的错觉。 在 xv6 中，进程由一个地址空间和一个线程组成。在实际操作系统中，一个进程可能具有多个线程来利用多个 CPU。 编译运行kernel首先，Makefile（XV6目录下的文件）会读取一个C文件，例如proc.c；之后调用gcc编译器，生成一个文件叫做proc.s，这是RISC-V 汇编语言文件；之后再走到汇编解释器，生成proc.o，这是汇编语言的二进制格式。 Makefile会为所有内核文件做相同的操作，比如说pipe.c，会按照同样的套路，先经过gcc编译成pipe.s，再通过汇编解释器生成pipe.o。 之后，系统加载器（Loader）会收集所有的.o文件，将它们链接在一起，并生成内核文件。这里生成的内核文件就是我们将会在QEMU中运行的文件。 我们来看传给QEMU的几个参数： -kernel：这里传递的是内核文件（kernel目录下的kernel文件），这是将在QEMU中运行的程序文件； -m：这里传递的是RISC-V虚拟机将会使用的内存数量； -smp：这里传递的是虚拟机可以使用的CPU核数； -drive：传递的是虚拟机使用的磁盘驱动，这里传入的是fs.img文件。 xv6，启动！To make xv6 more concrete, we’ll outline how the kernel starts and runs the first process. 不必拘泥于细节，掌握启动流程。","link":"/2024/01/07/MIT6.S081/book/chapter2/"},{"title":"MIT6.S081 lab1 utilities","text":"实验一主要是熟悉系统调用以及有限的C标准库使用，实现一些经典的命令。 推荐采用docker+目录映射方式搭建环境 pingpong用一个管道就能完成父子进程通信，子进程fork也会复制打开的文件描述符，我看网上好多实现都是双管道。 123456789101112131415161718192021222324252627282930#include &quot;kernel/types.h&quot;#include &quot;kernel/stat.h&quot;#include &quot;user/user.h&quot;int main(int argc, char *argv[]){ int p[2]; char buf[128]; // buffer for parent &amp;&amp; child process if(pipe(p)&lt;0){ fprintf(2, &quot;Please enter a number!\\n&quot;); } if(fork()==0){ // child process read(p[0], buf, 1); // read one byte from read end of pipe printf(&quot;%d: received ping\\n&quot;, getpid()); char send = 'a'; write(p[1], &amp;send, 1); close(p[0]); close(p[1]); exit(0); } write(p[1], &quot;x&quot;, 1); // send one byte to write end of pipe wait(0); read(p[0], buf, 1); printf(&quot;%d: received pong\\n&quot;, getpid()); close(p[1]); close(p[0]); exit(0);} 素数筛这个筛法挺有意思的，流式的工作思想，每个worker节点只输出一个素数。在这个实验中，需要额外注意文件描述符的关闭，否则就会因为系统资源不够而无法新开管道。 123456p = get a number from left neighborprint ploop: n = get a number from left neighbor if (p does not divide n) send n to right neighbor 123456789101112131415161718192021222324252627282930313233343536373839404142#include &quot;kernel/types.h&quot;#include &quot;kernel/stat.h&quot;#include &quot;user/user.h&quot;void worker(int* p){ close(p[1]); // 关闭写端 int first_num; if(read(p[0], &amp;first_num, sizeof(int))==0){ //如果读不到上一个输入，退出 close(p[0]); exit(0); } printf(&quot;prime %d\\n&quot;, first_num); int next_p[2]; if(pipe(next_p)&lt;0) {fprintf(2, &quot;create pipe error!\\n&quot;); exit(-1);} if(fork()==0) worker(next_p); // 创建子进程,如果worker没有exit，需要显式exit close(next_p[0]); int next_num; while(read(p[0], &amp;next_num, sizeof(int)) != 0){ if(next_num % first_num == 0) continue; write(next_p[1], &amp;next_num, sizeof(int)); // 否则传递给下一个进程 } close(p[0]); //关闭读端 close(next_p[1]); wait(0); exit(0);}int main(int argc, char *argv[]){ int p[2]; int i; if(pipe(p)&lt;0) fprintf(2, &quot;create pipe error!\\n&quot;); if(fork()==0){ worker(p); } for(i=2; i&lt;=35; ++i){ if(write(p[1], &amp;i, 4)!=4) fprintf(2, &quot;write pipe error!\\n&quot;); } close(p[0]); close(p[1]); wait(0); exit(0);} find对一个目录进行搜索，如果是目录还需要递归找下去。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374#include &quot;kernel/types.h&quot;#include &quot;kernel/stat.h&quot;#include &quot;user/user.h&quot;#include &quot;kernel/fs.h&quot;char* fmtname(char * path){ static char buf[DIRSIZ+1]; char *p; for (p = path + strlen(path); p &gt;= path &amp;&amp; *p != '/'; p--); p ++; if (strlen(p) &gt;= DIRSIZ) return p; memmove(buf, p, strlen(p)); buf[strlen(p)] = 0; return buf;}void find(char *root_path, char *file_name){ int fd; char buf[512], *p; struct dirent de; struct stat st; if((fd = open(root_path, 0)) &lt; 0){ fprintf(2, &quot;ls: cannot open %s\\n&quot;, root_path); return; } if(fstat(fd, &amp;st) &lt; 0){ fprintf(2, &quot;ls: cannot stat %s\\n&quot;, root_path); close(fd); return; } // ----file if(st.type==T_FILE) { if(strcmp(file_name, fmtname(root_path))==0) printf(&quot;%s\\n&quot;, root_path); close(fd); return; } // ----directory if(strlen(root_path) + 1 + DIRSIZ + 1 &gt; sizeof buf){ // kernel/fs.h #define DIRSIZ 14 printf(&quot;ls: path too long\\n&quot;); } strcpy(buf, root_path); p = buf+strlen(buf); *p++ = '/'; //此时p已经指向/的后一个 while(read(fd, &amp;de, sizeof(de)) == sizeof(de)){ if(de.inum == 0 || !strcmp(de.name, &quot;.&quot;) || !strcmp(de.name, &quot;..&quot;)) // 去除空目录以及. .. continue; memmove(p, de.name, DIRSIZ); //从p开始14位复制文件名 p[DIRSIZ] = 0; //作结尾 if(stat(buf, &amp;st) &lt; 0){ printf(&quot;ls: cannot stat %s\\n&quot;, buf); continue; }// printf(&quot;read buf:%s\\n&quot;, buf); if(st.type==T_FILE) { if(strcmp(file_name, de.name)==0) printf(&quot;%s\\n&quot;, buf); }else if (st.type == T_DIR){ find(buf, file_name); } } close(fd); return;}intmain(int argc, char *argv[]){ if(argc &lt; 2){ fprintf(2, &quot;argc &lt; 2!&quot;); exit(0); } find(argv[1], argv[2]); exit(0);} xargs有趣的一个命令，能够将标准输入读到数据当作额外的命令参数。 1//todo 需要注意的是：如果不按照手册上一个字符一个字符从标注输入中读取，那么就有可能出现读不到完整行的情况。 总结难点实验一的难点在于熟悉系统调用以及C系统库。熟悉系统调用其实就是熟悉进程、管道、文件描述符这些核心概念。 12345678910int fork(void);int exit(int) __attribute__((noreturn));int wait(int*);int pipe(int*);int write(int, const void*, int);int read(int, void*, int);int close(int);int exec(char*, char**);int open(const char*, int);int sleep(int); 系统调用的实现可能会有点困难，此时只需要理解如何使用，下一章会详细其实现。 123456789101112131415int atoi(const char*);uint strlen(const char*);char* strcpy(char*, const char*);char* strchr(const char*, char c);int strcmp(const char*, const char*);char* gets(char*, int max);void printf(const char*, ...);void fprintf(int, const char*, ...);void* memset(void*, int, uint);void* memmove(void*, const void*, int);void* memcpy(void *, const void *, uint);int memcmp(const void *, const void *, uint); C标准库的实现有必要好好读一读。 关于C阻碍可读性的一个很大关键问题就是C的指针以及类型不安全特性。 类型不安全一个经典的场景在于if的判断条件，可以把整数转换为布尔值，只有0是失败，其他都是成功。 指针我觉得是阻碍可读性的罪魁祸首，它的灵活性实在是太大了！ 1234*p++char* arr[] // 指针的数组void (*fun)(void) // 函数指针void (*fun[])(void) // 函数指针的数组 *和++一起用就很有迷惑性，到底是哪个先作用？答案是++。 1*p++ = *(p++)","link":"/2023/12/29/MIT6.S081/lab/lab1/"},{"title":"MIT6.S081 lab2 system calls","text":"lab2是实现几个系统调用，但此时阅读的资料其实有限，我觉得还是读到手册的第四章会比较好。 System call tracing这个命令是追踪系统调用的过程。 怎么追踪呢？其实这里就要求熟悉xv6发起一个系统调用的过程，仅仅阅读第二章还不能清楚地明白从用户态发起系统调用到内核态的整个过程，但就完成实验来说，靠一些猜测已经足够。 123456789print &quot;#include \\&quot;kernel/syscall.h\\&quot;\\n&quot;;sub entry { my $name = shift; print &quot;.global $name\\n&quot;; print &quot;${name}:\\n&quot;; print &quot; li a7, SYS_${name}\\n&quot;; print &quot; ecall\\n&quot;; print &quot; ret\\n&quot;;} 通过这段代码我们能够知道是：系统调用的号码预先定义在 kernel/syscall.h中，a7寄存器存储了系统调用的号码，通过ecall进入到内核态。 1234567891011121314151617181920static uint64 (*syscalls[])(void) = {[SYS_fork] sys_fork,[SYS_exit] sys_exit, ...}voidsyscall(void){ int num; struct proc *p = myproc(); num = p-&gt;trapframe-&gt;a7; if(num &gt; 0 &amp;&amp; num &lt; NELEM(syscalls) &amp;&amp; syscalls[num]) { p-&gt;trapframe-&gt;a0 = syscalls[num](); } else { printf(&quot;%d %s: unknown sys call %d\\n&quot;, p-&gt;pid, p-&gt;name, num); p-&gt;trapframe-&gt;a0 = -1; }} 然后经过一些中断调用，我们来到了syscall.c，这里可以得知：通过这个号码查表得知是哪个系统调用，并将返回值存储在 p-&gt;trapframe-&gt;a0。 System call implementations in the kernel need to find the arguments passed by user code. Because user code calls system call wrapper functions, the arguments are initially where the RISC-V C calling convention places them: in registers. 系统调用的参数存储在a0～a6寄存器上。 到这里，我们就能完成实验了。思路：从寄存器中取出用户态出入的掩码参数，然后保存位掩码到当前进程，以后每一个系统调用返回时，都要比较一次掩码来决定是否打印信息。 那为什么执行一个trae设置掩码后，再执行新的系统调用命令后就不会打印信息了呢，掩码又没被清零。是的，确实没有做掩码清零的操作。但shell执行进程的方式是fork+exec，这意味着每执行一个新的命令都会新开一个进程，命令结束后，这个进程也结束了。 Sysinfo这个实验说实话是有点坑的，因为此时你还不熟悉虚拟内存、进程调度。最大的作用我想就是熟悉copyout函数，从内核拷贝内容到用户。 （1）在/kernel/proc.c文件中 一开始就定义了一个数组 1struct proc proc[NPROC]; 这个数组就保存着所有的进程，所以只要遍历这个数组判断状态就好了， （2）在/kernel/kalloc.c文件中 定义了一个链表，每个链表都指向上一个可用空间，这个kmem就是一个保存最后链表的变量。 1234567struct run { struct run *next;};struct { struct spinlock lock; struct run *freelist;} kmem; 遇到的错误panic: acquire 原因： 1printf(&quot;%s: syscall %s -&gt; %d&quot;, p-&gt;pid, syscall_names[num], p-&gt;trapframe-&gt;a0); 在打印进程pid时，格式占位符写成了%s，使得输出以上错误。 详细原因之后再排查。","link":"/2024/01/05/MIT6.S081/lab/lab2/"},{"title":"MIT6.S081 lab3 page tables","text":"lab3主要是帮助复习页表、PTE、物理页之间的关系。 Speed up system callsWhen each process is created, map one read-only page at USYSCALL (a VA defined in memlayout.h). At the start of this page, store a struct usyscall (also defined in memlayout.h), and initialize it to store the PID of the current process. 实验指导已经很直白了，在进程创建时映射一块共享页，用来存储进程id。 Print a page table实际上就是熟悉三级页表的过程。 123456789101112131415161718192021222324252627void recursive_vmprint(pagetable_t pagetable, int level){ if(level&gt;=3) return; char* prefix = &quot;x&quot;; switch (level) { case 0: prefix = &quot;..&quot;; break; case 1: prefix = &quot;.. ..&quot;; break; case 2: prefix = &quot;.. .. ..&quot;; } for(int i=0; i&lt;512; ++i){ pte_t pte =pagetable[i]; if(pte &amp; PTE_V){ uint64 child = PTE2PA(pte); printf(&quot;%s%d: pte %p pa %p\\n&quot;, prefix, i, pte, child); recursive_vmprint((pagetable_t) child, level+1); } }}void vmprint(pagetable_t pagetable){ // 深度优先遍历，打印页表 printf(&quot;page table %p\\n&quot;, pagetable); recursive_vmprint(pagetable, 0);} 从PTE到PA的过程 uint64 child = PTE2PA(pte);，然后将它用作页表入口地址(pagetable_t) child 12typedef uint64 pte_t;typedef uint64* pagetable_t; xv6中的指针就是64位无符号整数。 Detecting which pages have been accessed 阅读手册可以知道PTE的第6位是访问标志位，通过观察这个标志就可以知道这个页面是否被访问。 硬件在执行访存指令后就会自动把相应页的PTE_A置为1. 注意：Be sure to clear PTE_A after checking if it is set. Otherwise, it won’t be possible to determine if the page was accessed since the last time pgaccess() was called (i.e., the bit will be set forever). 1234567891011121314151617181920212223int pgaccess(pagetable_t pagetable, uint64 addr, int n, uint64 uaddr) { if (n &gt; 64) { panic(&quot;too much page to check\\n&quot;); return -1; } uint64 bitmask = 0; int cur_bitmask = 1; uint64 va = addr; pte_t *pte;//由于修改bit位，必须采用指针方式 for (int i = 0; i &lt; n; ++i) { if ((pte = walk(pagetable, va, 0)) == 0) { panic(&quot;pte should exits\\n&quot;); return -1; } if (*pte &amp; PTE_A) { bitmask |= (cur_bitmask &lt;&lt; i); *pte &amp;= ~PTE_A; } va += PGSIZE; } copyout(pagetable, uaddr, (char *) &amp;bitmask, sizeof(bitmask)); return 0;}","link":"/2024/01/06/MIT6.S081/lab/lab3/"},{"title":"MIT6.S081 调试xv6","text":"之前学了一些gdb的使用，但是总不能实际上手操作，不如终端IDE可视化调试。这次由于Docker配置环境，不想再折腾连接IDE调试，于是学习GDB。 开始在课程的lab guidance上有这么一段话： In many cases, print statements will be sufficient, but sometimes being able to single step through some assembly code or inspecting the variables on the stack is helpful. To use gdb with xv6, run make make qemu-gdb in one window, run gdb (or riscv64-linux-gnu-gdb) in another window, set a break point, followed by followed by ‘c’ (continue), and xv6 will run until it hits the breakpoint. (See Using the GNU Debugger for helpful GDB tips.) 大意是，在一个终端上执行 make qemu-gdb ，在另一个终端上执行 gdb。 出现的问题当我在第二个终端执行gdb时出现以下提示： 1234567891011warning: File &quot;/home/xv6-labs-2021/.gdbinit&quot; auto-loading has been declined by your `auto-load safe-path' set to &quot;$debugdir:$datadir/auto-load&quot;.To enable execution of this file add add-auto-load-safe-path /home/xv6-labs-2021/.gdbinitline to your configuration file &quot;/root/.gdbinit&quot;.To completely disable this security protection add set auto-load safe-path /line to your configuration file &quot;/root/.gdbinit&quot;.--Type &lt;RET&gt; for more, q to quit, c to continue without paging--For more information about this security protection see the&quot;Auto-loading safe path&quot; section in the GDB manual. E.g., run from the shell: info &quot;(gdb)Auto-loading safe path&quot; 直接按照提示，add-auto-load-safe-path /home/xv6-labs-2021/.gdbinit 关于gdbinit文件查看 gdbinit文件内容，猜测 1// 另开一个Terminal窗口，切到xv6-labs-2020目录下，切到util分支，执行 1riscv64-unknown-elf-gdb kernel/kernel 然后在(gdb)环境下执行 1(gdb) target remote localhost:26000 不过可以按如下操作简化：在~目录下新建.gdbinit文件，内容为： 1add-auto-load-safe-path ~/xv6-labs-2020/.gdbinit 其中~改为自己的xv6-labs-2020目录所在路径 调试在一个终端上执行 make qemu-gdb ，在另一个终端上执行 gdb。 https://zhuanlan.zhihu.com/p/466423677 直接使用gdb命令会提示体系结构不支持，因此改用其他命令。 如果想调试特定的文件例如xargs.c，则在一开始启动gdb后执行: 1(gdb) file user/_xargs 加载特定的符号文件，然后就可以打断点了 1(gdb) b main 然后调试 1(gdb) c 如果不加载符号文件，打断点时就会找不到函数位置。","link":"/2024/01/03/MIT6.S081/lab/%E8%B0%83%E8%AF%95xv6/"},{"title":"MIT6.S081 xv6book chapter3","text":"第三章的主题是页表，单看页表会很抽象，但页表背后的思想是地址空间的隔离。让每个进程都有自己的地址空间，保护地址空间不受他人侵犯。同时，页表管理的“页”，页内地址连续，以页为单位，避免页表过于庞大（多级页表也是为了实现这个目标）。同时，虚拟空间到物理空间的映射，多了几分实用trick，比如内核采用直接映射、内核页表下的guard page（未映射）、内核和用户相同的映射（trampoline page，多对一映射）。 本节融合了课程lec04的内容。虚拟地址的抽象是为了程序的隔离性，理解这点后就很容易了。 地址空间先回顾一下，我们期望得到什么样的隔离结果？ 我们期望的是，每个用户程序都被装进一个盒子里，这样它们就不会彼此影响了，同时它们与操作系统也相互独立。这样，如果某个应用程序无意或故意做了一些坏事，也不会影响到操作系统。这就是我们对于隔离性的期望。 所以，我们想要某种机制，能够将不同程序之间的内存隔离开来，这样类似的事情就不会发生。一种实现方式是地址空间（Address Spaces）。 这里的基本概念也很简单直观，我们给包括内核在内的所有程序专属的地址空间。每个应用程序都能看到0～n的地址空间，同时它们都认为这些地址空间都是自己专有的，其他进程无法访问。换句话说，这些地址空间彼此独立。 所以现在我们的问题是如何在一个物理内存上，创建不同的地址空间，因为归根到底，我们使用的还是一堆存放了内存信息的DRAM芯片。如何在一个物理内存上，创建不同的地址空间？最常见的方法，同时也是非常灵活的一种方法就是使用页表（Page Tables）。 页表页表是在硬件中通过处理器和内存管理单元（Memory Management Unit）实现。 对于任何一条带有地址的指令，其中的地址应该认为是虚拟内存地址而不是物理地址。虚拟内存地址会被转到内存管理单元，内存管理单元会将虚拟地址翻译成物理地址。之后这个物理地址会被用来索引物理内存，并从物理内存加载，或者向物理内存存储数据。 从CPU的角度来说，一旦MMU打开了，它执行的每条指令中的地址都是虚拟内存地址。 怎么完成虚拟地址到物理地址的翻译呢？答案就是页表。MMU会有一个表单，表单中，一边是虚拟内存地址，另一边是物理内存地址。 同时，这张表单也需要保存在物理地址中，在运行时加载进内存。所以，CPU中需要有一些寄存器用来存放表单在物理内存中的地址（假设这个位置的物理内存地址是0x10，那么在RISC-V上一个叫做SATP的寄存器会保存地址0x10）。这样，CPU就可以告诉MMU，可以从哪找到将虚拟内存地址翻译成物理内存地址的表单。 那么，地址隔离的基本想法是每个应用程序都有自己独立的表单，并且这个表单定义了应用程序的地址空间。当操作系统将CPU从一个应用程序切换到另一个应用程序时，同时也需要切换SATP寄存器中的内容，从而指向新的进程保存在物理内存中的地址对应表单。这样的话，cat程序和Shell程序中相同的虚拟内存地址，就可以翻译到不同的物理内存地址，因为每个应用程序都有属于自己的不同的地址对应表单。 还有一个细节，表单是如何映射虚拟地址到物理地址的？如果为每个虚拟地址建立一个条目，那么64位的cpu内存很快就会被耗光。 实际情况是以页为单位，每一页对应一条表单条目，每一次地址翻译都是针对一页。所以对于虚拟内存地址，我们可以将它划分为两个部分，index和offset，index用来查找page，offset对应的是一个page中的哪个字节。 学生提问：我想知道4096字节作为一个page，这在物理内存中是连续的吗？ Frans教授：是的，在物理内存中，这是连续的4096个字节。所以物理内存是以4096为粒度使用的。 同一个学生：所以offset才是12bit，这样就足够覆盖4096个字节？ Frans教授：是的，page中的每个字节都可以被offset索引到。 物理页是连续的，单个页面内是一片连续的空间。 多级页表首先就是要理解单级页表的实现。 所谓页表，就是一个连续的数组，这个数组的元素是PTE（Page Table Entries）。 在xv6的实现上，一个进程都有自己的一个页表，这个页表就是一个64位的指针，指向数组开头地址。单级页表使用27位bit作为索引，这意味着，页表的大小也必须是这么大。在进程初始化时，必须分配2^27 * PTE大小的一个连续空间，作为存放PTE的仓库。这个仓库一开始是空的，尽管能通过索引访问仓库中的第k个PTE，但这个PTE的有效标识位是false，此时分配一个物理地址，将物理地址的高44位分配给PPN，这个PTE就有效了。 再看多级页表，xv6上实现的是3级页表，每个页表的大小是2^9PTE大小。SATP寄存器会指向最高一级的page directory的物理内存地址，之后我们用虚拟内存中index的高9bit用来索引最高一级的page directory，这样我们就能得到一个PPN，也就是物理page号。这个PPN指向了中间级的page directory。当我们在使用中间级的page directory时，我们通过虚拟内存地址中的L1部分完成索引。接下来会走到最低级的page directory，我们通过虚拟内存地址中的L0部分完成索引。*在最低级的page directory中，我们可以得到对应于虚拟内存地址的物理内存地址。 多级页表的好处就在于能够按需分配小页表。如果进程使用很少的地址空间，譬如只需要一个页面，那么在多级页表下只需要分配3个页表，大小是$3512PTE$。而在单级页表下，尽管我们只需要一个页，但仍然需要分配2^ 27*PTE大小的一个页表。 多级页表的坏处就在于访问内存多次。 a potential downside of three levels is that the CPU must load three PTEs from memory to perform the translation of the virtual address in the load/store instruction to a physical address PTE为什么存的是物理地址而不是虚拟地址？其实PTE存的是物理地址的高44位。 Frans教授：让我来问自己的一个有趣的问题，为什么是PPN存在这些page directory中？为什么不是一个虚拟内存地址？ 某学生回答：因为我们需要在物理内存中查找下一个page directory的地址。 Frans教授：是的，我们不能让我们的地址翻译依赖于另一个翻译，否则我们可能会陷入递归的无限循环中。所以page directory必须存物理地址。那SATP呢？它存的是物理地址还是虚拟地址？ 某学生回答：还是物理地址，因为最高级的page directory还是存在物理内存中，对吧。 Frans教授：是的，这里必须是物理地址，因为我们要用它来完成地址翻译，而不是对它进行地址翻译。所以SATP需要知道最高一级的page directory的物理地址是什么。 为什么中间页表能通过最高级页表的44位物理地址找到56位的物理地址？剩下的12位偏移量从哪来的？ 学生提问：我想知道我们是怎么计算page table的物理地址，是不是这样，我们从最高级的page table得到44bit的PPN，然后再加上虚拟地址中的12bit offset，就得到了完整的56bit page table物理地址？ Frans教授：我们不会加上虚拟地址中的offset，这里只是使用了12bit的0。所以我们用44bit的PPN，再加上12bit的0，这样就得到了下一级page directory的56bit物理地址。这里要求每个page directory都与物理page对齐（也就是page directory的起始地址就是某个page的起始地址，所以低12bit都为0）。 我：这其实也是困惑我蛮久的一个问题。其实一个页表的地址就是一个数组的开头地址，偏移量就是0。44位高位加上12位0，就能得到真实页表物理地址了。 三次索引，有一次没成功怎么办？ 学生提问：当一个进程请求一个虚拟内存地址时，CPU会查看SATP寄存器得到对应的最高一级page table，这级page table会使用虚拟内存地址中27bit index的最高9bit来完成索引，如果索引的结果为空，MMU会自动创建一个page table吗？ Frans教授：不会的，MMU会告诉操作系统或者处理器，抱歉我不能翻译这个地址，最终这会变成一个page fault。如果一个地址不能被翻译，那就不翻译。就像你在运算时除以0一样，处理器会拒绝那样做。 页表缓存To avoid the cost of loading PTEs from physical memory, a RISC-V CPU caches page table entries in a Translation Look-aside Buffer (TLB). 对于一个虚拟内存地址的寻址，需要读三次内存，这里代价有点高。所以实际中，几乎所有的处理器都会对于最近使用过的虚拟地址的翻译结果有缓存。这个缓存被称为：Translation Lookside Buffer（通常翻译成页表缓存）。 当处理器第一次查找一个虚拟地址时，硬件通过3级page table得到最终的PPN，TLB会保存虚拟地址到物理地址的映射关系。这样下一次当你访问同一个虚拟地址时，处理器可以查看TLB，TLB会直接返回物理地址，而不需要通过page table得到结果。 我：这个缓存感觉有点鸡肋，只能查相同虚拟地址。原本以为可以实现相同页的缓存。 Frans教授：有很多种方法都可以实现TLB，对于你们来说最重要的是知道TLB是存在的。TLB实现的具体细节不是我们要深入讨论的内容。这是处理器中的一些逻辑，对于操作系统来说是不可见的，操作系统也不需要知道TLB是如何工作的。 你们需要知道TLB存在的唯一原因是，如果你切换了page table，操作系统需要告诉处理器当前正在切换page table，处理器会清空TLB。因为本质上来说，如果你切换了page table，TLB中的缓存将不再有用，它们需要被清空，否则地址翻译可能会出错。所以操作系统知道TLB是存在的，但只会时不时的告诉操作系统，现在的TLB不能用了，因为要切换page table了。 在RISC-V中，清空TLB的指令是sfence_vma。 地址转换是通过硬件进行的To tell the hardware to use a page table, the kernel must write the physical address of the root page-table page into the satp register. Instructions use only virtual addresses, which the paging hardware translates to physical addresses, and then sends to the DRAM hardware to read or write storage 学生提问：3级的page table是由操作系统实现的还是由硬件自己实现的？ Frans教授：这是由硬件实现的，所以3级 page table的查找都发生在硬件中。MMU是硬件的一部分而不是操作系统的一部分。在XV6中，有一个函数也实现了page table的查找，因为时不时的XV6也需要完成硬件的工作，所以XV6有这个叫做walk的函数，它在软件中实现了MMU硬件相同的功能。 学生提问：之前提到，硬件会完成3级 page table的查找，那为什么我们要在XV6中有一个walk函数来完成同样的工作？ Frans教授：非常好的问题。这里有几个原因， 首先XV6中的walk函数设置了最初的page table，它需要对3级page table进行编程所以它首先需要能模拟3级page table。 另一个原因或许你们已经在syscall实验中遇到了，就是内核与用户的交互。 在XV6中，内核有它自己的page table，用户进程也有自己的page table，用户进程指向sys_info结构体的指针存在于用户空间的page table，但是内核需要将这个指针翻译成一个自己可以读写的物理地址。如果你查看copy_in，copy_out，你可以发现内核会通过用户进程的page table，将用户的虚拟地址翻译得到物理地址，这样内核可以读写相应的物理内存地址。这就是为什么在XV6中需要有walk函数的一些原因。 学生提问：对于walk函数，我有一个比较困惑的地方，在写完SATP寄存器之后，内核还能直接访问物理地址吗？在代码里面看起来像是通过page table将虚拟地址翻译成了物理地址，但是这个时候SATP已经被设置了，得到的物理地址不会被认为是虚拟地址吗？ Frans教授：让我们来看kvminithart函数，这里的kernel_page_table是一个物理地址，并写入到SATP寄存器中。从那以后，我们的代码运行在一个我们构建出来的地址空间中。在之前的kvminit函数中，kvmmap会对每个地址或者每个page调用walk函数。 学生提问：我想知道，在SATP寄存器设置完之后，walk是不是还是按照相同的方式工作？ Frans：是的。它还能工作的原因是，内核设置了虚拟地址等于物理地址的映射关系，这里很重要，因为很多地方能工作的原因都是因为内核设置的地址映射关系是相同的。 一旦将page table的物理地址写入satp寄存器，以后代码中所有的地址都会被视为虚拟地址进行地址翻译。而内核还能正常工作的原因是它设置了恒等映射，虚拟地址与物理地址相同。 内核地址空间的映射 图中的右半部分的结构完全由硬件设计者决定。如你们上节课看到的一样，当操作系统启动时，会从地址0x80000000开始运行，这个地址其实也是由硬件设计者决定的。主板的设计人员决定了，在完成了虚拟到物理地址的翻译之后，如果得到的物理地址大于0x80000000会走向DRAM芯片，如果得到的物理地址低于0x80000000会走向不同的I/O设备。 回到最初那张图的右侧：物理地址的分布。可以看到最下面是未被使用的地址，这与主板文档内容是一致的（地址为0）。地址0x1000是boot ROM的物理地址，当你对主板上电，主板做的第一件事情就是运行存储在boot ROM中的代码，当boot完成之后，会跳转到地址0x80000000，操作系统需要确保那个地址有一些数据能够接着启动操作系统。 地址0x02000000对应CLINT，当你向这个地址执行读写指令，你是向实现了CLINT的芯片执行读写。这里你可以认为你直接在与设备交互，而不是读写物理内存。 学生提问：为什么物理地址最上面一大块标为未被使用？ Frans教授：物理地址总共有2^56那么多，但是你不用在主板上接入那么多的内存。所以不论主板上有多少DRAM芯片，总是会有一部分物理地址没有被用到。实际上在XV6中，我们限制了内存的大小是128MB。 接下来我会切换到第一张图的左边，这就是XV6的虚拟内存地址空间。当机器刚刚启动时，还没有可用的page，XV6操作系统会设置内核使用的虚拟地址空间，也就是这张图左边的地址分布。因为我们想让XV6尽可能的简单易懂，所以这里的虚拟地址到物理地址的映射，大部分是相等的关系。比如说内核会按照这种方式设置page table，虚拟地址0x02000000对应物理地址0x02000000。这意味着左侧低于PHYSTOP的虚拟地址，与右侧使用的物理地址是一样的。 除此之外，这里还有两件重要的事情： 第一件事情是内核栈的映射。 kernel stack下有一个未映射的guard page，用来处理栈溢出 kernel stack对应的物理地址被映射两次，一次是在高位的PHYSTOP下，另一次是在Kernel data中。就是说，有两个虚拟地址对应同一个物理地址。实际只用高位的虚拟地址，因为有guard page，更加安全。 这是众多你可以通过page table实现的有意思的事情之一。你可以向同一个物理地址映射两个虚拟地址，你可以不将一个虚拟地址映射到物理地址。可以是一对一的映射，一对多映射，多对一映射。 第二件事情是权限。例如Kernel text page被标位R-X，意味着你可以读它，也可以在这个地址段执行指令，但是你不能向Kernel text写数据。通过设置权限我们可以尽早的发现Bug从而避免Bug。对于Kernel data需要能被写入，所以它的标志位是RW-，但是你不能在这个地址段运行指令，所以它的X标志位未被设置。（注，所以，kernel text用来存代码，代码可以读，可以运行，但是不能篡改，kernel data用来存数据，数据可以读写，但是不能通过数据伪装代码在kernel中运行） 学生提问：对于不同的进程会有不同的kernel stack吗？ Frans：答案是的。每一个用户进程都有一个对应的kernel stack。 物理空间的分配 xv6 uses the physical memory between the end of the kernel and PHYSTOP for run-time allocation。 学生提问：用户程序的虚拟内存会映射到未使用的物理地址空间吗？ Frans教授：在kernel page table中，有一段Free Memory，它对应了物理内存中的一段地址。XV6使用这段free memory来存放用户进程的page table，text和data。如果我们运行了非常多的用户进程，某个时间点我们会耗尽这段内存，这个时候fork或者exec会返回错误。 同一个学生提问：这就意味着，用户进程的虚拟地址空间会比内核的虚拟地址空间小的多，是吗？ Frans教授：本质上来说，两边的虚拟地址空间大小是一样的。但是用户进程的虚拟地址空间使用率会更低。 我：这只是实际能使用的物理空间小而已。各个进程看到的虚拟地址空间大小是一样的。 物理空间的分配通过free list进行，每次从free list分配一个页面大小的内存给进程。 free list通过链表的形式追踪空闲页面。 Frans教授：当kernel创建了一个进程，针对这个进程的page table也会从Free memory中分配出来。内核会为用户进程的page table分配几个page，并填入PTE。在某个时间点，当内核运行了这个进程，内核会将进程的根page table的地址加载到SATP中。从那个时间点开始，处理器会使用内核为那个进程构建虚拟地址空间。","link":"/2024/01/07/MIT6.S081/book/chapter3/"},{"title":"MIT6.S081 xv6book chapter4","text":"第四章的主题是陷阱与系统调用。关键问题：系统调用是怎么从用户态切换到内核态的？ 从中断角度看，系统调用是一软中断，发生中断后由中断向量处理，其中中断向量的地址又在寄存器stvec上。 这里融合了lec06的内容 和lec08的内容，lec08讲述了page fault中断处理的妙用，核心思想都是懒分配：给你虚拟页但不实际分配物理页，等到实际要用时再分配。 前言什么时候需要用户态到内核态的切换？ 程序执行系统调用； 程序出现了类似page fault、运算时除以0的错误； 一个设备触发了中断使得当前程序运行需要响应内核设备驱动。 这里用户空间和内核空间的切换通常被称为trap，而trap涉及了许多小心的设计和重要的细节，这些细节对于实现安全隔离和性能来说非常重要。trap机制要尽可能的简单来应对频繁的切换。 我们需要清楚如何让程序的运行，从只拥有user权限并且位于用户空间的Shell，切换到拥有supervisor权限的内核。在这个过程中，硬件的状态将会非常重要，因为我们很多的工作都是将硬件从适合运行用户应用程序的状态，改变到适合运行内核代码的状态。 应用程序的用户寄存器，像a0如此的有32个，此外还有一些特别的寄存器： stvec：The kernel writes the address of its trap handler here sepc：When a trap occurs, RISC-V saves the program counter here scause：RISC-V puts a number here that describes the reason for the trap. sscratch sstatus：硬件中断、一些标识位 satp：保存pagetable的地址 这些寄存器的值表明了执行系统调用时的计算机状态。那么执行trap时，我们需要做的事： 保存状态（包括32个寄存器、pc等） 将mode切换为supervisor，这样才能执行特权指令 切换satp页表为内核页表 设置堆栈寄存器指向内核中一个地址，这样内核的C函数才能使用栈 一旦设置好以上状态，跳入内核的C代码开始执行 要怎么实现？操作系统的一些high-level的目标能帮我们过滤一些实现选项。其中一个目标是安全和隔离，我们不想让用户代码介入到这里的user/kernel切换，否则有可能会破坏安全性。所以这意味着，trap中涉及到的硬件和内核机制不能依赖任何来自用户空间的东西。XV6的trap机制不会查看这些寄存器，而只是将它们保存起来。 Supervisor mode下能够执行的操作： 其中的一件事情是，你现在可以读写控制寄存器了。比如说，当你在supervisor mode时，你可以：读写SATP寄存器，也就是page table的指针；STVEC，也就是处理trap的内核指令地址；SEPC，保存当发生trap时的程序计数器；SSCRATCH等等。在supervisor mode你可以读写这些寄存器，而用户代码不能做这样的操作。 另一件事情supervisor mode可以做的是，它可以使用PTE_U标志位为0的PTE。当PTE_U标志位为1的时候，表明用户代码可以使用这个页表；如果这个标志位为0，则只有supervisor mode可以使用这个页表。 需要特别指出的是，supervisor mode中的代码并不能读写任意物理地址。在supervisor mode中，就像普通的用户代码一样，也需要通过page table来访问内存。如果一个虚拟地址并不在当前由SATP指向的page table中，又或者SATP指向的page table中PTE_U=1，那么supervisor mode不能使用那个地址。所以，即使我们在supervisor mode，我们还是受限于当前page table设置的虚拟地址。 shell执行write系统调用 上图是系统调用的大致流程。//todo 简述每一个过程 ecall12345.global writewrite: li a7, SYS_write ecall ret shell执行write系统调用实际是执行usys.S中的这段代码，其中透过ecall指令执行系统调用。 ecall指令做的事情：（实际上对应book第44页末尾那段硬件操作） ecall将mode从user mode改到supervisor mode； ecall将程序计数器的值保存在了SEPC寄存器； ecall会跳转到STVEC寄存器指向的指令。 所以现在，ecall帮我们做了一点点工作，但是实际上我们离执行内核中的C代码还差的很远。接下来： 我们需要保存32个用户寄存器的内容，这样当我们想要恢复用户代码执行时，我们才能恢复这些寄存器的内容。 因为现在我们还在user page table，我们需要切换到kernel page table。 我们需要创建或者找到一个kernel stack，并将Stack Pointer寄存器的内容指向那个kernel stack。这样才能给C代码提供栈。 我们还需要跳转到内核中C代码的某些合理的位置。 为什么ecall不多做点工作来将代码执行从用户空间切换到内核空间呢？为什么ecall不会保存用户寄存器，或者切换page table指针来指向kernel page table，或者自动的设置Stack Pointer指向kernel stack，或者直接跳转到kernel的C代码，而不是在这里运行复杂的汇编代码？ 原因是RISC的设计思想，尽可能的简单且通用，让用户完成自定义的操作。然后这样做的代价就是性能不是特别好。 uservec现在指令来到了TRAMPOLINE的vuservec。为什么会来这？是因为内核设置了stvec寄存器的值为这里。每个进程创建时都会映射TRAMPOLINE页面在虚拟地址的最高处，内容初始化为trampoline.S的代码。 12345678910111213141516171819202122232425.globl uservecuservec: # part1 保存状态 csrrw a0, sscratch, a0 sd ra, 40(a0) .... csrr t0, sscratch sd t0, 112(a0) # part2 加载内核sp指针 ld sp, 8(a0) # 确认自己是在哪个cpu核心上 ld tp, 32(a0) # part3 设置 address of usertrap(), p-&gt;trapframe-&gt;kernel_trap ld t0, 16(a0) # part4 切换页表 ld t1, 0(a0) csrw satp, t1 # 用户进程的页表物理地址保存在了t1寄存器中,p-&gt;pagetable仍然是用户进程的页表 sfence.vma zero, zero # jump to usertrap(), which does not return jr t0 现在已经是supervisor mode，但还没完成状态保存。 怎么保存状态？或许直接将32个寄存器中的内容写到物理内存中某些合适的位置，但此时还没完成页表的切换，并且在trap代码当前的位置，也就是trap机制的最开始，我们并不知道kernel page table的地址。并且更改SATP寄存器的指令，要求写入SATP寄存器的内容来自于另一个寄存器。 答案是用户地址空间的trapframe页。在创建用户进程时预先分配好这个页面来保存寄存器的值。 怎么知道trapframe页的虚拟地址？答案是SSCRATCH寄存器。所以uservec的第一条指令是csrrw a0, sscratch, a0交换寄存器的值，然后就能用a0寄存器干活儿了。保存完其他寄存器值后，还要记得保存原始a0寄存器的值（目前在SScRATCH寄存器上）。 然后加载内核sp指针，trapframe中的kernel_sp是由kernel在进入用户空间之前就设置好的，它的值是这个进程的kernel stack。 然后就是核心的保存，设置跳转地址，切换内核页表，最后跳转到内核C代码。 为什么切换内核页表后，还能正确的执行跳转指令？ 答：因为我们还在trampoline代码中，而trampoline代码在用户空间和内核空间都映射到了同一个地址。 usertrap()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// kernel/trap.cvoid usertrap(void){ int which_dev = 0; if((r_sstatus() &amp; SSTATUS_SPP) != 0) panic(&quot;usertrap: not from user mode&quot;); // part1 send interrupts and exceptions to kerneltrap(), // since we're now in the kernel. w_stvec((uint64)kernelvec); struct proc *p = myproc(); // part2 save user program counter. p-&gt;trapframe-&gt;epc = r_sepc(); // part3 判断中断原因并作相应处理 if(r_scause() == 8){ // system call if(p-&gt;killed) exit(-1); // sepc points to the ecall instruction, // but we want to return to the next instruction. p-&gt;trapframe-&gt;epc += 4; // an interrupt will change sstatus &amp;c registers, // so don't enable until done with those registers. intr_on(); syscall(); } else if((which_dev = devintr()) != 0){ // ok } else { printf(&quot;usertrap(): unexpected scause %p pid=%d\\n&quot;, r_scause(), p-&gt;pid); printf(&quot; sepc=%p stval=%p\\n&quot;, r_sepc(), r_stval()); p-&gt;killed = 1; } if(p-&gt;killed) exit(-1); // give up the CPU if this is a timer interrupt. if(which_dev == 2) yield(); // part4 执行返回流程 usertrapret();} usertrap最主要的作用就是判断中断类型，根据中断类型做出相应的处理。 这里看系统调用的流程， p-&gt;trapframe-&gt;epc += 4;是为了能在中断返回时返回到下一条指令，也就是ecall下一条指令ret。然后就调用syscall函数。 sysycall()1234567891011121314// kernel/syscall.cvoid syscall(void){ int num; struct proc *p = myproc(); num = p-&gt;trapframe-&gt;a7; if(num &gt; 0 &amp;&amp; num &lt; NELEM(syscalls) &amp;&amp; syscalls[num]) { p-&gt;trapframe-&gt;a0 = syscalls[num](); } else { printf(&quot;%d %s: unknown sys call %d\\n&quot;, p-&gt;pid, p-&gt;name, num); p-&gt;trapframe-&gt;a0 = -1; }} 这段代码写得非常简单，从a7寄存器中获取系统调用号然后根据哈希表查询执行相应的系统调用，将返回值保存在a0寄存器中。 usertrapret() 返回12345678910111213141516171819202122232425262728293031323334// kernel/trap.cvoid usertrapret(void){ struct proc *p = myproc(); // part1 关中断 intr_off(); // part2 设置用户中断向量 w_stvec(TRAMPOLINE + (uservec - trampoline)); // part3 reset trapframe p-&gt;trapframe-&gt;kernel_satp = r_satp(); // kernel page table p-&gt;trapframe-&gt;kernel_sp = p-&gt;kstack + PGSIZE; // process's kernel stack p-&gt;trapframe-&gt;kernel_trap = (uint64)usertrap; p-&gt;trapframe-&gt;kernel_hartid = r_tp(); // hartid for cpuid() // part4 设置mode状态 unsigned long x = r_sstatus(); x &amp;= ~SSTATUS_SPP; // clear SPP to 0 for user mode x |= SSTATUS_SPIE; // enable interrupts in user mode w_sstatus(x); // part5 设置sepc，ret指令会用到 w_sepc(p-&gt;trapframe-&gt;epc); // part6 提前准备好页表切换的参数 uint64 satp = MAKE_SATP(p-&gt;pagetable); // jump to trampoline.S at the top of memory, which // switches to the user page table, restores user registers, // and switches to user mode with sret. uint64 fn = TRAMPOLINE + (userret - trampoline); ((void (*)(uint64,uint64))fn)(TRAPFRAME, satp);} usertrapret最主要的作用就是设置返回到用户空间之前内核要做的工作。 重新设置stvec为用户中断向量，然后就是几个内核相关的寄存器值（这样下一次从用户空间转换到内核空间时可以用到这些数据）。 接下来我们要设置SSTATUS寄存器，这是一个控制寄存器。这个寄存器的SPP bit位控制了sret指令的行为，该bit为0表示下次执行sret的时候，我们想要返回user mode而不是supervisor mode。这个寄存器的SPIE bit位控制了，在执行完sret之后，是否打开中断。因为我们在返回到用户空间之后，我们的确希望打开中断，所以这里将SPIE bit位设置为1。修改完这些bit位之后，我们会把新的值写回到SSTATUS寄存器。 trampoline代码的最后执行了sret指令。这条指令会将程序计数器设置成SEPC寄存器的值。所以现在设置sepc为epc值，用于返回到正确位置。 倒数第二行的作用是计算出我们将要跳转到汇编代码的地址。我们期望跳转的地址是tampoline中的userret函数，这个函数包含了所有能将我们带回到用户空间的指令。所以这里我们计算出了userret函数的地址。 倒数第一行，将fn指针作为一个函数指针，执行相应的函数（也就是userret函数）并传入两个参数，两个参数存储在a0，a1寄存器中。 实际上，我们会在汇编代码trampoline中完成page table的切换，并且也只能在trampoline中完成切换，因为只有trampoline中代码是同时在用户和内核空间中映射。但是我们现在还没有在trampoline代码中，我们现在还在一个普通的C函数中，所以这里我们将page table指针准备好，并将这个指针作为第二个参数传递给汇编代码，这个参数会出现在a1寄存器。 userret12345678910111213141516171819userret: # part1 切换页表 csrw satp, a1 sfence.vma zero, zero # part2 保存a0到sscratch ld t0, 112(a0) csrw sscratch, t0 # part3 恢复各个寄存器的值 restore all but a0 from TRAPFRAME ld ra, 40(a0) .... # part4 restore user a0, and save TRAPFRAME in sscratch csrrw a0, sscratch, a0 # return to user mode and user pc. # usertrapret() set up sstatus and sepc. sret 现在程序执行又回到了trampoline代码。 第二步中，a0是上一步传入的trampoline地址，然后通过trampoline找到a0寄存器（保存了系统调用返回值），再保存在sscratch中。 第四步，让sscratch保存trampframe（这样下一次trap又能用了），同时恢复a0。 sret是我们在kernel中的最后一条指令，当我执行完这条指令： 程序会切换回user mode SEPC寄存器的数值会被拷贝到PC寄存器（程序计数器） 重新打开中断 这将会返回到ret指令，ret指令位于ecal指令下一条。 ret现在我们回到了用户空间，执行完ret指令之后我们就可以从write系统调用返回到Shell中了。或者更严格的说，是从触发了系统调用的write库函数中返回到Shell中。 最后总结一下，系统调用被刻意设计的看起来像是函数调用，但是背后的user/kernel转换比函数调用要复杂的多。之所以这么复杂，很大一部分原因是要保持user/kernel之间的隔离性，内核不能信任来自用户空间的任何内容。 另一方面，XV6实现trap的方式比较特殊，XV6并不关心性能。但是通常来说，操作系统的设计人员和CPU设计人员非常关心如何提升trap的效率和速度。 PageFault首先，我们需要思考的是，什么样的信息对于page fault是必须的。或者说，当发生page fault时，内核需要什么样的信息才能够响应page fault。 引起page fault的内存地址 引起page fault的原因类型 引起page fault时的程序计数器值，这表明了page fault在用户空间发生的位置 当出现page fault的时候，XV6内核会打印出错的虚拟地址，并且这个地址会被保存在STVAL寄存器中。 我们需要知道的第二个信息是出错的原因，比如因为load指令触发的page fault、因为store指令触发的page fault又或者是因为jump指令触发的page fault。出错原因存在SCAUSE寄存器中，其中总共有3个类型的原因与page fault相关，分别是读、写和指令。 我们或许想要知道的第三个信息是触发page fault的指令的地址。从上节课可以知道，作为trap处理代码的一部分，这个地址存放在SEPC寄存器中，并同时会保存在trapframe-&gt;epc中。 由于页表提供了一种非常有用的抽象，隔离性与抽象管理，这使得我们有许多优化可以进行，这些优化基本都是按照懒加载的思想进行。 在进行这些优化时，我们需要时常思考，page fault什么时候会产生以及产生page fault时的行为。 Lazy Allocation我们首先来看一下内存allocation，或者更具体的说sbrk，它使得用户应用程序能扩大自己的heap。当一个应用程序启动的时候，sbrk指向的是heap的最底端，同时也是stack的最顶端。这个位置通过代表进程的数据结构中的sz字段表示，这里以p-&gt;sz表示。 这意味着，当sbrk实际发生或者被调用的时候，内核会分配一些物理内存，并将这些内存映射到用户应用程序的地址空间，然后将内存内容初始化为0，再返回sbrk系统调用。 在XV6中，sbrk的实现默认是eager allocation，这表示了，一旦调用了sbrk，内核会立即分配应用程序所需要的物理内存。 但是实际上，对于应用程序来说很难预测自己需要多少内存，所以通常来说，应用程序倾向于申请多于自己所需要的内存。这意味着，进程的内存消耗会增加许多，但是有部分内存永远也不会被应用程序所使用到。 lazy allocation的核心思想非常简单，sbrk系统调基本上不做任何事情，唯一需要做的事情就是提升p-&gt;sz，将p-&gt;sz增加n，其中n是需要新分配的内存page数量。但是内核在这个时间点并不会分配任何物理内存。之后在某个时间点，应用程序使用到了新申请的那部分内存，这时会触发page fault，因为我们还没有将新的内存映射到page table。 所以，如果我们解析一个大于旧的p-&gt;sz，但是又小于新的p-&gt;sz（注，也就是旧的p-&gt;sz + n）的虚拟地址，我们希望内核能够分配一个内存page，并且重新执行指令。 实际上，lazy allocation会复杂一些。如果我们扩大用户内存而没实际分配页面时，要注意进程结束释放未分配的页面内存回收（实际上会回收空值）；如果sbrk传入负数，也要注意回收的内存是否实际分配页面。 Zero Fill On Demand首先，当你查看一个用户程序的地址空间时，存在text区域，data区域，同时还有一个BSS区域（BSS区域包含了未被初始化或者初始化为0的全局或者静态变量）。 之所以这些变量要单独列出来，是因为例如你在C语言中定义了一个大的全局变量，它的元素初始值都是0，为什么要为这个变量分配内存呢？其实只需要记住这个变量的内容是0就行。 通常可以调优的地方是，我有如此多的内容全是0的page，在物理内存中，我只需要分配一个page，这个page的内容全是0。然后将所有虚拟地址空间的全0的page都map到这一个物理page上。这样至少在程序启动的时候能节省大量的物理内存分配。 当然这里的mapping需要非常的小心，我们不能允许对于这个page执行写操作，因为所有的虚拟地址空间page都期望page的内容是全0，所以这里的PTE都是只读的。之后在某个时间点，应用程序尝试写BSS中的一个page时，比如说需要更改一两个变量的值，我们会得到page fault。 那么，对于这个特定场景中的page fault我们该做什么呢？ 学生回答：我认为我们应该创建一个新的page，将其内容设置为0，并重新执行指令。 假设store指令发生在BSS最顶端的page中。我们想要做的是，在物理内存中申请一个新的内存page，将其内容设置为0，因为我们预期这个内存的内容为0。之后我们需要更新这个page的mapping关系，首先PTE要设置成可读可写，然后将其指向新的物理page。这里相当于更新了PTE，之后我们可以重新执行指令。 好处： 假设程序申请了一个大的数组，来保存可能的最大的输入，并且这个数组是全局变量且初始为0。但是最后或许只有一小部分内容会被使用。 第二个好处是在exec中需要做的工作变少了。程序可以启动的更快，这样你可以获得更好的交互体验，因为你只需要分配一个内容全是0的物理page。 坏处是多次page fault代价更大。 Copy On Write Fork当Shell处理指令时，它会通过fork创建一个子进程。Shell的子进程执行的第一件事情就是调用exec运行一些其他程序，比如运行echo。现在的情况是，fork创建了Shell地址空间的一个完整的拷贝，而exec做的第一件事情就是丢弃这个地址空间，取而代之的是一个包含了echo的地址空间。这里看起来有点浪费。 所以对于这个特定场景有一个非常有效的优化：当我们创建子进程时，与其创建，分配并拷贝内容到新的物理内存，其实我们可以直接共享父进程的物理内存page。所以这里，我们可以设置子进程的PTE指向父进程对应的物理内存page。 一旦子进程想要修改这些内存的内容，相应的更新应该对父进程不可见，因为我们希望在父进程和子进程之间有强隔离性，所以这里我们需要更加小心一些。为了确保进程间的隔离性，我们可以将这里的父进程和子进程的PTE的标志位都设置成只读的。 在某个时间点，当我们需要更改内存的内容时，我们会得到page fault。在得到page fault之后，我们需要拷贝相应的物理page。假设现在是子进程在执行store指令，那么我们会分配一个新的物理内存page，然后将page fault相关的物理内存page拷贝到新分配的物理内存page中，并将新分配的物理内存page映射到子进程。这时，新分配的物理内存page只对子进程的地址空间可见，所以我们可以将相应的PTE设置成可读写，并且我们可以重新执行store指令。实际上，对于触发刚刚page fault的物理page，因为现在只对父进程可见，相应的PTE对于父进程也变成可读写的了。 学生提问：我们如何发现父进程写了这部分内存地址？是与子进程相同的方法吗？ Frans教授：是的，因为子进程的地址空间来自于父进程的地址空间的拷贝。如果我们使用了特定的虚拟地址，因为地址空间是相同的，不论是父进程还是子进程，都会有相同的处理方式。 学生提问：对于一些没有父进程的进程，比如系统启动的第一个进程，它会对于自己的PTE设置成只读的吗？还是设置成可读写的，然后在fork的时候再修改成只读的？ Frans教授：这取决于你。实际上在lazy lab之后，会有一个copy-on-write lab。在这个lab中，你自己可以选择实现方式。当然最简单的方式就是将PTE设置成只读的，当你要写这些page时，你会得到一个page fault，之后你可以再按照上面的流程进行处理。 学生提问：当发生page fault时，我们其实是在向一个只读的地址执行写操作。内核如何能分辨现在是一个copy-on-write fork的场景，而不是应用程序在向一个正常的只读地址写数据。是不是说默认情况下，用户程序的PTE都是可读写的，除非在copy-on-write fork的场景下才可能出现只读的PTE？ Frans教授：内核必须要能够识别这是一个copy-on-write场景。几乎所有的page table硬件都支持了这一点。我们之前并没有提到相关的内容，下图是一个常见的多级page table。对于PTE的标志位，我之前介绍过第0bit到第7bit，但是没有介绍最后两位RSW。这两位保留给supervisor software使用，supervisor softeware指的就是内核。内核可以随意使用这两个bit位。所以可以做的一件事情就是，将bit8标识为当前是一个copy-on-write page。 对于这里的物理内存page，现在有多个用户进程或者说多个地址空间都指向了相同的物理内存page，举个例子，当父进程退出时我们需要更加的小心，因为我们要判断是否能立即释放相应的物理page。如果有子进程还在使用这些物理page，而内核又释放了这些物理page，我们将会出问题。那么现在释放内存page的依据是什么呢？ 我们需要对于每一个物理内存page的引用进行计数，当我们释放虚拟page时，我们将物理内存page的引用数减1，如果引用数等于0，那么我们就能释放物理内存page。 Demand Paging我们回到exec，在未修改的XV6中，操作系统会加载程序内存的text，data区域，并且以eager的方式将这些区域加载进page table。 为什么我们要以eager的方式将程序加载到内存中？为什么不再等等，直到应用程序实际需要这些指令的时候再加载内存？程序的二进制文件可能非常的巨大，将它全部从磁盘加载到内存中将会是一个代价很高的操作。又或者data区域的大小远大于常见的场景所需要的大小，我们并不一定需要将整个二进制都加载到内存中。 所以对于exec，在虚拟地址空间中，我们为text和data分配好地址段，但是相应的PTE并不对应任何物理内存page。对于这些PTE，我们只需要将valid bit位设置为0即可。 接下来思考什么时候会触发page fault：应用程序是从地址0开始运行，位于地址0的指令会出发第一个page fault。 然后就是触发page fault的行为：首先我们可以发现，这些page是on-demand page。我们需要在某个地方记录了这些page对应的程序文件，我们在page fault handler中需要从程序文件中读取page数据，加载到内存中；之后将内存page映射到page table；最后再重新执行指令。 在最坏的情况下，用户程序使用了text和data中的所有内容，那么我们将会在应用程序的每个page都收到一个page fault。但是如果我们幸运的话，用户程序并没有使用所有的text区域或者data区域，那么我们一方面可以节省一些物理内存，另一方面我们可以让exec运行的更快。 在lazy allocation中，如果内存耗尽了该如何办？一个选择是撤回page（evict page）。比如说将部分内存page中的内容写回到文件系统再撤回page。一旦你撤回并释放了page，那么你就有了一个新的空闲的page，你可以使用这个刚刚空闲出来的page，分配给刚刚的page fault handler，再重新执行指令。 问题又来了，什么样的page可以被撤回？并且该使用什么样的策略来撤回page？常用的策略，Least Recently Used，或者叫LRU，除了这个策略之外，还有一些其他的小优化。如果你要撤回一个page，你可以在dirty page和non-dirty page中做选择。 如果你们再看PTE，还有其他信息。当硬件向一个page写入数据，会设置dirty bit，之后操作系统就可以发现这个page曾经被写入了。类似的，还有一个Access bit，任何时候一个page被读或者被写了，这个Access bit会被设置。 为什么这两个信息重要(access bit &amp; dirty bit)呢？它们能怎样帮助内核呢？ 学生回答：没有被Access过的page可以直接撤回，是吗？ Frans教授：是的，或者说如果你想实现LRU，你需要找到一个在一定时间内没有被访问过的page，那么这个page可以被用来撤回。而被访问过的page不能被撤回。所以Access bit通常被用来实现这里的LRU策略。 学生提问：那是不是要定时的将Access bit恢复成0？ Frans教授：是的，这是一个典型操作系统的行为。操作系统会扫描整个内存，这里有一些著名的算法例如clock algorithm，就是一种实现方式。 另一个学生提问：为什么需要恢复这个bit？ Frans教授：如果你想知道page最近是否被使用过，你需要定时比如每100毫秒或者每秒清除Access bit，如果在下一个100毫秒这个page被访问过，那你就知道这个page在上一个100毫秒中被使用了。而Access bit为0的page在上100毫秒未被使用。这样你就可以统计每个内存page使用的频度，这是一个成熟的LRU实现的基础。（注，可以通过Access bit来决定内存page 在LRU中的排名） Memory Mapped Files这里的核心思想是，将完整或者部分文件加载到内存中，这样就可以通过内存地址相关的load或者store指令来操纵文件。 现代操作系统一般会提供一个mmap系统调用，这个系统调用会接收一个虚拟内存地址（VA），长度（len），protection，一些标志位，一个打开文件的文件描述符，和偏移量（offset）。语义是，从文件描述符对应的文件的偏移量的位置开始，映射长度为len的内容到虚拟内存地址VA，同时我们需要加上一些保护，比如只读或者读写。 假设文件内容是读写并且内核实现mmap的方式是eager方式（不过大部分系统都不会这么做），内核会从文件的offset位置开始，将数据拷贝到内存，设置好PTE指向物理内存的位置。之后应用程序就可以使用load或者store指令来修改内存中对应的文件内容。当完成操作之后，会有一个对应的unmap系统调用，参数是虚拟地址（VA），长度（len）。来表明应用程序已经完成了对文件的操作，在unmap时间点，我们需要将dirty block写回到文件中。 当然，在任何聪明的内存管理机制中，所有的这些都是以lazy的方式实现。你不会立即将文件内容拷贝到内存中，而是先记录一下这个PTE属于这个文件描述符。相应的信息通常在VMA结构体中保存，VMA全称是Virtual Memory Area。例如对于这里的文件f，会有一个VMA，在VMA中我们会记录文件描述符，偏移量等等，这些信息用来表示对应的内存虚拟地址的实际内容在哪，这样当我们得到一个位于VMA地址范围的page fault时，内核可以从磁盘中读数据，并加载到内存中。 学生提问：如果其他进程直接修改了文件的内容，那么是不是意味着修改的内容不会体现在这里的内存中？ Frans教授：是的。但是如果文件是共享的，那么你应该同步这些变更。我记不太清楚在mmap中，文件共享时会发生什么。","link":"/2024/01/07/MIT6.S081/book/chapter4/"},{"title":"MIT6.S081 xv6book chapter5","text":"第五章主要讲述的是外部设备的中断，不同于软件中断，外部设备中断可以与CPU处理并行。 这里要特别理解外设的驱动，驱动的top部分一般是驱动提供给用户的接口服务，驱动的bottom部分则是interrupt handler。top部分和bottom部分通过buffer解藕，top部分往设备的缓冲区读写完事儿，待设备处理完成发送一个中断，bottom部分则处理中断，bottom亦能读写缓冲区。 值得注意的是：一个中断是如何产生，又如何被CPU处理的（这里会有多个CPU）；设备与CPU的并行。 这节融合了lec09的内容，通过追踪以下两个场景来分析中断过程： console中的提示符“$ ” 是如何显示出来的； 如果你在键盘输入“ls”，这些字符是怎么最终在console中显示出来的。 前言中断对应的场景很简单，就是硬件想要得到操作系统的关注。例如网卡收到了一个packet，网卡会生成一个中断；用户通过键盘按下了一个按键，键盘会产生一个中断。操作系统需要做的是，保存当前的工作，处理中断，处理完成之后再恢复之前的工作。系统调用，page fault，中断，都使用相同的机制。 中断与系统调用主要有3个小的差别： asynchronous。异步，当硬件生成中断时，Interrupt handler与当前运行的进程在CPU上没有任何关联。 concurrency。并行，对于中断来说，CPU和生成中断的设备是并行的在运行。比如，网卡自己独立的处理来自网络的packet，然后在某个时间点产生中断，但是同时，CPU也在运行。 program device。设备编程，每个设备都有一个编程手册，设备的编程手册包含了它有什么样的寄存器，它能执行什么样的操作，在读写控制寄存器的时候，设备会如何响应。根据这些手册对设备进行编程。 通常来说，编程是通过memory mapped I/O完成的。设备地址出现在物理地址的特定区间内，这个区间由主板制造商决定。操作系统需要知道这些设备位于物理地址空间的具体位置，然后再通过普通的load/store指令对这些地址进行编程。load/store指令实际上的工作就是读写设备的控制寄存器。 ![image-20240111091130275](/Users/mac/Library/Application Support/typora-user-images/image-20240111091130275.png) 中断是从哪里产生的？外设中断来自于主板上的设备（我们主要关心的是外部设备的中断，而不是定时器中断或者软件中断） 中断是怎么被CPU处理的？处理器上是通过PLIC（Platform Level Interrupt Control）来处理设备中断。PLIC会管理来自于外设的中断。 从左上角可以看出，我们有53个不同的来自于设备的中断。这些中断到达PLIC之后，PLIC会路由这些中断。图的右下角是CPU的核，PLIC会将中断路由到某一个CPU的核。如果所有的CPU核都正在处理中断，PLIC会保留中断直到有一个CPU核可以用来处理中断。所以PLIC需要保存一些内部数据来跟踪中断的状态。 uart会产生什么样的中断？ 接收中断（比如键盘按下一个按键，那么这个字符会存入到uart的RHR寄存器，uart产生一个接收中断） 发送完成中断（往uart的THR寄存器存入字符，当uart发送THR寄存器中的一个字符到console完成时，产生一个中断） 驱动driverA driver is the code in an operating system that manages a particular device: it configures the device hardware, tells the device to perform operations, handles the resulting interrupts, and interacts with processes that may be waiting for I/O from the device. 驱动大部分都分为两个部分，bottom和top。 bottom部分通常是Interrupt handler。当一个中断送到了CPU，并且CPU设置接收这个中断，CPU会调用相应的Interrupt handler。Interrupt handler并不运行在任何特定进程的context中，它只是处理中断。 top部分，是用户进程或者内核的其他部分调用的接口。对于UART来说，这里有read/write接口，这些接口可以被更高层级的代码调用。 通常情况下，驱动中会有一些队列（或者说buffer），top部分的代码会从队列中读写数据，而Interrupt handler（bottom部分）同时也会向队列中读写数据。这里的队列可以将并行运行的设备和CPU解耦开来。 设置中断(中断初始化)RISC-V有许多与中断相关的寄存器： SIE（Supervisor Interrupt Enable）寄存器。这个寄存器中有一个bit（E）专门针对例如UART的外部设备的中断；有一个bit（S）专门针对软件中断，软件中断可能由一个CPU核触发给另一个CPU核；还有一个bit（T）专门针对定时器中断。我们这节课只关注外部设备的中断。 SSTATUS（Supervisor Status）寄存器。这个寄存器中有一个bit来打开或者关闭中断。每一个CPU核都有独立的SIE和SSTATUS寄存器，除了通过SIE寄存器来单独控制特定的中断，还可以通过SSTATUS寄存器中的一个bit来控制所有的中断。 SIP（Supervisor Interrupt Pending）寄存器。当发生中断时，处理器可以通过查看这个寄存器知道当前是什么类型的中断。 xv6启动之初，首先设置uartinit()，使得uart设备能够产生中断。 然后设置plic设备，使得plic能够路由中断。 最后是打开cpu的中断开关（设置sstatus寄存器），使得cpu能够处理中断。 top部分（“$”的输出）sh.c 中调用fprintf(2, &quot;$ &quot;) user/printf.c文件中，fprintf代码只是调用了write系统调用，最终走到sys_write函数。 sysfile.c文件中的sys_write函数fetch参数，然后调用file.c文件的filewrite函数。 file.c文件的filewrite函数首先会判断文件描述符的类型，然后调用console.c中的consolewrite函数。 12345678//file.cint filewrite(struct file *f, uint64 addr, int n) { if(f-&gt;type == FD_DEVICE){ if(f-&gt;major &lt; 0 || f-&gt;major &gt;= NDEV || !devsw[f-&gt;major].write) return -1; ret = devsw[f-&gt;major].write(1, addr, n); //每个device都有对应的read write函数 }} console.c文件中的consolewrite函数先通过either_copyin将字符拷入，之后调用uart.c文件中的uartputc函数。 1234567891011// console.cint consolewrite(int user_src, uint64 src, int n){ int i; for(i = 0; i &lt; n; i++){ char c; if(either_copyin(&amp;c, user_src, src+i, 1) == -1) // Copy to either a user address, or kernel address break; uartputc(c); } return i;} uart.c文件中的uartputc函数，主要逻辑就是将字符写入uart的环形缓冲区，然后调用uartstart()。uartstart函数主要逻辑是不断从环形缓冲读数据，然后发送到console，WriteReg(THR, c);。 1234567891011121314151617181920212223242526272829303132// uart.cvoid uartputc(int c){ acquire(&amp;uart_tx_lock); if(panicked){ for(;;); } while(1){ if(uart_tx_w == uart_tx_r + UART_TX_BUF_SIZE){ // buffer is full. wait for uartstart() to open up space in the buffer. sleep(&amp;uart_tx_r, &amp;uart_tx_lock); }else { uart_tx_buf[uart_tx_w % UART_TX_BUF_SIZE] = c; uart_tx_w += 1; uartstart(); release(&amp;uart_tx_lock); return; } }}void uartstart() { while(1){ if(uart_tx_w == uart_tx_r){ return; } if((ReadReg(LSR) &amp; LSR_TX_IDLE) == 0){return;} // whether THR can accept another character to send int c = uart_tx_buf[uart_tx_r % UART_TX_BUF_SIZE]; uart_tx_r += 1; wakeup(&amp;uart_tx_r); // maybe uartputc() is waiting for space in the buffer. WriteReg(THR, c); }} 至此，一个$就打印在屏幕上了。一旦WriteReg完成，系统调用会返回，用户应用程序Shell就可以继续执行。 12#define RHR 0 // receive holding register (for input bytes) 接收寄存器#define THR 0 // transmit holding register (for output bytes) 发送寄存器 这里来理解top部分，主要的作用就是写到uart设备的缓冲区，然后再写到uart的寄存器，通知uart开始发送数据。 后续uart数据发送完成，uart就会产生一个发送完成中断，处理中断的代码就是bottom部分。 bottom部分bottom部分就是cpu处理中断的代码，我们来看cpu是怎么响应一个中断的。 假设键盘生成了一个中断并且发向了PLIC，PLIC会将中断路由给一个特定的CPU核，并且如果这个CPU核设置了SIE寄存器的E bit（针对外部中断的bit位），那么会发生以下事情： 清除SIE寄存器相应的bit，这样可以阻止CPU核被其他中断打扰； 设置SEPC寄存器为当前的PC（保存PC）； 保存当前的mode 设置为supervior mode 设置PC指向STVEC（指向中断向量地址，要么uservec要么kernelvec，uservec在Trampoline页面中） 执行指令 我们知道uservec最终会走向trap.c文件usertrap函数，usertrap会根据中断类型（系统调用or外部中断or计时器中断）作出相应处理。 1which_dev = devintr() 在trap.c的devintr函数中，首先会通过SCAUSE寄存器判断当前中断是否是来自于外设的中断。如果是的话，再调用plic_claim函数来获取中断。 12345678910111213141516171819202122232425262728// check if it's an external interrupt or software interrupt,// and handle it.// returns 2 if timer interrupt,// 1 if other device,// 0 if not recognized.int devintr() { uint64 scause = r_scause(); if((scause &amp; 0x8000000000000000L) &amp;&amp; (scause &amp; 0xff) == 9){ // this is a supervisor external interrupt, via PLIC. // irq indicates which device interrupted. int irq = plic_claim(); if(irq == UART0_IRQ){ uartintr(); } else if(irq == VIRTIO0_IRQ){ virtio_disk_intr(); } else if(irq){ printf(&quot;unexpected interrupt irq=%d\\n&quot;, irq); } // the PLIC allows each device to raise at most one // interrupt at a time; tell the PLIC the device is // now allowed to interrupt again. if(irq) plic_complete(irq); return 1; } ...} 在uartintr函数中，处理uart产生的中断（这个中断可能是发送完成中断，也可能是接收中断）。 123456789101112131415161718192021222324// handle a uart interrupt, raised because input has arrived, // or the uart is ready for more output, or both.void uartintr(void){ // read and process incoming characters. while(1){ int c = uartgetc(); if(c == -1) break; consoleintr(c); } // send buffered characters. acquire(&amp;uart_tx_lock); uartstart(); release(&amp;uart_tx_lock);}int uartgetc(void){ if(ReadReg(LSR) &amp; 0x01){ // input data is ready. return ReadReg(RHR); } else { return -1; }} 我们可以看到uartintr其实是完成两件事情的，读和写。读自己的接收寄存器（uartgetc）和写发送寄存器（userstart）。其中，读完寄存器后，调用consoleintr向console输出键盘。 简要的时钟中断计时器中断发生在机器模式下，在start.c中对CLINT计时器硬件进行编程，然后设置一个scratch区域，类似于trapframe,来存储信息。 The machine-mode timer interrupt handler is timervec (kernel/kernelvec.S:93). It saves a few registers in the scratch area prepared by start, tells the CLINT when to generate the next timer interrupt, asks the RISC-V to raise a software interrupt, restores registers, and returns. There’s no C code in the timer interrupt handler. 总结“$ “传送到屏幕的过程“$ “传送到屏幕的过程其实就是drive驱动的top部分，不过当$发送完成后，uart还会产生一个发送完成中断。此时，恰好有一个并行时序，使得$后的空格被写进uart设备缓冲区，同时cpu处理中断调用uartintr发送缓冲区里数据。此时驱动的top和bottom就解耦了（这里意思是top和bottom不再是串行时序，两者可以并行进行）。 在发送完$后的空格后其实也会产生一个发送完成中断，由于这个中断既无键盘输入，uart的缓冲区又无字符，所以并不会做什么。 刚刚执行shell的core，此时也返回了进程空间，并且继续执行shell。shell又执行gets，最终到sys_read，consoleread，consoleread会一直阻塞自己等待键盘中断传进来字符，所以我们看到启动xv6之后，输出完$ 之后便一直阻塞。 ls\\n的输出过程当我们敲击键盘ls,每一个字符会产生一个接收中断，这里触发中断traps,调用uartintr,调用uartgetc将 l 从寄存器中读出，然后调用consoleintr。 1234567891011121314151617default: if(c != 0 &amp;&amp; cons.e-cons.r &lt; INPUT_BUF){ c = (c == '\\r') ? '\\n' : c; // echo back to the user. consputc(c); // store for consumption by consoleread(). cons.buf[cons.e++ % INPUT_BUF] = c; if(c == '\\n' || c == C('D') || cons.e == cons.r+INPUT_BUF){ // wake up consoleread() if a whole line (or end-of-file) // has arrived. cons.w = cons.e; wakeup(&amp;cons.r); } } The job of consoleintr is to accumulate input characters in cons.buf until a whole line arrives. consoleintr treats backspace and a few other characters specially. When a newline arrives, consoleintr wakes up a waiting consoleread (if there is one). Once woken, consoleread will observe a full line in cons.buf, copy it to user space, and return (via the system call machinery) to user space. cosoleintr默认会将每个字符回显到console，同时也会存储这个字符到cons的buf中，这是为了一旦读到换行时能唤醒consoleread线程（如果有的话），这样consoleread便能返回。于是shell便能解析命令，然后执行。 关于解耦的问题 解耦：谁也不会影响谁 1.进程与设备解耦 2.生产者和消费者解耦 核心就是通过缓冲区和中断机制实现 1.进程不必等待设备输入，干自己的事情就好，设备输入会中断进来。设备也不必等着进程的输出，他要是想输出了把字符放在缓冲区就好。 2.生产者和消费者亦是如此。 谁想干什么事找缓冲区去~ 过buffer将consumer和producer之间解耦，这样它们才能按照自己的速度，独立的并行运行。如果某一个运行的过快了，那么buffer要么是满的要么是空的，consumer和producer其中一个会sleep并等待另一个追上来。 学生提问：这里的buffer对于所有的CPU核都是共享的吗？ Frans教授：这里的buffer存在于内存中，并且只有一份，所以，所有的CPU核都并行的与这一份数据交互。所以我们才需要lock。","link":"/2024/01/12/MIT6.S081/book/chapter5/"},{"title":"MIT6.S081 xv6book chapter6","text":"第六章主要是讲并发编程，为什么要用锁、什么时候使用锁、锁范围、加锁顺序、死锁、可重入锁等知识，还介绍了xv6中自旋锁的实现。 特别要注意xv6中持有锁就不允许中断；内存屏障用于避免指令重排，这些都是锁实现的细节。 本节融合了lec13的内容，总体上属于并发编程入门，信号量、条件变量等多进程同步机制没有介绍，后续章节会涉及。 竞态条件A race condition is a situation in which a memory location is accessed concurrently, and at least one access is a write. 锁是如何避免race condition的，这里有两个很好的描述词：序列化、原子化， You can think of a lock as serializing concurrent critical sections so that they run one at a time, and thus preserve invariants (assuming the critical sections are correct in isolation). You can also think of critical sections guarded by the same lock as being atomic with respect to each other, so that each sees only the complete set of changes from earlier critical sections, and never sees partially-completed updates. 锁的使用什么时候使用锁、使用多少个锁： A hard part about using locks is deciding how many locks to use and which data and invariants each lock should protect. There are a few basic principles. First, any time a variable can be written by one CPU at the same time that another CPU can read or write it, a lock should be used to keep the two operations from overlapping. Second, remember that locks protect invariants: if an invariant involves multiple memory locations, typically all of them need to be protected by a single lock to ensure the invariant is maintained 大内核锁： A simple kernel can do this on a multiprocessor by having a single lock that must be acquired on entering the kernel and released on exiting the kernel (though system calls such as pipe reads or wait would pose a problem). Many uniprocessor operating systems have been converted to run on multiprocessors using this approach, sometimes called a “big kernel lock”, but the approach sacrifices parallelism: only one CPU can execute in the kernel at a time. 如果内核中只有一把大锁，我们暂时将之称为big kernel lock。基本上所有的系统调用都会被这把大锁保护而被序列化。系统调用会按照这样的流程处理：一个系统调用获取到了big kernel lock，完成自己的操作，之后释放这个big kernel lock，再返回到用户空间，之后下一个系统调用才能执行。这样的话，如果我们有一个应用程序并行的调用多个系统调用，这些系统调用会串行的执行， 死锁与锁顺序it is important that all code paths acquire those locks in the same order. 获取锁的顺序很重要，如果所有获锁的代码都遵从相同的获锁顺序，那么是不会造成死锁的，但现实中获锁的顺序取决于代码逻辑。 对于一个系统设计者，你需要确定对于所有的锁对象的全局的顺序。例如在这里的例子中我们让d1一直在d2之前，这样我们在rename的时候，总是先获取排序靠前的目录的锁，再获取排序靠后的目录的锁。如果对于所有的锁有了一个全局的排序，这里的死锁就不会出现了。 不过在设计一个操作系统的时候，定义一个全局的锁的顺序会有些问题。如果一个模块m1中方法g调用了另一个模块m2中的方法f，那么m1中的方法g需要知道m2的方法f使用了哪些锁。因为如果m2使用了一些锁，那么m1的方法g必须集合f和g中的锁，并形成一个全局的锁的排序。这意味着在m2中的锁必须对m1可见，这样m1才能以恰当的方法调用m2。 但是这样又违背了代码抽象的原则。在完美的情况下，代码抽象要求m1完全不知道m2是如何实现的。但是不幸的是，具体实现中，m2内部的锁需要泄露给m1，这样m1才能完成全局锁排序。所以当你设计一些更大的系统时，锁使得代码的模块化更加的复杂了。 可重入锁The idea is that if the lock is held by a process and if that process attempts to acquire the lock again, then the kernel could just allow this (since the process already has the lock), instead of calling panic, as the xv6 kernel does But if re-entrant locks are allowed, and h happens to call g, call_once will be called twice. If re-entrant locks aren’t allowed, then h calling g results in a deadlock, which is not great either. 可重入锁有优点有缺点，缺点就是它使得并发编程更加复杂了，优点是至少能避免一些死锁的情况。 自旋锁的实现：原子指令锁的特性就是只有一个进程可以获取锁，在任何时间点都不能有超过一个锁的持有者。 1234567struct spinlock { uint locked; // Is the lock held? 1 is held. // For debugging: char *name; // Name of lock. struct cpu *cpu; // The cpu holding the lock.}; 实现锁的难点就在于看的动作和写的动作的不连续，中间可能被打断。 1234567void acquire(struct spinlock *lk) // does not work!{ for(;;) { if(lk-&gt;locked == 0) { lk-&gt;locked = 1; break; }} } 上面这段代码并不能实现acquire语义，问题就出在两个进程可以同时进入到判断锁的那一行，此时locked都为0，两个进程会同时将locked设置为1。这其实是三个操作（读locked、判断locked、写locked）的原子性，如果这三个操作是合在一起的， 便能保证正确性。 解决的方法是依赖于一个特殊的硬件指令，这个特殊的硬件指令会保证一次test-and-set操作的原子性，在RISC-V上，这个特殊的指令就是amoswap（atomic memory swap）原子交换。 The acquire function wraps the swap in a loop, retrying (spinning) until it has acquired the lock. Each iteration swaps one into lk-&gt;locked and checks the previous value; if the previous value is zero, then we’ve acquired the lock, and the swap will have set lk-&gt;locked to one. If the previous value is one, then some other CPU holds the lock, and the fact that we atomically swapped one into lk-&gt;locked didn’t change its value. 在获取锁时用1去交换，然后判断获取的旧值是否为0，为0说明获得了锁，为1说明此时有其他进程获得了锁，那么交换的1没有改变着之前的值。 这其实就是保证了锁的唯一性。将1看成苹果，将0看成锁，锁放在桌子上。每个都用苹果换桌子上的东西，如果换到锁，那么说明我拿到锁了，并且这个锁不会再被别人拿到。如果换到苹果，那也只是等价交换，桌子上还是苹果。 acquire12345678910void acquire(struct spinlock *lk) { push_off(); // disable interrupts to avoid deadlock. if(holding(lk)) panic(&quot;acquire&quot;); while(__sync_lock_test_and_set(&amp;lk-&gt;locked, 1) != 0) ; __sync_synchronize(); lk-&gt;cpu = mycpu();} 这里先忽略push_off的作用，可以看到在函数中有一个while循环，这就是刚刚提到的test-and-set循环。实际上C的标准库已经定义了这些原子操作，所以C标准库中已经有一个函数__sync_lock_test_and_set。 12345while(__sync_lock_test_and_set(&amp;lk-&gt;locked, 1) != 0) 800061b4: 87ba mv a5,a4 800061b6: 0cf4a7af amoswap.w.aq a5,a5,(s1) 800061ba: 2781 sext.w a5,a5 800061bc: ffe5 bnez a5,800061b4 &lt;acquire+0x22&gt; release1234567891011void release(struct spinlock *lk) { if(!holding(lk)) panic(&quot;release&quot;); lk-&gt;cpu = 0; __sync_synchronize(); __sync_lock_release(&amp;lk-&gt;locked); pop_off();} 释放锁的过程就是将locked字段原子更新为0的过程。为什么需要原子更新？ 因为更新的操作其实有三个步骤：读地址值到寄存器、修改寄存器的值、再将寄存器的值写回到内存。 锁与中断处理程序123456789101112131415161718192021222324252627// Per-CPU state.struct cpu { struct proc *proc; // The process running on this cpu, or null. struct context context; // swtch() here to enter scheduler(). int noff; // Depth of push_off() nesting. push off的嵌套层次 int intena; // Were interrupts enabled before push_off()? 中断是否开启};void push_off(void){ int old = intr_get(); intr_off(); if(mycpu()-&gt;noff == 0) mycpu()-&gt;intena = old; mycpu()-&gt;noff += 1;}void pop_off(void){ struct cpu *c = mycpu(); if(intr_get()) panic(&quot;pop_off - interruptible&quot;); if(c-&gt;noff &lt; 1) panic(&quot;pop_off&quot;); c-&gt;noff -= 1; if(c-&gt;noff == 0 &amp;&amp; c-&gt;intena) intr_on();} acquire calls push_off (kernel/spinlock.c:89) and release calls pop_off (kernel/spinlock.c:100) to track the nesting level of locks on the current CPU. When that count reaches zero, pop_off restores the interrupt enable state that existed at the start of the outermost critical section. 第二个细节是，在acquire函数的最开始，会先关闭中断。为什么会是这样呢？先来假设acquire在一开始并没有关闭中断。在uartputc函数中，首先会acquire锁，如果不关闭中断会发生什么呢？uartputc函数会acquire锁，UART本质上就是传输字符，当UART完成了字符传输它会做什么？是的，它会产生一个中断之后会运行uartintr函数，在uartintr函数中，会获取同一把锁，但是这把锁正在被uartputc持有。如果这里只有一个CPU的话，那这里就是死锁。 所以spinlock需要处理两类并发，一类是不同CPU之间的并发，一类是相同CPU上中断和普通程序之间的并发。 更深层次的原因是：锁会在各种各样的地方被用到，从用户程序到中断处理程序。而中断又是时时刻刻发生的，如果用户程序持有锁的同时发生中断，中断处理程序又要求获得同一把锁，就会发生死锁。 xv6解决的方法粗暴有效：when a CPU acquires any lock, xv6 always disables interrupts on that CPU. 哪个CPU持有锁就不允许那个CPU处理中断。 还要注意点的是： 关中断在获锁前，开中断在释放锁后； noff追踪了锁嵌套的层次（track the nesting level of locks on the current CPU），只有最后一个锁释放后才能开中断。 指令重排It is natural to think of programs executing in the order in which source code statements appear. Many compilers and CPUs, however, execute code out of order to achieve higher performance.The CPU’s ordering rules are called the memory model. 简单来说，CPU或编译器为了更好的执行性能，通常会调整一些代码的执行顺序。而这会使得锁失效，因为关键区的代码可能会被移到关键区外。 避免指令重排是通过一条硬件指令，内存屏障（memory fence或者叫做synchronize指令）来确定指令的移动范围。对于synchronize指令，任何在它之前的load/store指令，都不能移动到它之后。 那么，通过两个内存屏障，加锁时一个，释放锁时一个，就能避免指令乱排带来的后果。 学生提问：有没有可能在锁acquire之前的一条指令被移到锁release之后？或者说这里会有一个界限不允许这么做？ Frans教授：在这里的例子中，acquire和release都有自己的界限（注，也就是__sync_synchronize函数的调用点）。所以发生在锁acquire之前的指令不会被移到acquire的__sync_synchronize函数调用之后，这是一个界限。在锁的release函数中有另一个界限。所以在第一个界限之前的指令会一直在这个界限之前，在两个界限之间的指令会保持在两个界限之间，在第二个界限之后的指令会保持在第二个界限之后。 学生提问：在一个处理器上运行多个线程与在多个处理器上运行多个进程是否一样？ Frans教授：差不多吧，如果你有多个线程，但是只有一个CPU，那么你还是会想要特定内核代码能够原子执行。所以你还是需要有critical section的概念。你或许不需要锁，但是你还是需要能够对特定的代码打开或者关闭中断。如果你查看一些操作系统的内核代码，通常它们都没有锁的acquire，因为它们假定自己都运行在单个处理器上，但是它们都有开关中断的操作。 Sleep locksHolding a spinlock that long would lead to waste if another process wanted to acquire it, since the acquiring process would waste CPU for a long time while spinning. Another drawback of spinlocks is that a process cannot yield the CPU while retaining a spinlock; we’d like to do this so that other processes can use the CPU while the process with the lock waits for the disk. Yielding while holding a spinlock is illegal because it might lead to deadlock if a second thread then tried to acquire the spinlock; since acquire doesn’t yield the CPU, the second thread’s spinning might prevent the first thread from running and releasing the lock. Yielding while holding a lock would also violate the requirement that interrupts must be off while a spinlock is held. Thus we’d like a type of lock that yields the CPU while waiting to acquire, and allows yields (and interrupts) while the lock is held. 自旋锁的坏处在于尝试获取锁时必须让CPU自旋重试，因此自旋锁不能用于持锁时间长的场景。那么我们会想要这么一种锁：尝试获锁能够让出CPU，而在持有锁时又允许中断，这将会在后来介绍。","link":"/2024/01/13/MIT6.S081/book/chapter6/"},{"title":"MIT6.S081 xv6book chapter7","text":"第七章讲述了xv6中线程调度的机制，核心就是swtch函数以及调度器内核线程。在线程调度的基础上，讲述了线程同步的一个机制：sleep&amp;wakeup（其实就是条件变量）。有了同步机制后，继续展开讲进程退出、资源回收等知识。fork+exec+wait 一套流程。 融合了lec11和lec13的内容，两节课的内容，收获颇丰。 线程概述首先，线程可以认为是一种在有多个任务时简化编程的抽象。线程是串行执行代码的单元，尽管有许多不同线程的定义，在这里我们可以认为线程就是耽搁串行执行代码的单元，它只占用一个CPU并且以普通的方式一个接一个执行指令。 除此之外，线程还具有状态，我们可以随时保存线程的状态并暂停线程的运行，并在之后通过恢复状态来恢复线程的运行。 线程的状态包括： 程序计数器 寄存器 栈（Stack记录了函数调用的记录，并反映了当前线程的执行点） 多线程的并行运行主要有两个策略： 多核处理器，每个CPU对应运行一个线程，每个线程自动的根据所在CPU就有了程序计数器和寄存器。 一个CPU对应多个线程，一个CPU在多个线程之间来回切换。 实际上，与大多数其他操作系统一样，XV6结合了这两种策略，首先线程会运行在所有可用的CPU核上，其次每个CPU核会在多个线程之间切换，因为通常来说，线程数会远远多于CPU的核数。xv6的线程切换主要是时间片轮转（先运行一个线程，之后将线程的状态保存，再切换至运行第二个线程，然后再是第三个线程，依次类推直到每个线程都运行了一会，再回来重新执行第一个线程） 不同线程系统之间的一个主要的区别就是，线程之间是否会共享内存。一种可能是你有一个地址空间，多个线程都在这一个地址空间内运行，并且它们可以看到彼此的更新。 XV6内核共享了内存，并且XV6支持内核线程的概念，对于每个用户进程都有一个内核线程来执行来自用户进程的系统调用。所有的内核线程都共享了内核内存，所以XV6的内核线程的确会共享内存。 多核能够进行线程切换的前提是：多个CPU核心共享同一套内存。 xv6线程调度线程调度的难点： 第一个是如何实现线程间的切换。这里停止一个线程的运行并启动另一个线程的过程通常被称为线程调度（Scheduling）。 第二个挑战是，当你想要实际实现从一个线程切换到另一个线程时，你需要保存并恢复线程的状态，所以需要决定线程的哪些信息是必须保存的，并且在哪保存它们。 最后一个挑战是如何处理运算密集型线程（compute bound thread）。对于线程切换，很多直观的实现是由线程自己自愿的保存自己的状态，再让其他的线程运行。但是如果我们有一些程序正在执行一些可能要花费数小时的长时间计算任务，这样的线程并不能自愿的出让CPU给其他的线程运行。所以这里需要能从长时间运行的运算密集型线程撤回对于CPU的控制，将其放置于一边，稍后再运行它。 处理运算密集线程的答案就是定时器中断，定时器中断（比如说每隔10ms触发），能将程序运行的控制权从用户空间代码切换到内核中的中断处理程序。这里的基本流程是，定时器中断将CPU控制权给到内核，内核再自愿的出让CPU。 在执行线程调度的时候，调度程序需要能区分几类线程： 当前在CPU上运行的线程 RUNNING 一旦CPU有空闲时间就想要运行在CPU上的线程 RUNABLE 以及不想运行在CPU上的线程，因为这些线程可能在等待I/O或者其他事件 SLEEPING 对于RUNNING状态下的线程，它的程序计数器和寄存器位于正在运行它的CPU硬件中。UNABLE线程需要保存它的状态信息，我们需要拷贝的信息就是程序计数器（Program Counter）和寄存器。当线程调度器决定要运行一个RUNABLE线程时，这里涉及了很多步骤，但是其中一步是将之前保存的程序计数器和寄存器拷贝回调度器对应的CPU中。 学生提问：当一个线程结束执行了，比如说在用户空间通过exit系统调用结束线程，同时也会关闭进程的内核线程。那么线程结束之后和下一个定时器中断之间这段时间，CPU仍然会被这个线程占有吗？还是说我们在结束线程的时候会启动一个新的线程？ Robert教授：exit系统调用会出让CPU。尽管我们这节课主要是基于定时器中断来讨论，但是实际上XV6切换线程的绝大部分场景都不是因为定时器中断，比如说一些系统调用在等待一些事件并决定让出CPU。exit系统调用会做各种操作然后调用yield函数来出让CPU，这里的出让并不依赖定时器中断。 线程切换过程 xv6实现线程切换相当曲折： 首先用户程序会因为定时器中断陷入内核（走到内核线程），此时用户空间的状态已经保存在trapframe中； 从第一个用户内核线程切换到内核线程调度线程； 线程调度程序再切换到第二个用户内核线程； 第二个用户进程从内核态返回到用户态。 其中，从一个内核线程切换到另一个内核线程，需要保存旧线程的状态到context对象中，然后恢复从新的contex对象恢复另一个内核线程的状态（其实就是调用swtch函数） 学生提问：context保存在哪？ Robert教授：每一个内核线程都有一个context对象。但是内核线程实际上有两类。每一个用户进程有一个对应的内核线程，它的context对象保存在用户进程对应的proc结构体中。 每一个调度器线程，它也有自己的context对象，但是它却没有对应的进程和proc结构体，所以调度器线程的context对象保存在cpu结构体中。在内核中，有一个cpu结构体的数组，每个cpu结构体对应一个CPU核，每个结构体中都有一个context字段。 学生提问：为什么不能将context对象保存在进程对应的trapframe中？ Robert教授：context可以保存在trapframe中，因为每一个进程都只有一个内核线程对应的一组寄存器，我们可以将这些寄存器保存在任何一个与进程一一对应的数据结构中。对于每个进程来说，有一个proc结构体，有一个trapframe结构体，所以我们可以将context保存于trapframe中。但是或许出于简化代码或者让代码更清晰的目的，trapframe还是只包含进入和离开内核时的数据。而context结构体中包含的是在内核线程和调度器线程之间切换时，需要保存和恢复的数据。 学生提问：出让CPU是由用户发起的还是由内核发起的？ Robert教授：对于XV6来说，并不会直接让用户线程出让CPU或者完成线程切换，而是由内核在合适的时间点做决定。有的时候你可以猜到特定的系统调用会导致出让CPU，例如一个用户进程读取pipe，而它知道pipe中并不能读到任何数据，这时你可以预测读取会被阻塞，而内核在等待数据的过程中会运行其他的进程。 内核会在两个场景下出让CPU。当定时器中断触发了，内核总是会让当前进程出让CPU，因为我们需要在定时器中断间隔的时间点上交织执行所有想要运行的进程。另一种场景就是任何时候一个进程调用了系统调用并等待I/O，例如等待你敲入下一个按键，在你还没有按下按键时，等待I/O的机制会触发出让CPU。 学生提问：每一个CPU的调度器线程有自己的栈吗？ Robert教授：是的，每一个调度器线程都有自己独立的栈。实际上调度器线程的所有内容，包括栈和context，与用户进程不一样，都是在系统启动时就设置好了。如果你查看XV6的start.s（注：是entry.S和start.c）文件，你就可以看到为每个CPU核设置好调度器线程。 学生提问：我们这里一直在说线程，但是从我看来XV6的实现中，一个进程就只有一个线程，有没有可能一个进程有多个线程？ Robert教授：我们这里的用词的确有点让人混淆。在XV6中，一个进程要么在用户空间执行指令，要么是在内核空间执行指令，要么它的状态被保存在context和trapframe中，并且没有执行任何指令。这里该怎么称呼它呢？你可以根据自己的喜好来称呼它，对于我来说，每个进程有两个线程，一个用户空间线程，一个内核空间线程，并且存在限制使得一个进程要么运行在用户空间线程，要么为了执行系统调用或者响应中断而运行在内核空间线程 ，但是永远也不会两者同时运行。 线程调度代码yield12345678// Give up the CPU for one scheduling round.void yield(void) { struct proc *p = myproc(); acquire(&amp;p-&gt;lock); p-&gt;state = RUNNABLE; sched(); release(&amp;p-&gt;lock);} 线程切换的第一步（实际是内核线程的第一步），放弃CPU，调用sched切换到调度器程序。 sched123456789101112131415161718192021222324// Switch to scheduler.// Must hold only p-&gt;lock and have changed proc-&gt;state.// Saves and restores intena because// intena is a property of this kernel thread, not this CPU.// It should be proc-&gt;intena and proc-&gt;noff, but that would// break in the few places where a lock is held but// there's no process.void sched(void) { int intena; struct proc *p = myproc(); if(!holding(&amp;p-&gt;lock)) panic(&quot;sched p-&gt;lock&quot;); if(mycpu()-&gt;noff != 1) // 禁止持有p-&gt;lock以外的其他锁 panic(&quot;sched locks&quot;); if(p-&gt;state == RUNNING) panic(&quot;sched running&quot;); if(intr_get()) // 持有锁时不允许中断开启 panic(&quot;sched interruptible&quot;); intena = mycpu()-&gt;intena; swtch(&amp;p-&gt;context, &amp;mycpu()-&gt;context); mycpu()-&gt;intena = intena;} 这里其实有几个问题：为什么线程切换的时候禁止持有除了进程锁之外的其他锁？为什么要持有进程锁进行线程切换？ usually the thread that acquires a lock is also responsible for releasing the lock, which makes it easier to reason about correctness 一个进程持有锁同时也负有责任去释放锁 For context switching it is necessary to break this convention because p-&gt;lock protects invariants on the process’s state and context fields that are not true while executing in swtch. 但是context switch打破了这个常规。 One example of a problem that could arise if p-&gt;lock were not held during swtch: a different CPU might decide to run the process after yield had set its state to RUNNABLE, but before swtch caused it to stop using its own kernel stack. The result would be two CPUs running on the same stack, which would cause chaos. 因为yield将进程状态设置为runnable，如果提前释放锁，其他CPU就有可能运行这个进程，而此时进程还没完成内核栈的切换。两个CPU使用同一个内核栈会造成错误。 More reading One way to think about the structure of the scheduling code is that it enforces a set of invariants about each process, and holds p-&gt;lock whenever those invariants are not true. One invariant is that if a process is RUNNING, a timer interrupt’s yield must be able to safely switch away from the process; this means that the CPU registers must hold the process’s register values (i.e. swtch hasn’t moved them to a context), and c-&gt;proc must refer to the process. Another invariant is that if a process is RUNNABLE, it must be safe for an idle CPU’s scheduler to run it; this means that p-&gt;context must hold the process’s registers (i.e., they are not actually in the real registers), that no CPU is executing on the process’s kernel stack, and that no CPU’s c-&gt;proc refers to the process. Observe that these properties are often not true while p-&gt;lock is held. Maintaining the above invariants is the reason why xv6 often acquires p-&gt;lock in one thread and releases it in another, for example acquiring in yield and releasing in scheduler. Once yield has started to modify a running process’s state to make it RUNNABLE, the lock must remain held until the invariants are restored: the earliest correct release point is after scheduler (running on its own stack) clears c-&gt;proc. Similarly, once scheduler starts to convert a RUNNABLE pro- cess to RUNNING, the lock cannot be released until the kernel thread is completely running (after the swtch, for example in yield). Swtch.S123456789101112131415161718192021222324252627282930313233.globl swtchswtch: sd ra, 0(a0) sd sp, 8(a0) sd s0, 16(a0) sd s1, 24(a0) sd s2, 32(a0) sd s3, 40(a0) sd s4, 48(a0) sd s5, 56(a0) sd s6, 64(a0) sd s7, 72(a0) sd s8, 80(a0) sd s9, 88(a0) sd s10, 96(a0) sd s11, 104(a0) ld ra, 0(a1) ld sp, 8(a1) ld s0, 16(a1) ld s1, 24(a1) ld s2, 32(a1) ld s3, 40(a1) ld s4, 48(a1) ld s5, 56(a1) ld s6, 64(a1) ld s7, 72(a1) ld s8, 80(a1) ld s9, 88(a1) ld s10, 96(a1) ld s11, 104(a1) ret 真正执行切换的其实是switch汇编代码，swtch函数会将当前的内核线程的寄存器保存到p-&gt;context中。swtch函数的另一个参数c-&gt;context，c表示当前CPU的结构体。CPU结构体中的context保存了当前CPU核的调度器线程的寄存器。所以swtch函数在保存完当前内核线程的内核寄存器之后，就会恢复当前CPU核的调度器线程的寄存器，并继续执行当前CPU核的调度器线程。 注意两个特殊的寄存器ra和sp。ra寄存器保存的是当前函数的返回地址，所以调度器线程中的代码会返回到ra寄存器中的地址，sp则切换了内核栈。 这里有个有趣的问题，或许你们已经注意到了。swtch函数的上半部分保存了ra，sp等等寄存器，但是并没有保存程序计数器pc（Program Counter），为什么会这样呢？ 学生回答：因为程序计数器不管怎样都会随着函数调用更新。 是的，程序计数器并没有有效信息，我们现在知道我们在swtch函数中执行，所以保存程序计数器并没有意义。但是我们关心的是我们是从哪调用进到swtch函数的，因为当我们通过switch恢复执行当前线程并且从swtch函数返回时，我们希望能够从调用点继续执行。 另一个问题是，为什么RISC-V中有32个寄存器，但是swtch函数中只保存并恢复了14个寄存器？ 学生回答：因为switch是按照一个普通函数来调用的，对于有些寄存器，swtch函数的调用者默认swtch函数会做修改，所以调用者已经在自己的栈上保存了这些寄存器，当函数返回时，这些寄存器会自动恢复。所以swtch函数里只需要保存Callee Saved Register就行。（注，详见5.4） Caller saved寄存器，在函数调用中需要caller主动保存的寄存器。因此，callee可以直接自由更改这些寄存器，而不需要其他额外操作。 Callee saved寄存器则对称相反，caller可以直接修改这些寄存器而不用保存。 scheduler12345678910111213141516171819202122232425262728293031323334// Per-CPU process scheduler.// Each CPU calls scheduler() after setting itself up.// Scheduler never returns. It loops, doing:// - choose a process to run.// - swtch to start running that process.// - eventually that process transfers control// via swtch back to the scheduler.void scheduler(void) { struct proc *p; struct cpu *c = mycpu(); c-&gt;proc = 0; for(;;){ // Avoid deadlock by ensuring that devices can interrupt. intr_on(); for(p = proc; p &lt; &amp;proc[NPROC]; p++) { acquire(&amp;p-&gt;lock); if(p-&gt;state == RUNNABLE) { // Switch to chosen process. It is the process's job // to release its lock and then reacquire it // before jumping back to us. p-&gt;state = RUNNING; c-&gt;proc = p; swtch(&amp;c-&gt;context, &amp;p-&gt;context); // Process is done running for now. // It should have changed its p-&gt;state before coming back. c-&gt;proc = 0; } release(&amp;p-&gt;lock); } }} 可以看到调度器程序其实就是一个无限循环，不断从所有进程中挑选能够运行的程序，然后swtch到那个程序。同理，其他程序会swtch到scheduler调用swtch函数的那一行。每个CPU都有调度器，在xv6启动过程中kernel/main.c会调用scheduler。 然后我们还注意到 acquire(&amp;p-&gt;lock);，因为要修改进程的状态，但是在swtch之前我们都没有释放锁，这是为什么？与前面同理。 The only place a kernel thread gives up its CPU is in sched, and it always switches to the same location in scheduler, which (almost) always switches to some kernel thread that previously called sched. Thus, if one were to print out the line numbers where xv6 switches threads, one would observe the following simple pattern: (kernel/proc.c:456), (kernel/proc.c:490), (kernel/proc.c:456), (kernel/proc.c:490), and so on. 线程调用swtch总是切换到另一个线程调用swtch的地方，那么第一个线程调用swtch它切换到哪里？在第一个线程之前，没有其他线程之前调用过swtch。 学生提问：当调用swtch函数的时候，实际上是从一个线程对于switch的调用切换到了另一个线程对于switch的调用。所以线程第一次调用swtch函数时，需要伪造一个“另一个线程”对于switch的调用，是吧？因为也不能通过swtch函数随机跳到其他代码去。 Robert教授：是的。我们来看一下第一次调用switch时，“另一个”调用swtch函数的线程的context对象。proc.c文件中的allocproc函数会被启动时的第一个进程和fork调用，allocproc会设置好新进程的context，如下所示： 12345// Set up new context to start executing at forkret,// which returns to user space.memset(&amp;p-&gt;context, 0, sizeof(p-&gt;context));p-&gt;context.ra = (uint64)forkret;p-&gt;context.sp = p-&gt;kstack + PGSIZE; 再看forkret 123456789101112131415161718// A fork child's very first scheduling by scheduler()// will swtch to forkret.void forkret(void) { static int first = 1; // Still holding p-&gt;lock from scheduler. release(&amp;myproc()-&gt;lock); if (first) { // File system initialization must be run in the context of a // regular process (e.g., because it calls sleep), and thus cannot // be run from main(). first = 0; fsinit(ROOTDEV); } usertrapret();} 从代码中看，它的工作其实就是释放调度器之前获取的锁。函数最后的usertrapret函数其实也是一个假的函数，它会使得程序表现的看起来像是从trap中返回，但是对应的trapframe其实也是假的，这样才能跳到用户的第一个指令中。 学生提问：与之前的context对象类似的是，对于trapframe也不用初始化任何寄存器，因为我们要去的是程序的最开始，所以不需要做任何假设，对吧？ Robert教授：我认为程序计数器还是要被初始化为0的。 线程切换持锁限制xv6切换中，进程在调用switch函数的过程中，必须要持有p-&gt;lock（注，也就是进程对应的proc结构体中的锁），但是同时又不能持有任何其他的锁。 这是为什么？构建一个场景： 我们有进程P1，P1的内核线程持有了p-&gt;lock以外的其他锁，这些锁可能是在使用磁盘，UART，console过程中持有的。之后内核线程在持有锁的时候，通过调用switch/yield/sched函数出让CPU，这会导致进程P1持有了锁，但是进程P1又不在运行。 假设我们在一个只有一个CPU核的机器上，假设P2也想使用磁盘，UART或者console，它会对P1持有的锁调用acquire，这是对于同一个锁的第二个acquire调用。当然这个锁现在已经被P1持有了，所以这里的acquire并不能获取锁。但是很明显进程P2的acquire不会返回，所以即使进程P2稍后愿意出让CPU，P2也没机会这么做。这就造成了死锁。 Sleep &amp; Wakeup当你在写一个线程的代码时，有些场景需要等待一些特定的事件，或者不同的线程之间需要交互。比如 读pipe，等待pipe的非空事件 读磁盘，等待磁盘读完成 wait函数，等待子进程推出 怎么能让进程或者线程等待一些特定的事件呢？一种非常直观的方法是通过循环实现busy-wait，但是浪费CPU。 123456789101112131415struct semaphore { struct spinlock lock; int count;}void V(struct semaphore* s){ acquire(&amp;s-&gt;lock); s-&gt;count += 1; release(&amp;s-&gt;lock);}void P(struct semaphore* s){ while(s-&gt;count==0) ; //busy-waitting acquire(&amp;s-&gt;lock); s-&gt;count-=1; release(&amp;s-&gt;lock);} 我们希望能够在等待的时候让出CPU，然后在事件完成时重新获取CPU。Coordination就是出让CPU，直到等待的事件发生再恢复执行。人们发明了很多不同的Coordination的实现方式，但是与许多Unix风格操作系统一样，XV6使用的是Sleep&amp;Wakeup这种方式。 这里的机制是，如果一个线程需要等待某些事件，比如说等待UART硬件愿意接收一个新的字符，线程调用sleep函数并等待一个特定的条件。当特定的条件满足时，代码会调用wakeup函数。这里的sleep函数和wakeup函数是成对出现的。还需要注意：sleep和wakeup函数需要通过某种方式链接到一起。也就是说，如果我们调用wakeup函数，我们只想唤醒正在等待刚刚发生的特定事件的线程。所以，sleep函数和wakeup函数都带有一个叫做sleep channel的参数，我们在调用wakeup的时候，需要传入与调用sleep函数相同的sleep channel。 以信号量为例谈实现The basic idea is to have sleep mark the current process as SLEEPING and then call sched to release the CPU; wakeup looks for a process sleeping on the given wait channel and marks it as RUNNABLE. sleep函数做的事情很简单，将进程标记为sleep，记录channel（p-&gt;ch)到进程然后调用sched让出CPU；wakeup查找在相应channel（p-&gt;ch)上睡眠的进程，然后将其标记为runnable。 12345678910111213void V(struct semaphore* s){ acquire(&amp;s-&gt;lock); s-&gt;count += 1; wakeup(s); //唤醒 release(&amp;s-&gt;lock);}void P(struct semaphore* s){ while(s-&gt;count==0) sleep(s); //睡眠 acquire(&amp;s-&gt;lock); s-&gt;count-=1; release(&amp;s-&gt;lock);} 但如果sleep和wakeup都只带一个channel参数会出现lost wakeup问题：P刚判断完count为0，V就调整count值加一并且执行了wakeup，此时P还未睡眠，这个wakeup就丢失了。也就是说，P的判断count和sleep之间不是原子的。 解决这个问题也很简单，将锁上移，保护count。 12345678910111213void V(struct semaphore* s){ acquire(&amp;s-&gt;lock); s-&gt;count += 1; wakeup(s); //唤醒 release(&amp;s-&gt;lock);}void P(struct semaphore* s){ acquire(&amp;s-&gt;lock); // 锁上移 while(s-&gt;count==0) sleep(s); //睡眠 s-&gt;count-=1; release(&amp;s-&gt;lock);} 但这就带来了严重的问题：死锁。P带着锁睡眠，count将永远得不到更新，其他进程也得不到锁。 所以sleep的实现需要修改：增加一个额外参数，条件锁。在它将进程标记为sleep后要能够释放锁，然后在sleep返回时，还需要能获得锁。 正确实现123456789101112131415161718192021222324252627282930313233343536// Atomically release lock and sleep on chan.// Reacquires lock when awakened.void sleep(void *chan, struct spinlock *lk) { struct proc *p = myproc(); acquire(&amp;p-&gt;lock); release(lk); // Go to sleep. p-&gt;chan = chan; p-&gt;state = SLEEPING; sched(); //放弃CPU // Tidy up. p-&gt;chan = 0; // Reacquire original lock. release(&amp;p-&gt;lock); acquire(lk);}// Wake up all processes sleeping on chan.// Must be called without any p-&gt;lock.void wakeup(void *chan) { struct proc *p; for(p = proc; p &lt; &amp;proc[NPROC]; p++) { if(p != myproc()){ acquire(&amp;p-&gt;lock); if(p-&gt;state == SLEEPING &amp;&amp; p-&gt;chan == chan) { p-&gt;state = RUNNABLE; } release(&amp;p-&gt;lock); } }} 注意点： sleep依靠线程切换sched来放弃CPU的控制权； sleep在内部使用了两把锁：一把进程锁，一把是参数的条件锁； 参数中的条件锁提示sleep要和锁一起使用； sleep和wakeup通过一个channel参数联系在一起； sleep在sched返回后，还需要自动获得条件锁。 It is sometimes the case that multiple processes are sleeping on the same channel; for example, more than one process reading from a pipe. A single call to wakeup will wake them all up. One of them will run first and acquire the lock that sleep was called with, and (in the case of pipes) read whatever data is waiting in the pipe. The other processes will find that, despite being woken up, there is no data to be read. From their point of view the wakeup was “spurious,” and they must sleep again. For this reason sleep is always called inside a loop that checks the condition. xv6中的sleep和wakeup机制其实就是条件变量。 使用例子：pipe123456789101112131415161718192021222324int piperead(struct pipe *pi, uint64 addr, int n){ int i; struct proc *pr = myproc(); char ch; acquire(&amp;pi-&gt;lock); while(pi-&gt;nread == pi-&gt;nwrite &amp;&amp; pi-&gt;writeopen){ //DOC: pipe-empty if(pr-&gt;killed){ release(&amp;pi-&gt;lock); return -1; } sleep(&amp;pi-&gt;nread, &amp;pi-&gt;lock); //DOC: piperead-sleep } for(i = 0; i &lt; n; i++){ //DOC: piperead-copy if(pi-&gt;nread == pi-&gt;nwrite) break; ch = pi-&gt;data[pi-&gt;nread++ % PIPESIZE]; if(copyout(pr-&gt;pagetable, addr + i, &amp;ch, 1) == -1) break; } wakeup(&amp;pi-&gt;nwrite); //DOC: piperead-wakeup release(&amp;pi-&gt;lock); return i;} 代码第7行，如果pipe为空，需要等待写事件。需要注意的是，直接用nread作为sleep和wakeup的联系，因为nread只会在pipread中得到更新。 1234567891011121314151617181920212223242526int pipewrite(struct pipe *pi, uint64 addr, int n){ int i = 0; struct proc *pr = myproc(); acquire(&amp;pi-&gt;lock); while(i &lt; n){ if(pi-&gt;readopen == 0 || pr-&gt;killed){ release(&amp;pi-&gt;lock); return -1; } if(pi-&gt;nwrite == pi-&gt;nread + PIPESIZE){ //DOC: pipewrite-full wakeup(&amp;pi-&gt;nread); sleep(&amp;pi-&gt;nwrite, &amp;pi-&gt;lock); } else { char ch; if(copyin(pr-&gt;pagetable, &amp;ch, addr + i, 1) == -1) break; pi-&gt;data[pi-&gt;nwrite++ % PIPESIZE] = ch; i++; } } wakeup(&amp;pi-&gt;nread); release(&amp;pi-&gt;lock); return i;} 进程相关exit系统调用每个进程最终都需要退出，我们需要清除进程的状态，释放栈。在XV6中，一个进程如果退出的话，我们需要释放用户内存，释放page table，释放trapframe对象，将进程在进程表单中标为REUSABLE，这些都是典型的清理步骤。 两大问题： 不能直接单方面的摧毁另一个线程（指kill），如果我们直接就把线程杀掉了，我们可能在线程完成更新复杂的内核数据过程中就把线程杀掉了。 即使一个线程调用了exit系统调用是自己决定要退出，但它仍然持有运行代码所需要的一些资源，例如它的栈，以及它在进程表单中的位置。当它还在执行代码，它就不能释放正在使用的资源。 123456789101112131415161718192021222324252627282930313233343536373839void exit(int status) { struct proc *p = myproc(); if(p == initproc) panic(&quot;init exiting&quot;); // Close all open files. for(int fd = 0; fd &lt; NOFILE; fd++){ if(p-&gt;ofile[fd]){ struct file *f = p-&gt;ofile[fd]; fileclose(f); p-&gt;ofile[fd] = 0; } } begin_op(); iput(p-&gt;cwd); end_op(); p-&gt;cwd = 0; acquire(&amp;wait_lock); // Give any children to init. reparent(p); // Parent might be sleeping in wait(). wakeup(p-&gt;parent); acquire(&amp;p-&gt;lock); p-&gt;xstate = status; p-&gt;state = ZOMBIE; release(&amp;wait_lock); // Jump into the scheduler, never to return. sched(); panic(&quot;zombie exit&quot;);} 首先exit函数关闭了所有已打开的文件。接下来是类似的处理，进程有一个对于当前目录的记录，这个记录会随着你执行cd指令而改变。在exit过程中也需要将对这个目录的引用释放给文件系统。 如果一个进程要退出，但是它又有自己的子进程，接下来需要设置这些子进程的父进程为init进程(父进程中的wait系统调用会完成进程退出最后的几个步骤。所以如果父进程退出了，那么子进程就不再有父进程，当它们要退出时就没有对应的父进程的wait。所以在exit函数中，会为即将exit进程的子进程重新指定父进程为init进程，也就是PID为1的进程)。 之后，我们需要通过调用wakeup函数唤醒当前进程的父进程，当前进程的父进程或许正在等待当前进程退出。 接下来，进程的状态被设置为ZOMBIE。现在进程还没有完全释放它的资源，所以它还不能被重用。 现在我们还没有结束，因为我们还没有释放进程资源。我们在还没有完全释放所有资源的时候，通过调用sched函数进入到调度器线程。 到目前位置，进程的状态是ZOMBIE，并且进程不会再运行，因为调度器只会运行RUNNABLE进程。同时进程资源也并没有完全释放，如果释放了进程的状态应该是UNUSED。但是可以肯定的是进程不会再运行了，因为它的状态是ZOMBIE。所以调度器线程会决定运行其他的进程。 wait系统调用12345678910111213141516171819202122232425262728293031323334353637383940414243444546// Wait for a child process to exit and return its pid.// Return -1 if this process has no children.int wait(uint64 addr) { struct proc *np; int havekids, pid; struct proc *p = myproc(); acquire(&amp;wait_lock); for(;;){ // Scan through table looking for exited children. havekids = 0; for(np = proc; np &lt; &amp;proc[NPROC]; np++){ if(np-&gt;parent == p){ // make sure the child isn't still in exit() or swtch(). acquire(&amp;np-&gt;lock); havekids = 1; if(np-&gt;state == ZOMBIE){ // Found one. pid = np-&gt;pid; if(addr != 0 &amp;&amp; copyout(p-&gt;pagetable, addr, (char *)&amp;np-&gt;xstate, sizeof(np-&gt;xstate)) &lt; 0) { release(&amp;np-&gt;lock); release(&amp;wait_lock); return -1; } freeproc(np); // free a proc structure and the data hanging from it, userpage release(&amp;np-&gt;lock); release(&amp;wait_lock); return pid; } release(&amp;np-&gt;lock); } } // No point waiting if we don't have any children. if(!havekids || p-&gt;killed){ release(&amp;wait_lock); return -1; } // Wait for a child to exit. sleep(p, &amp;wait_lock); //DOC: wait-sleep }} 它里面包含了一个大的循环。当一个进程调用了wait系统调用，它会扫描进程表单，找到父进程是自己且状态是ZOMBIE的进程。从上一节可以知道，这些进程已经在exit函数中几乎要执行完了。之后由父进程调用的freeproc函数，来完成释放进程资源的最后几个步骤。 12345678910111213141516static void freeproc(struct proc *p){ if(p-&gt;trapframe) kfree((void*)p-&gt;trapframe); p-&gt;trapframe = 0; if(p-&gt;pagetable) proc_freepagetable(p-&gt;pagetable, p-&gt;sz); p-&gt;pagetable = 0; p-&gt;sz = 0; p-&gt;pid = 0; p-&gt;parent = 0; p-&gt;name[0] = 0; p-&gt;chan = 0; p-&gt;killed = 0; p-&gt;xstate = 0; p-&gt;state = UNUSED;} 如果由正在退出的进程自己在exit函数中执行这些步骤，将会非常奇怪。这里释放了trapframe，释放了page table。如果我们需要释放进程内核栈，那么也应该在这里释放。但是因为内核栈的guard page，我们没有必要再释放一次内核栈。不管怎样，当进程还在exit函数中运行时，任何这些资源在exit函数中释放都会很难受，所以这些资源都是由父进程释放的。 在Unix中，对于每一个退出的进程，都需要有一个对应的wait系统调用，这就是为什么当一个进程退出时，它的子进程需要变成init进程的子进程。init进程的工作就是在一个循环中不停调用wait。每个进程都需要对应一个wait，这样它的父进程才能调用freeproc函数，并清理进程的资源。当父进程完成了清理进程的所有资源，子进程的状态会被设置成UNUSED，之后，fork系统调用才能重用进程在进程表单的位置。 kill系统调用123456789101112131415161718int kill(int pid) { struct proc *p; for(p = proc; p &lt; &amp;proc[NPROC]; p++){ acquire(&amp;p-&gt;lock); if(p-&gt;pid == pid){ p-&gt;killed = 1; if(p-&gt;state == SLEEPING){ // Wake process from sleep(). p-&gt;state = RUNNABLE; } release(&amp;p-&gt;lock); return 0; } release(&amp;p-&gt;lock); } return -1;} 最后我想看的是kill系统调用。Unix中的一个进程可以将另一个进程的ID传递给kill系统调用，并让另一个进程停止运行。 如果我们不够小心的话，kill一个还在内核执行代码的进程，会有一些我几分钟前介绍过的风险，比如我们想要杀掉的进程的内核线程还在更新一些数据，比如说更新文件系统，创建一个文件。如果这样的话，我们不能就这样杀掉进程。所以kill系统调用不能就直接停止目标进程的运行。实际上，在XV6和其他的Unix系统中，kill系统调用基本上不做任何事情。 它先扫描进程表单，找到目标进程。然后只是将进程的proc结构体中killed标志位设置为1。如果进程正在SLEEPING状态，将其设置为RUNNABLE。 而目标进程运行到内核代码中能安全停止运行的位置时，会检查自己的killed标志位，如果设置为1，目标进程会自愿的执行exit系统调用。 这里需要注意的是sleep的进程被唤醒的问题： 通常sleep的进程都会等待某个事件，sleep的代码会被包含在一个loop条件检查中。当sleep被再次唤醒时，loop的条件检查还需要检查进程是否killed。 1234567while(pi-&gt;nread == pi-&gt;nwrite &amp;&amp; pi-&gt;writeopen){ //DOC: pipe-empty if(pr-&gt;killed){ release(&amp;pi-&gt;lock); return -1; } sleep(&amp;pi-&gt;nread, &amp;pi-&gt;lock); //DOC: piperead-sleep} 也就是说，现在进程被唤醒的原因多了一个：它可能是被杀死了，而不是等待的事件完成了。我们需要小心的检查进程唤醒后的状态。 学生提问：这节课可能没有怎么讲到，但是如果关闭一个操作系统会发生什么？ Robert教授：这个过程非常复杂，并且依赖于你运行的是什么系统。因为文件系统是持久化的，它能在多次重启之间保持数据，我们需要保持文件系统的良好状态，如果我们正在更新文件系统的过程中，例如创建文件，然后我们想关闭操作系统，断电之类的。我们需要一个策略来确保即使我们正在一个复杂的更新文件系统的过程中，我们并不会破坏磁盘上的文件系统数据。文件系统其实就是一个位于磁盘的数据结构。所以这里涉及到了很多的机制来确保如果你关闭操作系统或者因为断电之类，我们可以恢复磁盘上的文件系统。 其他的，你是否需要做一些特殊的操作来关闭系统，取决于你正在运行什么进程。如果你正在运行一些重要的服务器，例如数据库服务器，并且许多其他计算机依赖这个数据库并通过网络使用它。那谁知道呢？答案或许是你不能就这么直接关闭操作系统，因为你正在提供一个对于其他计算机来说非常关键的服务。 如果你的计算机并没有在做任何事情，那么你可以直接关闭它。或许对于你的问题来说，如果你想关闭一个计算机，确保文件系统是正确的，之后停止执行指令，之后就可以关闭计算机了。 总结xv6的线程调度确实蛮曲折的，所谓线程调度就是一个线程让出CPU，然后决定另外一个线程运行的过程。 我们需要知道一个线程会在什么场景让出CPU，一个是定时器中断，线程的时间片到期；另一个场景是等待事件，比如等待管道、等待外设等。第二个场景是通过sleep和wakeup做到让出CPU和恢复运行。 调度器程序本身就是个无限循环，从进程表中挑出可运行的线程，然后再交出CPU到可运行线程。线程切换需要保存上下文到contex，contex包括ra和sp寄存器以及14个callee save寄存器，然后恢复新线程的上下文。第一个线程会返回到forkret的位置，假装调用swtch。 有了同步机制后，我们就能理解fork+wait的威力。进程退出由自己释放资源显得有点奇怪，因为代码运行还是需要依靠一些资源（比如栈、页表等）。这就给进程的ZOMBIE状态一个很好的解释：进程打算退出了，有一些资源还没释放，它等待父进程来释放这些资源。同样的，父进程需要主动调用wait来清理子进程的剩余资源。wait并不仅仅是等待子进程结束那么简单。 kill调用反而最无力，只能标记进程的killed字段，唤醒沉睡的进程。如此一来，进程在任何唤醒的地方都要增加进程是否被杀死的条件检验。","link":"/2024/01/16/MIT6.S081/book/chapter7/"},{"title":"MIT6.S081 xv6book chapter8","text":"这八章讲述了xv6的文件系统，这个文件系统的实现很简单，有许多可以优化的地方，但也有很多复杂的地方。从磁盘组织、缓存、日志、Inode、目录、文件名与文件描述符。其实可以简单分为三部分： 底层存储（磁盘组织、磁盘缓存、Inode、Directory） 持久层（日志事务） 用户层（文件名、文件描述符） 本节融合了lec14和lec15的内容，收获颇丰。 前言文件系统的有趣性： 抽象：如何对硬件的抽象 崩溃恢复——文件系统的持久性 文件组织——如何在磁盘上排布文件系统 性能——读取磁盘通常比较慢，如何取得性能的提升 文件系统分层： 最底层是磁盘，也就是一些实际保存数据的存储设备，正是这些设备提供了持久化存储。 在这之上是buffer cache或者说block cache，这些cache可以避免频繁的读写磁盘。这里我们将磁盘中的数据保存在了内存中。 为了保证持久性，再往上通常会有一个logging层。 longging层之上有inode cache，这主要是为了同步（synchronization）。 再往上就是inode本身了。它实现了read/write。 再往上，就是文件名，和文件描述符操作。 文件究竟维护了怎样的数据结构呢？核心的数据结构就是inode和file descriptor。后者主要与用户进程进行交互。 最重要的就是Inode，它代表了一个文件。文件名只是一个link，Inode之间通过编号进行区分。inode必须有一个link count来跟踪指向这个inode的文件名的数量。一个文件（inode）只能在link count为0的时候被删除。实际中还有一个openfd count，也就是当前打开了文件的文件描述符计数。一个文件只能在这两个计数器都为0的时候才能被删除。文件描述符必然自己悄悄维护了对于文件的offset。 磁盘组织屏蔽不同磁盘的区别，我们可以将磁盘看成block或setor的数组，每个block大小固定，这样我们就能通过块号读取一个块的内容。 block0要么没有用，要么被用作boot sector来启动操作系统。 block1通常被称为super block，它描述了文件系统。它可能包含磁盘上有多少个block共同构成了文件系统这样的信息。 在XV6中，log从block2开始，到block32结束。实际上log的大小可能不同，这里在super block中会定义log就是30个block。 接下来在block32到block45之间，XV6存储了inode。我之前说过多个inode会打包存在一个block中，一个inode是64字节。 之后是bitmap block，这是我们构建文件系统的默认方法，它只占据一个block。它记录了数据block是否空闲。 之后就全是数据block了，数据block存储了文件的内容和目录的内容。 On-disk inode structureInode代表一个文件，那Inode究竟是怎么组织的呢？ Inode有两种形式，一种是在磁盘上，一种是在内存上。稍后将会解释为什么会有两种Inode模型，以及这两种Inode之间的同步。 123456789// On-disk inode structurestruct dinode { short type; // File type， files, directories, and special files (devices) or zero short major; // Major device number (T_DEVICE only) short minor; // Minor device number (T_DEVICE only) short nlink; // Number of links to inode in file system uint size; // Size of file (bytes) uint addrs[NDIRECT+1]; // Data block addresses #define NDIRECT 12}; The type field distinguishes between files, directories, and special files (devices). A type of zero indicates that an on- disk inode is free. The nlink field counts the number of directory entries that refer to this inode, in order to recognize when the on-disk inode and its data blocks should be freed. The addrs array records the block numbers of the disk blocks holding the file’s content.The last entry in the addrs array gives the address of the indirect block. dinode 最令人不解的通常就是addrs数组了，它其实类似多级页表。首先，addrs数组存储了所有文件内容所在块的块号。它分为两级索引，第一级索引是直接映射，意思是我得到的块号就是文件内容真实的块号。第二级索引是addrs[12]的内容，它得到块号指向一个数据块，这个数据块才真正指向了文件内容块号。所以在xv6中，文件大小最多是 （12 + 256）* block size 这么大。 当dinode的type字段为T_DIR时，表明这个dinode是目录。目录的数据内容存的是目录条目，包含2字节的inode编号和14字节的文件名。 1234struct dirent { ushort inum; char name[DIRSIZ]; // #define DIRSIZ 14}; 看完On-disk inode structure我们就知道了，文件内容是放在data区，Inode用来索引这些文件，并区分文件类型。这是通常的设计，文件的元信息和文件内容分离存储。 in-memory copy of an inode123456789101112131415// in-memory copy of an inodestruct inode { uint dev; // Device number uint inum; // Inode number int ref; // Reference count 指向inode的指针个数 struct sleeplock lock; // protects everything below here int valid; // inode has been read from disk? short type; // copy of disk inode short major; short minor; short nlink; //指向inode的目录项个数 uint size; uint addrs[NDIRECT+1];}; struct inode is the in-memory copy of a struct dinode on disk. The kernel stores an inode in memory only if there are C pointers referring to that inode 为什么会有in-memory copy of an inode 的存在？其实就是方便操作系统管理inode，提供更多关于inode的信息，比如引用计数等。 Buffer Cache创建文件的过程创建文件的过程其实就是创建inode，然后写inode的内容，最后同步到磁盘。 12345678910111213141516171819202122// Allocate an inode on device dev.// Mark it as allocated by giving it type.// Returns an unlocked but allocated and referenced inode.struct inode* ialloc(uint dev, short type) { int inum; struct buf *bp; struct dinode *dip; for(inum = 1; inum &lt; sb.ninodes; inum++){ bp = bread(dev, IBLOCK(inum, sb)); // 读取缓存 dip = (struct dinode*)bp-&gt;data + inum%IPB; // 地址+偏移 if(dip-&gt;type == 0){ // a free inode memset(dip, 0, sizeof(*dip)); dip-&gt;type = type; log_write(bp); // mark it allocated on the disk brelse(bp); return iget(dev, inum); } brelse(bp); } panic(&quot;ialloc: no inodes&quot;);} superblock记录了inode的数量，遍历所有创建好的inode，然后查看是否是空闲的inode（其type字段为0），然后使用它。 重点看这两行： 12bp = bread(dev, IBLOCK(inum, sb)); dip = (struct dinode*)bp-&gt;data + inum%IPB; 1234// Inodes per block.#define IPB (BSIZE / sizeof(struct dinode))// Block containing inode i#define IBLOCK(i, sb) ((i) / IPB + sb.inodestart) 通过bread函数，我们读取了特定设备dev上的第IBLOCK(inum, sb)个block的内容到buf上。通过宏定义我们能够知道IBLOCK(inum, sb)就是第inum 个 inode所在的块号，inum%IPB则是inode在块内的偏移量。 bread函数将读取磁盘的过程作了一层封装，我们再看bread函数: 1234567891011// Return a locked buf with the contents of the indicated block.struct buf* bread(uint dev, uint blockno){ struct buf *b; b = bget(dev, blockno); if(!b-&gt;valid) { // 如果没在cache中找到，就读取磁盘 virtio_disk_rw(b, 0); b-&gt;valid = 1; } return b;} 可以看到bread其实是先调用bget 1234567891011121314151617181920212223242526272829303132// Look through buffer cache for block on device dev.// If not found, allocate a buffer.// In either case, return locked buffer.static struct buf* bget(uint dev, uint blockno){ struct buf *b; acquire(&amp;bcache.lock); // Is the block already cached? for(b = bcache.head.next; b != &amp;bcache.head; b = b-&gt;next){ if(b-&gt;dev == dev &amp;&amp; b-&gt;blockno == blockno){ b-&gt;refcnt++; // 增加引用计数 release(&amp;bcache.lock); acquiresleep(&amp;b-&gt;lock); return b; // returns the locked buffer } } // Not cached. 回收一个buf // Recycle the least recently used (LRU) unused buffer. for(b = bcache.head.prev; b != &amp;bcache.head; b = b-&gt;prev){ if(b-&gt;refcnt == 0) { b-&gt;dev = dev; b-&gt;blockno = blockno; b-&gt;valid = 0; b-&gt;refcnt = 1; release(&amp;bcache.lock); acquiresleep(&amp;b-&gt;lock); return b; } } panic(&quot;bget: no buffers&quot;);} bget读取的是bcache（缓存），如果缓存中没有，返回一个加锁的buf（containing a copy of a block which can be read or modified in memory)，如果buf失效，最后才从磁盘读。 bcache12345678910111213141516struct buf { int valid; // has data been read from disk? int disk; // does disk &quot;own&quot; buf? uint dev; uint blockno; struct sleeplock lock; uint refcnt; struct buf *prev; // LRU cache list struct buf *next; uchar data[BSIZE];};struct { struct spinlock lock; struct buf buf[NBUF]; // 30 struct buf head;} bcache; bcache就是个大小为30的LRU链表，链表的元素为buf。buf具有引用计数，表明有多少个线程正在使用它。blockno块号的内容就存在data里。 The buffer cache has two jobs: (1) synchronize access to disk blocks to ensure that only one copy of a block is in memory and that only one kernel thread at a time uses that copy; (2) cache popular blocks so that they don’t need to be re-read from the slow disk. buffer cache作为缓存能有效的减少访问磁盘的时间，同时buffer cache必须保证一个磁盘block之对应一个buf，一个buf只能被一个线程使用，否则就会出问题。 如果buffer cache中有两份block 33的cache将会出现问题。假设一个进程要更新inode19，另一个进程要更新inode20。如果它们都在处理block 33的cache，并且cache有两份，那么第一个进程可能持有一份cache并先将inode19写回到磁盘中，而另一个进程持有另一份cache会将inode20写回到磁盘中，并将inode19的更新覆盖掉。所以一个block只能在buffer cache中出现一次。 Logging Layerlogging的目标：实现原子的系统调用，快速恢复和高性能。 持久化的基本思想xv6 系统调用不直接写入磁盘上的文件系统数据结构。相反，它会在磁盘上的日志中放置它希望进行的所有磁盘写入的描述。一旦系统调用记录了其所有写入操作，它就会将一条特殊的提交记录写入磁盘，指示该日志包含完整的操作。此时，系统调用将写入复制到磁盘文件系统数据结构中。完成这些写入后，系统调用将擦除磁盘上的日志。 简单来说：就是系统调用先写log区，log区写完写一条提交记录。提交记录写完，再将log区的block搬回到data区，搬运完之后擦除磁盘的日志。 遵循write ahead rule，也就是说在写入commit记录之前，你需要确保所有的写操作都在log中。 日志设计 1234567891011121314151617// Contents of the header block, used for both the on-disk header block// and to keep track in memory of logged block# before commit.struct logheader { int n; // log blocks int block[LOGSIZE];};struct log { struct spinlock lock; int start; // log信息在磁盘上的位置（开始的block块的索引号) int size; // log区的总的block块的数目。 int outstanding; // 当前正在使用LOG机制的文件系统调用数目(目的是别超过了LOG系统总容量) int committing; // 当前是不是正处于LOG的提交中,也就是正在写LOG进入磁盘呢 int dev; struct logheader lh; // 磁盘logheader在内存中的一份映射};struct log log; log主要由两部分组成，log header和log block。header里有一个数组追踪每个log block。 日志基本调用流程1234567begin_op();...bp = bread(...);bp-&gt;data[...] = ...;log_write(bp);...end_op(); begin_op表示开启一次日志记录，这里暂时不揭示内容。 bread读缓存然后对data进行修改，此时需要调用log_write来记录修改到log。让我们来看看： 1234567891011121314151617181920212223// Caller has modified b-&gt;data and is done with the buffer.// Record the block number and pin in the cache by increasing refcnt.// commit()/write_log() will do the disk write.void log_write(struct buf *b){ int i; acquire(&amp;log.lock); if (log.lh.n &gt;= LOGSIZE || log.lh.n &gt;= log.size - 1) panic(&quot;too big a transaction&quot;); if (log.outstanding &lt; 1) panic(&quot;log_write outside of trans&quot;); for (i = 0; i &lt; log.lh.n; i++) { if (log.lh.block[i] == b-&gt;blockno) // log absorption break; } log.lh.block[i] = b-&gt;blockno; if (i == log.lh.n) { // Add new block to log? bpin(b); log.lh.n++; } release(&amp;log.lock);} 当在内存中修改了一个磁盘数据后，如果想从缓存真正写入的磁盘上， 有bwirte()函数。但是，xv6支持了log机制，使用log_write()代替了bwrite()函数来完成这个工作。 该函数其实只完成：在logheader中记录要写入的block块。(如果已经记录过，就无需再次添加，称之为log absorbtion) 真正的写磁盘的动作在end_op()函数中来完成。 12345678910111213141516171819202122232425262728void end_op(void) { int do_commit = 0; acquire(&amp;log.lock); log.outstanding -= 1; if(log.committing) panic(&quot;log.committing&quot;); if(log.outstanding == 0){ do_commit = 1; log.committing = 1; } else { // begin_op() may be waiting for log space, // and decrementing log.outstanding has decreased // the amount of reserved space. wakeup(&amp;log); } release(&amp;log.lock); if(do_commit){ // call commit w/o holding locks, since not allowed // to sleep with locks. commit(); acquire(&amp;log.lock); log.committing = 0; wakeup(&amp;log); release(&amp;log.lock); }} 代码最前端有一些复杂情况处理，直接跳过，看commit函数。 123456789static void commit(){ if (log.lh.n &gt; 0) { write_log(); // Write modified blocks from cache to log write_head(); // Write header to disk -- the real commit install_trans(0); // Now install writes to home locations log.lh.n = 0; write_head(); // Erase the transaction from the log }} 这整个流程还是非常清晰明了的。 日志挑战第一个挑战是bcache不能撤回已经在日志transaction中的buf，这么做会破坏原子性。所以有一个buf_pin操作会将buf固定在cache中（实际上就是增加一个引用计数） 第二个挑战是文件系统操作受限于log大小。这里意思是说xv6的log区大小为30，这就限制一次系统调用最多写的block数量。如果写入的block数超过了30，那么一个写操作会被分割成多个小一些的写操作。 123456int max = ((MAXOPBLOCKS-1-1-2) / 2) * BSIZE;int i = 0;while(i &lt; n){ int n1 = n - i; if(n1 &gt; max) n1 = max; 第三个挑战就是并发操作。 log的并发还挺有意思的，除了加锁保护外，还限制于log的空间大小。 比如，现在有两个并发的transaction，其中t0在log的前半部分，t1在log的后半部分，可是用完了log空间但一个transcation都没完成。这样就陷入了死锁，任何一个transaction 都期待另一个提交释放空间，但一个都不能提交。 所以说还要保证多个并发transaction也适配log的大小。当我们还没有完成一个文件系统操作时，我们必须在确保可能写入的总的log数小于log区域的大小的前提下，才允许另一个文件系统操作开始。 XV6通过限制并发文件系统操作的个数来实现这一点。在begin_op中，我们会检查当前有多少个文件系统操作正在进行。如果有太多正在进行的文件系统操作，我们会通过sleep停止当前文件系统操作的运行，并等待所有其他所有的文件系统操作都执行完并commit之后再唤醒。这里的其他所有文件系统操作都会一起commit。有的时候这被称为group commit，因为这里将多个操作像一个大的transaction一样提交了，这里的多个操作要么全部发生了，要么全部没有发生。 12345678910111213141516// called at the start of each FS system call.void begin_op(void){ acquire(&amp;log.lock); while(1){ if(log.committing){ sleep(&amp;log, &amp;log.lock); } else if(log.lh.n + (log.outstanding+1)*MAXOPBLOCKS &gt; LOGSIZE){ // this op might exhaust log space; wait for commit. sleep(&amp;log, &amp;log.lock); } else { log.outstanding += 1; release(&amp;log.lock); break; } }} 首先，如果log正在commit过程中，那么就等到log提交完成，因为我们不能在install log的过程中写log；其次，如果当前操作是允许并发的操作个数的后一个，那么当前操作可能会超过log区域的大小，我们也需要sleep并等待所有之前的操作结束；最后，如果当前操作可以继续执行，需要将log的outstanding字段加1，最后再退出函数并执行文件系统操作。 12345678910111213141516void end_op(void) { int do_commit = 0; acquire(&amp;log.lock); log.outstanding -= 1; if(log.committing) panic(&quot;log.committing&quot;); if(log.outstanding == 0){ do_commit = 1; log.committing = 1; } else { wakeup(&amp;log); } release(&amp;log.lock); ...} 最后再看end_op的前半部分。在最开始首先会对log的outstanding字段减1，因为一个transaction正在结束；其次检查committing状态，当前不可能在committing状态，所以如果是的话会触发panic；如果当前操作是整个并发操作的最后一个的话（log.outstanding == 0），接下来立刻就会执行commit；如果当前操作不是整个并发操作的最后一个的话，我们需要唤醒在begin_op中sleep的操作，让它们检查是不是能运行。 所以，即使是XV6中这样一个简单的文件系统，也有一些复杂性和挑战。 崩溃恢复过程崩溃恢复的过程也很简单，只需要读log里未提交的日志就行。那什么是真正的提交节点呢？在commit函数中已经指示了，write head就是那么一个节点。 123456789static void commit(){ if (log.lh.n &gt; 0) { write_log(); // Write modified blocks from cache to log write_head(); // Write header to disk -- the real commit install_trans(0); // Now install writes to home locations log.lh.n = 0; write_head(); // Erase the transaction from the log }} write_head将n不为0的head写入log区。下次开机启动时，扫描log区的head，查看其n字段是否为0. 12345678static voidrecover_from_log(void){ read_head(); install_trans(1); // if committed, copy from log to disk log.lh.n = 0; write_head(); // clear the log} Path name我们知道，inode代表文件，但是为了便于使用，我们还管理一个命令空间。命名空间是以”/“为起点的树，每个目录下有”.”代表自身，有”..”代表上一级目录。怎么实现呢？ 一般来说，根目录是固定在磁盘上某个块上的，比如1号块。遍历路径逻辑就是从根目录开始读取目录条目，然后逐个查找。 12if(*path == '/') ip = iget(ROOTDEV, ROOTINO); xv6没有对目录查找进行优化，只是简单的线性查找。 1234567891011121314151617181920212223242526272829303132static struct inode* namex(char *path, int nameiparent, char *name){ struct inode *ip, *next; if(*path == '/') ip = iget(ROOTDEV, ROOTINO); else ip = idup(myproc()-&gt;cwd); while((path = skipelem(path, name)) != 0){// skiplem相当于将path分为两部分，name是前一个部分，path是后一部分 ilock(ip); if(ip-&gt;type != T_DIR){ iunlockput(ip); return 0; } if(nameiparent &amp;&amp; *path == '\\0'){ // Stop one level early. iunlock(ip); return ip; } if((next = dirlookup(ip, name, 0)) == 0){ iunlockput(ip); return 0; } iunlockput(ip); // avoid 死锁 ip = next; // 通过name目录找到当前的path } if(nameiparent){ iput(ip); return 0; } return ip;} File descriptor layerUnix 界面的一个很酷的方面是 Unix 中的大多数资源都表示为文件，包括控制台、管道等设备，当然还有真实文件。文件描述符层是实现这种通用性的层。 具体来说，就是用一个file结构体来包裹文件、管道、设备。 12345678910struct file { //万物皆文件，就是这里了 enum { FD_NONE, FD_PIPE, FD_INODE, FD_DEVICE } type; int ref; // reference count char readable; char writable; struct pipe *pipe; // FD_PIPE struct inode *ip; // FD_INODE and FD_DEVICE uint off; // FD_INODE, io offset short major; // FD_DEVICE}; 进程有一个打开文件的数组，数组下标就是文件描述符。 12345struct proc { ... struct file *ofile[NOFILE]; // Open files ...}; 当我们使用文件描述符进行读写时，实际上是通过文件描述符作为索引得到file结构体，再通过file结构体进行相应type的读写。 ftable12345678// file.cstruct file* filealloc(void);void fileclose(struct file*);struct file* filedup(struct file*);void fileinit(void);int fileread(struct file*, uint64, int n);int filestat(struct file*, uint64 addr);int filewrite(struct file*, uint64, int n); xv6对于file结构体的使用，也采用了一个池化的思想。 1234struct { struct spinlock lock; struct file file[NFILE];} ftable; 123456789101112131415// Allocate a file structure.struct file* filealloc(void){ struct file *f; acquire(&amp;ftable.lock); for(f = ftable.file; f &lt; ftable.file + NFILE; f++){ if(f-&gt;ref == 0){ f-&gt;ref = 1; release(&amp;ftable.lock); return f; } } release(&amp;ftable.lock); return 0;} 让我们看看打开文件的过程：open系统调用，如果传入的是 O_CREATE 标志，说明要新创建文件。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465uint64 sys_open(void){ char path[MAXPATH]; int fd, omode; struct file *f; struct inode *ip; int n; if((n = argstr(0, path, MAXPATH)) &lt; 0 || argint(1, &amp;omode) &lt; 0) return -1; begin_op(); if(omode &amp; O_CREATE){ ip = create(path, T_FILE, 0, 0); if(ip == 0){ end_op(); return -1; } } else { //否则就通过name打开相应的inode if((ip = namei(path)) == 0){ end_op(); return -1; } ilock(ip); if(ip-&gt;type == T_DIR &amp;&amp; omode != O_RDONLY){ iunlockput(ip); end_op(); return -1; } } if(ip-&gt;type == T_DEVICE &amp;&amp; (ip-&gt;major &lt; 0 || ip-&gt;major &gt;= NDEV)){ iunlockput(ip); end_op(); return -1; } if((f = filealloc()) == 0 || (fd = fdalloc(f)) &lt; 0){ if(f) // 这里可能分配的file结构体，所以还需要释放它 fileclose(f); iunlockput(ip); end_op(); return -1; } if(ip-&gt;type == T_DEVICE){ f-&gt;type = FD_DEVICE; f-&gt;major = ip-&gt;major; } else { f-&gt;type = FD_INODE; f-&gt;off = 0; } f-&gt;ip = ip; f-&gt;readable = !(omode &amp; O_WRONLY); f-&gt;writable = (omode &amp; O_WRONLY) || (omode &amp; O_RDWR); if((omode &amp; O_TRUNC) &amp;&amp; ip-&gt;type == T_FILE){ itrunc(ip); } iunlock(ip); end_op(); return fd;} 再看看create函数，其实就是找到父级目录，然后分配inode结构体，增加目录项。 1234567891011121314151617181920212223242526272829303132333435363738394041424344//creates a new name for a new inodestatic struct inode*create(char *path, short type, short major, short minor){ struct inode *ip, *dp; char name[DIRSIZ]; // find path‘s parent，return inode if((dp = nameiparent(path, name)) == 0) return 0; ilock(dp); // look in directory first，file类型在dp中找到name是合理的 if((ip = dirlookup(dp, name, 0)) != 0){ // Look for a directory entry in a directory. iunlockput(dp); ilock(ip); if(type == T_FILE &amp;&amp; (ip-&gt;type == T_FILE || ip-&gt;type == T_DEVICE)) return ip; iunlockput(ip); return 0; } // then create it if((ip = ialloc(dp-&gt;dev, type)) == 0) panic(&quot;create: ialloc&quot;); ilock(ip); ip-&gt;major = major; ip-&gt;minor = minor; ip-&gt;nlink = 1; iupdate(ip); if(type == T_DIR){ // Create . and .. entries. dp-&gt;nlink++; // for &quot;..&quot; iupdate(dp); // No ip-&gt;nlink++ for &quot;.&quot;: avoid cyclic ref count. if(dirlink(ip, &quot;.&quot;, ip-&gt;inum) &lt; 0 || dirlink(ip, &quot;..&quot;, dp-&gt;inum) &lt; 0) panic(&quot;create dots&quot;); } if(dirlink(dp, name, ip-&gt;inum) &lt; 0) panic(&quot;create: dirlink&quot;); iunlockput(dp); return ip;} 再回到sys_open，这里才是分配fd的地方：先分配file结构体，然后分配fd文件描述符。 1if((f = filealloc()) == 0 || (fd = fdalloc(f)) &lt; 0){ 分配文件描述符的过程就是遍历文件的openfiletable，找到未使用的下标。这样我们就能理解一个进程打开的文件描述符是有限的这句话。 1234567891011121314// Allocate a file descriptor for the given file.// Takes over file reference from caller on success.static int fdalloc(struct file *f){ int fd; struct proc *p = myproc(); // 遍历进程的open file table，find an unused slot for(fd = 0; fd &lt; NOFILE; fd++){ if(p-&gt;ofile[fd] == 0){ p-&gt;ofile[fd] = f; return fd; } } return -1;} 总结通过这一章的学习，xv6的架构基本已经完成。我们学习了文件块在磁盘上的组织，读取磁盘块时的LRU缓存，为文件系统操作系统持久化的日志块，为用户提供友好的命名空间以及文件描述符，这都是unix很精髓的一部分。 文件系统的学习，主要有以下几个思想吧： 文件系统的设计（磁盘块具体存储分布、Inode文件、file统一文件） 缓存池化思想（bcache、itable、ftable） 日志持久化思想（transaction） 当然，文件系统还需应对并发处理，这里讲得内容很少。其中一个点是磁盘读取时用了sleeplock而不是spinlock，这是因为磁盘读取通常是一个持续时间较长的操作。更多关于加锁控制，比如ilock加锁，namex不加锁等等有具体的原因，这点也需要继续深入。 同时xv6的很多实现都可以继续优化，比如目录项查找以及日志性能等。这些下一章会讲。","link":"/2024/01/18/MIT6.S081/book/chapter8/"}],"tags":[{"name":"分布式系统","slug":"分布式系统","link":"/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"},{"name":"双指针","slug":"双指针","link":"/tags/%E5%8F%8C%E6%8C%87%E9%92%88/"},{"name":"滑动窗口","slug":"滑动窗口","link":"/tags/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/"},{"name":"二分法","slug":"二分法","link":"/tags/%E4%BA%8C%E5%88%86%E6%B3%95/"}],"categories":[{"name":"工具学习","slug":"工具学习","link":"/categories/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/"},{"name":"Vim","slug":"工具学习/Vim","link":"/categories/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/Vim/"},{"name":"Git","slug":"工具学习/Git","link":"/categories/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/Git/"},{"name":"终端","slug":"工具学习/终端","link":"/categories/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/%E7%BB%88%E7%AB%AF/"},{"name":"操作系统","slug":"操作系统","link":"/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"后端开发","slug":"后端开发","link":"/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"},{"name":"设计模式","slug":"设计模式","link":"/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"数据结构与算法","slug":"数据结构与算法","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"MIT6.824","slug":"MIT6-824","link":"/categories/MIT6-824/"},{"name":"数组与字符串","slug":"数据结构与算法/数组与字符串","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%95%B0%E7%BB%84%E4%B8%8E%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"name":"Linux&#x2F;Unix","slug":"Linux-Unix","link":"/categories/Linux-Unix/"},{"name":"MIT6.S081","slug":"MIT6-S081","link":"/categories/MIT6-S081/"},{"name":"lab","slug":"MIT6-S081/lab","link":"/categories/MIT6-S081/lab/"},{"name":"xv6book","slug":"MIT6-S081/xv6book","link":"/categories/MIT6-S081/xv6book/"}],"pages":[{"title":"","text":"this is test file","link":"/test.html"},{"title":"about","text":".intro { text-align: center; font-weight: bold } .intro a { color:var(--font-color)!important } .intro a:hover { text-decoration: underline } .intro p { line-height: 1.75 } (｡･∀･)ﾉﾞ BJTUer | Desirer INTJ Vim | C++/JAVA/GO/Python 二次元 ｜ 追番列表 《提问的智慧》 ｜ 《异步沟通》","link":"/about/index.html"}]}