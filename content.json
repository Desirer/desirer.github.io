{"posts":[{"title":"Static关键字总结","text":"static关键字主要起的作用： 限定作用域 变量持久化 默认初始化为0（static变量） 前言static关键字用法体现在两个方面： C中面向过程，主要包括static全局变量、static局部变量和static函数 C++中面向对象，主要包括static成员变量和static成员函数 额外知识：程序的存储模型 堆区：是由程序员手动申请（new）与释放（delete）的内存区域。从低地址向高地址申请；内存空间大、存储地址不连续，一般是链式的；速度较慢。 栈区：由编译器自动分配和释放，主要存储 函数的参数值、函数内部的变量的值、函数调用的空间。从高地址向低地址申请；容量有限；速度较快；存储地址连续，会溢出。 代码区：又叫文本段（.text）,存放着程序的机器代码，可执行指令就是存储在这里的，这里的代码是只读的。 全局区（静态区）：全局变量和静态变量是存储在这里的。初始化的全局变量和静态变量在一块区域（.data），未初始化的全局变量和未初始化的静态变量在相邻的另一块区域(.bbs)。系统结束后由系统释放。 常量区：常量字符串放在这里，程序结束后，由系统进行释放。 经过static修饰的变量，存储在内存的全局静态区，只能在本模块的函数引用。 面向过程的static静态全局变量static作用在全局变量上，主要起到限定作用域的作用。 所有未加static前缀的全局变量和函数都具有全局可见性，其它的源文件也能访问，如果加了static，就会对其它源文件隐藏，使得作用域限制在本文件内。 内存中的位置：静态存储区，在整个程序运行期间一直存在。 初始化：未经初始化的全局静态变量会被自动初始化为0（自动对象的值是任意的，除非他被显式初始化）； 作用域：全局静态变量在声明他的文件之外是不可见的，准确地说是从定义之处开始，到文件结尾。 存储在静态数据区的变量会在程序刚开始运行时就完成初始化，也是唯一的一次初始化。 共有两种变量存储在静态存储区：全局变量和static变量，只不过和全局变量比起来，static可以控制变量的可见范围，说到底static还是用来隐藏的。 如果将static去掉，全局变量具有以下特点： 1）全局变量默认是有外部连接性的,其作用域是整个工程，在一个文件内定义的全局变量可以通过包含其所在头文件或显示调用 extern关键字修饰全局变量的变量名声明来引用； 2）静态全局变量是显式调用static修饰的全局变量，其作用域只在声明此变量的文件中，其他文件即使利用extern关键字修饰其声明也不可使用； 静态局部变量static作用在局部变量上，主要起到保持变量持久化的作用。 通常，在一个函数作用域内定义一个变量，每次运行到该函数时，系统会给局部变量分配内存。当函数结束时，该变量的内存会被系统回收至栈内存当中。 如果作为static局部变量在函数内定义，它的生存期为整个源程序，但是其作用域仍与自动变量相同，只能在定义该变量的函数内使用该变量。退出该函数后， 尽管该变量还继续存在，但不能使用它。 内存中的位置：静态存储区 初始化：未经初始化的全局静态变量会被自动初始化为0（自动对象的值是任意的，除非他被显式初始化）； 作用域：作用域仍为局部作用域，当定义它的函数或者语句块结束的时候，作用域结束。但是当局部静态变量离开作用域后，并没有销毁，而是仍然驻留在内存当中，只不过我们不能再对它进行访问，直到该函数再次被调用，并且值不变； 基于以上两点可以得出一个结论：把局部变量改变为静态变量后是改变了它的存储方式即改变了它的生存期。把全局变量改变为静态变量后是改变了它的作用域， 限制了它的使用范围。因此static 这个说明符在不同的地方所起的作用是不同的。 静态函数static作用在函数上，主要起到限定作用域的作用。 所有未加static前缀的全局变量和函数都具有全局可见性，其它的源文件也能访问，如果加了static，就会对其它源文件隐藏，使得作用域限制在本文件内。 在函数返回类型前加关键字static，函数就定义成静态函数。函数的定义和生命在默认情况下都是extern的，但静态函数只是在声明他的文件当中可见，不能被其他文件所用； 特点： 1）作用域只在声明它的文件当中，不能被其他文件引用，其他文件可以定义同名的全局函数； 2）其他文件想要调用本文件的静态函数，需要显示的调用extern关键字修饰其声明； 面向对象的static静态成员变量类内用static关键字声明，必须在类外定义，定义时不加satic关键字。初始化时使用作用域运算符来标明所属类。 特点： 1）静态数据成员的服务对象并非是单个类实例化的对象，而是所有类实例化的对象(这点可以用于设计模式中的单例模式实现)； 2）静态数据成员必须显式的初始化分配内存，在其包含类没有任何实例化之前已经有内存分配； 3）静态数据成员与其他成员一样，遵从public,protected,private的访问规则； 4）静态数据成员内存存储在全局数据区，只随着进程的消亡而消亡； 优势： 1）静态数据成员不进入程序全局命名空间，不会与其他全局名称的同名同类型变量冲突； 2）静态数据成员可以实现C++的封装特性，由于其遵守类的访问权限规则，所以相比全局变量更加灵活； 静态成员函数类的成员函数返回类型之前添加static，此成员函数为静态成员函数。实现的时候也不需要static的修饰，因为static是声明性关键字； 特点： 1）在没有实例化的类对象的条件下可以调用类的静态成员函数； 2）类的静态成员函数是属于整个类而非类的对象，所以它没有this指针，这就导致了它仅能访问类的静态数据和静态成员函数。 3）不能将静态成员函数定义为虚函数，静态成员函数可以继承和覆盖 类的静态函数是该类的范畴内的全局函数，不能访问类的私有成员，只能访问类的静态成员，不需要类的实例即可调用；实际上，他就是增加了类的访问权限的全局函数； 总结2）可以在头文件中声明静态全局变量，该头文件被多个cpp文件包含后，包含该头文件的cpp文件实际上会各自拥有独立的同名变量；（最好不要这么做） 3）不能将静态成员函数定义为虚函数； 4）静态成员函数没有this指针； 5）static缩短了子类对父类静态成员访问的时间，相对来说节省了内存空间； 6）如果不想在子类中操作父类的静态成员，则可以在子类中定义一个同名的static成员。这样既可覆盖父类中的静态成员，并且根据C++的多态性变量命名规则，这样做是安全的； warning 在.h里使用static定义，不会进行编译（.h文件不编译），只会在其每个include的cpp文件中包含编译，相当于在.cpp里使用static定义。 不要在头文件中声明static的全局函数 该文件被多个cpp文件包含后，包含该头文件的cpp文件实际会各自拥有独立的同名函数。 不要在cpp内声明非static的全局函数，为什么？（仅在该模块内的函数请用static修饰） 例子： example.cpp 123456789101112#include &quot;stdio.h&quot;static int counter = 0; // 静态全局变量，仅在 example.c 中可见static void incrementCounter() { // 静态函数，仅在 example.c 中可见 counter++;}void publicFunction() { // 非静态函数，可以被外部调用 incrementCounter(); printf(&quot;Counter: %d\\n&quot;, counter);} main.cpp 1234567void publicFunction(); int main(){ publicFunction(); return 0;} 结果：example.cpp内的函数被调用。 123456编译g++ main.cpp example.cpp -o run.out运行./run.out输出：Counter: 1 参考文章： http://t.csdn.cn/lH8Xm https://www.cnblogs.com/jhmu0613/p/7131997.html https://www.cnblogs.com/biyeymyhjob/archive/2012/07/19/2598815.html","link":"/2025/05/18/C++/Static%E5%85%B3%E9%94%AE%E5%AD%97/"},{"title":"extern关键字使用","text":"如何加载其他模块的全局变量？ extern关键字 声明与定义根据C++标准的规定，一个变量声明必须同时满足两个条件，否则就是定义： 声明必须使用extern关键字； 不能给变量赋初值 1234int a; //定义int a = 0; //定义extern int a =0; //定义extern int a; //声明 使用其他模块变量例子123456789101112//file.hextern int a;//file.cppint a = 10;//main.cpp#include &lt;cstdio&gt;#include &quot;file.h&quot;int main(){ printf(&quot;a = %d&quot;, a);} 终端上编译运行，输出 1gcc main.cpp file.cpp &amp;&amp; ./a.out 这等同于 123456789//file.cppint a = 10;//main.cpp#include &lt;cstdio&gt;extern int a;int main(){ printf(&quot;a = %d&quot;, a);} 如果不佳extern关键字将提示变量重复声明。 最佳实践 h文件extern声明 c/cpp文件内定义 使用时include头文件","link":"/2025/05/20/C++/extern%E5%85%B3%E9%94%AE%E5%AD%97/"},{"title":"约定对象创建限制","text":"如何限制一个类对象只在堆/栈上分配空间？ 为什么需要限制一个类对象只在堆/栈上分配空间？ more effective cpp ：条款27 为什么要限制对象创建？可能你是嵌入式设备，堆空间有限，你希望某类对象不会泄漏内存（不允许在堆上创建，就绝不会内存泄漏，😊）。 可能你想要某些对象有自杀”delete this“的能力，如此安排，对象必须创建在堆上（否则将会被析构两次，调用自杀函数一次，编译器调用一次）。 123run.out(8482,0x7ff853a44700) malloc: *** error for object 0x7ff7bf21bf98: pointer being freed was not allocatedrun.out(8482,0x7ff853a44700) malloc: *** set a breakpoint in malloc_error_break to debug[1] 8482 abort ./run.out 在C++中，类的对象建立分为两种，一种是静态建立，如A a；另一种是动态建立，如A* ptr=new A； 静态建立类对象：由编译器为对象在栈空间中分配内存。通过直接移动栈顶指针，在这片内存空间上调用构造函数形成一个栈对象。使用这种方法，将直接调用类的构造函数。 动态建立类对象：使用new运算符将对象建立在堆空间中。这个过程分为两步，第一步执行operator new()函数，在堆空间中搜索合适的内存并进行分配；第二步调用构造函数构造对象，初始化这片内存空间。这种方法，将间接调用类的构造函数。 只在堆上建立Non-heap object会在定义点自动构造，在其声明周期结束时自动析构。因此，只需要将那些隐式调用构造函数或析构函数动作非法化，就能限制对象在栈上的建立。 直截了当的方式将构造函数与析构函数声明为private。 原理：在栈上构建对象时，编译器负责对象的生命周期，自动调用对象的析构函数。如果析构函数为私有，编译器就不能调用对象的析构函数，类对象就无法静态建立。 稍好点的方式将构造函数声明为public，然后将析构函数声明为private，再导入一个伪析构函数，用于释放对象。 为什么不是将构造函数声明为private？ 因为一个类有许多构造函数，析构函数只有一个。编译器添加的构造函数总是public的。 1234567class A { public: A(){} void destory(){delete this;} private: ~A(){} }; 但这种方式（将析构函数声明为private）妨碍了继承与包含：派生类无法访问基类的析构函数；包含类无法访问被包含类的析构函数。 123456789101112class B : public A{};class C{private: A a;};int main(){ B* pb = new B(); // 编译错误 C* pc = new C(); // 编译错误} 解决方式：将基类的析构函数声明为protected可解决继承问题；将成员变量使用方式改为指针，可解决包含问题。 123456789101112131415161718192021class A { public: A(){} void destory(){delete this;} protected: ~A(){} };class C{ // C的析构函数注意释放Aprivate: A *a;};// 这下ok了int main(){ B* pb = new B(); B b; C* pc = new C(); C c;} 更严厉的限制上述方式，并没有限制派生类在栈上创建。如果更严厉点，要求其派生类也必须在堆上建立，该如何解决？ 很遗憾，不能。 more effective cpp 介绍了两种方法： 重载operator new，设置onHeap标志，构造函数判断onHeap标志。 通过对象地址判断是否位于堆内 遗憾的是，前者无法应对数组（内存一次分配，多次构造）；后者无法区分堆对象与静态对象。 只在栈上建立方法：将operator new() 设为私有 Operator new[]可能也需要设置为private。 12345678class A { private: void* operator new(size_t t){} // 注意函数的第一个参数和返回值都是固定的 void operator delete(void* ptr){} // 重载了new就需要重载delete public: A(){} ~A(){} }; 但是这种方法无法面对继承： 1234567891011121314class B : A{public: B(int m):mem(m){} // static void* operator new(size_t size){ // return ::operator new(size); // } // static void operator delete(void* pointer){ // delete pointer; // }private:int mem;};B* pb = new B(1); // 错误 包含并无大碍： 1234567891011class C{public: C(int m):mem(m){}private: A a; int mem;};C* pc = new C(1); //okC c(1); //ok 更严厉的制约同样无法达到。","link":"/2025/05/25/C++/%E7%BA%A6%E5%AE%9A%E5%AF%B9%E8%B1%A1%E5%88%9B%E5%BB%BA%E9%99%90%E5%88%B6/"},{"title":"MIT6824笔记十 分布式事务","text":"本节介绍了分布式事务，如何进行并发控制和原子提交，主要是2PL和2PC。 2PL区别于简单锁，事务锁数量是动态增长的，并在事务commit或abort之后才能释放锁。2PC其实有3阶段，包括inform、prepare、commit阶段。每一阶段为了防止数据丢失都要进行Write Ahead Log操作。每个服务器也要维护各自的锁表单，用来记录当前锁被哪个事务持有。 分布式事务背景对于拥有大量数据的人来说，他们通常会将数据进行分割或者分片到许多不同的服务器上，人们需要跨机器的原子操作(cross-machine atomic ops)。 分布式事务主要有两部分组成。 第一个是并发控制（Concurrency Control） 第二个是原子提交（Atomic Commit） 可以这么理解事务：程序员有一些不同的操作，或许针对数据库不同的记录，他们希望所有这些操作作为一个整体，不会因为失败而被分割，也不会被其他活动看到中间状态。 事务原语这里举例应用事务时的程序编写，假设有T1和T2两个正在进行的事务，我们只需要通过指定的事务原语编程程序，就能保证逻辑被原子地执行，而无需感知事务内部实现使用什么锁等机制。 begin：声明一个事务的开始 commit：提交事务，commit成功被执行后，begin～commit之间的逻辑被原子地执行 abort：取消事务，begin～abort之间的逻辑将被撤销，即产生的影响会消除(比如put修改的值被改回去之类的)。除了人为在逻辑里使用abort，事务本身遇到死锁等情况时也会自动调用abort。 并发下的正确性——可序列化在多个并发事务的存在下，我们需要一个概念来定义什么是正确的结果。一旦我们知道了这个概念，我们需要构建能执行这些事务的机制，在可能存在并发和失败的前提下，仍然得到正确的结果。 首先，什么是正确性？ 数据库通常对于正确性有一个概念称为ACID。分别代表： Atomic，原子性。它意味着，事务可能有多个步骤，比如说写多个数据记录，尽管可能存在故障，但是要么所有的写数据都完成了，要么没有写数据能完成。不应该发生类似这种情况：在一个特定的时间发生了故障，导致事务中一半的写数据完成并可见，另一半的写数据没有完成，这里要么全有，要么全没有（All or Nothing）。 Consistent，一致性。我们实际上不会担心这一条，它通常是指数据库会强制某些应用程序定义的数据不变，这不是我们今天要考虑的点。 Isolated，隔离性。这一点还比较重要。这是一个属性，它表明两个同时运行的事务，在事务结束前，能不能看到彼此的更新，能不能看到另一个事务中间的临时的更新。目标是不能。隔离在技术上的具体体现是，事务需要串行执行，我之后会再解释这一条。但是总结起来，事务不能看到彼此之间的中间状态，只能看到完成的事务结果。 Durable，持久化的。这意味着，在事务提交之后，在客户端或者程序提交事务之后，并从数据库得到了回复说，yes，我们执行了你的事务，那么这时，在数据库中的修改是持久化的，它们不会因为一些错误而被擦除。在实际中，这意味着数据需要被写入到一些非易失的存储（Non-Volatile Storage），持久化的存储，例如磁盘。 我们说可序列化是指，并行的执行一些事物得到的结果，与按照某种串行的顺序来执行这些事务，可以得到相同的结果。实际的执行过程或许会有大量的并行处理，但是这里要求得到的结果与按照某种顺序一次一个事务的串行执行结果是一样的。这里的结果包括两个方面：由任何事务中的修改行为产生的数据库记录的修改和任何事务生成的输出。 可序列化是一个应用广泛且实用的定义，背后的原因是，它定义了事务执行过程的正确性。可序列化特性确保你可以安全的写你的事务，就像没有其他事情发生一样。因为系统最终的结果必须表现的就像，你的事务在这种一次一个的顺序中是独占运行的。这是一个非常简单，非常好的编程模型。 可序列化的另一方面优势是，只要事务不使用相同的数据，它可以允许真正的并行执行事务。 并发控制第一种主要策略是悲观并发控制（Pessimistic Concurrency Control）。那就是在事务使用任何数据之前，它需要获得数据的锁。如果一些其他的事务已经在使用这里的数据，锁会被它们持有，当前事务必须等待这些事务结束，之后当前事务才能获取到锁。在悲观系统中，如果有锁冲突，比如其他事务持有了锁，就会造成延时等待。所以这里需要为正确性而牺牲性能。 第二种主要策略是乐观并发控制（Optimistic Concurrency Control）。这里的基本思想是，你不用担心其他的事务是否正在读写你要使用的数据，你直接继续执行你的读写操作，通常来说这些执行会在一些临时区域，只有在事务最后的时候，你再检查是不是有一些其他的事务干扰了你。如果没有这样的其他事务，那么你的事务就完成了，并且你也不需要承受锁带来的性能损耗，因为操作锁的代价一般都比较高；但是如果有一些其他的事务在同一时间修改了你关心的数据，并造成了冲突，那么你必须要Abort当前事务，并重试。 如果冲突非常频繁，你或许会想要使用悲观并发控制，因为如果冲突非常频繁的话，在乐观并发控制中你会有大量的Abort操作。如果冲突非常少，那么乐观并发控制可以更快，因为它完全避免了锁带来的性能损耗。 两阶段锁2PL所谓两阶段，第一个阶段是扩张，获得锁的数量不断增加，期间不能释放锁；第二阶段是收缩，锁的数量单调下降，不能获得锁。 第一个规则：acquing lock before using record 第二个规则：hold lock until done（commit） or abort 对于两阶段锁来说，第一个规则是在执行任何数据的读写之前，先获取锁。第二个规则是，事务必须持有任何已经获得的锁，直到事务提交或者Abort。换言之，持有锁直到事务结束。 为什么需要在事务结束前一直持有锁？假设事务在读写完记录后就释放了锁，另一个事务有机会运行，可能会得到非法的结果。 如图所示，T1，T2两个事务。只有两种一次一个的串行顺序，要么是T1，T2，要么是T2，T1。同样对应两种结果11，9和10，10。 假设T2读取了X，然后立刻释放了锁，那么在这个位置，T2不持有任何锁，因为它刚刚释放了对于X的锁。因为T2不持有任何锁，这意味着T1可以完全在这个位置执行。从前面的反例我们已经知道，这样的执行是错误的（因为T2会打印“10，9”），因为它没能生成正确结果。 对比 2PL是对简单锁(严格锁)的改进。 简单锁(simple locking)或严格锁(strict locking)，在事务开始前，你获取整个事务所需的所有锁，持有这些锁直到提交点进行commit或者abort，然后释放所有锁。 2PL的锁更细粒度一点，不需要在事务开始前直接获取所有锁，相反的，在事务运行时动态增量的获取锁，支持某些严格锁(简单锁)不允许的并发模式。 一般而言，使用2PL要比使用简单锁(严格锁)有更高的并发度。比如事务中读取的某个变量极小概率会是true，而变量为true时，才会执行后序事务逻辑，那么这里不需要在事务开始前就加锁，可以等读到变量时再加锁。 2PL死锁场景两阶段锁非常容易造成死锁，比如以下这种情况： 123T1: T2:get(x) get(y)get(y) get(x) 每个事务都获取了第一个读取数据的锁，直到事务结束了，它们都不会释放这个锁。接下来，它们都会等待另一个事务持有的锁。 不过好在事务系统提供了abort操作。如果事务系统可以检测到死锁(deadlock)，那么可以对T1或T2事务任意一个执行abort操作，使其中一个事务能正常获取lock完成事务，并中止另一个事务。而客户端client或应用程序可以自己决定如何处理事务被abort的情况，比如事务重试或放弃执行等等，但至少避免了死锁。 可以看出来2PL也会进入死锁的场景，但至少提供了abort操作，能够解决死锁问题，而不是永远停在死锁场景中。 问题：事务系统如何检测到死锁？ 回答：人们用两种方法来检测，尽管不够可靠。一种是基于超时(timeout)的，比如几个事务执行了许久看似没有新进展，则中止其中一个。另一种更系统的方法是构造一个**等待图(wait-for graph)**，如果发现等待图中出现环，则说明有死锁（比如上面T1等待T2的Lock Y，T2等待T1的Lock X，T1和T2成环）。 问题：检测到死锁后，中止其中一个事务会发生什么？ 回答：假设中止了T2，事务系统会安排T2没有result或者其result是可见的，此时abort强制释放T2占有的Lock Y，T1之后可获得Lock Y完成事务，而发起T2的客户端会知道T2被系统中止，一般情况下你可以选择重新发起T2。 原子性提交在分布式场景下，我们希望涉及事务的所有机器要么全都完成提交，要么全都表现得事务没有发生一样。 两阶段提交2PC通常情况下，我们需要执行的任务会以某种方式分包在多个服务器上，每个服务器需要完成任务的不同部分。我们需要一个计算机用来管理事务，它被称为事务协调者（Transaction Coordinator）。 通常协调者以试探的方式协调分布式事务。 以下为简单的示例，以及对应的崩溃处理： 下面所有的操作，都需要预写日志，即(WAL, write-ahead log)，先写日志，在做实际操作，确保崩溃恢复时能重现log完成已commit的操作，以及舍弃或恢复未commit的操作。 时序 coordinator(协调器) A服务器拥有X记录 B服务器拥有Y记录 1 新建事务(tid)，告知A执行put(X), 告知B执行put(Y) 2 Lock X, put(X), log X(日志记录)。这里暂时没有实际操作数据库，只是log记录 log Y(日志记录), Lock Y, log Y(日志记录)，这里暂时没有实际操作数据库，只是log记录 3 对A、B发起prepare询问请求，询问A和B是否正常log了事物需要的操作 4 A查看自己的状态，发现持有X的锁，并且log了需要执行的put操作，回应prepare请求YES B查看自己的状态，发现持有Y的锁，并且log了需要执行的put操作，回应prepare请求YES 5 收到A和B的prepare响应YES后，得知A和B可以准备提交事务了，向A和B发起commit(tid)请求 6 A看本地log，发现tid对应的事务可以提交了，于是install日志，即执行日志中记录的put(X)操作，然后释放X的锁，对commit请求响应OK B看本地log，发现tid对应的事务可以提交了，于是install日志，即执行日志中记录的put(Y)操作，然后释放Y的锁，对commit请求响应OK 7 收到A和B的OK，知道A和B都成功执行完事务了 假设时序4准备执行事务时，A或者B由于死锁或者log空间不足等原因无法执行事务操作，那么A或者B会对prepare请求回应NO，拒绝执行事务。 此时协调者在时序5的位置发现有人不同意执行事务，于是改成向A和B发送abort请求，要求停止执行事务。 在时序6的位置，A和B接收到abort请求后，会根据log里的记录，对tid事务操作进行回滚。回滚完毕后，A和B回应OK 在时序7的位置，协调者收到A和B的OK后，得知A和B都回滚tid事务成功了。 下图展示了2PC的过程（忽略了最初的RPC）。 在一个完整的系统中，或许会有很多不同的并发运行事务。每个持有数据的服务器会维护一个锁的表单，用来记录锁被哪个事务所持有。 缺点1.性能问题 无论是在第一阶段的过程中,还是在第二阶段,所有的参与者资源和协调者资源都是被锁住的,只有当所有节点准备完毕，事务 协调者 才会通知进行全局提交，参与者 进行本地事务提交后才会释放资源。这样的过程会比较漫长，对性能影响比较大。 2.单节点故障 由于协调者的重要性，一旦 协调者 发生故障。参与者 会一直阻塞下去。尤其在第二阶段，协调者 发生故障，那么所有的 参与者 还都处于锁定事务资源的状态中，而无法继续完成事务操作。（虽然协调者挂掉，可以重新选举一个协调者，但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题） 崩溃恢复分析两阶段提交会发送3N条消息，故障可能出现在这3次交互中的任意一次。 场景1:事务参与者在回应prepare后崩溃 首先，B已经对prepare回应OK了，所以这里B恢复后不能反悔，必须继续执行事务。这里B恢复后，仍持有数据Y的锁，并且检查log中记录的状态（比如需要把一些状态值加载到内存之类的），然后后续就和没发生崩溃一样走原本的流程了。 场景2：协调者在发送commit(tid)请求后崩溃 假设协调者在时序5的位置，向A和B发送commit请求后崩溃，需要怎么确保整个流程顺利执行？ 类似事务参与者，协调者在发送commit(pid)请求之前，需要记录log，崩溃后根据log继续执行事务流程。这里假设协调者崩溃前，A回应了OK，但是B回应协调者之前，协调者崩溃了。那么B必须等待协调者恢复后，再回应协调者OK，而不能私自中止事务。 这种情况下，B很不幸必须一直等待，这里其他事务如果要占用Y数据的锁就会失败，因为B需要等待协调者恢复后，能响应协调者时再释放锁。 场景3：A一直没有回应协调者prepare请求 假设A因为某些原因，在时序4的位置一直没有回应prepare，那么协调者会以超时等机制，在时序5的位置告知B执行abort来中止事务。后序A又和协调者联系上时，协调者会告诉A，tid这个事务已经中止了。这意味着B收到abort后可以释放Y数据的锁，然后后续尝试其他涉及Y数据的事务之类的。","link":"/2024/03/30/MIT6.824/%E7%AC%94%E8%AE%B010%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"},{"title":"MIT6824笔记十 Spanner","text":"论文材料： https://pdos.csail.mit.edu/6.824/papers/spanner.pdf Spanner是谷歌公司研发的、可扩展的、多版本、全球分布式、同步复制数据库。它是第一个吧数据分布在全球范围内的系统，并且支持外部一致性的分布式事务。Spanner实现了一个强大的时间API，用于实现非阻塞的读、不采用锁机制的只读事务和原子模式变更。 Spanner论文比较复杂，这里我结合课程，只重点讲述如何利用时间API完成分布式事务，包括读写事务和只读事务。 12http://loopjump.com/google_spanner/十问Spanner https://zhuanlan.zhihu.com/p/47870235 架构略 True Time API分布式环境里，我们无法保证不同机器的时钟总是具有相同的值。时钟偏移为给事务带来很多困扰，比如： 假设有3台机器ABC，A的时间戳快50，BC正常。事务T1更新A和C机器上的值，事务T2更新B和C机器上的值。以2PC为例，T1在时间50开始，协调者得到A=104（实际上为54）和C=50的回复，那么协调者就会选104作为提交时间戳，发起提交请求。T2在时间60开始，协调者得到B=100和C=60的回复，那么协调者就会选100作为提交时间戳，发起提交请求。然后C机器上，就会认为T2比T1先完成，T2的改变就会被覆盖，实际上T2晚于T1。 本质问题是多机器时间drift引起的多机时钟无法同步，从而使得，由于不同事务参与的集群和他们的时钟不同，则使全部数据库的commit时间戳混乱，无法与真实事件发生顺序一致。 简单解释Spanner的TrueTime在分布式事务中的作用 - 阿莱克西斯的文章 - 知乎https://zhuanlan.zhihu.com/p/44254954 Spanner的TrueTime利用硬件和软件的优化，保证给出的时间戳在一个时间区间内TT.now() = [earliest, latest]，返回最早的物理时间和最晚的物理时间。这个误差$\\epsilon$非常小。 当coordinator选择好时间戳之后，会等待一个ε的时间才告诉参与transaction的partition这个时间戳来commit。 读写事务 Client 事务协调者(Paxos组) Sa(A数据分片Paxos组) Sb(B数据分片Paxos组) 事务tid，向Sa的Paxos组leader发起数据分片A的读请求，向Sb的Paxos组leader发起数据分片B的读请求 Sa根据2PL，leader对X加锁，Owner是Client Sb根据2PL，leader对Y加锁，Owner是Client Client向事务协调者发起X=X-1，Y=Y+1的操作 收到X和Y更新的操作，通过2PC流程，分别发送X更新操作和Y更新操作到分片A和分片B的Paxos组leader 根据2PC流程，leader发现X已经有锁，将读锁升级为写锁，根据WAL进行事务操作的log 根据2PC流程，leader发现Y已经有锁，将读锁升级为写锁，根据WAL进行事务操作的log 发起prepare请求，确认Sa和Sb是否可以准备事务提交，同样需要Paxos组log、复制 检查已拥有锁，log记录事务状态和2PC状态，lock持有状态等信息，以及在Paxos组内同步log，确认整个Paxos组可以准备提交，leader回应OK 检查已拥有锁，log记录事务状态和2PC状态，lock持有状态等信息，以及在Paxos组内同步log，确认整个Paxos组可以准备提交，leader回应OK 发起commit(tid)请求，要求提交事务，同样需要Paxos组log、复制 Paxos组实际install log，执行log记录的事务操作，leader释放锁，leaer回应OK Paxos组实际install log，执行log记录的事务操作，leader释放锁，leader回应OK 读写事务是直接的2PL和2PC，两阶段锁和两阶段提交。TC（Tansaction Coordinator）由参与事务的某个Paxos Group leader担任，而不是设置一个专门的Paxos Group。 过程： client读请求直接发到对应的replica上，写的数据buffer到client自己这里，等执行结束，要提交时，将buffer的这些数据推到对应的参与者，然后选一个参与者作为协调者执行2PC。 各个参与者先申请写锁，然后分配一个prepare的时间戳，然后写日志，回应协调者。 所有参与者回应协调者，协调者选择一个时间戳s作为提交时间戳，写commit日志（协调者不写prepare日志），然后按照commit wait规则等待TT.now(s)条件满足后，将commit应用到Paxos状态机，然后通知其他参与者进入2PC Commit阶段， 其他参与者明白事务确定要提交，因此写outcome日志，这个日志包含了时间戳s的值，同步该日志成功后，应用到状态机，释放锁。 外部一致性为了实现外部一致性：如果一个事务T2在事务T1提交以后开始执行，那么T2的时间戳一定比T1大。 分配时间戳时遵循两条规则：Start和Commit Wait。 记担任协调者的leader发出提交请求的事件为$e_i^{server}$ ，在所有的锁获得以后，被释放之前，就可以为事务分配时间戳s。 Start规则保证事务协调者分配的时间戳s不会小于TT.now().latest。TT.now().latest在$e_i^{server}$ 后计算。 提交等待规则，就是确保客户端看到事务提交的数据时，事务已经真正提交了，即TT.after(s)为真。 那么协调者要怎么选时间戳呢？ s大于等于所有其他参与者的prepare时间戳； 大于协调者收到client commit请求时TT.now().latest（commit wait规则，先取TT.now().latest为时间戳，等待TT.now().latest为真之后才commit） 大于已经分配的时间戳 wound wait读写事务内部的读操作，使用伤停等待避免死锁。 2PC+2PL的事务实现非常容易死锁，比如A：lock(a) lock(b)；B：lock(b) lock(a)。 死锁处理使用伤害等待（wound-wait）的方式，新的事务会等待旧事务，而旧事务杀死新事务，事务被杀死后等待一段时间后用旧的时间戳重启，保证不会饿死也不会出现死锁。 这张图很好说明了伤停等待的效果：优先保证旧事务的执行，旧事务需要新事务的资源时直接杀死新事务；新事务需要旧事务的资源时，等待旧事务完成。 Wait-die 和 wound-die都是利用时间戳进行死锁预防，判断事务的新老级别。 wait-die和wound-wait两种机制都可以避免饿死。任何时候均存在一个时间戳最小的事务，并且这个事务都不允许回滚。由于时间戳总是增长，并且回滚的事务不赋予新时间戳，被回滚的事务最终会变成最小时间戳事务，从而最终会progress。 可以发现在wait-die、wound-wait机制中，事务的时间戳相当于事务的优先级，并且时间戳越小的事务优先级越高。wait-die、wound-wait机制之所以可以保证不出现死锁是因为在各自的机制中，事务间的等待都是单向的。wait-die中只有老事务会等待新事务，wound-wait中只有新事务会等待老事务。 wound-wait机制相比wait-die引起的回滚可能更少。wait-die机制中，如果事务T1由于申请数据项的锁被事务T2持有，而引起T1回滚，则当事务T1重启时，它可能发出相同的申请序列，如果该数据项的锁仍然被T2持有，那么T1会再度死亡，因此在T1最终加锁成功前可能会多次回滚。同样的场景，在wound-wait机制中，T1会一直等待。 只读事务Spanner实现了无锁机制的只读事务，怎么实现呢？ （1）bad implementation：always read lastet committed value 事务 时间戳10 时间戳20 时间戳30 T1 set X=1, Y =1, Commit T2 Set X=2, Y=2, Commit T3 Read X (now X=1) Read Y (now Y=2), Commit T3观察到了来自不同事务的写入，而不是得到一致的结果。（不符合可串行化，理论上T3要么X和Y都读取到1，要么都读取到2，要么都读取到X和Y的原始值）。 （2）true idea：snapshot isolation Spanner实现无锁机制的只读事务，主要依靠时间戳做MVCC（Multi Version Concurrence Control）。 为事务分配时间戳(Assign TS to TX) 读写事务：在开始提交时分配时间戳（R/W：commit） 只读事务：在事务开始时分配时间戳（R/O：start） 按照时间戳顺序执行所有的事务(Execute in TX order) 每个副本保存多个键的值和对应的时间戳(Each replica stores data with a timestamp) 事务(开始的时间戳) 时间戳10 时间戳20 时间戳30 T1 (10) set X=1, Y =1, Commit T2 (20) Set X=2, Y=2, Commit T3 (15) Read X (X=1) Read Y (Y=1), Commit 这里T3需要读取时间戳15之前的最新提交值，这里时间戳15之前的最新值，只有T1事务提交的写结果，所以T3读取的X和Y都是1。因为所有的事务按照全局时间戳执行，所以保证了我们想要的线性一致性或串行化。 每个replica给数据维护了version表，可想而之，表中应该是数据的值以及对应的时间戳。 safe time机制Spanner还使得读操作能分散到各个机器上，使得读本地副本也能读到最新commit值，依靠的就是safe time机制。 Paxos按照时间戳顺序发送所有的写入操作(Paxos sends write in timestamp order) 读取X数据的T时间戳版本数据之前，需等待T时间戳之后的任意数据写入(Before Read X @15, wait for Write &gt; @15) 这里等待写入，同时还需要等待在2PC中已经prepare但是还没有commit的事务(Also wait for TX that have prepared but not committed) 每个副本无论主备，都维护一个tsafe的时间戳，这个tsafe是一个副本最近更新后的最大时间戳。只有读操作的时间戳t，满足$t \\le t_{safe}$时，读操作才生效。 $\\begin{equation}t_{safe}=min(t_{safe}^{Paxos},t_{safe}^{TM}) \\end{equation}$ $t_{safe}^{Paxos}$指已经应用到Paxos状态机的Paxos write的时间戳的安全时间戳，因为Paxos write应用到状态机是顺序应用的，因此只要维护最后一次应用的Paxos write的时间戳就可以了。 $t_{safe}^{TM}$是指所有没有提交的事务的提交时间戳下界。 总结本文对Spanner解读有限，集中讨论了读写事务和只读事务的实现。读写事务依靠2PL+2PC，同时使用wound wait避免死锁。只读事务利用TT无锁进行，利用saft time保证在本地副本读新的操作。","link":"/2024/04/03/MIT6.824/%E7%AC%94%E8%AE%B011Spanner/"},{"title":"MIT6824笔记一 绪论与MapReduce","text":"MIT 6.824 课程第一节笔记，主要介绍了分布式系统的驱动力、难点、类型等，还介绍了MapReduce。 分布式系统介绍（1）驱动力 更高的计算性能（并行计算、大CPU、大内存、大磁盘） 容错机制（两台计算机运行相同的任务，一台失败可到另外一台） 问题的分布特性（比如说银行转账） RPC与代码隔离，只通过网络通信 这门课程主要研究性能与容错。 （2）困难 并行 容错 兼顾性能 （3）分布式系统的类型 基础架构的类型主要是存储，通信（网络）和计算。 实际上我们最关注的是存储，构建一种多副本，容错的，高性能分布式存储实现。 会讨论一些计算系统，比如MapReduce。 也会说一些关于通信的问题，但是主要的出发点是通信是我们建立分布式系统所用的工具。 对于存储和计算，我们的目标是为了能够设计一些简单接口，让第三方应用能够使用这些分布式的存储和计算，这样才能简单的在这些基础架构之上，构建第三方应用程序。 （4）工具 RPC（Remote Procedure Call）。RPC的目标就是掩盖我们正在不可靠网络上通信的事实。 线程。这是一种编程技术，使得我们可以利用多核心计算机。对于本课程而言，更重要的是，线程提供了一种结构化的并发操作方式，这样，从程序员角度来说可以简化并发操作。 并发控制，比如锁。 （5）其他特性 可拓展性：N倍的机器能否带来N倍的性能提升？ 可用性：容错、故障应对 一致性：读写一致性，系统正确的行为 Map Reduce背景Google （2003 年左右）面对巨量（数十 T）的索引数据和全网结构的数据，需要找到最重要的网页。这可以简化为一个排序问题，但如此数量级的排序，单机不是一个可选项。 MapReduce的思想是，应用程序设计人员和分布式运算的使用者，只需要写简单的Map函数和Reduce函数，而不需要知道任何有关分布式的事情，MapReduce框架会处理剩下的事情。 工作原理 两类任务：Map和Reduce一个主节点分配任务，若干个worker节点干活。 看起来很简单的架构，但在分布式环境下，需要考虑： worker节点崩溃，需要任务完成确认机制以及崩溃后临时文件的清理 网络通信不可靠，发送任务和确认任务的消息均可能丢失","link":"/2023/11/25/MIT6.824/%E7%AC%94%E8%AE%B01%E7%BB%AA%E8%AE%BA/"},{"title":"MIT6824笔记二 Go与RPC","text":"这节课主要介绍Go语言以及用Go实现爬虫的例子。 GOGO的优势 语法层面支持线程和管道 垃圾回收机制，不需要手动管理内存 类型安全（内存安全） //关于内存安全还需要再深刻认识 线程协调方式 channels：go 中比较推荐的方式，分阻塞和带缓冲。 sync.Cond：信号机制。 waitGroup：阻塞知道一组 goroutine 执行完毕，后面还会提到。 爬虫例子 从一个种子网页 URL 开始 通过 HTTP 请求，获取其内容文本 解析其内容包含的所有 URL，针对所有 URL 重复过程 2，3 为了避免重复抓取，需要记下所有抓取过的 URL。 串行爬取（1）串行爬取的主要逻辑 12fmt.Printf(&quot;=== Serial===\\n&quot;)Serial(&quot;http://golang.org/&quot;, fetcher, make(map[string]bool)) 1234567891011121314func Serial(url string, fetcher Fetcher, fetched map[string]bool) { if fetched[url] { return } fetched[url] = true urls, err := fetcher.Fetch(url) if err != nil { return } for _, u := range urls { Serial(u, fetcher, fetched) } return} 深度优先遍历（DFS ）全部网页构成的图结构，利用一个名为 fetched 的 set 来保存所有已经抓取过的 URL。 （2）爬取函数的主要逻辑 Fetcher接口，里面定义了一个Fetch方法 fakeFetcher自定义类型，是一个string到fakeResult的map fakeResult结构体，包括body和urls 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859//// Fetcher//type Fetcher interface { // Fetch returns a slice of URLs found on the page. Fetch(url string) (urls []string, err error)}// fakeFetcher is Fetcher that returns canned results.type fakeFetcher map[string]*fakeResult //自定义类型type fakeResult struct { body string urls []string}func (f fakeFetcher) Fetch(url string) ([]string, error) { if res, ok := f[url]; ok { fmt.Printf(&quot;found: %s\\n&quot;, url) return res.urls, nil } fmt.Printf(&quot;missing: %s\\n&quot;, url) return nil, fmt.Errorf(&quot;not found: %s&quot;, url)}// fetcher is a populated fakeFetcher.var fetcher = fakeFetcher{ &quot;http://golang.org/&quot;: &amp;fakeResult{ &quot;The Go Programming Language&quot;, []string{ &quot;http://golang.org/pkg/&quot;, &quot;http://golang.org/cmd/&quot;, }, }, &quot;http://golang.org/pkg/&quot;: &amp;fakeResult{ &quot;Packages&quot;, []string{ &quot;http://golang.org/&quot;, &quot;http://golang.org/cmd/&quot;, &quot;http://golang.org/pkg/fmt/&quot;, &quot;http://golang.org/pkg/os/&quot;, }, }, &quot;http://golang.org/pkg/fmt/&quot;: &amp;fakeResult{ &quot;Package fmt&quot;, []string{ &quot;http://golang.org/&quot;, &quot;http://golang.org/pkg/&quot;, }, }, &quot;http://golang.org/pkg/os/&quot;: &amp;fakeResult{ &quot;Package os&quot;, []string{ &quot;http://golang.org/&quot;, &quot;http://golang.org/pkg/&quot;, }, },} 并行爬取（1）思考并行的方法 简单将抓取部分用go关键并行。 但如果仅这么改造，不利用某些手段（sync.WaitGroup）等待子 goroutine，而直接返回，那么可能只会抓取到种子 URL，同时造成子 goroutine 的泄露。 如果访问已经抓取的 URL 集合 fetched 不加锁，很可能造成多次拉取同一个网页（两个线程都访问fetched，这个url访问过了吗，结果都是未访问） （2）并行实现——利用锁和共享变量 12fmt.Printf(&quot;=== ConcurrentMutex ===\\n&quot;)ConcurrentMutex(&quot;http://golang.org/&quot;, fetcher, makeState()) 1234567891011121314151617181920212223242526272829303132333435363738394041//// Concurrent crawler with shared state and Mutex//type fetchState struct { mu sync.Mutex fetched map[string]bool}func makeState() *fetchState { return &amp;fetchState{fetched: make(map[string]bool)}}func (fs *fetchState) testAndSet(url string) bool { fs.mu.Lock() defer fs.mu.Unlock() r := fs.fetched[url] fs.fetched[url] = true //已经访问过 return r}func ConcurrentMutex(url string, fetcher Fetcher, fs *fetchState) { if fs.testAndSet(url) { //这里其实就是用锁保护map的更新 return } urls, err := fetcher.Fetch(url) if err != nil { return } var done sync.WaitGroup for _, u := range urls { done.Add(1) go func(u string) { defer done.Done() ConcurrentMutex(u, fetcher, fs) }(u) } done.Wait() return} 其中，关键部分为：sync.WaitGroup 123456789var done sync.WaitGroupfor _, u := range urls { done.Add(1) go func(u string) { defer done.Done() ConcurrentMutex(u, fetcher, fs) }(u)}done.Wait() WaitGroup 内部维护了一个计数器：调用 wg.Add(n) 时候会增加 n；调用 wait.Done() 时候会减少 1。调用 wg.Wait() 会一直阻塞直到当计数器变为 0 所以 WaitGroup 适合等待一组 goroutine 都结束的场景。 利用channel实现并行爬取我们可以实现一个新的爬虫版本，不用锁 + 共享变量，而用 go 中内置的语法：channel 来通信。具体做法类似实现一个生产者消费者模型，使用 channel 做消息队列。 初始将种子 url 塞进 channel。 消费者：master 不断从 channel 中取出 urls，判断是否抓取过，然后启动新的 worker goroutine 去抓取。 生产者：worker goroutine 抓取到给定的任务 url，并将解析出的结果 urls 塞回 channel。 master 使用一个变量 n 来追踪发出的任务数；往发出一份任务增加一；从 channel 中获取并处理完一份结果（即将其再安排给 worker）减掉一；当所有任务都处理完时，退出程序。 12fmt.Printf(&quot;=== ConcurrentChannel ===\\n&quot;)ConcurrentChannel(&quot;http://golang.org/&quot;, fetcher) 1234567891011121314151617181920212223242526272829303132333435363738//// Concurrent crawler with channels//func worker(url string, ch chan []string, fetcher Fetcher) { urls, err := fetcher.Fetch(url) if err != nil { ch &lt;- []string{} } else { ch &lt;- urls }}func coordinator(ch chan []string, fetcher Fetcher) { n := 1 fetched := make(map[string]bool) for urls := range ch { for _, u := range urls { if fetched[u] == false { fetched[u] = true n += 1 go worker(u, ch, fetcher) } } n -= 1 if n == 0 { break } }}func ConcurrentChannel(url string, fetcher Fetcher) { ch := make(chan []string) go func() { ch &lt;- []string{url} }() coordinator(ch, fetcher)} Q&amp;A: master 读 channel，多 worker 写 channel，不会有竞争问题吗？channel 是线程安全的。 channel 不需要最后 close 吗？我们用 n 追踪了所有执行中的任务数，因此当 n 为 0 退出时，channel 中不存在任何任务 / 结果，因此 master/worker 都不会对 channel 存在引用，稍后 gc collector 会将其回收。 为什么在 ConcurrentChannel 需要用 goroutine 往 channel 中写一个 url？否则 master 在读取的时候会一直阻塞。并且 channel 是一个非缓冲 channel，如果不用 goroutine，将会永远阻塞在写的时候。第3个问题，如果不用goroutine，并且是非缓冲管道情况下，发送方会阻塞在发送代码，直到有接收放接收消息。","link":"/2023/11/25/MIT6.824/%E7%AC%94%E8%AE%B02RPC%E4%B8%8E%E7%BA%BF%E7%A8%8B/"},{"title":"MIT6824笔记三 分布式存储系统GFS","text":"这节课主要介绍分布式存储系统的难点以及论文GFS。 分布式系统出现的原因是人们想要利用更多的机器实现更好的性能，但更多的机器意味着故障的期望上升。解决单台机器故障最简单的办法就是多副本的容错机制，但多副本间需要时间同步。一致性难题意味着牺牲性能，这是个闭环，人们必须在性能和一致性上做取舍。 对于GFS的学习，我觉得首先要明白GFS应对的需求，整体的架构设计，然后就是读写过程，数据一致性，这是从使用层面上来说的。在高可用方面，GFS的备份管理、文件快照、崩溃恢复等细节需要再深入研究。 分布式存储系统的难点从一种角度出发理解分布式储存的难点： 性能 一开始，人们想用大量机器提供更高的性能，这称之为分片（sharding）。但分片一多，故障率就上来了。 故障 故障：单台计算机出错概率小，多台计算机出错的期望就上来了。上千台计算机总有一台失效停机。我们需要一种容错机制（fault torlance）。 容错 实现容错机制最简单的办法就是提供多个副本（replication、backup），一旦一个副本失败，就马上用另一个副本顶替。 副本 有了复制，也还需要注意副本之间的同步，或者说一致型。 一致性 维护一致性通常需要精心设计的手段，比如说主从之间定期通信，传快照或者状态改变。但无论如何设计，一致性的存在或多或少会损害性能。这就是分布式存储系统/分布式系统的难点所在。 如果构建强一致系统会付出相应代价，如果不想付出很多代价，就得忍受不确定的行为。在实践中，要根据场景设计合理的系统，适当取舍。 尽管我们会通过数百台计算机构建一个系统，但是对于一个理想的强一致模型，你看到的就像是只有一台服务器，一份数据，并且系统一次只做一件事情。这是一种直观的理解强一致的方式。 Google File SystemGFS 是谷歌最早开发应用的分布式存储框架。GFS的可贵之处在于它的应用性，尽管学界研究了数十年的分布式系统，但GFS是第一个应用到上千台计算机的分布式系统。论文写得很棒，推荐读英文原文。 论文中的一些思想在当时都不是特别新颖，比如分布式，分片，容错这些在当时已经知道如何实现了。这篇论文的特点是，它描述了一个真正运行在成百上千台计算机上的系统，这个规模远远超过了学术界建立的系统。并且由于GFS被用于工业界，它反映了现实世界的经验，例如对于一个系统来说，怎样才能正常工作，怎样才能节省成本，这些内容也极其有价值。 GFS 可贵之处是经过实践检验、部署过上千台机器的工业级系统，颠覆了之前学术界中很多的经典设计认知，比如： 为了保证数据访问不出错，需要提供强一致性保证（GFS 仅提供某种弱一致性） 为了系统的可靠性，用多机来保证主节点的可靠性（GFS 使用了单点 Master） GFS的设计场景对于任何一种分布式系统，都要明确它应用的场景需求，然后才能对此作出相应设计保障。 大文件存储，GB级别大小 大量顺序读和少量随机读 大量追加写和少量随机写 能够应对多客户端并发写入 部署在普通计算机上，有较高故障率，需要好的容错机制 GFS的总体设计 一个GFS集群包括若干个客户端、一个主节点、若干个从节点（分片服务器成，chunkserver）。 文件被分为64MB大小的块，每个块对应一个唯一64bit的块标识（chunk handle）并分散存储在从节点上。从节点就只是个运行LInux系统的普通机器。 主节点维护命名空间（文件系统的路径）、访问控制信息、文件与块的对应信息、块的存储信息（每个块存储在哪个从节点上）。 客户端与主节点的交互只有文件的元信息。客户端得到它想要的文件存储的真实信息后，就直接向从节点索要数据。 GFS读过程// 略 GFS写过程// 略 GFS的一致性GFS 把自己的一致性称为松弛的一致性模型（relaxed consistency model）。 元数据（命名空间）的操作都是由单一的 master 处理的，并且操作通过锁来保护，保证了原子性，也保证了正确性。 文件的数据修改则相对复杂。在讲述接下来的内容前，首先我们先明确，在文件的某一部分被修改后，它可能进入以下三种状态的其中之一： 客户端读取不同的 Replica 时可能会读取到不同的内容，那这部分文件是不一致的（Inconsistent） 所有客户端无论读取哪个 Replica 都会读取到相同的内容，那这部分文件就是一致的（Consistent） 所有客户端都能看到上一次修改的所有完整内容，且这部分文件是一致的，那么我们说这部分文件是确定的（Defined） 在修改后，一个文件的当前状态将取决于此次修改的类型以及修改是否成功。具体来说： 如果一次写入操作成功且没有与其他并发的写入操作发生重叠，那这部分的文件是确定的（同时也是一致的） 如果有若干个写入操作并发地执行成功，那么这部分文件会是一致的但会是不确定的：在这种情况下，客户端所能看到的数据通常不能直接体现出其中的任何一次修改 失败的写入操作会让文件进入不一致的状态 适应 GFS 的松弛一致性GFS 的松弛一致性模型，实际上是一种不一致的模型，或者更准确地说，在一致的数据中间夹杂着不一致的数据。这就要求上层应用在使用 GFS 时能够适应 GFS 所提供的一致性语义。 论文中给出了几条使用 GFS 的建议：依赖追加（append）而不是依赖覆盖（overwrite）、设立检查点（checkpoint）、写入自校验（write self-validating）、自记录标识（self-identifying record）。 简单来讲，上层应用可以通过两种方式来做到这一点：更多使用追加操作而不是覆写操作；写入包含校验信息的数据。 青睐追加操作而不是覆写操作的原因是明显的：GFS 针对追加操作做出了显著的优化，这使得这种数据写入方式的性能更高，而且也能提供更强的一致性语义。 对于不一致的数据，为每条记录添加校验数，读取方通过校验数识别出不一致的数据，并且丢弃不一致的数据。 对于重复数据，可以采用数据幂等处理。具体来说，可以采用两种方式处理。第一种，对于同一份数据处理多次，这并无负面影响；第二种，如果执行多次处理带来不同的结果，那么应用就需要过滤掉不一致的数据。写入方写入记录时额外写入一个唯一的标识（identifier），读取方读取数据后，通过标识辨别之前是否已经处理过该数据。 GFS的设计哲学前面讲解了基于GFS的应用，需要通过一些特殊手段来应对GFS的松弛一致性模型带来的各种问题。对于使用者来说，GFS的一致性保证是非常不友好的，很多人第一次看到这样的一致性保证都是比较吃惊的。 GFS在架构上选择这样的设计，有它自己的设计哲学。GFS追求的是简单、够用的原则。GFS主要解决的问题是如何使用廉价的服务器存储海量的数据，且达到非常高的吞吐量（GFS非常好地做到了这两点，但这不是本书的主题，这里就不展开介绍了），并且文件系统本身要简单，能够快速地实现出来（GFS的开发者在开发完GFS之后，很快就去开发BigTable了[2]）。 GFS很好地完成了这样的目标，但是留下了一致性问题，给使用者带来了负担。这个问题在GFS推广应用的初期阶段不明显，因为GFS的主要使用者（BigTable系统是GFS系统的主要调用方）就是GFS的开发者，他们深知应该如何使用GFS。这种不一致性在BigTable中被屏蔽掉（采用上面所说的方法），BigTable提供了很好的一致性保证。 但是随着GFS推广应用的不断深入，GFS简单、够用的架构开始带来很多问题，一致性问题仅仅是其中之一。Sean Quinlan作为Leader主导GFS的研发很长时间，在一次采访中，他详细说明了在GFS渡过推广应用的初期阶段之后，这种简单的架构带来的各种问题[2]。 在清晰地看到GFS的一致性模型给使用者带来的不便后，开源的HDFS（Hadoop分布式文件系统）坚定地摒弃了GFS的一致性模型，提供了更好的一致性保证（第3章将介绍HDFS的实现方式）。 参考资料： Google File System 论文详析 https://zhuanlan.zhihu.com/p/33944479 GFS的分布式哲学 https://mp.weixin.qq.com/s/ut8Q7vXa5Lm0auNaN2_Emg [1] Ghemawat S, Gobioff H, Leung S T. The Google File System. ACM SIGOPS Operating Systems Review, 2003. [2] Marshall, Kirk, McKusick, et al. GFS: Evolution on Fast-forward. Communications of the ACM, 2009.","link":"/2023/11/25/MIT6.824/%E7%AC%94%E8%AE%B03GFS/"},{"title":"MIT6824笔记四 容错与FTVM","text":"这节课主要介绍容错的主要手段——复制以及相应的论文：Fautl-Tolerant Virtual Machines。 复制与容错关系容错本身是为了提供高可用性。例如，当你想构建一个服务时，尽管计算机硬件总是有可能故障，但是我们还是希望能稳定的提供服务。 容错的简单手段就是复制。复制能应对什么样的故障？ 最简单的描述就是单台计算机的fail-stop故障。Fail-stop是一种容错领域的通用术语。它是指，如果某些东西出了故障，比如说计算机，那么它会单纯的停止运行。当任何地方出现故障时，就停止运行，而不是运算出错误结果。 但是复制不能处理软件中的bug和硬件设计中的缺陷，关联性错误（同一批次产品的生产设计缺陷）。 Fautl-Tolerant Virtual MachinesINTRODUCTION论文的introduction写得很简练，直接放原文。 A common approach to implementing fault-tolerant servers is the primary / backup approach [1], where a backup server is always available to take over if the primary server fails. The state of the backup server must be kept nearly identical to the primary server at all times, so that the backup server can take over immediately when the primary fails, and in such a way that the failure is hidden to external clients and no data is lost. 应对容错的主要方式就是主从复制。主节点崩溃时，从节点能够马上接管，并且从节点的状态要与主节点尽可能一致。 One way of replicating the state on the backup server is to ship changes to all state of the primary, including CPU, memory, and I/O devices, to the backup nearly continuously. However, the bandwidth needed to send this state, particular changes in memory, can be very large. 在备份服务器上复制状态的一种方法是将对主服务器的所有状态（包括 CPU、内存和 I/O 设备）的更改几乎连续地传送到备份中。但是，发送此状态所需的带宽（特别是内存中的更改）可能非常大。 A different method for replicating servers that can use much less bandwidth is sometimes referred to as the state-machine approach [13]. The idea is to model the servers as deterministic state machines that are kept in sync by starting them from the same initial state and ensuring that they receive the same input requests in the same order. Since most servers or services have some operations that are not deterministic, extra coordination must be used to ensure that a primary and backup are kept in sync. However, the amount of extra information need to keep the primary and backup in sync is far less than the amount of state (mainly memory updates) that is changing in the primary. 另一种方法基于状态机。这个想法是通过从相同的初始状态启动服务器并确保它们以相同的顺序接收相同的输入请求来将服务器建模为保持同步的确定性状态机。由于大多数服务器或服务都具有一些不确定的操作，因此必须使用额外的协调来确保主服务器和备份服务器保持同步。但是，保持主数据库和备份数据库同步所需的额外信息量远远小于主数据库中更改的状态（主要是内存更新）量。 BASIC FT DESIGN 所有的输入（网络输入、鼠标键盘输入）由主节点接收。主节点和从节点间通过网络的方式通信，称之为logging channel。主节点将它看见的所有输入都通过logging channel 发给从节点。另外，logging channel还传输一些其他包括非确定性行为的信息。 这样从节点就和主节点执行一模一样的的操作，但是从节点的输出被抛弃，只有主节点才能回复客户端。 非确定性事件非确定性事件：不由当前内存和寄存器直接决定的指令 比如随机数生成、事件日期、唯一ID，这些统称为Weird Instructions 客户端的网络输入：包中的数据和包到达的中断触发位置。 FT Protocoloutput requirement if the backup VM ever takes over after a failure of the primary, the backup VM will continue executing in a way that is entirely consistent with all outputs that the primary VM has sent to the external world. 如果备份虚拟机在主虚拟机发生故障后接管，则备份虚拟机将继续以与主虚拟机发送到外部世界的所有输出完全一致的方式执行。 感觉这句话就是脱裤子放屁，多此一举。从状态机肯定要与主状态机状态一致，这样才能在故障时进行主从切换。可以通过延迟任何外部输出（通常是网络数据包）来确保输出要求，直到备份 VM 收到所有信息，使其至少可以重播到该输出操作的点。这就引出来第二个点 output rule the primary VM may not send an out put to the external world, until the backup VM has received and acknowledged the log entry associated with the operation producing the output. 只有主节点收到日志复制完成的回复，它才向外部输出。这意味着从节点收到了日志（此时日志可能堆在缓冲区，尚未执行） Test-and-Set服务一种常见的场景就是主从间网络不可用，此时它们都以为对方挂了，从而各自掌权回复客户端，也就是脑裂问题。 这篇论文解决这个问题的方法是，向一个外部的第三方权威机构求证，来决定Primary还是Backup允许上线。这里的第三方就是Test-and-Set服务。 VM通过网络请求Test-and-Set服务，这个服务会在内存中保留一些标志位，当你向它发送一个Test-and-Set请求，它会设置标志位，并且返回旧的值。这有点像锁，保证了原子操作。任何情况下，想要上线掌权的副本都需要获取Test-and-Set服务。 持有锁的服务挂了怎么办？一般锁都是设置一个租约，有一些心跳机制来续约。","link":"/2023/11/25/MIT6.824/%E7%AC%94%E8%AE%B04VMwareFT/"},{"title":"MIT6824笔记五 Raft","text":"Raft是一个分布式共识算法/协议，即让多台机器达成一致的算法。 Raft将共识问题分解为三部分：Leader选举、Log复制以及安全性设置(一致性设置）。 由于实验2完整复现了Raft协议，这里只挑一些重点讲。复现时应该着重考虑：节点崩溃又上线、不可靠网络。 Leader选举角色转变 server有三种状态：follower、candidate、leader。分别经过如图所示的过程进行状态转变。 follower和candidate的任务就是等定时器过期发起投票，leader则是发起心跳请求。 当followers选举时间间隔到期后转变为candidate，增加自己的任期号，发起一轮投票； 当leader时，心跳时间间隔开启，选举时间间隔关闭，每隔一段时间向所有node发送空的AppendEntry。 任期机制 发送和回复RPC都要带上自己的任期。任何时刻（收到请求和处理回复）发现自己的任期旧，都要转变身份为follower。 一期一票制度：一个机器在一个任期只能投一票，投票对象VotedFor应该作持久化，避免节点崩溃再次上线重新投票。 投票过程想明白几个问题： 什么时候才能发起投票？ 发起投票的步骤？ 收到过半选票后的处理？ 什么条件下才能为candidate投出自己的选票？ 选举定时器重置的时间点？ 过半票决的好处： 在一机一票的场景下，只会产生一个leader节点 出现网络分区的时候，只可能有一个分区会有超过一半的服务器互相通信 旧leader的过半服务器必然与新leader的过半服务器有重叠，那么就有一个服务器经历过两个任期，它收集了完整的log信息 响应投票： 收到投票RPC消息后，需要比较任期号，驳回旧的任期号投票请求； 如果任期号校验通过，重置选举时间； 当且仅当自己的votedFor为空或为消息中的candidateId时，并且比较自己的log与RPC中的lastLog信息后，才同意投票，并设置自己的votedFor为candidateId。 日志复制想明白几个问题： nextIndex和matchIndex的作用？ 日志不一致时的回退算法？ 什么时候日志能提交？怎么避免日志重复提交？ leader只能提交当前任期内的日志。","link":"/2023/12/13/MIT6.824/%E7%AC%94%E8%AE%B05Raft/"},{"title":"MIT6824笔记七 链式复制","text":"这节课主要介绍了链复制的基本思想以及链复制的改进（Chain Replication with Apportioned Queries，CRAQ）。 CRAQ通过引入版本机制以及clean/dirty状态机制来改进多个节点的分散读。当数据首次到达中间节点时，该数据会被标识为dirty；当数据达到tail节点时，数据标识为clean，并进行反向传播，使之前的节点也将该数据标识为clean。 论文：https://pdos.csail.mit.edu/6.824/papers/craq.pdf 链复制基本方法![image-20231213135524616](/Users/mac/Library/Application Support/typora-user-images/image-20231213135524616.png) 为了保持线性一致的语义，链复制的基本思想是将服务器组成链表，请求从头部开始，一直链式传递到尾部。 写请求发往头部，读请求发往尾部。不同的是，写请求要经过完整的链传递复制，读请求不需要。 具体而言，当链表头部的服务器收到写请求时，它应用写请求，然后传递给下一个服务器。下一个服务器同样应用写请求，再传递下一个服务器。当尾部服务器应用完写请求时，它才回复客户端写请求已经完成。 读请求则十分简单，直接根据尾部服务器的状态读取。没有完成的写请求要么没有传递到尾服务器，要么就是回复丢失。而链复制一次只处理一个请求。所以读请求能看到最新的写请求状态，自然就是线性一致。 故障恢复链复制的写请求出现故障只有两种情况：要么写请求被所有服务器看到（commited），要么写请求只传递到中间某个服务器。 （1）Head故障 写请求在Head转发前，Head就故障了。那么没有服务器能看到这个写请求，第二个节点成为新的Head。 写请求在Head转发后，Head故障了，那么这个写请求还是会被持续转发下去，所有live服务器都看到这个写请求。 （2）Tail故障 如果TAIL出现故障，处理流程也非常相似，TAIL的前一个节点可以接手成为新的TAIL。所有TAIL知道的信息，TAIL的前一个节点必然都知道，因为TAIL的所有信息都是其前一个节点告知的。 （3）中间节点故障 或许有一些写请求被故障节点接收了，但是还没有被故障节点之后的节点接收，所以，当我们将其从链中移除时，故障节点的前一个节点或许需要重发最近的一些写请求给它的新后继节点。这是恢复中间节点流程的简单版本。 对比Raft（1）性能 对于Raft，如果我们有一个Leader和一些Follower。Leader需要直接将数据发送给所有的Follower 然而在Chain Replication中，HEAD只需要将写请求发送到一个其他节点。 所以Raft Leader的负担会比Chain Replication中HEAD的负担更高。当客户端请求变多时，Raft Leader会到达一个瓶颈，而不能在单位时间内处理更多的请求。 （2）读写分离 另一个与Raft相比的有趣的差别是，Raft中读请求同样也需要在Raft Leader中处理，所以Raft Leader可以看到所有的请求。而在Chain Replication中，每一个节点都可以看到写请求，但是只有TAIL可以看到读请求。所以负载在一定程度上，在HEAD和TAIL之间分担了，而不是集中在单个Leader节点。 （3）故障恢复 Chain Replication故障恢复更加简单。 配置管理器Chain Replication并不能抵御网络分区，也不能抵御脑裂。在实际场景中，这意味它不能单独使用。总是会有一个外部的权威（External Authority）来决定谁是活的，谁挂了，并确保所有参与者都认可由哪些节点组成一条链，这样在链的组成上就不会有分歧。这个外部的权威通常称为Configuration Manager。 Configuration Manager的工作就是监测节点存活性，一旦Configuration Manager认为一个节点挂了，它会生成并送出一个新的配置，在这个新的配置中，描述了链的新的定义，包含了链中所有的节点，HEAD和TAIL。Configuration Manager认为挂了的节点，或许真的挂了也或许没有，但是我们并不关心。因为所有节点都会遵从新的配置内容，所以现在不存在分歧了。 现在只有一个角色（Configuration Manager）在做决定，它不可能否认自己，所以可以解决脑裂的问题。 当然，你是如何使得一个服务是容错的，不否认自己，同时当有网络分区时不会出现脑裂呢？答案是，Configuration Manager通常会基于Raft或者Paxos。在CRAQ的场景下，它会基于Zookeeper。而Zookeeper本身又是基于类似Raft的方案。 所以，你的数据中心内的设置通常是，你有一个基于Raft或者Paxos的Configuration Manager，它是容错的，也不会受脑裂的影响。之后，通过一系列的配置更新通知，Configuration Manager将数据中心内的服务器分成多个链。 CRAQ对象存储对象存储支持两种基本原语： read 或 query 操作返回存储在对象名称下的数据块 write 或 update 操作更改单个对象的状态 一致性模型本文涉及到的两种一致性模型为： 强一致性：系统保证对一个对象的读写操作都以顺序执行，并且对于一个对象的读操作总是会观察到最新被写入的值。 最终一致性：在系统中，对一个对象的写入仍是按顺序在所有节点上应用的，但对不同节点的最终一致性读取可能会在一段时间内（即，在写操作应用于所有节点之前）返回过时的数据。但是，一旦所有副本都接收到写入操作，则读操作将不会返回比最新提交的写操作更早的版本。 链复制基本方法是将所有存储对象的节点组织在一条链中，其中链的尾节点处理所有读取请求，而链的头节点处理所有写入请求。在客户端收到确认之前，写操作沿链向下传播，因此尾节点可以得到所有对象操作的执行顺序，具有强一致性。该方法没有任何复杂或多轮通信的协议，但是提供了简单、高吞吐量和容易故障恢复的特性。 不幸的是，基础的链复制方法有一些局限性。对一个对象的所有读取都在头节点，从而导致潜在的热点问题。虽然可以通过一致性哈希方法或更中心化的目录方法将集群中的节点组织到多个链中，以实现更好的负载均衡，但是如果特定对象访问较少，这些算法仍然可能会负载不平衡，这在实践中是一个真实的问题。 链式复制的 故障恢复： 当头节点出故障时：后续节点取代它成为头节点，没有丢失的已提交写操作 当尾节点出故障时：前一个节点取代它成为尾节点，没有丢失的写操作 当中间节点故障时：从链中去掉，前一个节点需要重新发送最近的写操作 局限性：对一个对象的所有读取必须都要转到同一个节点，尾节点的负载很大。 CRAQ分散读的改进 CRAQ的主要思想，在保证强一致性的前提下，通过允许任意节点接收处理client读请求，提升系统读吞吐量。其主要扩展包括： 每个节点都可以存储一个object的多个版本，每个版本包含一个单调递增的版本号和一个表示该版本dirty/clean状态的附加属性。每个版本的初始状态设置为clean。 当节点接收到一个object的新版本时（写入操作沿着复制链传播），将其加入到该object的版本列表中，存在以下两种情况： 若该节点不是TAIL节点，则将object的当前版本状态标记为dirty，并传播write请求； 若该节点是TAIL节点，则将object的当前版本状态标记为clean，意味着该write请求已committed，并发送ack确认消息（ack消息沿着复制链传播）。 当节点收到一个object的某个版本的ack消息时，将object对应版本状态标记为clean，并删除之前所有的版本。 当节点接收到一个object的读请求时，按照以下方式处理： 若object的最新版本状态为clean，则返回该值； 否则，向TAIL节点获取该object最新提交的版本号，并返回该版本的值。（TAIL节点在回复object的最新提交版本号之后，可能又提交了新的write请求，但并不破坏强一致性保证：读写请求最终都是由TAIL节点确定执行顺序。） CRAQ的一致性模型CRAQ同时提供3种读一致性模型，允许读请求指明可选的一致性类型。 • 强一致性，默认的一致性类型，允许从任意节点均可读取到object最近已提交的数据。 • 最终一致性，从任意节点读，均返回该节点已知的object的最新版本数据（clean）。这可能会导致连续两次从不同节点读取到不一致的数据，因此，不满足单调读一致性保证。 • 具有最大不一致边界的最终一致性，从任意节点能读取到object新写入的未提交的数据（dirty），但需要满足某些限制条件。该模型下，读请求的返回值具有最大不一致的周期（时间或版本号）。对于正常情况下，该不一致表示获取到比最后一次提交的版本更新的版本。对于异常情况下，比如网络分区导致部分节点未参与写请求，该不一致表示获取到比当前已提交的版本更旧的版本。 CRAQ的拓展https://zhuanlan.zhihu.com/p/539352802","link":"/2023/12/13/MIT6.824/%E7%AC%94%E8%AE%B07CRAQ/"},{"title":"MIT6824笔记六 线性一致与Zookeeper","text":"这节课主要介绍了线性一致的概念与Zookeeper论文。 线性一致描述的是系统的行为，正确的行为是客户端发送了一个写请求并且收到服务端答复后，这个写请求能被之后的读请求看到。每个读请求看到的都是最新的写请求所作的更改。 Zookeeper论文是我接触到的最抽象的一篇论文。首先它的功能就很抽象：分布式协调内核。它提供的两个保证：线性写和FIFO客户端请求也费时间理解。最后则是它的API调用以及具体实现。 读这篇论文的原因我想一是Zookeeper的广泛使用，证明了其实用性；二是其“线性一致”的设计，契合课程。收获就是其API的设计、Watch模式。 参考文章：【MIT 6.824】学习笔记 6: ZooKeeper - 知乎 线性一致（1）例子 12345example history 1: |-Wx1-| |-Wx2-| |---Rx2---| |-Rx1-|is this history linearizable? 满足以下两个要求： 线性后的序列要与实际请求时间相匹配（一个请求的结束时间在另一个请求的开启时间之前，那么线性序列也必须遵守） 每个读请求看到都是序列中前一个写请求的值 （2）线性一致 线性一致更多描述的是关于系统行为的定义，我们只能通过一系列请求以及返回值来推测一个系统是否是线性一致的。 在一个线性一致的系统中，读请求不允许返回旧的数据。也就是说，如果我发起了一个写请求，然后再读，如果读到的不是上次写的值，那这个系统就不是线性一致的。 ZooKeeper 参考了个人笔记：https://zhuanlan.zhihu.com/p/363396366 介绍ZookeeperZookeeper是一个通用的分布式协调服务（General-Purpose Coordination Service），通过提供协调内核/客户端API的形式，让开发者自己实现诸多原语/功能，包括统一命名、配置管理、成员管理、分布式锁、双重屏障等。 Zookeeper基于Zab（类似Raft的基于领导者的原子广播协议）实现了多副本容错机制，但不同于Raft，Zookper的所有副本都能接受读请求。这得益于Zookeeper的两个设计：线性写和FIFO客户端请求。 Zookeeper为客户端提供了一组数据节点（称之为Znode），Znode根据分层名称空间进行组织，记法上类似于Unix的文件系统。客户端通过Zookeeper提供的API能对数据节点进行创建、删除、读取、写入、获取目录下所有文件等操作。Zookeeper还实现了一种Watch机制，通过此机制，客户端能够监听某个Znode的变化（更新、删除），Zookeeper会在Znode发生变化时向客户端发送一条通知消息。 Zookeeper API Zookeeper的API某种程度上来说像是一个文件系统。它有一个层级化的目录结构，有一个根目录（root），之后每个应用程序有自己的子目录。文件和目录都被称为znodes。 1234567891011`CREATE(PATH，DATA，FLAG)`。入参分别是文件的全路径名PATH，数据DATA，和表明znode类型的FLAG。这里有意思的是，CREATE的语义是排他的。`DELETE(PATH，VERSION)`。入参分别是文件的全路径名PATH，和版本号VERSION。有一件事情我之前没有提到，每一个znode都有一个表示当前版本号的version，当znode有更新时，version也会随之增加`EXIST(PATH，WATCH)`。入参分别是文件的全路径名PATH，和一个有趣的额外参数WATCH。通过指定watch，你可以监听对应文件的变化。`GETDATA(PATH，WATCH)`。入参分别是文件的全路径名PATH，和WATCH标志位。这里的watch监听的是文件的内容的变化。`SETDATA(PATH，DATA，VERSION)`。入参分别是文件的全路径名PATH，数据DATA，和版本号VERSION。如果你传入了version，那么Zookeeper当且仅当文件的版本号与传入的version一致时，才会更新文件。`LIST(PATH)`。入参是目录的路径名，返回的是路径下的所有文件。 Znode有两种基本类型：Regular和Ephemeral。创建的api还包括一个sequential flag。Znode还关联了时间戳、版本信息。 更新方法都带有一个版本号参数，只有版本号与Znode的版本号一致时，更新操作才能成功。 配置管理如何利用Zookeeper实现动态配置管理？非常简单。 配置管理器将配置写在一个Znode中，其他进程读这个Znode，同时设置Watch标志位。如果Znode中的配置改变了，那么其他进程将会收到通知，并且会再次读取最新配置。 集合点Rendezvous我理解为进程同步。客户端创建Znode，然后将Zode的full path作为参数传递给master process和worker process。如果master process先创建完成，那么它就将它的信息（addresses and ports）写入到Znode中；如果是worker process先创建完成，它照样读取Znode并设置Watch标志位，后续mater改变Znode后，worker就能读取信息。 组成员管理利用一个Znode 表示组。当组成员创建时，只需创建一个对应的Znode的Child Znode。如果需要唯一的对应，可设置Sequentail标志位。如果需要获取一个Group的信息，只需要简单调用list api查看Znode的所有Child。如果一个进程要监视组信息的变化，为每一个组成员设置Watch标志位即可。 ephemeral node有一个好处是能代表会话的状态，当进程失败或结束时，ephemeral node会自动移除。 分布式锁1234WHILE TRUE: IF CREATE(&quot;f&quot;, data, ephemeral=TRUE): RETURN IF EXIST(&quot;f&quot;, watch=TRUE): WAIT 总的来说，先是通过CREATE创建锁文件，或许可以直接成功。如果失败了，我们需要等待持有锁的客户端释放锁。通过Zookeeper的watch机制，我们会在锁文件删除的时候得到一个watch通知。收到通知之后，我们回到最开始，尝试重新创建锁文件，如果运气足够好，那么这次是能创建成功的。 Herd Effect如果有1000个客户端同时要获得锁文件，为1000个客户端分发锁所需要的时间也是N方。因为每一次锁文件的释放，所有剩下的客户端都会收到WATCH的通知，并且回到循环的开始，再次尝试创建锁文件。 为了获得锁，要通知一大群的线程，也就是惊群，最会只有一个线程能获得锁。 123456CREATE(&quot;f&quot;, data, sequential=TRUE, ephemeral=TRUE)WHILE TRUE: LIST(&quot;f*&quot;) IF NO LOWER #FILE: RETURN IF EXIST(NEXT LOWER #FILE, watch=TRUE): WAIT 代码第4行，如果现存的Sequential文件的序列号都不小于我们在代码第1行得到的序列号，那么表明我们在并发竞争中赢了，我们获得了锁。所以当我们的Sequential文件对应的序列号在所有序列号中最小时，我们获得了锁，直接RETURN。序列号代表了不同客户端创建Sequential文件的顺序。在这种锁方案中，会使用这个顺序来向客户端分发锁。当存在更低序列号的Sequential文件时，我们要做的是等待拥有更低序列号的客户端释放锁。在这个方案中，释放锁的方式是删除文件。所以接下来，我们需要做的是等待序列号更低的锁文件删除，之后我们才能获得锁。 所以，在代码的第5行，我们调用EXIST，并设置WATCH，等待比自己序列号更小的下一个锁文件删除。如果等到了，我们回到循环的最开始。但是这次，我们不会再创建锁文件，代码从LIST开始执行。这是获得锁的过程，释放就是删除创建的锁文件。 学生提问：为什么这种锁不会受羊群效应（Herd Effect）的影响？ Robert教授：假设我们有1000个客户端在等待获取锁，每个客户端都会在代码的第6行等待锁释放。但是每个客户端等待的锁文件都不一样，比如序列号为500的锁只会被序列号为501的客户端等待，而序列号500的客户端只会等待序列号499的锁文件。 每个客户端只会等待一个锁文件，当一个锁文件被释放，只有下一个序列号对应的客户端才会收到通知，也只有这一个客户端会回到循环的开始，也就是代码的第3行，之后这个客户端会获得锁。所以，不管有多少个客户端在等待锁，每一次锁释放再被其他客户端获取的代价是一个常数。而在非扩展锁中，锁释放时，每个等待的客户端都会被通知到，之后，每个等待的客户端都会发送CREATE请求给Zookeeper，所以每一次锁释放再被其他客户端获取的代价与客户端数量成正比。 双重屏障// todo 计数器第一个很简单的例子是计数器，假设我们在Zookeeper中有一个文件，我们想要在那个文件存储一个统计数字，例如，统计客户端的请求次数，当收到了一个来自客户端的请求时，我们需要增加存储的数字。 1234WHILE TRUE: X, V = GETDATA(&quot;F&quot;) IF SETDATA(&quot;f&quot;, X + 1, V): BREAK 这个例子，其实就是大家常说的mini-transaction。这里之所以是事务的，是因为一旦我们操作成功了，我们对计数器达成了_读-更改-写_的原子操作。 之所以称之为mini-transaction，是因为这里并不是一个完整的数据库事务（transaction）。一个真正的数据库可以使用完整的通用的事务，你可以指定事务的开始，然后执行任意的数据读写，之后结束事务。一个真实的事务可能会非常复杂，而Zookeeper支持这种非常简单的事务，使得我们可以对于一份数据实现原子操作。这对于计数器或者其他的一些简单功能足够了。所以，这里的事务并不通用，但是的确也提供了原子性，所以它被称为mini-transaction。 Zookeeper的保证Zookeeper基于Raft框架，是容错的，在发生网络分区的时候，也能有正确的行为。Zookeeper有一些性能增强，使得读请求可以在任何副本被处理，因此，可能会返回旧数据。 为什么Zookeeper在允许多副本读的情况下还能保证正确的行为？ 这得益于ZooKeeper 两个基本的一致性保证：线性写和先进先出(FIFO)的客户端请求。 写请求是线性一致的 All requests that update the state of ZooKeeper are serializable and respect precedence. Leader 保证写操作的顺序，并且该顺序在所有 Follower 上保持一致。 客户端可以并发的发送写请求，然后Zookeeper表现的就像以某种顺序，一次只执行一个写请求，并且也符合写请求的实际时间。所以如果一个写请求在另一个写请求开始前就结束了，那么Zookeeper实际上也会先执行第一个写请求，再执行第二个写请求。 所有更改Zookeeper状态的请求都是线性的，那么这就保证了主从状态一致性。 先进先出的客户端请求 All requests from a given client are executed in the order that they were sent by the client. 每个客户端可以为其操指定一个顺序，ZooKeeper 会按照客户端指定的顺序来执行。即zookeeper为每个单独的客户端提供了线性一致性。 这里的线性一致性只对于单个客户端的请求。比如说，客户端先发了一个写请求，然后再发读请求到落后的副本，那么这个读请求得看到它自己之前的写更新。 所以，如果我发送一个写请求给Leader，在Leader commit这个请求之前需要消耗一些时间，所以我现在给Leader发了一个写请求，而Leader还没有处理完它，或者commit它。之后，我发送了一个读请求给某个副本。这个读请求需要暂缓一下，以确保FIFO客户端请求序列。读请求需要暂缓，直到这个副本发现之前的写请求已经执行了。这是FIFO客户端请求序列的必然结果，（对于某个特定的客户端）读写请求是线性一致的。 ZooKeeper 通过 zxid 来实现，zxid 是最后一个事务的标记，当客户端发出一个请求到一个相同或者不同的副本时，会在请求带上 zxid 标记，副本通过检查客户端的 zxid 和自己的 zxid，保证读到的是更新的 zxid 的数据(没有具体说怎么处理，是阻塞等待还是拒绝请求) 更进一步，如果同一个客户端发送一个写请求&lt;X, 17&gt;，然后立即去某个副本服务器读 X，这里会暂缓一下读请求，直到这个副本发现写请求的 zxid 已经执行了，即客户端将会读到 &lt;X, 17&gt;，不会读到过期的数据。 同步操作 sync尽管有了Zookeeper的两个保证，但这还不是线性一致性。Zookeeper提供了另外一种弥补线性一致的方法：sync。 To handle this scenario more efficiently ZooKeeper provides the sync request: when followed by a read, constitutes a slow read. sync causes a server to apply all pending write requests before processing the read without the overhead of a full write. This primitive is similar in idea to the flush primitive of ISIS。 可以简单认为sync操作等于原子的写+读。这样客户端的读操作一定能看到最新的写入操作。因为FIFO的客户端请求使得它看到了自己的写请求，而写请求又是线性的，于是之前的写请求一定也被看见。 Zookeeper的实现//todo","link":"/2023/11/27/MIT6.824/%E7%AC%94%E8%AE%B06Zookeeper/"},{"title":"MIT6824笔记八 Aurora","text":"本节介绍了一个事务的基本实现方式以及Aurora。 对于Aurora，值得注意的是6个副本3个中心的设计，以及Quorum的读写思想。还有就是违背抽象，设计耦合的日志专用存储能极大提升性能。 论文指路：https://pdos.csail.mit.edu/6.824/papers/aurora.pdf 故障可恢复事务认识事务Atomic事务是指将多个操作打包成原子操作，并确保多个操作顺序执行。 Isolation我们希望数据库顺序执行事务里的操作，并且不允许其他任何人看到执行的中间状态。 Consistency同时，考虑到故障，如果在执行的任何时候出现故障，我们需要确保故障恢复之后，要么所有操作都已经执行完成，要么一个操作也没有执行。 Duration如果一个事务提交了，用户期望事务的效果是可以持久保存的，即使数据库故障重启了，数据也还能保存。 事务实现通常来说，事务是通过对涉及到的每一份数据加锁来实现。 在硬盘中，除了有数据之外，还有一个预写式日志（Write-Ahead Log，简称为WAL）。预写式日志对于系统的容错性至关重要。 当你在执行一个事务内的各个操作时，例如执行 X=X+10 的操作时，数据库会从硬盘中读取持有X的记录，给数据加10。但是在事务提交之前，数据的修改还只在本地的缓存中，并没有写入到硬盘。 在允许数据库软件修改硬盘中真实的data page之前，数据库软件需要先在WAL中添加Log条目来描述事务。在提交事务之前，数据库需要先在WAL中写入完整的Log条目，来描述所有有关数据库的修改，并且这些Log是写入磁盘的。 在提交并写入硬盘的data page之前，数据库通常需要写入至少3条Log记录： 第一条表明，作为事务的一部分，我要修改X，它的旧数据是500，我要将它改成510。 第二条表明，我要修改Y，它的旧数据是750，我要将它改成740。 第三条记录是一个Commit日志，表明事务的结束。 通常来说，前两条Log记录会打上事务的ID作为标签，这样在故障恢复的时候，可以根据第三条commit日志找到对应的Log记录，进而知道哪些操作是已提交事务的，哪些是未完成事务的。 如果数据库成功的将事务对应的操作和commit日志写入到磁盘中，数据库可以回复给客户端说，事务已经提交了。而这时，客户端也可以确认事务是永久可见的。 接下来有两种情况: 如果数据库没有崩溃，那么在它的cache中，X，Y对应的数值分别是510和740。最终数据库会将cache中的数值写入到磁盘对应的位置。所以数据库写磁盘是一个lazy操作，它会对更新进行累积，每一次写磁盘可能包含了很多个更新操作。这种累积更新可以提升操作的速度。 如果数据库在将cache中的数值写入到磁盘之前就崩溃了，这样磁盘中的page仍然是旧的数值。当数据库重启时，恢复软件会扫描WAL日志，发现对应事务的Log，并发现事务的commit记录，那么恢复软件会将新的数值写入到磁盘中。这被称为redo，它会重新执行事务中的写操作。 AuroraAmazon Aurora 是专为云构建的一种兼容 MySQL 和 PostgreSQL 的关系数据库，Amazon Aurora 的速度可达标准 MySQL 数据库的五倍、标准 PostgreSQL 数据库的三倍。 参考：https://zhuanlan.zhihu.com/p/338582762 背景Amazon有装满了服务器的数据中心，并且会在每一个服务器上都运行VMM（Virtual Machine Monitor）。 （1）EBS（Elastic Block Store，弹性块存储） Web服务所在的EC2（Elastic Cloud 2）实例会与数据库所在的EC2实例交互，完成数据库中记录的读写。但是如果数据库所在的服务器宕机了，并且数据存储在服务器的本地硬盘中，那么就会有大问题，因为数据丢失了。所以，为了向用户提供EC2实例所需的硬盘，并且硬盘数据不会随着服务器故障而丢失，就出现了一个与Aurora相关的服务，并且同时也是容错的且支持持久化存储的服务，这个服务就是EBS。 在实现上，EBS底层是一对互为副本的存储服务器。一个EBS volume看起来就像是一个普通的硬盘一样，但却是由一对互为副本EBS服务器实现，每个EBS服务器本地有一个硬盘。 所以，现在你运行了一个数据库，相应的EC2实例将一个EBS volume挂载成自己的硬盘。当数据库执行写磁盘操作时，数据会通过网络送到EBS服务器。这两个EBS服务器会使用Chain Replication进行复制。 问题一：网络传输大。如果你在EBS上运行一个数据库，那么最终会有大量的数据通过网络来传递。 问题二：EBS的容错性不是很好。为了降低使用Chain Replication的代价，Amazon总是将EBS volume的两个副本存放在同一个数据中心，如果整个数据中心挂了，那就没辙了。 （2）Amazon RDS（Relational Database Service，关系型数据服务） 在MySQL基础上，结合Amazon自己的基础设施，Amazon为其云用户开发了改进版的数据库，叫做RDS。RDS是第一次尝试将数据库在多个AZ之间做复制，这样就算整个数据中心挂了，你还是可以从另一个AZ重新获得数据而不丢失任何写操作。 通过EBS存储DB的data page&amp;log。再通过网络传输data个另一个DB。 这个数据库将它的data page和WAL Log存储在EBS，而不是对应服务器的本地硬盘。当数据库执行了写Log或者写page操作时，这些写请求实际上通过网络发送到了EBS服务器，所有这些服务器都在一个AZ中。 每一次数据库软件执行一个写操作，Amazon会自动的将写操作拷贝发送到另一个数据中心的AZ中。 每一次写操作，例如数据库追加日志或者写磁盘的page，数据除了发送给AZ1的两个EBS副本之外，还需要通过网络发送到位于AZ2的副数据库。副数据库接下来会将数据再发送给AZ2的两个独立的EBS副本。之后，AZ2的副数据库会将写入成功的回复返回给AZ1的主数据库，主数据库看到这个回复之后，才会认为写操作完成了。 RDS的写操作代价极高，因为需要写大量的数据。这意味着，哪怕是只写入这两个数字，当需要更新data page时，需要向磁盘写入多得多的数据。通过网络来传输8k字节的page数据时，RDS的架构很明显太慢了。 学生提问：为什么会慢呢？ Robert教授：在这个架构中，对于数据库来说是无感知的，每一次数据库调用写操作，更新自己对应的EBS服务器，每一个写操作的拷贝穿过AZ也会写入到另一个AZ中的2个EBS服务器中，另一个AZ会返回确认说写入成功，只有这时，写操作看起来才是完成的。所以这里必须要等待4个服务器更新完成，并且等待数据在链路上传输。 性能低：这种Mirrored MySQL比Aurora慢得多的原因是，它通过网络传输了大量的数据。并且具有大量串行操作。 Aurora架构整体上来看，我们还是有一个数据库服务器，但是这里运行的是Amazon提供的定制软件。 第一个是，在替代EBS的位置，有6个数据的副本，位于3个AZ，每个AZ有2个副本。所以现在有了超级容错性，并且每个写请求都需要以Quorum方式发送给这6个副本。 第二个是，这里通过网络传递的数据只有Log条目。后果是，这里的存储系统不再是通用存储，而是专门理解MySQL Log条目的存储系统。 Quorum复制思想Aurora使用的是一种经典quorum（法定人数机制）思想的变种。通常来说，Quorum系统就是简单的读写系统，支持Put/Get操作。 有N个副本； 写请求，至少确保写操作被W个副本确认，W小于N。 读请求，至少需要从R个副本得到所读取的信息。 Quorum系统要求，发送写请求的W个服务器，必须与任意接收读请求的R个服务器有重叠。这意味着，R加上W必须大于N（ 至少满足R + W = N + 1 ），这样任意W个服务器至少与任意R个服务器有一个重合。 读请求这里还有一个关键的点，客户端读请求可能会得到R个不同的结果，现在的问题是R个结果中，哪一个是正确的呢？不能使用投票法决定，因为返回的R个结果可能只有一个结果是正确的。 在Quorum系统中使用的是版本号（Version）。每一次执行写请求，你需要将新的数值与一个增加的版本号绑定。之后，客户端发送读请求，从Read Quorum得到了一些回复，客户端可以直接使用其中的最高版本号的数值。 优点（1）相比Chain Replication，这里的优势是可以轻易的剔除暂时故障、失联或者慢的服务器。发N个只需要等最快的R或W个回复。 实际上，这里是这样工作的，当你执行写请求时，你会将新的数值和对应的版本号给所有N个服务器，但是只会等待W个服务器确认。类似的，对于读请求，你可以将读请求发送给所有的服务器，但是只等待R个服务器返回结果。因为你只需要等待R个服务器，这意味着在最快的R个服务器返回了之后，你就可以不用再等待慢服务器或者故障服务器超时。这里忽略慢服务器或者挂了的服务器的机制完全是隐式的。在这里，我们不用决定哪个服务器是在线或者是离线的，只要Quorum能达到，系统就能继续工作，所以我们可以非常平滑的处理慢服务或者挂了的服务。 （2）Quorum系统可以调整读写的性能。通过调整Read Quorum和Write Quorum，可以使得系统更好的支持读请求或者写请求。 对于前面的例子，我们可以假设Write Quorum是3，每一个写请求必须被所有的3个服务器所确认。这样的话，Read Quorum可以只是1。所以，如果你想要提升读请求的性能，在一个3个服务器的Quorum系统中，你可以设置R为1，W为3，这样读请求会快得多，因为它只需要等待一个服务器的结果，但是代价是写请求执行的比较慢。 当R为1，W为3时，写请求就不再是容错的了，同样，当R为3，W为1时，读请求不再是容错。 Aruora的读写存储服务器对于Aurora来说它的写请求只会在当前Log中追加条目（Append Entries），不会覆盖数据。 Aurora使用Quorum只是在数据库执行事务并发出新的Log记录时，确保Log记录至少出现在4个存储服务器之后才能提交事务（Aurora的Quorum系统中，N=6，W=4，R=3）。所以，每个新的Log记录必须至少追加在4个存储服务器中，之后才可以认为写请求完成。 数据分片目前为止，我们已经知道Aurora将自己的数据分布在6个副本上。但是如果只是这样的话，我们不能拥有一个大于单机磁盘空间的数据库。为了能支持超过10TB数据的大型数据库，Amazon将数据按照10GB为单位分割存储到多组存储服务器上。 即把整个DB volume切分成 10GB 的chunk，每个chunk六个副本存储在三个AZ上。Aurora还需要一个成员组管理服务，用来记录各个chunk所在服务器，常见方式是租约机制的一致性共识协议，比如Paxos。 （2）故障恢复 每个存储服务器有几TB的磁盘，上面存储了属于数百个Aurora实例的10GB数据块。当一个存储服务器故障时，它还带走了其他数百个数据库的10GB数据。如何做崩溃恢复？ 从存储服务器的副本拷贝吗？如果网卡是10Gb/S，通过网络传输10TB的数据需要8000秒。 Aurora实际使用的策略是：对于每一个数据块，从Protection Group中挑选一个副本，作为数据拷贝的源。这样，对于100个数据块，相当于有了100个数据拷贝的源。之后，就可以并行的通过网络将100个数据块从100个源拷贝到100个目的地，时长相当于只拷贝一个数据块。 只读数据库对于Aurora来说，通常会有非常大量的只读数据库查询。读请求，可以发送给多个数据库。 当客户端向只读数据库发送读请求，只读数据库需要弄清楚它需要哪些data page来处理这个读请求，之后直接从存储服务器读取这些data page，并不需要主数据库的介入。之后它会缓存读取到的page，这样对于将来的一些读请求，可以直接根据缓存中的数据返回。Aurora的主数据库也会将它的Log的拷贝发送给每一个只读数据库来更新自身缓存。 这的确意味着只读数据库会落后主数据库一点，但是对于大部分的只读请求来说，这没问题。因为如果你查看一个网页，如果数据落后了20毫秒，通常来说不会是一个大问题。 总结 事务性数据库是如何工作的、怎么与后端存储交互的（性能、故障修复等） Quorum思想，通过读写Quorum的重合，可以确保总是能看见最新的数据，但是又具备容错性。 数据库和存储系统可以耦合开发。通常来说，存储系统是非常通用的，并不会为某个特定的应用程序定制。因为一个通用的设计可以被大量服务使用。但是在Aurora面临的问题中，性能问题是非常严重的，它不得不通过模糊服务和底层基础架构的边界来获得35倍的性能提升，这是个巨大的成功。","link":"/2024/02/27/MIT6.824/%E7%AC%94%E8%AE%B08Aurora/"},{"title":"cmu15-445笔记一 Introduction","text":"本节课主要介绍数据库系统的一些概念以及SQL语句。 Lec01 Introductiondatabase organized data core component of most computer applications database management system software that allows applications to store and analyze information in a database Definition,creation,querying,update and administration of a database with some data model Data models concepts for describing the data in database Relation model Physical storage, store database in simple data structures(relations) Dbms for logits, access data through high-level language Primary keys uniquely identifies a single tuple. Relational algebra konw the basic operations and its symbol about relational algebra defines the primitives for processing queries on a relational database conclusion Relational algebra defines the primitives for processing queries on a relational database. Lec02 Modern SQLRELATIONAL LANGUAGES Data Manipulation Language (DML) Data Definition Language (DDL) Data Control Language (DCL) SQL语言是一种声明式语言，你只需要告诉计算机你需要什么样的数据，计算机会自动帮你找出来。 SQL based on bags not sets。bags可以允许重复，sets就是不重复集合。 各种SQL操作： Aggregates（min、max、count、distinct、sum） Group by Having String operation Data/time operation Output redirection Output control（order by、limit） Nested queris Window function Performs a “sliding” calculation across a set of tuples that are related. Like an aggregation but tuples are not grouped into a single output tuples. 比如 12345SELECT *, ROW_NUMBER() OVER () AS row_num FROM enrolledSELECT cid, sid,ROW_NUMBER() OVER (PARTITION BY cid)FROM enrolled ORDER BY cid The OVER keyword specifies how to group together tuples when computing the window function. Use PARTITION BY to specify group. Common table expression Think of it like a temp table just for one query。就像是查询时额外有一张临时表。 123WITH cteName (col1, col2) AS ( SELECT 1, 2)SELECT col1 + col2 FROM cteName CTE还能嵌套使用 1234567WITH RECURSIVE cteSource (counter) AS ( (SELECT 1) UNION ALL (SELECT counter + 1 FROM cteSource WHERE counter &lt; 10) )SELECT * FROM cteSource Conclusion： SQL是一个标准，各家厂商有各自实现，不尽相同。SQL标准也在修改变动。 明白SQL语言的操作。","link":"/2024/04/10/cmu15445/Lec01/"},{"title":"cmu15-445笔记二 存储模型","text":"存储-1 How the DBMS represents the database in files on disk. DBMS是怎么在底层表示数据的？ 本节融合了三节课内容，主要是数据库底层存储的表现，讨论了页中tuple的存储模型，包括两种类型基于tuple和基于log。讨论了具体的数据表示，系统元数据。最后介绍OLTP和OLAP，对应的行存储和列存储优缺点。简单介绍了数据压缩方法。 存储硬件认知 在非易失性存储上进行随机读写通常慢于顺序读写。 DBMS will want to maximize sequential access. → Algorithms try to reduce number of writes to random pages so that data is stored in contiguous blocks. → Allocating multiple pages at the same time is called an “extent”. 基于磁盘的DBMS存储模型 其实这里与OS的VMM无异，BufferPool就是磁盘的缓存，以页为单位进行读取、淘汰。 为啥不让OS做这个事情呢？当然也有一些基于OS的解决方案。 OS不懂事务，脏页随时可能被刷回硬盘 DBMS需要合适页替换策略 DBMS需要合适的多线程控制 数据库底层存储表现数据库以合适的格式存储在一个或多个文件中，OS不知其内容。 通常有一个storage manager管理文件，将文件视作页的集合。 页是固定大小的块，每个页都有唯一的标识。页大小不固定，4KB-16KB不等。 Heap FileHeap FIile就是存储页的集合，把若干个页放一起作为一个文件管理。当有多个文件时，通过页ID找页的过程就不是那么直观了，我们需要页目录。 页目录需要追踪页的位置、空闲页等 Page模型一个页分为页头和数据两部分。页头包括了页的元信息：页大小、校验和、数据库版本、事务可见性等；数据体则是存储一大堆的tuple。 数据体该怎么组织？两种方式： Tuple-oriented Log-structured Tuple-oriented Storage（1）Tuple-oriented Strawman Idea 基于元组的存储，将一堆tuple放在一起。只能应对固定长度的tuple，无法很好应对删除操作（破坏顺序，内存碎片）。 （2）slotted pages 基于槽的元组存储 在data区域的最前面有一个slot数组，其中的每个元素和一个tuple构成一对一的映射关系，每个slot记录对应的tuple的位置。 slot是从页的data区域的最前面往后存，tuple是从data区域的最后面往前存。 删除操作后，需要对元组进行规整操作。 Tuple模型![image-20240410172509151](/Users/mac/Library/Application Support/typora-user-images/image-20240410172509151.png) Each tuple is prefixed with a header that contains meta-data about it. → Visibility info (concurrency control) → Bit Map for NULL values. Tuple的头会记录事务可见性以及NULL的位数组。为什么要记录NULL的位数组？因为Tuple里的attribute是没有分隔符，紧挨在一起存储。表的类型要么在Page Header，要么在tabel层面存储，DBMS解析每个字段格式，然后根据字段格式再逐位解析数据。NULL值不会存储，一方面节省空间，另一方面避免避免误读。 以下来源于next course，但是内容相关，就放在一起了。 Log-structured storagelog-structured还是page里data部分组织tuple的内容，对比于tuple-oriented storage，log-structured只存储日志而不是数据本身。 DBMS将tuple的change log以append的方式存储，一页存满就刷回磁盘。 日志的格式为：操作+tuple ID+value，由此可见，tuple必须具有唯一ID。 读操作需要回放日志，比如我们要读ID为101的记录的值，就必须从磁盘中取出涉及第一条ID101的日志所在页，然后逐条应用日志，最终得到值。 由此可见，这种操作开销很大。通常有一个索引，记住每个tuple的最新修改在哪一个位置。 由于日志页会越来越大，通常需要进行日志压缩操作，即将若干个页里冗余的操作合并在一起。合并后还可以根据Tuple的ID进行排序，以便进行更好的读取。那么，这就是Sorted String Tables（SSTables）的思想。 压缩日志的方法也不止一种，首先是层级压缩（Level Compaction）。单page压缩、双page压缩、四page压缩，一层一层向下合并。压缩完读数据，从第0层开始读，层层往上。 优点数据的修改、删除、插入非常快。 基于log存储只需要执行顺序的添加写。而基于tuple的存储，需要先读取相应数据页，再修改数据，最后写回磁盘。 缺点→ Write-Amplification 写放大，对于一个元组的修改却需要写多次。 → Compaction is Expensive 日志合并过程代价是昂贵的。 Data Representation小数的准确存储浮点数并不是精确存储，对此，DB采取的措施为字面值，即利用字符串表示数字。 长字段存储超长字段，比如字符串类型存储一部小说，那么这个字段长度可能超出一页的大小。 为了解决这个问题，DB采用引用+溢出页方式管理。字符串内容存储在溢出页中，字段值存储溢出页地址。 如果一个溢出页不够存储，那么采用溢出页链表形式。第二种方式采用外部文件，external file。 System CatalogsSystem Catalogs，即DBMS的目录，用于存储DBMS的元数据，比如说表结构，列的结构，索引，视图，用户，权限，内部的统计信息，数据库的元数据都是以表的形式存在的。 表、列、索引、视图 用户、权限 Internal statistics其他统计数据 You can query the DBMS’s internal INFORMATION_SCHEMA catalog to get info about the database. Database workloadsOLTP，在线事务/交易处理，支持快速的操作，读写数据量很小的tuple，而且一般是高并发的，像微信支付这样的场景，同时发生很多交易，但每笔交易涉及的数据量都很小 OLAP，在线分析处理，OLTP这种workload一般来自用户，OLAP则来自于提供相应软件服务的公司本身，比如说微信支付要统计当天有多少笔交易，交易的平均金额是多少，交易总额是多少，这一般对应着复杂的SQL语句，要读大量的数据 第三种，HTAP，则是前两者的混合，意味着可以同时应对这两种类型的workload的数据库架构 OLTP更倾向于写，OLAP更倾向于读。 在不考虑HTAP的情况下（目前工业界HTAP的实践并不多），软件公司会将OLTP和OLAP这两类工作负载分开处理，用小数据库的集群处理OLTP，用分库分表的策略将工作负载分开，等到需要统计分析数据（即OLAP对应的场景）时，对这个集群执行ETL操作（提取数据-&gt;做变换-&gt;加载），把得到的数据转存到大的数据仓库里，让数据仓库应对OLAP的负载； 行存储数据库的关系模型和SQL语句并没有要求或者限制数据库底层的数据存储方式，只要通过层层的向上封装能满足它们想提出的抽象即可，即“SQL想查出来一行一行的数据，但数据库不一定在磁盘上一行一行的存”，我们可以修改底层的存储方式，进而更好的应对OLTP/OLAP。 Ideal for OLTP workloads where queries tend to operate only on an individual entity and insert- heavy workloads. 行存储有利于OLTP，因为OLTP的查询通常针对的是一个实体，并且写频繁。比如修改一个用户的用户名，密码等。 Advantages→ Fast inserts, updates, and deletes. → Good for queries that need the entire tuple. Disadvantages→ Not good for scanning large portions of the table and/or a subset of the attributes. 对于大量数据针对几个字段的查询不友好。因为基于行存储的引擎需要将所有行读出，解析大量无关字段。 列存储列存储的情况下，一个字段的所有记录值被连续存储。一个tuple就是存储数据表里的一列数据，实际存储中，数据库不同的页存储不同字段/列。 列存储的整行读 基于固定偏移 Embedded Tuple Ids 第一种方法，找到每个字段第offset个值，然后拼起来，得到一行数据。 Advantages→ Reduces the amount wasted I/O because the DBMS only reads the data that it needs. → Better query processing and data compression (more on this later). 适合大量读 Disadvantages→ Slow for point queries, inserts, updates, and deletes because of tuple splitting/stitching. 插入行记录更费劲了，因为字段被分裂存储到各个表中。 数据压缩数据压缩可以节省空间。基于columns的数据压缩方法。 Run-length Encoding 将单列中相同值的运行压缩为三元组 Bit-Packing Encoding 当属性的值始终小于该值声明的最大大小时，请将其存储为较小的数据类型。比如64位只存8位，前56位均为0. Bitmap Encoding 为属性的每个唯一值存储单独的位图，其中矢量中的偏移量对应于元组。比如男女属性用bit表示。 Delta Encoding 记录同一列中彼此跟随的值之间的差异。类似差分 Incremental Encoding 避免在连续元组之间重复公共前缀/后缀的增量编码类型。这最适用于排序数据。 Dictionary Encoding 构建将可变长度值映射到较小的整数标识符的数据结构。将这些值替换为字典数据结构中的相应标识符。（应该是额外表存储映射关系。用序号代替商品类型，避免长字段商品类型重复，节省空间）","link":"/2024/04/10/cmu15445/Lec02/"},{"title":"cmu15-445笔记三 缓存池","text":"存储-2 How the DBMS manages its memory and move data back-and-forth from disk. DBMS是怎么管理其内存的，怎么与硬盘交互的（包括加载和写数据）。 本节课主要介绍缓存池的加载策略、替换策略。 Buffer Pool Manager缓存池存在于内存中，用于缓存磁盘中的数据库文件的部分页。 缓存池有两大作用， 缓存页访问，因为用户有可能再次访问该页，这样的话就可以直接去内存中查询，提升效率； 缓存页更新，用户对数据库的内容的修改也是先被存储在内存的缓存池里的，先把修改缓存在内存中，再集中将修改写回硬盘或者采用其他策略，而不是每次一修改就立刻写回硬盘。 两大控制： 空间控制：经常使用的页靠近一起 时间控制：决定何时读数据页、何时写回、替换，最小化磁盘IO时间 数据查找的基本流程 DBMS的执行引擎会先去缓存池中找，看看2号页是否已经被缓存在其中，如果没有的话，就从硬盘中把索引页读到缓存池里，通过索引页得知我们想要的2号页在硬盘中的位置，然后去硬盘中再把2号页读入缓存池，之后把缓存池中2号页的指针返回给执行引擎。 缓存池基本模型缓存池由数组形式的连续存放的一些帧构成，每个帧用于缓存数据库文件的一个页。 对于缓存池的查找同样可以使用索引加快，PageTable就追踪了页在缓存池中的情况。 一段辨析： page directory：映射了 page id to page location page table：映射了 page id to page frame in buffer pool 一些策略： 全局策略：为所有活跃事务统一安排 局部策略：为每个事务单独管理 缓存池的性能优化策略（1）多缓存池 数据库有各种各样的页，可以为每种类型的页创建缓冲池；可以为不同的database建立缓冲池； 多个缓冲池可以减少锁争用。具体实现上，可以采用数据ID到缓冲池的映射记录，也可以采取哈希方式。 （2）预拉取 prefetch 执行全表扫描时，可以预先将未来读取的数据页从磁盘中读入内存。 （3）共享扫描 scan sharing If a query wants to scan a table and another query is already doing this, then the DBMS will attach the second query’s cursor to the existing cursor. 两次查询共享一次执行结果。 （4）Buffer Pool Bypass 旁路扫描，又名“轻扫描”。有些数据我们可能只需要用一次，后面也不会用了，我们可以将这种数据直接从磁盘放入内存当中没有池化的区域，之后把这块内存交给执行引擎使用，执行引擎使用完之后就把这块内存释放或者垃圾回收。 比如全表扫描的连续读，每张数据页只用一次，若不用轻扫描，将出现大量的页置换。 （5）OS cache 操作系统自己也实现了页缓存。但是DBMS一般会绕过操作系统提供的缓存机制，不需要操作系统缓存数据库文件，因为和DBMS维护的缓存池相比，操作系统对自己提供的磁盘缓存区没有很明确的淘汰策略，即每个缓存块保留多久，何时淘汰，甚至可以说OS的页缓存的淘汰机制很差，并且OS提供的缓存的DBMS的缓存池如果都存储了同样的数据，那就是很大的冗余(redundant)。 因此DBMS需要读磁盘时，在操作系统提供的磁盘读写api中加入O_DIRECT参数，直接和磁盘进行I/O，绕过操作系统的页缓存。 Replacement PoliciesDBMS的缓存池替换策略要保证它的正确性（不能把正在使用的页踢出），准确性，速度（不能花费太长时间用于决定踢出哪一页，即相关置换算法的复杂度不能太高），并且注意维护元数据带来的开销（比如说，元数据记录的是哪个页在缓存池里，哪个页不在缓存池里，把一些页踢出之后，要更新元数据，更新元数据的时候也不宜有太大开销） LRU（1）原理 Least Recently Used，最近最久未使用。使用一个最近使用时间降序的有序队列，优先清理队列最后的数据。 （2）实现 一种实现方法，给缓存池中的每个页带上时间戳。每次牺牲页时，找出时间戳最小的页。可想而知，查询时间复杂度O（N）。可以采取排序的方法优化，保持队头的时间戳最小。 另一种方法，采用环形队列的近似估计。缓存池中的页以逻辑方式形成环形，页带有访问标志ref。时钟指针顺时针旋转，如果遇到页的ref=1，则重置ref=0，然后转到下一个。 环形队列这个没搞懂 （3）缺点：缓存污染问题 面对大量一次性的扫描时，热点数据将被驱逐。比如以下例子： 123Q1 SELECT * FROM A WHERE id = 1 Q2 SELECT AVG(val) FROM A Q3 SELECT * FROM A WHERE id = 1 1偶发性的、周期性的批量操作会导致LRU命中率急剧下降，这时候缓存中的数据大部分都不是热点数据。 LRU-K论文指路：https://dl.acm.org/doi/epdf/10.1145/170036.170081 （1）原理 核心概念：Backward K-distance ，Backward k-distance is computed as the difference in time between current timestamp and the timestamp of kth previous access。 我们有磁盘页的集合$N={1,2,3,..,n}$，然后给定磁盘页访问的时间序列 $r_1, r_2,…r_t$，其中$r_t = p$表示在t时刻访问页号为p的磁盘页，那么页号p的Backward K-distance 可以表示为 $b_t(p, K)$。 $b_t(p, K) = x$ ，如果 $r_{t-x}=p$，并且在时刻t-x到t中，p出现了K次。 $b_t(p, K) = +\\infin$ ， 如果在 1,2,3..t 时刻中，p出现不足K次。 LRU-K算法就是在驱逐页面时，选择具有最大Backward K-distance的页。如果有多个页的Backward K-distance都是正无穷，那么可采取其他页面替换算法，比如LRU算法，驱逐最近不常使用的页面。 （2）实现 在实现上会维护两个队列history和buffer。histroty队列存储访问次数未到达K次的页号，buffer队列存储访问次数达到K次的页。 历史队列可以采取多种驱逐算法，比如FIFO、LRU、LFU。根据不同驱逐算法，历史队列也有不同维护方式。采取FIFO时，历史队列直接采用先进先出方式；采用LRU时，可以维护一个有序链表。链表的顺序由访问时间决定，表头最近使用，表尾最久使用。访问链表某个节点时，将该节点调整到表头。驱逐页面时从表尾开始。 缓冲队列根据Backward k-distance排序，在驱逐页面时，选择最大Backward K-distance的页。访问一个页面，更新其Backward K-distance同时也需要调整其位置。 查找页的过程：为了达成O（1）的查询，还需维护一个哈希表，记录页号对应的地址。 插入页的过程：首先查找页在缓冲队列中还是历史队列中。队列未满可以按照队列规则插入，队列满时按照队列驱逐规则牺牲页面，然后再按队列规则插入。 注意：还需要一个容器access_history，记录每个页面last K 次的时间戳。 （3）K值确定 1K值增大，命中率会更高，但是适应性差（清除一个缓存需要大量的数据访问，一般选择LRU-2）。 LocalizationThe DBMS chooses which pages to evict on a per txn/query basis. This minimizes the pollution of the buffer pool from each query. 本地化：有点抽象，像是为每个事务单独维护一个驱逐页面的需求，使得各个事务互不影响。 PRIORITY HINTS优先级提醒：DBMS执行引擎在运行时可以给缓存池一些指示，类似于“告诉缓存池这个页很重要，后面还要被用到，不要轻易清理”，至于怎么判断出来某个页重不重要，可以通过机器学习算法或者其他的很高级的策略来实现。 Dirty Page脏页说的就是在内存里面被修改了但还没写回磁盘的页。干净的页可以直接丢弃，但脏页必须刷回磁盘作持久化。 脏页的存在催生了WAL策略，即write ahead log，修改缓存池的数据之后不会立刻写回磁盘，否则会导致过多的磁盘I/O开销。一般会找一个机会集中写回，但是如果修改了缓存池里的数据后断电了，为了解决这个问题，可以额外再记个日志，专门记录哪些东西在缓存池里被修改了但还没写回磁盘，我们可以在用户修改数据库时，不将缓存池的脏页立刻写回磁盘，但日志必须要先被立刻写回磁盘 DBMS可以周期性地检查page table，将脏页刷回磁盘。 其他类型缓存DBMS不仅需要缓存磁盘上的文件数据，还需要缓存其他的东西，比如说热点的SQL语句的执行结果，WAL策略中的日志，etc. 这本质上是因为磁盘I/O的开销太大，因此需要使用内存作为磁盘读/写时的缓存。 总结The DBMS can almost always manage memory better than the OS.","link":"/2024/04/10/cmu15445/Lec03/"},{"title":"cmu15-445笔记四 哈希表","text":"哈希表具有无法比拟的常数查询性能，是数据库的常用查询数据结构。 本节课探讨了静态哈希与动态扩容的哈希。动态扩容包括链式哈希、extendible hash以及线性哈希。 哈希表能较好应对多次点查询，但无法较好应对范围查询。 哈希表的设计要求怎么组织数据结构？要存储哪些信息？如何保证并发安全？ 设计点： 哈希函数 Trade-off between being fast and collision rate 哈希模型 如何应对哈希冲突？大空间vs多指令？ Hash FunctionsDBMS期望的哈希函数，可以被快速完成，并且不容易发生哈希冲突。 We want something that is fast and has a low collision rate. Static Hashing SchemesLINEAR PROBE HASHING线性指针探测。发生哈希冲突时，检测下一个地址是否冲突，不冲突直接落座，否则继续检测下一个。 缺点：删除数据时不能直接删除，因为现在哈希出的位置与元素的位置不是严格对应的，可能出现哈希在一个空位置上，而那个位置的元素被删除（实际经删除元素线性探测才能找到对应元素）。 删数据的应对方法： 每次删除数据时rehash一次（nobody do this） Tombstone法（墓碑），采用删除标志位。 问题：采用线性探测发生碰撞时，怎么才能知道往后面找多少个元素呢？ Non-Unique Key 非唯一键是可能会相同的，这时候怎么办呢？ 链表连接唯一键 冗余键 第一种方法，我只存非唯一键去重后的集合，将同一个键的值放在一起，然后用引用的方式将键与多个值连接在一起。 第二种方法，将值与键当做一个复合大键，相当于扩张键的大小，这样每个键就不一样了。 ROBIN HOOD HASHING罗宾汉散列，采用劫富济贫的思想。具体来说： 每个key记录它与最佳位置偏移量，无冲突时偏移量为零。 插入时，如果发生哈希冲突，则比较两个key的偏移量。偏移量大的key占据该槽位，偏移量小的key让出位置并与下一个地址的key比较。 这样做不会让某个槽位的偏移量太大，在该哈希策略的执行过程当中，会将开放寻址时被遍历到的槽块的后缀值平均化，不使它们之间的方差太大。 CUCKOO HASHING杜鹃鸟哈希，杜鹃鸟会将蛋下在其他鸟巢中。具体而言： 采取多个哈希表，每个哈希表的哈希函数不同； 插入时，检查每个哈希表，选择空闲的一张表的一个位置插入；如果没有空闲位置，那么随机牺牲一个key。被牺牲的key再重新去其他表找位置。 静态哈希总结静态哈希表最大的问题是存储的key有限，槽数固定。但DBMS无法提前获知key的数量，因此有了动态哈希。 Dynamic Hashing SchemesCHAINED HASHING这就是指传统的拉链法解决哈希冲突。这里哈希槽可以放多个元素，称之为哈希桶。一个桶满了再链接一个桶。 Go语言中的哈希表也是基于此方法来实现的，Go的map的每个哈希槽指向的第一个哈希桶中有八个空位，是通过一个结构体来实现的，结构体中有一个成员是拥有八个空位的数组，如果这八个空位被用完了，就会将这个桶链接到一个溢出桶。 Extendible Hashing拉链式的哈希表的哈希槽的数目固定，发生的哈希冲突越多，哈希桶就越往链表退化。 Extendible Hashing（EH）比较复杂，从图中看主要分为两个部分，左边为directory，右边为hash bucket。EH维护两个变量（位计数），为directory维护global depth，为每个hash bucket维护local depth。dirctory可以有多个位置指向同一个hash bucket。 global depth 用来在directory中查找key对应的bucket local depth 在同一个bucket内的所有元素的前local detph位数字相同 （1）查找过程 假设我们要找key=0110，现在global depth=3，取前3位得到011，由图中的值对应bucket是第一个。 （2）插入扩容过程 由key找到对应bucket的过程与查找相同。不同的是，我们还为bucket维护一个bucket max size，当插入某个bucket发现已经满了时，就触发扩容机制，拆分当前桶并rehash桶内元素。 有两种扩容情况： local depth &lt; global depth local depth == global depth 第一种情况只涉及bucket split，第二种情况涉及bucket split 和 directory expansion。 bucket split过程：增加local depth，然后创建两个新桶，根据新的local depth将原桶的数据分配（采取位运算）到新的两个桶中。最后调整directory的指针，即将指向原桶的指针分配（采取位运算）给新的两个桶。 directory expansion过程：将directory扩容至原先两倍，扩容采取复制的办法。这样指向每一个桶的指针就会变为原先的两倍。 （3）特点 每个bucket有若干个指针指向它，具体地，当前bucket有$2^{global-local}$个指针指向它； 每个bucket的大小固定； data overflow的过程只需要rehash单个桶内的数据，其他桶保持不变。 推荐阅读：https://www.geeksforgeeks.org/extendible-hashing-dynamic-approach-to-dbms/ Linear Hashing线性哈希，线性地一点一点地扩容。 利用一个指针追踪下一个即将要分裂的哈希槽，采用多个哈希函数要决定具体的槽位。 这个过程比较晦涩。具体而言，我们有一个split pointer指向要分裂的槽，初始值 split = 0。哈希表大小n=4。从图中可以看出，当插入17时发生了溢出，此时进行扩容。 split=0，对0号桶进行扩容。0号桶内有8和20两个元素。8%8=0，那么8仍然留在0号桶内。20%8=4，那么20被安置在4号桶内。然后split移到下一个桶，即split=1。0号哈希槽最先开始“分家”，每执行完“分家”操作一次，split pointer指向下一个哈希槽，然后下一次扩容操作又被触发时，就又对此时的split pointer指向的哈希槽执行同样的“分家”操作。这样的每次往下移动一格的行为是线性变化的，因此该策略得名线性哈希。 最终，当split pointer使得最初的所有哈希槽都被“分家”了之后，那这也就完成了Extendible Hashing做的扩容。split pointer会移回最初的起点0号槽，进行下一轮循环，hash1函数不再被使用，hash2函数作为唯一的哈希函数存在。最后的效果与4个哈希槽扩容成8个哈希槽相同。 总结哈希表是可以在理想情况下完成O(1)复杂度查询的数据结构，这是它在查询这方面巨大的优点，其他的数据结构很难企及，因此它在DBMS中应用广泛，并且哈希表的设计要在速度和灵活性之间做trade-off。 但哈希表对于范围查询（比如说查id=3~10000）没有任何优势，因为原始Key连续的一组KV数据经过哈希运算之后，在哈希桶/哈希槽中的存放就不在连续，这也是“散列表”为何得名，因此往往不用于实现DBMS的索引，这个会由B+ Tree实现。","link":"/2024/04/12/cmu15445/Lec04/"},{"title":"cmu15-445笔记五 索引与B+树","text":"本节课首先介绍B+树索引，然后介绍B+树的设计，最后介绍B+树的优化措施。 表索引A table index is a replica of a subset of a table’s columns that is organized and/or sorted for efficient access using a subset of those attributes. DBMS 可以查找表索引的辅助数据结构，以更快地查找元组，而不是执行顺序扫描。 DBMS 确保表和索引的内容在逻辑上始终同步。 B+树B+树是一种保持数据排序并且自平衡的数据结构，允许搜索、顺序访问、插入和删除。B+树对于磁盘上读写多个页的文件具有特殊的优势。B+树从二叉搜索树演变而来，实际上是M-way的，一个内部结点可以有最多M个孩子结点。 Formally, a B+Tree is an M -way search tree (where M represents the maximum number of children a node can have) with the following properties: It is perfectly balanced (i.e., every leaf node is at the same depth). Every inner node other than the root is at least half full (M/2 -1 &lt;= num of keys &lt;= M-1) Every inner node with k keys has k+1 non-null children. B+树的每个节点都是一个KV数组，这个数组内部是严格按照K的大小顺序组织的，内部节点的V存储的是指向子节点的指针，叶子节点的V是存储的数据。 更具体地，叶子结点的V有两种方式存储数据： Record IDs：Record IDs refer to a pointer to the location of the tuple. Tuple Data：leaf node store the the actual contents of the tuple. B+树的插入首先找到需要插入到的叶子节点，然后在叶子节点里依照之前维护好的顺序将新的数据插入到正确的位置，如果这个叶子节点已经满了的话，就把它分裂成两个叶子节点。 叶子结点分裂过程：均匀地重新分配条目并复制中间键，将指向 L2 的索引条目插入到 L 的父项中（如果父结点也满了，同样进行分裂操作） 内部结点分裂过程：均匀地重新分配条目，但向上推中间键。 B+树的删除首先找到要删除结点的叶子结点L。 如果L有半数以上，那么直接删除key。 否则从邻居中借一个数据 如果邻居数据不够，合并两个叶子，并删除父结点中指向L的指针。 很多的DBMS会推迟这个合并的操作，因为在很多情况下，从B+树中删掉某个数据之后还会再插入新的数据，这样刚刚合并好的节点就有可能要再进行分裂，造成很大的开销。 重复键的处理对于重复的键，该怎么处理？有两种方法： Append Record ID：在原先的Key上再添加一个unique Record ID，将 &lt;key, recordId&gt;作为一个大键，保证大键唯一性。 Overflow Leaf Node：在原有的叶子节点上外接一个溢出节点。 B+树设计考量节点大小B+树节点的大小最好和文件页的大小一致或者是其倍数，以便于管理。 （1）磁盘设备类型 磁盘越低速，B+树节点占用的存储空间应该越大，这样的话一次对单个节点的磁盘I/O就可以读取更多的数据，索引更容易命中； 越快速的设备，B+树节点占用更小的存储空间。因为B+树节点占用的空间越大，所存储的数据越多，冗余数据也越多。 换句话说，就是IO次数与索引命中之间的平衡。越快速的设备IO代价越低，那么可以减小节点大小，降低索引命中率。 （2）DBMS负载类型 B+树的节点大小的选择也和DBMS所应对的负载类型有关，如果是应对OLAP类型的负载，常常会全表扫描，会遍历B+树的叶子节点，因此不妨让每个节点大一点，这样单次I/O就能扫描更多数据。 对于OLTP这种事务型的经常进行点查询的工作负载，会经常从B+树的根节点遍历到叶子节点，我们不妨就让B+树的节点小一点，这样的话在查询过程中，在节点之间跳跃的开销就会变小 节点合并的阈值DBMS会延迟B+树删除操作后的节点合并，从而减少重新组织B+树带来的开销 可变长度的Key的处理如果拿字符串当作索引的Key，那么很有可能它是变长的，对于变长的Key，DBMS有如下的处理方式： 改为存储Key的指针：由于必须为每个键维护指针的效率低下，因此在生产中使用这种方法的唯一地方是嵌入式设备，其中的微型寄存器和缓存可能会受益于这种空间节省。 Padding策略：固定长度策略，将不足长度的key补空字节，达到设计的固定长度。 键重定向（Key Map/Indirection）：键替换为单独字典中键值对的索引。（这与tuple在Page里通过slot来组织的方式相似，节点里面有数组形式排布的slot，slot中存储指向对应KV的指针，这使得节点中KV的存储有很大灵活性） 节点内部搜索在工业界的B+树实现中，一个节点里会存储成百上千个数据，假设我们之前通过索引，已经确定好了想要获取的数据就在某个特定的叶子节点当中，但是叶子节点中仍然有成百上千条数据，如何更快地从中把我们想要的那一条数据找出来仍然是不小的挑战，因此有如下的策略： 线性扫描，可以理解为暴力地去遍历，虽然看起来低效，但很多数据库都是这么实现的，因为相比于把叶子节点从磁盘读入缓存池用的时间，暴力扫描用的时间微不足道 二分查找，就是使用简单的二分查找算法，因为叶子节点中的KV都是按照K的大小有序排列的 插值估计：此方法利用存储在节点上的任何元数据（例如 max 元素、min 元素、平均值等），并使用它来生成键的大致位置。例如，如果我们在一个节点中查找 8，并且我们知道 10 是最大键，$10 -(n + 1)$ 是最小键（其中 n 是每个节点中的键数），那么我们知道从最大键开始搜索 2 个插槽，因为在这种情况下，距离最大键一个插槽的键必须是 9。 B+树优化性能优化、存储空间优化 Pointer Swizzling因为 B+Tree 的每个节点都存储在缓冲池的页面中，所以每次加载新页面时都需要从缓冲池中获取它，这需要锁存和查找。为了完全跳过这一步，我们可以存储实际的原始指针来代替页面 ID（称为“swizzling”），从而完全防止缓冲池提取。 Rather than manually fetching the entire tree and placing the pointers manually, we can simply store the resulting pointer from a page lookup when traversing the index normally. Note that we must track which pointers are swizzled and deswizzle them back to page ids when the page they point to is unpinned and victimized. 就是说缓存池已经加载了我们想要的页面，之后的访问相同页避免再次访问缓冲池（其中有锁和查找）。相比之下，我们自己建立哈希表，避免并发。 Bulk Insert 批量插入当最初构建 B+Tree 时，必须以通常的方式插入每个键会导致持续的拆分操作。由于我们已经为叶子提供了同级指针，因此，如果我们构造一个排序的叶节点链表，然后使用每个叶节点的第一个键自下而上轻松地构建索引，则初始插入数据的效率要高得多。 这种思想和创建堆时可以选择快速建堆策略而非一个一个地插入建堆的思想相似。 Prefix Compression 前缀压缩在同一个叶子节点里很多Key的前缀是相同的，我们可以在叶子节点的元数据里面找个地方记录一下公共的前缀，实际存储Key的时候只需存储前缀后面不一样的内容。 Deduplication 去重有些时候K会有冗余的可能，多个KV的K是一样的，我们其实可以通过去掉冗余的K来减少所占用的存储空间。 Suffix Truncation 后缀截断 内部节点的 Key 只用于**流量导向( direct traffic )**，我们并不需要整个Key。 存储将探测正确路由到索引所需的最小前缀。 我的理解：相当于同层内 采用前缀压缩。","link":"/2024/04/19/cmu15445/Lec05/"},{"title":"cmu15-445笔记六 排序与聚集","text":"本节课介绍了排序与聚集。由于数据库中的数据量巨大，排序与聚集无法在内存中完成，因此有了相应的基于外存的算法。 排序排序的好处： ORDEY BY GROUP BY JOIN DISTINCT 外部归并排序如果要排序的数据不能全部装载到内存中，那么外部归并排序（external merge sort）是常用的排序方法。这种方法将数据分为若干个块，对每个块排序，然后合并已排序的块。 排序：在内存中排序一块数据，然后将排序好的块写回磁盘。 归并：将已排好序的几个块合并为一个更大的有序块。 一个sorted run就意味着一次排序，排序后的结果是一列键值对，即KV。V有两种形式，分别为早物化/晚物化。早物化的V是Tupl本身，晚物化的V是Record ID。晚物化能够解决早物化时Tuple过大引起的内存开销问题。 2路归并排序排序阶段：读取硬盘上的一个页，排序 ，然后写回硬盘。 归并阶段：在内存上开辟3个页，读取2个已排序的页，然后归并到第三个页，当第三个页满时，将其写回磁盘。继续merge，直至完成。 Passes我愿称之为轮数，一共要运行 $1+\\lceil \\log_2N \\rceil$ 次。由于每个pass都需要读写全部的page，所以总的IO是 $2N\\times(# passes)$ 2阶外排序的情况下，只需要缓存池有3个页大即可，两个用于存储待排序的输入数据，另一个用于存放排序后的中间结果。如果内存充足，可以作优化： Double Buffering Optimization：将下次要读的数据提前读入内存。 General External Merger Sort：通用的N阶外排序。 N阶外归并排序The generalized version of the algorithm allows the DBMS to take advantage of using more than three buffer pages. 假设待排序的数据有N个页大小，缓存池有B个页大小，runs称之为一次排序的页的集合。 排序阶段：一次性读取B个页排序（这B个页就是一个run）。 合并阶段：读取B-1个已排序好的页，然后合并这B-1个页。 Passes：$1+\\lceil \\log_{B-1}{\\lceil N/B\\rceil} \\rceil$ Total IO: $2N\\times(# passes)$ 使用B+树于B+树的叶子节点本身就是天然有序的，所以当我们使用B+树来作为我们感兴趣的KV的索引时，就无需排序了，B+树分为聚簇和非聚簇的，聚簇的B+树与早物化的概念相似。 聚集将来自多个tuple的单个attribute坍缩为一个实值。DBMS需要快速地找到多个具有相同attribute的tuples。两种方法：排序和哈希。 排序聚集实现order by，distinct。 The DBMS first sorts the tuples on the GROUP BY key(s). It can use either an in-memory sorting algorithm if everything fits in the buffer pool (e.g., quicksort) or the external merge sort algorithm if the size of the data exceeds memory. The DBMS then performs a sequential scan over the sorted data to compute the aggregation. The output of the operator will be sorted on the keys. 对Group By的key进行排序，然后就能快速找到相同key的Group。通常来说，这样的Sql还需带有Order By以最大效率利用排序。 哈希聚集如果我们仅仅是想实现某类数据的聚集（比如GroupBy或Distinct），不需要在此基础上再进行排序（因为排序往往都会有不小的开销），那可以使用哈希聚集。 如果数据量比内存大，可以使用外部哈希聚集策略。 partition阶段：一个partion就是拥有相同哈希值的kv。parition会因内存不够存储到磁盘上。 假设我们有B个缓冲页，B-1个缓冲页用于partion，1个页用于数据输入。 rehash阶段：为每个pation构建一个内存的hash table（不同于第一阶段的哈希表），然后计算aggregation。具体而言，遍历这个哈希表的每个桶，得到具有符合条件的tuple。这里假设每个partion都能放入内存。 前面讨论的都是去重，很多聚集操作并不是以去重为终点，而是在去重之后再进行一些计算得出一些额外的统计值，这种情况下，在rehash阶段，还需额外记录一些动态变化的临时结果。 During the ReHash phase, the DBMS can store pairs of the form (GroupByKey→RunningValue) to compute the aggregation. The contents of RunningValue depends on the aggregation function. To insert a new tuple into the hash table: If it finds a matching GroupByKey, then update the RunningValue appropriately. Else insert a new (GroupByKey→RunningValue) pair. 计算AVG就是以count， sum的形式。","link":"/2024/05/02/cmu15445/Lec06/"},{"title":"cmu15-445笔记七 表连接","text":"表连接是关系型数据库的最频繁的操作之一。如何优化表连接是提高数据库性能的重点。 本节课介绍了三种Join，分别是Loop join、sort-merge join和hash join。 join的输出连表时，有个原则，要尽量把小表（所占页数较少的表）放在左侧（此时这个小表也叫驱动表），这会减少硬盘IO次数。 join算子输出的内容由以下三个因素决定： SQL处理模型 存储模型 整个SQL语句所需要的数据 join算子输出的内容有如下几种： 直接输出数据这种情况属于早物化，被join的都是完整的tuple，因此join操作结束后输出的就是完整的一行数据 输出record id这种属于晚物化，join后得到的一条数据里只含有在相对应的原始表中的record id，而不是全部的字段。这种输出方式符合列存储的思想，DBMS在对join后得到的表执行查询时无需拷贝不需要的数据。 join的开销join操作有时可以通过笛卡尔积来完成，先对两个表进行笛卡尔积，然后用谓词来筛选，但这非常低效，因为笛卡尔积导致的中间结果非常巨大，所以说除了笛卡尔积以外，DBMS的设计者更倾向于采用下面的几种join算法： M pages in table R, m tuples in R N pages in table S, n tuples in S Nested Loop JoinNested Loop Join123foreach tuple r ∈ R: foreach tuple s ∈ S emit，if r and s match 外层循环是遍历R表的所有行，对于R表的每一行，再开一个内层循环，遍历S表的所有行，看r和s能不能连上。 它十分低效，当扫描S的整张表时，缓存池完全用不上（比如说S有3个页大，缓存池有1个页大，扫描S全表的时候会把缓存池灌满，然后不断地淘汰） Block Nested Loop Join12345foreach block BR ∈ R: foreach block BS ∈ S: foreach tuple r ∈ BR: foreach tuple s ∈ Bs: emit, if r and s match Nested Loop Join对于R表的每条tuple，都需要完整地遍历一遍S表；而Block Nested Loop Join对于R表的每一个Block才去完整遍历一次S表。可以大大减少S表的IO次数。 回到现实中，如果我们的缓冲池足够大，有B个缓冲页，那么可以拿出B-2个页给R表，1个页给S表，1个页用于输出。 12345foreach B-2 pages pR ∈R: foreach page pS ∈ S: foreach tuple r ∈ B - 2 pages: foreach tuple s ∈ ps: emit, if r and s match 这个算法的思想就是把缓存池尽可能多地给outer table使用，从而减少遍历inner table表的次数，从而减少开销，毕竟给inner table用的缓存池再大，在遍历inner table时，都会面临缓存重刷的问题。 INDEX NESTED LOOP JOIN123foreach tuple r ∈ R: foreach tuple s ∈ Index(ri = sj): emit, if r and s match 在前面介绍的各种嵌套循环join当中，无论怎么优化都会不止一次遍历右侧的表，这本质上是因为我们没有构建相应的索引，只能通过暴力地遍历去探测有没有可以join的tuple。因此就有了如下的优化方式：我们以inner table的参与join的那一列字段为key构建索引，这称为index nested loop join或lookup join。 嵌套循环总结： 小表（页数少）作为外表； buffer尽可能给外表； 遍历内表（可以使用index优化） Sort-Merge JoinJoin的本意是找到两个表中符合条件的记录。sort merge join先对两个表进行排序，然后在使用游标分别遍历两个表。 merge阶段维护两个指针，它们先分别指向R表和S表的第一行数据，然后比较这两个指针所指向的两行数据的连接列字段的大小，之后如上图所示走向不同的分支。 这段伪代码其实少描述了一种情况：在某些时刻指针会有回溯操作。 总开销：sort + merge 缺点：但是这种策略存在退化的问题，和指针回溯的操作有关，极端情况就是要join的两列里所有字段的值都相等，这会退化成最原始的Nested Loop join。 使用场景：在要参与join运算的表都是已经排好序的情况下（或者是通过join key的索引来扫描表），merge join的效率是最高的，开销最低；如果我们期望join的结果是排好序的，那么merge join也非常合适，因为在这个算法内部实现里面已经完成了排序，在这种场景下使用别的join算法都还需要额外再执行一遍外排序。 Hash Join在前面介绍index nested loop join时，是以B+树为索引来举例的，B+树点查询的时间复杂度是O(log N)，随着其中存储的KV增多，点查询速度会变慢。 虽然B+树的好处是支持高效的区间查找，可以按照K递增/递减的顺序遍历叶子节点中的KV，但在index nested loop join场景下，我们要进行的是一次次的点查询，前后两次查询中的key大概率毫无关系。 与B+树索引相对的是哈希索引，不管哈希表里存储了多少KV，哈希索引的开销始终都是常熟量级O(1)，点查询执行的飞快。Hash Join的策略是给outer table构建哈希索引，对inner table进行遍历。 哈希表中每个KV中的Key是要join的连接列的字段，Value的选择也存在早物化/晚物化的差别。 原始的哈希join中，每次都使用inner table中一行的join key去哈希表里查询，但使用有些join key去查询的时候，根本没有对应的哈希表项，这种无效的查询增大了开销，我们不妨使用布隆过滤器，给outer table构建哈希表的时候顺便构建一个布隆过滤器，inner table在去哈希表中查询前，先去查布隆过滤器，判断本次查询在哈希表中能否找到相应的表项，如果能通过布隆过滤器断定哈希表里没有对应的表项，便可以确定这是一次无效的查询，于是让此次查询提前结束。 Grace Hash Join如果给outer table构建的哈希表太大了（因为outer table太大），内存里放不下，那么我们就要把哈希表的部分内容驱逐到硬盘里。 做两套哈希表，也就是对前面的例子中的S表和R表都构建相应的哈希索引，并且使用相同的哈希函数。我们把哈希表存在硬盘里，查询索引时，把硬盘中两个表相对应的哈希桶都取出，之后我们对刚刚从硬盘里取出的两个哈希桶里的KV数据做nested loop join。 这个策略提出的基础是认为：虽然无法把整个哈希表放进内存里，但可以把哈希表的某个哈希桶放入内存，如果单个的哈希桶太大，也放不进内存，那该怎么办呢？如果使用哈希函数h1构建的哈希表里的哈希桶太大，那我们就把这个大的哈希桶存储硬盘，使用哈希函数h2，对这个哈希表再进行一次哈希操作来进行分区，递归地进行这个过程，直到切成足够小的块。 总结 如果是面对OLAP型的负载，join两个大表，那么大多数情况下哈希join最为合适，但也有一些特例，如果数据是“倾斜的”，也就是说为其构建哈希表会导致严重的哈希碰撞，sort-merge join效率好的多，此外，如果要求join的输出结果必须有序，sort-merge join也是最优选择，DBMS的优化器会结合实际场景在sort-merge join和hash join之间做选择。","link":"/2024/05/02/cmu15445/Lec07/"},{"title":"cmu15-445笔记八 Sql执行","text":"本节介绍了SQL的执行流程，首先有查询计划，接着是查询计划的执行方式，然后是单表的访问方法。最后介绍了修改性的SQL语句的注意点以及表达式求值的优化。 Query Plan DBMS 将 SQL 语句转换为查询计划。查询计划中的运算符排列在树中。数据从这棵树的叶子流向根部。树中根节点的输出是查询的结果。 Processing Models处理模型定义了系统执行查询计划的方式。不同的工作负载场景有不同的处理模型。 迭代模型 物化模型 向量模型/批模型 Iterator Model迭代模型又称火山模型、流式模型。每个算子/操作符要实现一个Next()方法，每次调用它时操作符会返回一个tuple或者null。null表示tuple已经遍历完毕。 位于根节点的投影算子的实现方式就是循环地调用其子节点的Next()方法，然后将所有返回的tuple经过投影处理后输出。 Join算子执行方法就是哈希join，先循环地调用其左子节点的Next()函数，用所有返回的tuple（它们合起来就是outer table）去构建哈希表（此时等待join算子的Next函数返回的投影算子处于阻塞状态），之后循环地调用其右子节点（筛选算子）的Next方法，每次调用时，右子节点吐出一个tuple，然后拿着join算子拿着这个tuple的join key去刚刚构建的哈希表里查询，查看能否成功匹配，如果可以的话，那就返回一条join后的结果，即向其父算子（投影算子）吐一条数据。 火山模型便于实现对输出的控制，比如说SQL语句中有”limit 100”这样的关键字，限制只输出100条数据 ，在火山模型下我们只需先流式地输出100条，然后让顶端的算子停止输出。我们不需要额外控制最底层的table reader（也就是读表的算子），只需要在操作符树的顶端控制数据的出口。但火山模型在性能上也有一些问题，每一条数据的传输都依赖函数调用，虽然函数调用的开销远小于硬盘IO，但如果要上千万条这样大量的数据向上流动，函数调用的次数将非常多，这会降低性能。 Materialization Model算子一次性读入全部要处理的数据，将得到的结果一次性地输出。 每个查询计划运算符都实现一个 Output 函数： 操作员一次处理其子级的所有元组。 此函数的返回结果是运算符将发出的所有元组。 当操作员 完成执行后，DBMS 永远不需要返回它来检索更多数据。 此方法更适合 OLTP 工作负载，因为查询通常一次只能访问少量元组。因此，用于检索元组的函数调用较少。具体化模型不适用于具有大型中间结果的 OLAP 查询，因为 DBMS 可能必须在运算符之间将这些结果溢出到磁盘。 Vectorized/Batch Model火山模型每获取一条数据就要经过一系列的函数调用，物化模型每次函数调用可以获取很多数据，它们有各自的优点和缺点，向量化模型是这二者中和的产物，向量化模型中，每个算子也有Next函数，但它返回的不是一条数据，而是一批数据（tuple batch），这样可以减少函数调用的次数，从而降低开销。 这种模型对经常进行大数据分析的OLAP型数据库比较友好，既能做到向上层算子返回的数据量不是太大，又可以控制函数调用的次数与开销。 执行方向Approach #1: Top-to-Bottom Start with the root and “pull” data from children to parents Tuples are always passed with function calls Approach #2: Bottom-to-Top Start with leaf nodes and “push” data from children to parents Allows for tighter control of caches / registers in operator pipelines DBMS计划执行/函数调用的方向分为两种，一种是让父算子调用子算子，自顶向下，另一种是子算子完成操作之后调用父算子，自底向上，但不论如何，数据流的方向始终是从操作符树的叶子节点流向根节点。 Access Methods访问方法是 DBMS 访问存储单表中的数据的方式。 通常，有两种方法可以访问模型：通过顺序扫描从表或索引中读取数据。 Sequential Scan顺序扫描运算符循环访问表中的每个页面，并从缓冲池中检索它。当扫描遍历每页上的所有元组时，它会评估谓词，以决定是否将元组发出给下一个运算符。 DBMS 维护一个内部光标，用于跟踪它检查的最后一页/插槽。 顺序表扫描几乎始终是 DBMS 执行查询的最低效率方法。有许多优化可用于帮助加快顺序扫描速度： Prefetching：提起加载下一页，避免IO的等待 Buffer Pool Bypass：在local memory中进行顺序扫描的页加载，避免buffer pool的sequentail flooding Parallelization：多线程并行顺序加载 Late Materialization：晚物化，DBMS 可以延迟将元组拼接在一起，直到查询计划的上半部分。这允许每个操作员将所需的最少信息传递给下一个操作员 运算符（例如，记录 ID，与列中记录的偏移量）。 Heap clustering： Data Skipping类策略 Zone Maps：预先计算页面中每个元组属性的聚合。 然后，DBMS 可以通过首先检查Zone Map来决定是否需要访问页面。比如事先统计记录最大值为400，那么val &gt; 600的查询语句就不必执行了。 Approximate Queries：对整个样本的子集执行查询以生成近似估计。 Index Scan利用索引查询。 There are many factors involved in the DBMSs’ index selection process, including: What attributes the index contains What attributes the query references The attribute’s value domains Predicate composition Whether the index has unique or non-unique keys 索引的选择有很多的策略与trade-off，在Lec13查询优化具体讲述。 Multi-Index Scan对查询使用多个索引时，DBMS使用每个匹配的索引计算记录 ID 集，根据查询的谓词组合这些记录 ID 集，并检索记录并应用可能保留的任何谓词。DBMS 可以使用位图、哈希表或 Bloom 筛选器通过集交集计算记录 ID。 Modification Queries修改性的Sql（INSERT、UPDATE、DELETE）需要检查约束与维护索引。 For UPDATE/DELETE, child operators pass Record IDs for target tuples and must keep track of previously seen tuples. UPDATE/DELTE查询语句执行时，子算子会把要处理的tuple的id传递给上层负责完成更新/删除操作的父算子，然后父算子通过id找到相应的tuple，然后执行对应的操作。此外，负责更新/删除的算子必须要记住在执行本次的查询语句时操作了哪些数据。 就比如图中update的执行，由下层算子传来要执行的记录ID。假设salary=900的这条记录先被删除，然后执行加100变成1000，最后被插入索引中。但是1000仍然小于1100，这条记录会被再次扫描到，update应该记住它看过这条记录，跳过执行。 There are two implementation choices on how to handle INSERT operators: Choice #1: Materialize tuples inside of the operator. Choice #2: Operator inserts any tuple passed in from child operators. 插入语句根据是否物化有两种选择： 一种是它不管物化，只管插入子操作符传递来的完整tuple，并维护索引； 第二种是它来物化，并维护索引。 Expression Evaluation 解析SQL语句构建条件树，但是一种情况： 加法会被多次计算（对于S表的每个Tuple都会计算一遍），这种情况下存在对应的优化策略：在执行SQL语句的查询计划前，先把语句中的常数提前算出来。 这和Java的高级技术JIT（即时编译技术）有相似之处，和JIT（Just in Time）对应的是AOT（Ahead of time） 在Java的JIT技术中，JVM虚拟机会将被频繁执行的热点代码段（比如说JVM能检测出来有些循环被执行了好多好多次，那这就可以被标记为热点代码段）中的字节码转化成二进制代码，下次再运行到这个热点代码段的时候就直接运行二进制代码，不经过中间那层虚拟机，从而提升了效率 JIT技术是在代码被执行的时候动态地判断出哪段代码是频繁被执行的，而AOT技术是在代码被执行之前就进行这样的判断。","link":"/2024/05/03/cmu15445/Lec08/"},{"title":"cmu15-445笔记九 查询优化","text":"本节课主要关于查询优化，首先介绍了Sql语句的执行过程，然后就是两种优化方式：基于规则的优化和基于代价的优化。 SQL语句是声明式的，只说明要什么，没说明怎么做。DBMS的优化器将优化SQL的执行过程。有如下两种方式： Heuristics / Rules，启发式/基于规则 Cost-based Search，基于代价 启发式方法重写查询语句，以移除低效部分。这种方法有可能需要查阅目录数据结构，但是不需要数据本身。基于代价的方法估计每种执行计划的代价，然后选择代价最低的执行。 逻辑计划是关系代数级别的，物理计划包括了各个算子的具体执行方式，即物理算子（比如说join算子是用nested-loop join还是merge/hash join来完成）。 用户的业务会发出SQL查询语句，少部分DBMS会有SQL Rewriter这个组件，对字符串形式的SQL语句进行文本上的预处理（在字符串层面上做简单的优化）。 之后SQL查询语句进入Parser，Parser会把SQL语句变成抽象语法树，抽象语法树当中会涉及到库/表/列的名称，这些名称要和数据库系统元数据里面的库/表/列/索引的ID对应上，因此会有Binder（即连接器）把SQL抽象语法树中用户写的表名/列名/索引名转化成数据库内部使用的ID，并且这个步骤中会有检查：如果用户请求了一个不存在的表，那么就会直接报错。 经Binder处理过之后的抽象语法树会被送入Tree Rewriter，这个组件大多数DBMS都有，它会输出一个标准的执行计划（比如说SQL语句里有一堆join操作，一开始的抽象语法树中的join的排布可能是乱的，Tree Rewriter会把所有的join排列成左深树，这个步骤也叫正则化），这个过程中也会查一些系统的元数据，Tree Rewriter输出的原始的逻辑计划是优化器进行优化的源头。 之后基于规则的优化器（RBO， rule based optimizer）会查询一些系统的元数据来做优化，基于代价的优化器（CBO， cost based optimizer）不仅会查询元数据，还会查询相关的代价模型，根据代价模型去做优化，最后优化器会生成物理计划，被实际使用。 Relational Algebra Equivalences关系代数表达式的等价，如果两个关系代数表达式所输出的结果集是一样的，那么它们等价。 比如说谓词下推： join算子具有结合率、交换率，这会被用于查询优化 投影算子也可以有一些优化点： 投影下推，从而把无关的attribute对应的列删掉，让tuple和中间结果更小； project out all attributes except the ones requested or required（e.g. joining keys） 这些查询优化策略对于列存储的数据库不重要，因为列存储的数据库永远都是最后进行对tuple的物化。 Logical Query OptimizationSplit Conjunctive Predicates分开连接谓词将连在一起的谓词分开。图片上来看，sql语句并未改变，只不过执行时，将连续的谓词判断分为若干个判断，虽然多了若干个判断，但是方便优化器优化语句。 Decompose predicates into their simplest forms to make it easier for the optimizer to move them around. Predicate Pushdown谓词下推谓词下推，把谓词尽量往下推，推到越接近读表越好，这便可以提前筛掉一部分的数据，减少上层算子的负担。 从图片上可以看到，enrolled表通过谓词下推后，减少了筛选上来的数据，进而减轻了连接时的数据代价。 Replace Cartesian Products with Joins取代笛卡尔积根据相应的谓词，把笛卡尔积变成join。笛卡尔积和谓词合为一个等价的join连接。比如： 如下两图所示，原本artist和appears需要先做笛卡尔积再进行谓词筛选，但是这个操作可以转化为连接。因为DBMS对于Join有多种优化方式（Loop join、sort-merge join和hash join等）。 关于join还有优化手段：应该用“小表”作为驱动表，“大表”作为被驱动表。因为nest loop join算法，把缓存池尽可能多地给outer table使用，从而减少遍历inner table表的次数，从而减少开销，毕竟给inner table用的缓存池再大，在遍历inner table时，都会面临缓存重刷的问题。 Projection Pushdown投影下推执行过程中先执行投影算子，从而把无关的attribute对应的列删掉，让tuple和中间结果更小 Nested Queries 嵌套查询优化SQL语句中经常会有一些嵌套的子查询，DBMS一般会用如下两大手段去优化它： 重写语句，取消嵌套或者扁平化 分解嵌套查询并将结果存储到临时表中 原始的SQL语句里的谓词既涉及到了外层的主查询，也涉及到了内层的子查询，可以发现：实际上它想做的就是join，那不妨就直接进行两个表的join，写成上图下方的形式。这样的话接下来优化器只需优化这一个SQL语句，因此也更容易生成比较高效的物理执行计划。 在一些复杂的查询当中，可能不太容易将内部的子查询和外部的主查询rewrite成一个查询，那么DBMS可以将子查询分离出来，先把子查询做完，把结果存放在一个临时的表里面，然后把这个临时的表带到主查询中。这里的解耦是指：不让子查询嵌套在主查询里面，而是把它拿出来，提前执行它。 Expression Rewriting 表达式重写DBMS会通过人为设置的一些规则把查询语句的表达式（尤其是谓词表达式）重写，让它变得更加精简、高效。 去除无效谓词 合并谓词 Cost Estimations基于代价的优化器会根据当前数据库的状态估算出查询计划的代价。 物理代价：磁盘IO、CPU周期、缓存失效 逻辑代价：算子开销 算法开销：细粒度估计单个算子的开销 为了估算查询成本，DBMS 在其内部目录中维护有关表、属性和索引的内部统计信息。不同的系统以不同的方式维护这些统计信息。大多数系统试图通过维护内部统计表来避免动态计算。然后，这些内部表可能会在后台更新。 Selection Statistics对于每张表R，DBMS追踪表中tuple的数量$N_R$以及每个attribute A的distinct value的数量$V(A,R)$。selection cardinality选择基数由 $SC(A, R)=\\frac{N_R}{V(N,R)} $ 计算得出。 一个attribute A的选择率selectivity由SC的倒数给出。形象的说，就是“谓词能选上来百分之多少的数据” 。 可以察觉到：选择率和数据出现的概率是很相似的概念。多谓词情况下，可以使用计算概率的方法，根据每个谓词的选择率计算总体的选择率。 前面所讨论的都是和select语句相关的基数的计算，对于带有join操作的语句来说，两个表join得到的结果集的规模该如何计算呢？ 在计算选择基数的过程中，遵循了几个假设： 数据一致性 谓词独立性：The predicates on attributes are independent. 包括规则：连接键的域重叠，使得内部关系中的每个键将也存在于外表中。 实际应用场景并不会这么理想化，比如说：关于不同的attribute的不同谓词之间往往不是完全独立的。 Histograms对于不均匀分布/attribute之间不独立的数据，可以利用直方图记录信息。 等宽直方图 等深直方图 Sampling还有一种较为简单粗暴的统计方式，sampling-采样，这种策略的思想是：如果表特别大的话，我们不妨从其中随机选择一些tuple然后构成一个小表，把这个小表作为完整表的一个代表，然后下一步转而分析这个小表，将得出的统计信息用于对完整表的查询代价分析。 DBMS 可以使用采样将谓词应用于具有类似分布的表的较小副本（参见图 13）。每当基础表的更改量超过某个阈值（例如，元组的 10%）时，DBMS 就会更新样本。 sampling的问题：额外维护小表（比如说采样时提取出来的tuple如果在完整的表里被删掉了，那么我们也要对小表做相应的改动），而且每个SQL语句在完整的表上面运行之前，还要先在小表上面跑一遍以获取统计信息，这毫无疑问会带来一定的开销。 sampling的好处就是基于真实的数据去做估计。 Plan Enumeration 计划列举基于前面介绍的各种策略，我们可以粗略地去估计谓词的选择率（selectivity），在知道了谓词的选择率之后，就可以计算出有多少数据被送入了每个算子，知道了这个数据之后就可以计算每个算子的开销，进而得出整个执行计划的开销代价，知道了计划的开销，那么优化器就可以进入下一阶段：计划列举。 对于那些仅涉及单表的查询计划，优化器做的事情非常简单，可以仅仅启发式地依据规则对逻辑计划rewrite，比如说确定访问数据的最佳方式（相关的规则可以是：“若存在这个字段的索引，那么就走索引”），而不用去量化分析查询计划的开销。只涉及单表的OLTP就可以作简单的优化： 多表查询优化对于那些涉及到多个表的查询，不可避免地会有表与表之间的join，而inner-join运算既符合交换律，又符合结合律，因此4～5个表做join时计划列举的空间极大（join操作的顺序，join运算符左边和右边各是哪个表，这些都有极大的搜索空间，因此我们要用一些手段去降低这个搜索空间）。 IBM的System R只考虑左深树对应的join排列，即join的左子树也是一个join操作（如下图最左侧所示，因此下图的右边两个join排列都会被pass掉）。 而且左深树带来了意想不到的好处：如果计划的执行模型（process model）是火山模型，那么就可以做到（假设B~D表的哈希表都做好了并且进行的是hash join）：A表和B表做join得到一个tuple，吐给上层的join算子，然后上层的join算子拿这个tuple和C表做join，之后再吐给上层，和D表做join，这便实现了几乎完美的流式操作，极大程度上使中间结果集更小。","link":"/2024/05/03/cmu15445/Lec09/"},{"title":"cmu15-445笔记十 并发控制基础-事务","text":"这节课主要介绍并发控制的基础-事务的相关知识点。 事务的隔离性，冲突可串行化。 并发控制理论并发控制主要关于事务的ACID。 简化模型：将事务表达为一系列的对象读写操作，比如R（A），W（B）等。 原子性 日志 shadow page 阴影页 备份修改页。事务想修改哪些文件页，DBMS就给这些页做备份，事务操作这些备份，如果事务成功提交，那就拿备份替换下原有的页，否则就删除备份，实现回滚。 隔离性如何实现一个算法，让DBMS能够判断出一系列的读写是否会导致一致性的错误？ 术语解释： （1）schedule 调度 一系列操作的执行顺序被称为数据库系统的执行调度，两个输出结果相同的执行调度被称为是等价调度。 （2）串行调度 按顺序来执行一个个事务，不进行事务操作的交错执行的执行调度是串行调度。 （3）等价 两个输入相同，输出结果也相同的执行调度被称为是等价调度。 （3）可串行调度 如果一个执行调度能够和串行执行等价，那么它就拥有正确的一致性，它也被称作可串行化调度。 那么应该如何判断一个执行调度是可串行化调度呢？如果实现了这一点，DBMS就可以判断出某个调度是否会导致一致性的错误。 首先，需要实现一个证明两个执行调度是等价的算法。 术语解释： （1）冲突操作 如果两个操作来自不同的事务，它们都在操作同一个数据并且至少其中一个是操作是写，那么这两个操作就是冲突的。比如RW冲突、WR冲突、WW冲突。 冲突操作不能在时间序列上更改先后顺序，否则会改变执行调度的结果。 （2）冲突等价（conflict equivalent）如果两个执行调度包含了相同事务的相同操作，并且有相同的冲突，那么这两个调度就被称为冲突等效的。 （3）基于冲突的可串行化 Conflict Serializability 如果某个执行调度S和某个真正串行的执行调度冲突等效，那么它就是冲突可串行化的（conflict serializable）。 （4）基于观察的可串行性 View Serializability 基于观察的可串行性说的就是通过观察来确定某个执行调度是可串行还是不可串行，它与冲突可串行性相比，对执行调度的要求要更加宽松，但目前还没有DBMS能实现它。 冲突可串行化的一种算法：基于交换操作先后顺序如果一个调度S经过交换位于不同事务里，时间上连续，不构成冲突（比如读写不同对象，或者读同一个对象）的位置后可以转换为串行的调度，那么它就是冲突可串行化的。 这个基于swap的算法对于仅包含两个事务的执行调度很有效，但如果调度中有很多事务，这个算法的开销会变得巨大，并不适合。 冲突可串行化的一种算法：基于依赖图 如果一对冲突操作中Ti事务里的0i操作先于Tj事务里的0j操作执行，那么就在依赖图中画从Ti指向Tj的一条有向边。 如果图中出现了环，那么对应的调度就不是可串行化的。 Lecture中所介绍的判断执行调度是否满足冲突可串行化的方法需要等到执行调度里所包括的多个事务都执行完之后才能判断出这个执行调度是否可串行化，但等到执行调度所包括的事务全都执行完并提交了之后，它们就都已经完成了对DBMS的更新，如果这个执行调度是不可串行化的，那么DBMS的一致性就会被破坏，因此这种检测可串行化的方式是无济于事的.","link":"/2024/05/14/cmu15445/Lec10/"},{"title":"cmu15-445笔记十一 并发控制：二阶段锁","text":"这节课主要介绍了悲观并发控制的手段，两阶段锁。还从锁层次上介绍了意向锁，最后是锁实践。 朴素加锁事务执行在事务T1访问A之前，先通过DBMS的锁管理器（Lock Manager）获取A的锁并且注册（记录下来“A的锁当前归T1所有”），之后事务T2想访问A，于是也要获得A的锁，锁管理器便会拒绝它的请求，T2之后便阻塞在这里，直到T1完成了对A的全部操作后通过锁管理器释放A的锁，T2才可以通过锁管理器获取A的锁，并且完成对A的全部操作后释放A的锁。 在带有Lock的情况下，事务执行的过程如下： 事务获取对应的锁 锁管理器授权或阻塞事务 访问某个数据完毕，事务释放锁 虽然有锁了，但事务还是不一致。上图所示。 两阶段锁二阶段锁是一个并发控制协议，它规定了一个事务在运行的过程中如何跟其他事务之间协调锁，从而实现可串行化。 增长阶段（Growing）在这个阶段事务只能不断地获得锁，不能释放锁 缩小阶段（Shrinking）在这个阶段只能释放释放锁，不能再获取新的锁 最终锁释放完毕，事务提交。 使用二阶段锁便可以使得不可串行化的执行调度的最终执行结果具有一致性。如下所示，在两阶段锁协议下，事务T1执行完W(A)后并不会立即释放A的锁，因为二阶段锁协议的规定就是“先一直获取各个锁，然后把所有获取的锁逐个释放”，直到R(A)执行完了之后T1才会释放锁（如果按照之前的策略，先获取X-Lock，再释放X-Lock，然后再获取S-Lock，之后再释放S-Lock，这就违反了两阶段锁的协议） 在使用了二阶段锁协议后，相应的执行调度对应的依赖图（Dependency Graph）一定没有环，二阶段锁可以严格地保证冲突可串行化。 级联回滚问题（脏读问题） 如图所示，事务1进行回滚，但事务2读到了事务1的数据（脏读），此时事务2也不得不跟着回滚。 级联回滚本质上的原因是T2事务在T1事务更新得到的临时版本的数据上进行了操作。事务T1释放锁后处于shrink阶段，虽然shrink阶段不能获得锁，但仍然对未释放锁的对象进行读取，事务本身正在进行。这就造成了读未提交事务的情况。 SS2PL严格二阶段锁（Strong Strict 2PL，简称SS2PL）。在严格二阶段锁协议下，事务只有在提交时才允许释放排他锁（只有事务完成所有操作后，锁才能释放）。 This requirement ensures that any data written by an uncommitted transaction are locked in exclusive mode until the transaction commits, preventing any other transaction from reading the data. 在ss2pl下，任何未提交事务所做的改变只有在提交的时候才能被看到（这就阻止了脏读的出现）。 严格二阶段锁协议的特点是事务所修改的数据在事务结束之前，其他事务都不能读写。 还有一个变种，rigorous two-phase locking protocol，所有锁（共享锁和排它锁）都能只能在最后提交时释放。 死锁问题 严格二阶段锁协议可能会导致死锁。上图所示BA和AB的加锁顺序。 解决死锁问题Deadlock Detection，死锁检测DBMS内部会维护一个锁等待图（waits-for graph），它记录了当前所有并发的事务里谁在等谁的锁，图中每个节点对应一个事务，每条有向边对应一个锁的等待关系（从Ti指向Tj的有向边代表着事务Ti等待Tj释放一个锁），DBMS会周期性地检查这个图，看看图里有没有成环，如果有的话就会想办法把环给解开 如果DBMS检测到锁等待图里出现了环，那就会选择一个victim事务，让它回滚，这样环就会解开，死锁被拆除（这和哲学家吃饭问题很像）。 被选择的victim事务要么会重启要么会中止，这和它是怎么被调用的有关：如果这个事务是DBMS用户的业务的一部分，就可以把它abort，因为用户的业务代码里会有一些应对abort情况的逻辑（比如说转账的事务进行到一半然后被abort，那么就会在前端告诉用户“转账失败，请稍后再试”）；如果用户要求DBMS定时地触发一些SQL语句，到了定好的时间，用户的业务代码可能不在执行，因此如果abort了的话用户可能就不知道，这种情况下就需要DBMS去重启事务。并且这个策略里有一些trade-off，因为DBMS是周期性地检查锁等待图，如果周期的频率很高的话，处理死锁的开销就比较大，因此不易检查地太频繁；但频率太低也不好，这有可能导致一些陷入死锁的事务被卡了好久 不光是死锁检测的频率要做trade-off，选哪个事务当victim也要权衡，我们可以综合考虑“这个事务已经执行了多长时间”（让一个已经执行了很长时间的事务回滚，这不太合理），“事务执行了多少”（可以以每个事务都执行了多少条SQL语句这样的指标来衡量），“这个事务已经得到了多少个锁”（DBMS倾向于让得到的锁多的事务回滚，因为得到的锁越多，就有可能让更多的其他事务陷入阻塞，这样的事务回滚了之后其他事务就都能继续往下执行了)，以及如下所示的其他因素 1234→ By age (lowest timestamp)→ By progress (least/most queries executed)→ By the # of items already locked→ By the # of txns that we have to rollback with it 回滚事务时也有两个方案： Approach 1 完全回滚，让victim事务回滚到它开始执行时的状态，就好像它没发生过Approach 2 最小化地去回滚，去判断到底是哪几个SQL语句造成的死锁，回滚到这些语句还没开始执行的状态即可，没必要完全回滚，并且与此同时让其他事务继续执行 Deadlock Prevention，死锁预防前面介绍的处理死锁的策略是通过建图来检测是否已经发生了死锁，并且在已经构成死锁后去解开死锁。 Deadlock Prevention这个策略是去预防死锁，不让死锁发生。When a txn tries to acquire a lock that is held by another txn, the DBMS kills one of them to prevent a deadlock.当一个事务想要获取其他事务的锁时，DBMS就会杀死其中一个事务。 比如，根据时间戳给各个事务优先级，规定越先开始的事务它的优先级越高。 Wait-Die，高优先级的事务想获取低优先级事务已经拥有了的锁时，那么它将等待低优先级的事务去释放锁；如果低优先级的事务想获取高优先级的事务已经拥有了的锁，那么这个事务直接abort回滚 Wound-Wait，高优先级的事务想获取低优先级的事务已经持有的锁时，持有锁的低优先级事务会abort并且释放锁；低优先级的事务想获取高优先级事务已经持有的锁时，它会等待高优先级事务释放这个锁 Wait-die 事务是个绅士，高级事务想要锁时，主动等待低级事务释放锁。低级事务想要锁时，主动谦让自己的锁。 Wound-wait 事务是暴力分子。高级事务想要锁时，主动强迫低级事务释放锁。低级事务想要锁时，也不放弃自己的锁，等待高级事务执行完毕。 这两个方案本质上是不让事务之间互相等待，因为事务之间互相等待就有可能死锁。 此外还要注意，因为预防死锁被abort了的事务重新开始执行时，它的时间戳（即优先级）不会发生变化，不然就有可能一直因为优先级太低被abort，造成饥饿。 锁粒度到目前为止锁探讨的锁的粒度一般都是DBMS中如tuple这种的对象的锁，如果一个事务想修改很多很多个tuple，那么它就要不停地获取/释放tuple的锁，这会带来很大的开销，导致性能变差。 因此我们不妨加大锁的粒度，当事务想获取锁时，DBMS可以根据实际情况对锁的粒度进行调整（锁的是attribute还是tuple还是数据库文件里的一个页，还是整个表），从而减少事务需要获取的锁的数量。 DBMS中锁的粒度层级如下所示： 意向锁在众多锁粒度分层的情况下，如果想获取table的锁，需要检查它的全部tuple的锁的情况，只要其中有一个tuple的锁被其他事务持有，那当前事务就暂时不能获取这个table的锁。如果检查到了最后一个tuple才发现有tuple被其他事务锁住，这便十分低效，尤其是表很大tuple、很多的情况下。 Intention locks allow a higher level node to be locked in shared mode or exclusive mode without having to check all descendant nodes. 意向锁（Intention Locks）的存在可以解决上面的问题：通过对table这种更高层级的对象加一些标记来表明它是否含有被锁住的tuple，有了这样的意向标记（它并没有真的锁住table），想获取table的锁的事务就不必逐个检查这个table里的tuple。 IS e.g. table含有的tuple中有被上共享锁的 IX e.g. table含有的tuple中有被上排他锁的 SIX e.g. table含有的tuple中有被上排他锁的，并且整个table也被上了共享锁 意向锁存在情况下加锁原则：Each txn obtains appropriate lock at highest level of the database hierarchy. 每个 txn 在数据库层次结构的最高级别获得适当的锁。 To get S or IS lock on a node, the txn must hold at least IS on parent node. 如果想对tuple加S/IS锁，那必须先对tuple所在的table加IS锁 To get X, IX, or SIX on a node, must hold at least IX on parent node. 如果想对tuple加X/IX/SIX锁，那必须先对其所在的table加IX锁 意向锁存在情况下解锁原则：Transaction Ti can unlock a node Q only if Ti currently has none of the children of Q locked. 事务能够对某个节点进行解锁，前提是那个节点的任何子节点都已经解锁。 Observe that the multiple-granularity protocol requires that locks be acquired in top- down (root-to-leaf) order, whereas locks must be released in bottom-up (leaf-to-root) order.可以观察到，多层次锁存在下，加锁原则是从上到下的，解锁则是从下到上。 The DBMS can automatically switch to coarser- grained locks when a txn acquires too many low- level locks. 当一个事务想要太多低层次的锁时，DBMS可以将之转化为粗粒度的锁。 锁升级 考虑这样一个例子，事务T8需要对a1进行读写，事务T9同样对a1进行读。然而，在二阶段锁协议下，T8一开始需要获得a1的排他锁，这将使得两个事务串行进行。 注意到，如果事务T8能够在一开始获得a1的共享锁，最后执行a1的写操作时，将共享锁转化为排它锁，这样两个事务就能并排进行。 有锁升级upgrade，同样有锁降级downgrade。 Rather, upgrading can take place in only the growing phase, whereas downgrading can take place in only the shrinking phase. 升级只能在扩张阶段进行，降级只能在缩小阶段进行。 锁实践 应用程序通常不会手动获取事务的锁（即显式 SQL 命令）。 有时可以主动加锁以提高并发性（给予DBMS提示） 总结2PL是数据库常用的加锁方式。 2PL会出现级联回滚问题，因此出现SS2PL，将释放锁的时机推迟到事务提交。 2PL还会有死锁问题，死锁检测在死锁出现之后，构造锁等待图，并选择事务牺牲以接触死锁。死锁预防在出现事务锁争抢时及时杀死事务，有wait-die和wound-wait两种方式。 不同粒度的锁能提高并发。","link":"/2024/05/14/cmu15445/Lec11/"},{"title":"cmu15-445笔记十二 并发控制：乐观控制","text":"这节课主要介绍了乐观并发控制：时间戳顺序并发控制、OCC协议。最后还介绍了幻相，幻相引起的原因、解决方式。 二阶段锁协议属于一种悲观的并发控制方法：总是假设未来可能出现数据竞争，因此总是给共享的对象上锁。 也存在一些乐观的并发控制方法，比如说基于时间戳顺序的并发控制（Timestamp Ordering），它的基本原理是，给每个事务一个时间戳，根据事务的时间戳来决定它们的顺序以及出现冲突操作时该如何处理。 时间戳赋予 可以通过系统时钟，但有些时候这会出问题，因为系统时钟不是完全精确的，它会每隔一段时间和服务器通信，进行同步，因此在同步的时候就会出现“时间突然被调慢了一分钟”这种情况，这就可能导致系统时间校准之前到达的事务和系统时间校准的之后到达的事务的时间戳顺序发生了混乱 由于系统时钟并不完全可靠，因此在很多单节点的数据库中使用Logical Counter（逻辑计数器），第一个到达的事务标记为1号，第二个到达的标记为2号…，通过简单的计数完成时间戳的排列，从而避免系统时钟的跳变 对于分布式系统来说，Logical Counter很难校准（因为在各个节点之后依赖于网络的通讯比较慢，如果A节点和B节点相距很远的话，有可能某一时刻到达A节点的事务和到达B节点的事务对应同一个counter，因为它们之间不会立即获取到对方的counter更新）。因此就有了系统时钟和逻辑计数器混合使用的时间戳确定办法，具体的实现方法在本课程中并未提及 Basic Timestamp Ordering(T/O) Protocol基础的T/O协议中，事务在读/写对象的时候是不加锁的 数据库中的所有对象（一般就是指tuple这种对象）上面要附带两个时间戳，一个读时间戳（上一次读这个对象的事务的时间戳/事务号），一个写时间戳（上一次写这个对象的事务的时间戳/事务号）。 每次读/写数据的时候都要检查时间戳（比较当前事务的时间戳和操作过当前正在进行读/写的对象的事务的时间戳），要求是“不能操作未来的数据”。 基于时间戳协议的读流程：比较事务的时间戳和对象写时间戳，如果当前时间戳小于上次写的时间戳，则放弃事务进行。否则读对象，然后更新读时间戳，最后拷贝一份（可重复读）。 基于时间戳协议的写流程：比较事务的时间戳与对象的读时间戳和写时间戳，需要当前时间戳均大于二者。然后更新写时间戳，最后拷贝一份。 托马斯写规则 在基于时间戳的写流程中，如果事务的时间戳小于对象写时间戳，事务被迫abort。但是，这个过程表明，有未来的事务正在写这个共享对象。当前事务的写会被覆盖，那么其实也没事。 TO 缺点如果不考虑托马斯写规则带来的优化，基础T/O协议会生成冲突可串行化的执行调度，它的优点是没有采用锁，因此不可能构成死锁。 长事务饥饿问题：较长的事务（比如说有几百条SQL语句）有可能会饥饿，因为很有可能它执行了一段时间之后，想要访问的数据都是被比它更“年轻”的事物修改过的，那它只能abort，重启之后又迎来同样的结局。 性能问题：事务在读任何数据的时候都要往本地拷贝一份同时还可能更新时间戳 Optimistic Concurrency ControlOCC是基于事务之间发生冲突的概率低，并且事务都比较短这个假设提出的优化策略，它希望通过无锁化来对事务之间无冲突的场景做出优化。 基本策略每个事务都有一个自己的工作区，任何读对象都会拷贝到这个工作区，对对象的更改也在这个工作区。 等到事务即将commit的时候，DBMS会将要提交的数据更新和其他事务要提交的更新进行比较，如果它们之间没有冲突的话，DBMS会一次性地把事务所做的所有更新都提交，如果出现了冲突，那么事务会abort。 三个阶段： 读阶段 这个阶段之所以称为读阶段，是对于数据库来说的它是一直只被读的。在OCC策略下，即便是写语句，也是读数据库到工作区进行更改，所有写操作在事务完成时才进行。 验证阶段 事务执行完了准备提交时，把它完成的数据更新和其他事务相比较。如果校验通过，那么就转至下一个阶段，否则abort并重启事务。 Checks other txns for RW and WW conflicts and ensure that conflicts are in one direction (e.g., older→younger). 写阶段 ​ 把事务本地所记录的更新提交到数据库中。 实现OCC的DBMS一般会在写阶段锁全表，除了当前事务以外没有其他线程可以修改数据库，也就不能多个事务并发地写，虽然这牺牲了并发性，但由于前面已经准备好了要写的数据，所以写操作的时间并不长，因此开销可以接受。 验证阶段（1）后向校验 与已经发生过的事务校验 （2）前向校验 即向未来的事务校验，与当前正在进行的事务进行对比。 每个事务的时间戳在校验开始时赋予。假设当前$TS(T_i)&lt;TS(T_j)$，那么必须满足以下条件： Ti completes all three phases before Tj begins its execution. 即本身就是可串行的，Ti在Tj开始前就结束了。 Ti在Tj的写阶段开始前就结束了，并且Ti的写集合与Tj的读集合交集为空（Ti修改过的对象Tj没读过）。 Ti先于Tj完成读阶段，Ti修改过的对象Tj没读过，Ti修改过的对象Tj没修改过。 缺点 性能问题，它还是会和基础T/O一样要求事务把要读写的数据拷贝到本地 校验这个步骤的逻辑很复杂，容易构成性能瓶颈 写阶段是串行的，不能并发，也容易成为瓶颈 OCC中如果校验阶段失败的话，那么前面所做的全部操作就都会前功尽弃，不像二阶段锁有死锁检测，这样可以在事务进行到一半的时候abort 幻觉现象到现在为止我们讨论的事务都是基于读写操作，如果引入删除操作，那么就会发生新的问题。 如果一个事务开启期间，另外一个事务插入了一条数据，那么当前事务读取的count/max/min就会前后不一致。 为什么会发生？因为前面所讨论的事务并发控制（二阶段锁和OCC）只对存在的数据有用，插入时的新数据并不存在于数据库中。 Re-Execute Scans记录下来事务所有可能出现幻读的地方（像查最大值，平均值，最小值这些涉及到范围扫描的操作），为了防止察觉不到有其他事务在扫描完成后再向表里插入新数据，在事务提交之前会再执行一遍前面所记录的所有扫描。 Example: Run the scan for an UPDATE query but do not modify matching tuples. 比如说重新执行一遍更新语句，但不真正执行更新，只核对扫描的数据条目。 Predicate Locking 谓词锁。 对于含有where clause的SQL语句：给select语句对应的谓词加共享锁，给update/insert/delete语句对应的谓词加独占锁。 Never implemented in any system except for HyPer (precision locking). Index Locking基于索引的锁。 如果对谓词里的attribute已经构建了索引的话，那么DBMS可以给相关的索引页上锁。如果没有构建相关的索引，就使用表锁这种宽范围的锁。 基于索引的锁有多种模式： （1）Key-Value Lock 锁住索引中的单一键值，如果键不存在则需要虚拟键。 （2）Gap Locks 间隙锁，锁住当前key到下一个key的间隙。 （3）Key-Range locks 范围锁，锁住一个范围内的键值。对于无穷大等键需要虚拟键。 没有索引时If there is no suitable index, then the txn must obtain: → A lock on every page in the table to prevent a record’s status=’lit’ from being changed to lit. → The lock for the table itself to prevent records with status=’lit’ from being added or deleted. 锁住条件出现的每一个页面，避免插入或删除。 弱隔离级别前面从2PL到T/O这些策略都是为了实现串行化这样一个最高的事务隔离级别，实际的业务场景里有些业务可以忍受非串行化的执行调度，而且非串行化时性能会更好，因此也存在一些比串行化更弱的隔离级别。 更低的隔离级别下事务之间会互相暴露，这也会引发一些问题： 脏读（当前事务读的数据是其他事务修改过的但这个修改还没被提交） 不可重复读（前后两次读同一个对象得到的数据不同，因为被其他事务修改过了） 幻读（前后两次读同一个谓词下的数据集合，读到的数据规模不一样） 各个隔离级别的实现方法： SERIALIZABLE: Obtain all locks first; plus index locks, plus strict 2PL. REPEATABLE READS: Same as above, but no index locks. READ COMMITTED: Same as above, but S locks are released immediately. READ UNCOMMITTED: Same as above but allows dirty reads (no S locks).","link":"/2024/05/14/cmu15445/Lec12/"},{"title":"cmu15-445笔记十三 MVCC","text":"这节课主要介绍了多版本并发控制。 多版本并发控制基本思想DBMS保持一个逻辑对象的多个物理版本： 当事务写一个对象时，事务创建一个新版本 当事务读一个对象时，事务读创建时最新的版本 MVCC解决的问题/存在的原因： 2PL协议中，一个事务更新一个对象到它提交的期间，其他的事务均无法读取对象（即其他读取这个对象的事物都阻塞在这里）。 而MVCC的基础思想是，留下数据的历史版本，这样其他的事务可以读历史版本而不是被阻塞。只读的事务就可以在无锁的情况下读它所需要的那个版本的一致性快照，不受数据库动态变化的影响。 WRITE SKEW ANOMALY 写偏斜在快照隔离的基础下，每个事务看到的都是它开始的一致性快照。 假设当前有一黑一杯两个棋子，事务1是将所有白棋变成黑棋，事务2是将所有黑棋变为白棋。如果仅使用快照隔离，那么这两个事务最终运行结果是一黑一白两个棋子（因为这两个事务恰好各自更新了一颗棋子）。但是在可串行化的语义下，运行结果应该是全黑或者全白。 写偏斜的原因是：一个事务读出的数据作为写入的依据，而在提交前，这个读出的数据被其他事物改变。 让我们重复一下快照隔离的效果是： 一个事务读到的数据都来自于数据库某同一个时刻（时刻甲）的状态，然后所有写都发生在之后的某同一个时刻（时刻乙）。 这里的矛盾的矛盾就清楚了： 时刻甲时数据有个状态，等到了时刻乙，数据的状态可能不一样了。根据时刻甲的状态作出写的决定，这个决定到时刻乙真正写时，就未必适用了。 有点刻舟求剑的味道。 因此只依靠MVCC是不能达到调度的串行化，因此MVCC需要结合其他并发控制手段。 设计MVCC的选择并发控制协议 版本存储 垃圾回收 索引管理 删除管理 MVCC并发控制只使用MVCC无法做到serializable的隔离级别，因此会和如下的其他一些协议结合在一起： 基于时间戳：事务被赋予时间戳，然后决定串行顺序 乐观控制：三阶段协议，每个事务都有一个私有工作区 两阶段锁协议 版本存储DBMS可以用tuple对象所包含的指针，建立一个包含各个版本的链表，因此DBMS可以在这个链表上去寻找各个版本，如果对表构建了B+树之类的索引，那么索引最后指向的是版本链表的头节点。 简单追加 append only storage新版本的tuple被追加到表中，一个logical tuple的多个版本通过链表被连起来。 简单追加也有两种思路： oldest to newest 在链表末尾追加新版本 newest to oldest 在链表头头结点插入新版本 如果把新的版本放在链表的末尾，那么经过索引查到的是最老的版本。也就是说，这么做的话，追加新版本的时候开销小，但想要读取快照，即执行查询时搜索对应版本的时候开销会大。 反之，如果把新的版本放在链表的头部，那么执行查询，搜索相应版本的时候效率会高，但追加新版本时维护链表的工作量大，因为要更新索引结构中的指针。 Time travel storage单独建立一个额外的表用于存储历史数据，主表（Main Table）存储的就是当前最新的数据，历史数据在单独的Time-Travel Table（历史表）里。 当事务对数据进行更新时，也就是产生新版本时，DBMS会把旧版本的对象拷贝至历史表中，并且在历史表中维护好串联起多个旧版本的链表，之后在主表里写入新版本的数据，覆盖旧版本，然后再修改主表中相应的tuple的指针，令其指向历史表里最新的历史版本。 Delta Storage 增量存储实际的数据库的表中，每个tuple不止有一个attribute，而事务对tuple的一次更新可能只是修改了众多attribute里的一个，因此在历史表里每次都追加一个完整的tuple，这未免有些浪费存储空间。因此就有了只存储每次数据更新时的增量的idea。 垃圾回收数据库不可能无限地存储各个数据的历史版本，否则就会导致数据库爆炸，存不下那么多的数据，因此DBMS需要把那些已经没有用了，作废了的历史版本删除。 如果任何active状态的事务都看不到某个历史版本（比如说现在的事务的时间戳都是10以上的，但这个历史版本的时间戳/版本号是1），那么这个古老的历史版本可以把它删除 如果某个事务创建了某个历史版本，但这个事务后来回滚了。那么这个历史版本可以删除 在实现垃圾回收时，要解决如下两个问题： 如何发现无用的历史版本？ 什么时候去删除无用的历史版本？ Tuple级别的垃圾回收（1）后台清理 后台会有一个单独的线程每隔一段时间就扫描历史表（或同类的其他表），然后结合当前active的事务的时间戳去分析表中哪一个版本是无用的。 优化手段：维护一个dirty block bitmap，去跟踪自从上次垃圾回收至今表里有哪些页被事务修改过，因此下一次垃圾回收的时候，只需要扫描自从上次GC以来被修改过的页面。 （2）合作清理 事务执行SQL查询语句时需要通过索引来访问相应的tuple及其历史版本，在这个过程中可以顺便扫描tuple，把无用的历史版本删除。 这只对尾插法的版本存储有用。 这样的话就不需要额外的GC线程来完成垃圾回收，而是各个事务在执行的时候都会做一点垃圾回收的工作。 事务级别的垃圾回收每个事务会记下来它读/写的集合，记录因为更新导致无用的历史版本，当事务提交时，将这些信息交给垃圾回收器。 垃圾回收器会检查所有正在运行的事物，判断哪些旧版本可以删除。这样，回收器就无需扫描所有tuple了。 索引管理一般情况下，主键索引相对比较好处理，因为主键索引会指向版本链表的头部，而且是通过物理地址（在哪个页的哪个slot）来定位的（如下图）。 辅助索引有点难处理，辅助索引的key是建索引的attribute的值，但val有两种选择： 逻辑指针 物理指针 逻辑指针指的是val为Tuple的主键或者ID，需要再次通过主键索引找到完整的tuple。 物理指针则直接存储完整Tuple的物理地址（比如哪个页的哪个slot），但是缺点在于更新维护。一张表可能存在多个辅助索引，如果对某个tuple进行更新，不仅要维护主键索引，还要修改所有辅助索引的指针。 MVCC Deletes当一个tuple的所有版本都不可见时，DBMS物理地将这个tuple删除。 需要一种方式来表明tuple已经逻辑删除： deleted flag tombstone tuple 可以在tuple的header中加删除标识位；或者加入一个空tuple的版本作为标志。","link":"/2024/05/14/cmu15445/Lec13/"},{"title":"cmu15-445笔记十三 日志","text":"这节课主要介绍基于日志的事务实现。 故障级别（1）事务级别故障 又分为逻辑错误和内部状态错误。逻辑错误是事务回滚（包括用户主动回滚和OCC校验阶段冲突回滚等），内部错误比如说事务死锁（死锁检测，牺牲等待环中的一个事务）。 事务级别的故障是数据库正常运行所不可避免的，因此这也是数据库开发者所必须考虑的。 （2）系统级故障 这又分为软件异常和硬件异常，软件异常可能是DBMS或者OS的bug，硬件故障可能是断电、CPU故障。硬件故障不包括存储介质故障。 （3）存储介质故障 这类故障一般是无法修复的，数据库开发者无需考虑这些。 Buffer Pool PoliciesDBMS需要保证，一旦一个事务提交了，那么这个事务的改变就是永久的。而事务一旦回滚，没有任何部分改变持久化。 DBMS需要特定的缓存池管理方案来实现如下的Undo/Redo操作，从而保证事务的原子性和持久化： Undo：撤销事务不完全的改变 Redo：重做已经提交事务的改变 根据事务对于硬盘的更改，由以下几种语义： Steal：事务未提交时，允许其修改硬盘上的数据 No-Steal：事务未提交时，不允许其修改硬盘上的数据 Force：事务提交时，所做的更改必须全部落到硬盘上 No-Force：事务提交时，不要求所做的更改必须全部落到硬盘上 No-Steal+Force这种语义下，未提交的事务只能操纵缓冲区，然后在提交时，一次性地将所有更改写回磁盘。 优点：实现容易 不需要实现undo，因为未提交的事务的更改不会反映到磁盘上（只有缓冲区被污染，还原即可） 不需要实现redo，因为提交的事务的更改必定反映在磁盘上 缺点： 事务的更改都存在缓冲区，严重占用缓冲区空间。如果有一部分被修改过的页提前被踢出缓存池，那么就破坏了事务的原子性。特别是全表扫描然后更新的这种场景下，缓存池就会非常紧张。也就是说，每个事务可修改的数据的量严重受缓存池大小限制。 Shadow PagingShadow Paging是上文No-Steal+Force策略的一个具体实现。具体地，它会维护两份数据库的数据。 Master：所有数据的更改都已经提交，是一个一致性的状态。 Shadow：在Master上作修改，但是事务没有提交。 shadow可以理解为数据库的一份拷贝，事务先在shadow上作修改，提交后，shadow就成为新的master。 为了提高效率，DBMS 不会复制整个数据库，只需要复制有变动的页面。 优点：仍然是容易实现redo和undo undo：只需撤销shadow page，DB root仍然指向原先的master。 redo：不需要做什么。 缺点： 磁盘IO开销大，事务的每个更新都要落盘；事务提交后还要更新page table、DB root 数据的碎片化，存储不连续 内存和磁盘旧页需要垃圾清理 只支持一个写事务或批量写事务 SQLite SQLite曾经使用改进后的shadow paging的策略。 硬盘上journal file里存储的是事务要修改的页的原始版本，commit时会把缓存池里修改后的页刷入磁盘里对应的地方（非jouranl file区）。如果刷入Page 2’之后停电了，机器重启后会把journal file加载入缓存，然后把它写入磁盘，这就完成了对断电时未提交的事务的回滚，保证了事务的原子性。 Shadow Paging策略会造成对硬盘的大量的随机访问，这会降低性能，DBMS需要一个方案去把对磁盘的随机的写转换成连续的写。 Write-Ahead Log“预写日志”，也就是要先写日志，再写数据。在这个策略里，磁盘里面会单独开辟一块类似于前面所讲的journal file的区域，称为log file，用于保存事务对于数据的修改。 DBMS在把用户所修改过的缓存池中的页刷入磁盘之前，它需要先把预写日志写入磁盘中的日志文件，也就是说先完成预写日志的持久化，再完成缓存池里dirty page的持久化。当日志持久化完成，事务才能提交。之后才将dirty page持久化。 Buffer Pool Policy：Steal + No-Force WAL的日志格式： 1234→ Transaction Id→ Object Id→ Before Value (UNDO) → After Value (REDO) 实现优化：在事务提交时，需要将日志都刷回磁盘，这将成为性能瓶颈。不妨把多个事务的日志攒到一起提交（第一个到达的事务执行到commit时先阻塞住，然后多攒几个要commit的事务，之后一次性地把它们的日志全部刷入磁盘，然后同时将“事务成功提交”返回给所有等待着的用户），这样的话就会把多个事务的磁盘I/O合并到一起来处理，减少磁盘I/O的次数与开销。 如果某段时间内DBMS中的事务数量不多，很长的一段时间内都没有新的事务到达，那么也没有必要等到事务攒够一定的数量再group commit，不然会导致等待的时间过长。可以设置一个等待时长上限，到了这个上限之后就把当前所有想要commit的事务的日志写入硬盘。 runtime performance是事务正常执行的时候的性能，no-force+steal策略的runtime performance是最好的，因为steal策略会把多次的刷dirty page回磁盘的I/O合并成一次（而且还是顺序写），no-force策略下没有强制要求用户在commit的时候刷盘；与之相反，force+no-steal的runtime performance最差。 recover performance是数据库恢复的时候的性能，no-force+steal策略下的recover performance最差，因为no-force策略会导致宕机后重启时用log重放事务（因为事务commit的时候没有立即把dirty page刷回磁盘），steal策略会导致往磁盘里刷了好多没有还没有提交的事务所做的数据更新，因此DBMS需要执行undo操作把crash的时候没执行完的事务回滚。 DBMS比较注重运行性能，故障恢复比较不常见。 Logging Schemes 物理日志：记录每个二进制位的变化 逻辑日志：记录日志执行的操作，比如更新、删除、插入等 混合式日志phsilogical logging：比如说用page id + slot id记录一条tuple的二进制位发生的变化 物理日志缺点是记录的数据量大，比如修改全表的一个attribute，逻辑日志之需要一条sql语句。 逻辑日志的缺点是：并发问题。由于逻辑日志难以携带并发执行顺序的信息，当同时有多个事务产生更新操作时，数据库内部会将这些操作调度为串行化序列执行，需要机制来保障每次回放操作的执行顺序与调度产生的顺序一致。 逻辑日志的另外一个缺点是：如果sql语句带有不可复现的语句，比如“当前时间”，还是需要记录物理变化。 混合式日志优点是：不会受存储引擎整理数据页中的tuple时造成的影响。（比如，删除相关的SQL指令在页中删除tuple后导致空穴和碎片，DBMS会整理tuple进而清理碎片。整理前后，同一个tuple在这个页中的偏移量会发生变化，因此在清理碎片的同时需要维护物理日志。如果日志里记录的是slot号而非偏移量，那么就省去了这个维护操作带来的开销） CheckpointsWAL日志的缺点： 无限增大 崩溃后，重做日志花费时间长 那么就有一种思想，数据库每隔一段时间，将自己的状态以物理形式记录在磁盘上，这个点以前的日志就无需存储。崩溃重做时，只需加载备份，然后重做一小部分日志即可恢复。 生成checkpoint的算法： 停止查询 将所有WAL日志都刷到磁盘 将所有脏页都刷回磁盘 将一个checkpoint的标记刷到日志，然后保存状态（只有当DBMS中已有的事务都结束，而且新的事务没有开始，也就是数据库中没有任何事务在进行，整个数据库是静态的时候，在这样的一个“空档期”才能做checkpoint，这样才能保证实现一致性的快照） 开放查询 Checkpoint本身肯定会带来性能损耗，存档需要花时间做磁盘I/O，事务的执行会被阻塞住。并且在数据库恢复的时候需要去根据日志判断哪些事务在crash前没有commit，进而需要扫描日志文件，因此也会带来开销。 数据库多长时间存档一次也是问题。频繁存档影响性能，太长时间存档影响恢复效率。","link":"/2024/05/16/cmu15445/Lec14/"},{"title":"cmu15-445笔记十四","text":"这节课主要讲述数据库恢复。 ARIESAlgorithms for Recovery and Isolation Exploiting Semantics，“数据库恢复原型算法“。 主要思想： 预写式日志 所有改变记在日志中，日志先于数据落盘 使用 steal + no-force 缓冲池策略 当 DBMS 重启时，按照日志记录的内容做回放，恢复到故障发生前的状态 在 undo 过程中记录 undo 操作到日志中，确保在恢复期间再次出现故障时不会执行多次相同的 undo 操作 Log Sequence NumbersWAL中的每条日志记录都需要包含一个全局唯一且一般是单调递增的log sequence number (LSN)。 flushedLSN：最后一个刷回磁盘的日志序号 pageLSN：对于一个page x，最后修改它的日志的序号 recLSN：对于一个page x，它刷回磁盘后第一个修改它的日志序号 lastLSN：对于一个事务T，它的最后一条日志的序号 MasterRecord：上一次checkpoint对应的lsn 事务每一次修改缓存里面的数据页，都要顺带修改page对应的pageLSN。 每次把内存里的log刷入磁盘时，DBMS也要顺带更新flushedLSN。 将一个page x刷回磁盘时，要遵循 $pageLSN_X \\leq flushedLSN$ ，目的是保证page的修改日志已经落盘。 事务提交12345Assumptions in this lecture:→ All log records fit within a single page.→ Disk writes are atomic.→ Single-versioned tuples with Strong Strict 2PL.→ STEAL + NO-FORCE buffer management with WAL 当事务提交时，DBMS 先写入一条 COMMIT 记录到 WAL ，然后将 COMMIT 及之前的日志落盘。 一旦COMMIT记录安全地存储在磁盘上，DBMS就向应用程序返回事务已提交的确认信息，并将flushedLSN 被修改为 COMMIT 记录的 LSN。 在将来某一时刻，DBMS 会将内存中 COMMIT 及其之前的日志清除，并将缓存池中的脏页刷回磁盘，完成后再写入一条 TXN-END 记录到 WAL 中，作为内部记录。 When the commit succeeds, write a special TXN-END record to log. → Indicates that no new log record for a txn will appear in the log ever again. → This does not need to be flushed immediately. TXN-END日志不需要马上刷新到磁盘，丢失也没关系，因为日志已经持久化了。 事务回滚事务回滚对于数据库来说是特殊情况，因此ARIES算法也会做特殊的处理：在日志记录中再加一个字段：prevLSN。 这个字段代表着相同事务的日志的上一条日志，这样同一个事务的日志就形成了链（e.g. 15号日志记录的上一条日志记录不一定是14号日志记录，因为它们可能属于不同的事务）。 COMPENSATION LOG RECORDS在对事务做回滚，也就是进行undo操作的时候，要记录”compensation log records”（简称CLR），也就是把进行过的回滚操作也写入日志，从而防止在回滚过程中再次故障导致部分操作被执行多次。 CLR 记录的是 undo 操作，它除了记录原操作相关的记录，还记录了 undoNext 指针，指向下一个将要被 undo 的 LSN。 CLR日志不需要强制落盘，因为大不了就下次DBMS重启的时候重新回滚一遍，不影响事务的原子性（也就是说，在事务abort的时候可以直接告知用户事务abort了，而不必等到所有的undo操作都做完并且CLR都落盘） 回滚算法首先记录一条abort的日志。 然后反向分析事务的更新，对于每个更新记录，写一个CLR日志，然后加载恢复旧值。 最后，写TXN-END日志表明回滚完毕，释放所有锁。 Fuzzy checkpointsBlocking CHECKPOINTSDBMS在标记checkpoint的时候不让任何新的事务开始执行，并且把系统中还没有执行完的事务都执行完并且完成相应的数据更新的落盘。如果在还没执行完的那些事务里，有的事务非常的长，那么DBMS就会等待相当长的一段时间，在这段时间里不能接收新的事务，这会使得性能非常的差。 SLIGHTLY BETTER CHECKPOINTS做checkpoint的时候不必等待当前还没执行完的事务去执行完，让它们停下即可。 让事务暂停的方法可以是在checkpoint开始后阻止事务获取数据或索引的写锁 (write latch) 如果事务是read-only的，那么可以让它继续 这时有些未commit的事务写入的数据可能会被checkpoint线程一起捎带落盘，因此这时磁盘中的数据 snapshot可能处于 inconsistent 的状态。 但是只要我们在 checkpoint 的时候记录哪些活跃事务正在进行，哪些数据页是脏的，故障恢复时读取 WAL 就能知道存在哪些活跃事务的数据可能被部分写出，从而恢复 inconsistent 的数据。因此整个 checkpoint 过程需要两类信息：活跃事务表 (ATT)与脏页表(DPT) 活跃事务表ATT中的entry包含三个字段：事务ID、状态、事务更新的lastLSN 事务彻底完成的时候（也就是它所做的全部更新都落盘，即TXN-END被写入日志时），ATT表中它所对应的entry才可以被删除 状态有：Running、Committing、U（Candidate for Undo） （事务状态中的U可以理解为“还没提交”：如果数据库crash的时候这个事务还没提交，那么它就需要undo，所以称为”candidate for undo”） DPT记录的是缓存池中当前还没落盘的脏页。 entry代表一个未落盘的脏页，以及recLSN（让这个页开始变脏的log record的LSN） 采取了slightly better checkpoints策略后的WAL日志，checkpoint存档点中多了ATT和DPT。 FUZZY CHECKPOINTSSlightly better checkpoints尽管比 Non-fuzzy 好一些，不需要等待所有活跃事务执行完毕，但仍然需要在 checkpoint 期间暂停执行所有写事务。fuzzy checkpoints策略下，在做checkpoint的时候，所有的事务都可以正常工作，并且不会强制把所有的脏页都 落盘。 fuzzy checkpoints会把原先的日志中的checkpoint的一个时间点变成一个时间段： checkpoint-begin：标志着checkpoint的开始，DBMS拍摄ATT和DPT的快照 checkpoint-end：标志着checkpoint的结束，带有ATT和DPT（由begin阶段获取而来） 在checkpoint开始后的事务不会记录到checkpoint-end的ATT表。 ARIES RecoveryARIES协议的恢复算法有三个阶段： Analysis：读取WAL日志，然后分析哪些脏页还没被刷到磁盘（DPT），哪些事务还是活跃的（ATT） Redo：重做 undo：撤销未提交事务的影响 The DBMS starts the recovery process by examining the log starting from the last BEGIN-CHECKPOINT found via MasterRecord. It then begins the Analysis phase by scanning forward through time to build out ATT and DPT. In the Redo phase, the algorithm jumps to the smallest recLSN, which is the oldest log record that may have modified a page not written to disk. The DBMS then applies all changes from the smallest recLSN. The Undo phase starts at the oldest log record of a transaction active at crash and reverses all changes up to that point. 分析阶段12345678Analysis PhaseStart from last checkpoint found via the database’s MasterRecord LSN.1. Scan log forward from the checkpoint.2. If the DBMS finds a TXN-END record, remove its transaction from ATT.3. All other records, add transaction to ATT with status UNDO, and on commit, change transactionstatus to COMMIT.4. For UPDATE log records, if page P is not in the DPT, then add P to DPT and set P ’s recLSN to the logrecord’s LSN. Redo阶段此阶段的目标是让 DBMS 重复历史记录，以重建其状态，直到崩溃的那一刻。它将重新应用所有更新（甚至中止的事务）并重做 CLR。 123The DBMS scans forward from log record containing smallest recLSN in the DPT. For each update log record or CLR with a given LSN, the DBMS re-applies the update unless:• Affected page is not in the DPT, or• Affected page is in DPT but that record’s LSN is less than the recLSN of the page in DPT, or • Affected pageLSN (on disk) ≥ LSN. 若要重做操作，DBMS 会重新应用日志记录中的更改，然后将受影响页面的 pageLSN 设置为该日志记录的 LSN。 在重做阶段结束时，为所有状态为 COMMIT 的事务写入 TXN-END 日志记录，并将其从 ATT 中删除。 Undo阶段在最后阶段，DBMS 会撤消崩溃时处于活动状态的所有事务。这些都是在分析阶段之后在 ATT 中具有 UNDO 状态的事务。 DBMS 使用 lastLSN 以相反的 LSN 顺序处理事务，以加快遍历速度。 当它撤消事务的更新时，DBMS 会为每次修改将一个 CLR 条目写入日志。 成功中止最后一个事务后，DBMS 将清除日志，然后准备开始处理新事务。","link":"/2024/05/17/cmu15445/Lec15/"},{"title":"网络编程API","text":"多年前写的笔记，同步上传下。 一、基础socket函数12345678910111213141516171819202122232425262728293031323334#include &lt;sys/socket.h&gt;int socket(int domain, int type, int protocol);// 功能：创建套接字。// 参数：domain：采取的协议族，一般为 PF_INET；// type：数据传输方式，一般为 SOCK_STREAM； // protocol：一般设为 0 即可。// 返回值：成功时返回文件描述符，失败时返回 -1 int bind(int sockfd, struct sockaddr *myaddr, socklen_t addrlen);// 功能：为套接字分配地址信息。// 参数：sockfd：要分配地址信息的套接字文件描述符；// myaddr：存有地址信息的结构体变量指针；// addrlen：第二个参数的长度。// 返回值：成功时返回 0，失败时返回 -1 int listen(int sockfd, int backlog); // 功能：将套接字转换为可接收连接的状态。// 参数：sock：希望进入等待连接请求状态的套接字文件描述符；// backlog：连接请求等待队列的长度，最多使 backlog 个连接请求进入队列。// 返回值：成功时返回 0，失败时返回 -1int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);// 功能：受理连接请求等待队列中待处理的连接请求。// 参数：sock：服务器套接字的文件描述符；// addr：用于保存发起连接请求的客户端地址信息；// addrlen：第二个参数的长度。// 返回值：成功时返回创建的套接字文件描述符，失败时返回 -1 int connect(int sockfd, struct sockaddr *serv_addr, socklen_t addrlen); // 功能：请求连接。// 参数：sock：客户端套接字的文件描述符；// serv_addr：保存目标服务器端地址信息的结构体指针；// addrlen：第二个参数serv_addr的长度（单位是字节）// 返回值：成功时返回 0，失败时返回 -1 1.1常用TCP连接方法1234567891011121314151617181920212223242526#include &lt;stdio.h&gt;#include &lt;sys/socket.h&gt;int main(int argc, char *argv[]){ if(argc!=3){ printf(&quot;Usage : %s &lt;ip&gt; &lt;port&gt;\\n&quot;, argv[0]); exit(1); } const char* ip = argv[1]; char* port = argv[2]; struct sockaddr_in serv_addr; /* addr网络地址信息初始化 */ int serv_sock=socket(PF_INET, SOCK_STREAM, 0); //assert(serv_sock &gt;= 0); int ret = bind(serv_sock, (struct sockaddr*) &amp;serv_addr, sizeof(serv_addr); //assert(ret != -1 ); ret = listen(serv_sock, 5); //assert(ret != -1 ); struct sockaddr_in clnt_addr; socklen_t clnt_addr_size = sizeof(clnt_addr); int connfd = accept(serv_sock, (struct sockaddr*)&amp;clnt_addr, &amp;clnt_addr_size); assert(connfd&gt;0); printf(&quot;a client has been connected!\\n&quot;); } 1.2 socket选项123456#include &lt;sys/socket.h&gt;int getsockopt(int sockfd, int level, int option_name, void* option_value, socklen_t* restrict option_len); int setsockopt(int sockfd, int level, int option_name, void* option_value, socklen_t* restrict option_len); 二、网络地址信息初始化结构体sockaddr_in以及IP地址转换函数 12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;arpa/inet.h&gt;struct sockaddr_in { sa_family_t sin_family; // 地址族 uint16_t sin_port; // 16 位端口号 struct in_addr sin_addr; // 表示 32 位 IP 地址的结构体 char sin_zero[8]; // 不使用}struct in_addr { in_addr_t s_addr; // 32 位 IP 地址，实际位为 uint32_t 类型}/* 本地字节序与主机字节序的转换 *///short 类型，用于端口号的转换unsigned short htons(unsigned short);unsigned short ntohs(unsigned short);//long 类型，用于 IP 地址的转换unsigned long htonl(unsigned long);unsigned long ntohl(unsigned long);/* IP地址字符串与整数的转换 */in_addr_t inet_addr(const char* string); // 功能：将字符串形式的 IP 地址转换为 32 位整型数据并返回。// 返回值：成功时返回 32 位大端序整型值，失败时返回 INADDR_NONE。int inet_aton(const char* string, struct in_addr* addr); // 功能：将字符串形式的 IP 地址转换为 32 位网络字节序整数并存储到 addr 中。// 返回值：成功时返回 1，失败时返回 0char* inet_ntoa(struct in_addr adr); // 功能：将网络字节序的整数型 IP 地址转换为字符串形式// 返回值：成功时返回转换的字符串地址值，失败时返回 -1/* 更新的IP字符串与整数的转换函数 */int inet_pton(int af, const char* src, void* dst);// 功能：将字符串表示的IP地址src转换成网络字节序整数表示，存入dst内。af表示地址族，AF_INET// 返回值：成功时返回 1，失败时返回 0const char* inet_ntop(int af, const void* src, char* dst, socklen_c cnt);// 与inet_pton功能相反，最后一个参数cnt表示目标存储单元的大小// 返回值：成功时返回 1，失败时返回 0 2.1套接字创建过程中常见的网络地址信息初始化方法：步骤： 声明一个sockaddr_in（用于IPV4） 将struct全部置为0 sin_family Sin_addr.s_addr （将点分十进制IP转为32位整数） Sin_port （将字符串转为整数，并转为大端序） 12345678910111213141516171819202122#include &lt;arpa/inet.h&gt;#include &lt;string.h&gt;#include &lt;stdlib.h&gt;char *ip = &quot;192.168.0.109&quot;; // 声明 IP 地址字符串char *port = &quot;9190&quot;; // 声明端口号字符串// 步骤1struct sockaddr_in addr;// 步骤2memset(&amp;addr, 0, sizeof(addr)); // memset #include&lt;string.h&gt;//bzero(&amp;addr, sizeof(addr)); //bzero #include&lt;string.h&gt;//步骤3addr.sin_family = AF_INET; //步骤4addr.sin_addr.s_addr = inet_addr(ip); //inet_pton(AF_INET, ip, &amp;addr.sin_addr); // 随IPv6出现的函数,//addr.sin_addr.s_addr = htonl(INADDR_ANY); //自动获取服务端IP地址//步骤5addr.sin_port = htons(atoi(port)); //atoi #include &lt;stdlib.h&gt; 三、基础IO函数12345678#include &lt;sys/types.h&gt; //for size_t, pid_t etc#include &lt;sys.stat.h&gt;#include &lt;fcntl.h&gt; int open(const char *path, int flag); // 功能：按 flag 指定的模式打开文件。// 参数：path：文件名的地址；// flag：文件打开的模式。// 返回值：成功时返回文件描述符，失败时返回 -1 注意包含的头文件区别 123456789101112131415#include&lt;unistd.h&gt; int close(int fd);// 功能：关闭 fd 对应的文件或套接字。当关闭一个套接字时会向对方发送 EOF。// 参数：fd：文件或套接字的文件描述符。// 返回值：成功时返回 0，失败时返回 -1ssize_t read(int fd, void* buf, size_t nbytes); // 功能：从文件 fd 读取数据。read 函数会阻塞，直到读取到数据或 EOF 才返回。// 参数：fd：文件描述符；buf：保存要接收的数据；nbytes：要接收的最大字节数。// 返回值：成功时返回接收的字节数（遇到文件尾则返回 0），失败时返回 -1 ssize_t write(int fd, const void* buf, size_t nbytes);// 功能：向文件 fd 输出数据。// 参数：fd：文件描述符；buf：要传输的数据；nbytes：要传输的字节数。// 返回值：成功时返回写入的字节数，失败时返回 -1 sock编程接口提供了几个专门用于socket数据读写的系统调用，它们增加了对数据读写的控制，比如传输带外数据。 123456#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;ssize_t recv(int sockfd, void* f, size_t len, int flags);//成功返回实际读写数据的长度，出错返回-1，返回0代表通信对方关闭连接。ssize_t send(int sockfd, const void* buf, size_t len, int flags);//buf是读缓冲区。失败返回-1 四、IO复用基础函数4.1 EPOLL函数三步走，注册内核事件表-&gt;向事件表中添加要监听的文件描述符-&gt;调用epoll_wait监听 123456789101112131415161718192021#include &lt;sys/epoll.h&gt;int epoll_create(int size);// 功能：申请 size 大小的 epoll 内核事件表// 参数：size：申请的 epoll 例程的大小// 返回值：成功时返回 epoll 文件描述符，失败时返回 -1。int epoll_ctl(int epfd, int op, int fd, struct epoll_event* event);// 功能：在 epoll 例程内部注册要监视的文件描述符// 参数：epfd：epoll 例程的文件描述符；// op：指定监视对象的添加、删除或更改等操作。EPOLL_CTL_ADD||EPOLL_CTL_DEL// fd：需要注册的监视对象文件描述符。// event：监视对象的事件类型 EPOLLIN|EPOLLET// 返回值：成功时返回 0，失败时返回 -1int epoll_wait(int epfd, struct epoll_event* events, int maxevents, int timeout);// 功能：监视发生事件的文件描述符// 参数：epfd：epoll 例程的文件描述符；// events：保存发生事件的文件描述符集合的结构体地址；// maxevents：最多监听的事件数，必须大于 0；// timeout：超时时间，以 ms 为单位。如果为 -1，则一直等待到事件发生。// 返回值：成功时返回发生事件的文件描述符数量，失败时返回 -1。 其中涉及的epoll_event结构体 123456789101112struct epoll_event{ __uint32_t events; epoll_data_t data;}typedef union epoll_data // 注意：epoll_data 是一个联合不是结构体{ void* ptr; int fd; __uint32_t u32; __uint64_t u64; }epoll_data_t; 4.1.1 epoll的常规用法12345678910111213141516171819202122#include &lt;sys/epoll.h&gt;#define MAX_EVENT_NUMBER 1024epoll_event events[MAX_EVENT_NUMBER]; //保存监听结果int epollfd = epoll_create(5);assert(epollfd!=-1);/*add socket to epollfd*/epoll_event event;event.data.fd = socket;event.events = EPOLLIN;epoll_ctl(epollfd, EPOLL_CTL_ADD, socket, &amp;events);/*监听返回结果*/int ret = epoll_wait(epollfd, events, MAX_EVENT_NUMBER, -1); //-1表示阻塞调用，直到事件发生int i;for(i=0; i&lt;ret; i++){ int sockfd = events[i].data.fd; /*直接对就绪的sockfd进行处理*/} 4.2 POLL函数用法poll函数与select函数相似，也是指定时间轮询一定数量的文件描述符。 123456789101112#include &lt;poll.h&gt;int poll(struct pollfd* fds, nfds_t nfds, int timeout);//返回值：成功返回就绪的文件描述符的总数，失败返回-1//timeout参数以毫秒为单位，若为-1则阻塞调用直至事件发生struct pollfd{ int fd; short events; //注册的事件 POLLIN|POLLRDHUP short revents; //实际发生的事件，由内核填充}typedef unsigned long int nfds_t; 4.2.1 poll的常规用法12345678910111213141516171819202122232425#include &lt;poll.h&gt;#define MAX_EVENT_NUMBER 64pollfd fds[MAX_EVENT_NUMBER];fds[0].fd = sockfd;fds[0].events = POLLIN;fds[0].revents = 0;fds[1].fd = sockfd2;fds[1].events = POLLIN;fds[1].revents = 0;//....until MAX_EVENT_NUMBER/*调用poll监听*/int ret = poll(fds, MAX_EVENT_NUMBER, -1); //阻塞调用int i;for(i=0; i&lt;MAX_EVENT_NUMBER; i++) //必须遍历所有文件描述符找到就绪者{ if(fds[i].revents &amp; EPOLLIN) { int sockfd = fds[i].fd; /*处理sockfd上的时间*/ }} 五、高级IO函数5.1 pipe函数创建管道 1234#include &lt;unistd.h&gt;int pipe(int fd[2]);//功能：创建管道，fd[1]是写端，fd[0]是读端//返回值：成功返回0，失败返回-1 创建双向管道 1int sockpair（） 5.2 spilice函数splice函数用于在两个文件描述符间移动数据，零拷贝操作（CPU不需要先将数据从某处内存复制到另一个特定区域）。 1234567#include &lt;fcntl.h&gt;ssize_t splice(int fd_in, loff_t* off_in, int fd_out, loff_t* off_out, size_t len, unsigned int flags);//功能：从fd_in移动数据到fd_out，移动数据的长度是len//参数：off_in 是输入数据流的偏移，flags控制数据的移动//flags：SPLICE_F_MOVE|SPLICE_F_MORE//返回值：成功返回移动的字节数量，失败返回-1并设置errno 注意：splice函数中的两个文件描述符必须有一个是管道文件描述符。 当文件描述符为管道文件描述符时，偏移量必须设置为NULL。 5.3 fcntl函数fcntl函数提供了对文件描述符的各种控制操作。 1234#include &lt;fcntl.h&gt;int fcntl(int fd, int cmd, ...);//该函数时可变参数。//cmd常见F_GETFL, F_SETFL 常用来设置非阻塞套接字。 123456int setnonblocking(int fd){ int old_option = fcntl(fd, F_GETFL); int new_option = old_option|O_NONBLOCK; fcntl(fd, F_SETFL, new_option); return old_option;} 六、线程相关函数6.1 线程6.1.1 线程创建12345678#include &lt;pthread.h&gt;int pthread_create(pthread_t* restrict thread, const pthread_attr_t* restrict attr, void*(* start_routine)(void *), void* restrict arg);// 功能：创建线程并设置该线程的入口函数，然后运行该线程。// 参数：thread：用于保存新创建的线程 ID；// attr：用于传递线程属性，为 NULL 时创建默认属性的线程；// start_routine：相当于线程的 main 函数； arg：传递 start_routine 函数的参数信息。// 返回值：成功时返回 0，失败时返回其他值。 restrict 是 C99 引入的一种类型限定符，它告诉编译器，对象已经被指针所引用，不能通过除该指针外所有其他直接或间接的方式修改该对象的内容。 6.1.2 线程销毁123456#include &lt;pthread.h&gt;int pthread_join(pthread_t thread, void** status);// 功能：等待线程 thread 的终止，并获取线程 main 函数的返回值。// 参数：thread：要等待的线程 ID；// status：用于保存线程的 main 函数返回值的指针变量的地址值。// 返回值：成功时返回 0，失败时返回其他值。 注意：pthread_join会阻塞主函数，直到子线程结束。 12345#include &lt;pthread.h&gt;int pthread_detach(pthread_t thread);// 功能：分离线程，将线程的状态转换为 unjoinable 状态。// 参数：thread：需要分离的线程 ID；// 返回值：成功时返回 0，失败时返回其他值。 == pthread_detach与join区别？== 销毁线程的两种方法 Linux 并不会自动销毁由线程创建的内存空间，要使用如下两种方法来明确销毁线程： 调用 pthread_join 函数。此函数不仅会等待指定的线程终止，还会引导线程销毁。 调用 pthread_detach 函数。此函数会将主线程与指定的子线程分离，分离后的子线程执行结束时，资源会自动回收。 理解：pthread 有 joinable 和 unjoinable 两种状态： joinable 状态：默认状态。当线程函数执行结束时或 pthread_exit 时不会释放线程所占用堆栈和线程描述符等资源。只有当调用了 pthread_join 之后这些资源才会被释放。 unjoinable 状态：线程占用的资源会在线程函数退出时或 pthread_exit 时自动释放。pthread_detach() 函数就是分离线程，即将线程状态转换为 unjoinable 状态，以保证资源的释放。 此外 unjoinable 属性也可以在 pthread_create 时指定。 6.2 线程同步6.2.1 互斥锁123456789101112131415161718#include &lt;pthread.h&gt;int pthread_mutex_init(pthread_mutex_t* mutex, const pthread_mutexattr_t* attr);// 功能：创建互斥量。// 参数：mutex：用于保存操作系统创建的互斥量；// attr：设置即将创建的互斥量属性，不需要指定属性时设为 NULL。// 返回值：成功时返回 0，失败时返回其他值。int pthread_mutex_destory(pthread_mutex_t* mutex);// 功能：销毁互斥量。// 参数：mutex：保存将要销毁的互斥量；// 返回值：成功时返回 0，失败时返回其他值。int pthread_mutex_lock(pthread_mutex_t* mutex); // 功能：加锁；返回值：成功时返回 0，失败时返回其他值。int pthread_mutex_unlock(pthread_mutex_t* mutex); // 功能：解锁；返回值：成功时返回 0，失败时返回其他值。 6.2.2 信号量123456789101112131415161718#include &lt;semaphore.h&gt;int sem_init(sem_t* sem, int pshared, unsigned int value);// 功能：创建信号量// 参数：sem：用于保存创建的信号量；// pshared：取 0 时，创建只允许一个进程内部使用的信号量，取其他值时，创建可由多个进程共享的信号量；// value：要创建的信号量的初始值；// 返回值：成功时返回 0，失败时返回其他值。int sem_destory(sem_t* sem);// 功能：销毁信号量// 参数：sem：保存将要销毁的信号量；// 返回值：成功时返回 0，失败时返回其他值。int sem_wait(sem_t* sem); // 功能：将信号量值减 1；返回值：成功时返回 0，失败时返回其他值。int sem_post(sem_t* sem); // 功能：将信号量值加 1；返回值：成功时返回 0，失败时返回其他值。 6.2.3 条件变量xx 七、进程相关函数xx 八、信号处理目标进程在收到一个信号时，需要定义一个信号处理函数，原型如下 123#include &lt;signal.h&gt;typedef void (*__sighandler_t) (int);//信号处理函数__sighandler_t只有一个整形参数 Linux可用信号定义在 bits/signum.h头文件中，常用的信号有 SIGINT：输入CTRL+C SIGALARM SIGPIPE：向读端被关闭的管道写数据或socket连接中写数据 SIGCHLD：子进程终止 SIGTERM SIGURG：socket收到紧急数据 SIGIO 8.1 信号函数为一个信号设置处理函数，可以利用以下的系统调用： 123456#include &lt;signal.h&gt;_sighandler_t signal (int sig, _sighandler_t _handler);// 功能：为信号sig注册处理函数_handler// 参数：sig为信号，_handler为函数指针// 返回值：前一次调用signal的传入的函数指针，第一次调用时返回默认的函数处理指针SIG_DEF// 出错返回SIG_ERR，设置errno 或者更robust的系统调用： 1234567891011121314151617181920#include &lt;signal.h&gt;int sigaction(int sig, const struct sigaction* act, struct sigaction* oact);// 功能：为信号sig注册处理动作act// 参数：sig为信号，act为新的信号处理方式，oact为旧的信号处理函数// 返回值：成功时返回0，失败时返回-1/*同名结构体sigaciton定义如下*/struct sigaction{ _sighandler_t sa_handler; _sigset_t sa_mask; int sa_flags;};// 该结构体中sa_handler设置信号处理函数// sa_mask设置信号屏蔽的掩码// sa_flag设置程序收到信号时的行为int sigfillset(sigset_t * set);// sigfillset()用来将参数set信号集初始化，然后把所有的信号加入到此信号集里// 即将所有的信号标志位置为1// 返回值 执行成功则返回0，如果有错误则返回-1。 8.2 统一事件源将信号和IO统一处理，统一监听。典型的处理方案： 信号处理函数收到信号时，仅将信号传递给主循环 主循环统一监听套接字，判断为信号时再处理 如何将信号传递给主循环呢？ 利用管道：信号处理函数往管道写端写入信号值，主循环监听管道读端。","link":"/2023/02/05/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8BAPI%E9%80%9F%E8%A7%88/"},{"title":"网络编程学习笔记","text":"多年前写的笔记，同步上传下。 一、网络编程速览网络编程就是编写程序使两台连网计算机互相通信。 1.1 套接字概念套接字就是用于网络通信的操作系统接口。 1.1.1 服务器套接字用到的各函数123456789101112131415161718192021222324#include &lt;sys/socket.h&gt;int socket(int domain, int type, int protocol);// 返回值：成功时返回文件描述符，失败时返回 -1 // 功能：创建套接字。// 参数：domain：采取的协议族，一般为 PF_INET；// type：数据传输方式，一般为 SOCK_STREAM； // protocol：一般设为 0 即可。 int bind(int sockfd, struct sockaddr *myaddr, socklen_t addrlen);// 返回值：成功时返回 0，失败时返回 -1 // 功能：为套接字分配地址信息。// 参数：sockfd：要分配地址信息的套接字文件描述符；// myaddr：存有地址信息的结构体变量指针；// addrlen：第二个参数的长度。 int listen(int sockfd, int backlog); // 返回值：成功时返回 0，失败时返回 -1// 功能：将套接字转换为可接收连接的状态。// 参数：sock：希望进入等待连接请求状态的套接字文件描述符；// backlog：连接请求等待队列的长度，最多使 backlog 个连接请求进入队列。 int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);// 返回值：成功时返回创建的套接字文件描述符，失败时返回 -1 // 功能：受理连接请求等待队列中待处理的连接请求。// 参数：sock：服务器套接字的文件描述符；// addr：用于保存发起连接请求的客户端地址信息；// addrlen：第二个参数的长度。 接受连接请求的服务器端套接字编程流程： 调用 socket 函数创建套接字； 调用 bind 函数为套接字分配 IP 地址与端口号； 调用 listen 函数将套接字转换为可接收状态； 调用 accept 函数受理连接请求。accept 会阻塞，直到有连接请求才会返回； 调用 read/write 函数进行数据交换； 调用 close 函数断开连接； 1.1.2 客户端用到的各函数客户端程序只需：1）调用socket函数创建套接字；2）调用connetc函数向服务端发送连接请求。 1234567#include &lt;sys/socket.h&gt;int connect(int sockfd, struct sockaddr *serv_addr, socklen_t addrlen);// 返回值：成功时返回 0，失败时返回 -1// 功能：请求连接。// 参数：sock：客户端套接字的文件描述符；// serv_addr：保存目标服务器端地址信息的结构体指针；// addrlen：第二个参数的长度（单位是字节） 客户端请求连接步骤： 调用 socket 函数创建套接字； 调用 connect 函数请求连接； 调用 read/write 函数进行数据交换； 调用 close 函数断开连接； 客户端的 IP 地址和端口在调用 connect 函数时自动分配，无需调用 bind 函数。 1.2 服务器端和客户端（1）下面展示一个简单的服务端代码，该服务端收到客户端发起的连接请求后向请求者返回“hello world！”。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// hello_server.c#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;sys/socket.h&gt;void error_handling(char *message);int main(int argc, char *argv[]){ int serv_sock; int clnt_sock; struct sockaddr_in serv_addr; struct sockaddr_in clnt_addr; socklen_t clnt_addr_size; char message[]=&quot;Hello World!&quot;; if(argc!=2){ printf(&quot;Usage : %s &lt;port&gt;\\n&quot;, argv[0]); exit(1); } serv_sock=socket(PF_INET, SOCK_STREAM, 0); //调用socket函数创建套接字 if(serv_sock == -1) error_handling(&quot;socket() error&quot;); memset(&amp;serv_addr, 0, sizeof(serv_addr)); serv_addr.sin_family=AF_INET; serv_addr.sin_addr.s_addr=htonl(INADDR_ANY); serv_addr.sin_port=htons(atoi(argv[1])); if(bind(serv_sock, (struct sockaddr*) &amp;serv_addr, sizeof(serv_addr))==-1 ) //bind函数分配IP地址和端口号 error_handling(&quot;bind() error&quot;); if(listen(serv_sock, 5)==-1) //listen函数将套接字转为可接收请求状态 error_handling(&quot;listen() error&quot;); clnt_addr_size=sizeof(clnt_addr); clnt_sock=accept(serv_sock, (struct sockaddr*)&amp;clnt_addr,&amp;clnt_addr_size); //accept函数接受请求 if(clnt_sock==-1) error_handling(&quot;accept() error&quot;); write(clnt_sock, message, sizeof(message)); //传输数据 close(clnt_sock); close(serv_sock); return 0;}void error_handling(char *message){ fputs(message, stderr); fputc('\\n', stderr); exit(1);} （2）客户端代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// hello_client.c#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;sys/socket.h&gt;void error_handling(char *message);int main(int argc, char* argv[]){ int sock; struct sockaddr_in serv_addr; char message[30]; int str_len; if(argc!=3){ printf(&quot;Usage : %s &lt;IP&gt; &lt;port&gt;\\n&quot;, argv[0]); exit(1); } sock=socket(PF_INET, SOCK_STREAM, 0); //调用socket函数创建套接字 if(sock == -1) error_handling(&quot;socket() error&quot;); memset(&amp;serv_addr, 0, sizeof(serv_addr)); serv_addr.sin_family=AF_INET; serv_addr.sin_addr.s_addr=inet_addr(argv[1]); serv_addr.sin_port=htons(atoi(argv[2])); if(connect(sock, (struct sockaddr*)&amp;serv_addr, sizeof(serv_addr))==-1) //调用connetc函数向服务端发送连接请求 error_handling(&quot;connect() error!&quot;); str_len=read(sock, message, sizeof(message)-1); if(str_len==-1) error_handling(&quot;read() error!&quot;); printf(&quot;Message from server: %s \\n&quot;, message); close(sock); return 0;}void error_handling(char *message){ fputs(message, stderr); fputc('\\n', stderr); exit(1);} 1.3 在Linux下运行linux下C语言编译器-gcc； gcc hello_server.c -o hserver 这句命令编译hello_server.c并生成名字为hserver的可执行文件， -o 为指定可执行文件名的可选参数。 （1）打开一个终端，运行服务端，$ 是命令行模式行下的命令提示符。 12$ gcc hello_server.c -o hserver$ ./hserver 9190 此时程序将停留在此状态，等待客户端的请求 （2）打开另外一个终端 123$ gcc hello_client.c -o hclient$ ./hclient 127.0.0.1 9190Message from server: Hello World! 1.4 Linux文件操作linux下万物皆为文件。socket也被认为是文件，因此可以使用文件I/O的相关函数。通过套接字发送、接收数据就和读写文件一样，通过 read、write 这些函数来接收、发送数据。 文件描述符是操作系统分配给文件或套接字的整数。 0、1、2 分别由系统分配给了标准输入、标准输出和标准错误。 文件和套接字创建时才会被分配文件描述符。它们的文件描述符会从 3 开始按序递增。 Windows 系统中术语”句柄“和 Linux 中的文件描述符含义相同。 12345678910111213141516171819202122#include&lt;fcntl.h&gt; #include&lt;unistd.h&gt;// fcntl.h 和 unistd.h 包含的内容有些相似，包括 open 函数等。//总之使用文件函数时将 fcntl.h 和 unistd.h 都 include 就可以了int open(const char *path, int flag);// 返回值：成功时返回文件描述符，失败时返回 -1 // 功能：按 flag 指定的模式打开文件。// 参数：path：文件名的地址；// flag：文件打开的模式。 int close(int fd);// 返回值：成功时返回 0，失败时返回 -1// 功能：关闭 fd 对应的文件或套接字。当关闭一个套接字时会向对方发送 EOF。// 参数：fd：文件或套接字的文件描述符。ssize_t read(int fd, void* buf, size_t nbytes); // 返回值：成功时返回接收的字节数（遇到文件尾则返回 0），失败时返回 -1 // 功能：从文件 fd 读取数据。read 函数会阻塞，直到读取到数据或 EOF 才返回。// 参数：fd：文件描述符；buf：保存要接收的数据；nbytes：要接收的最大字节数。ssize_t write(int fd, const void* buf, size_t nbytes);// 返回值：成功时返回写入的字节数，失败时返回 -1 // 功能：向文件 fd 输出数据。// 参数：fd：文件描述符；buf：要传输的数据；nbytes：要传输的字节数。 文件打开模式： 以_t为后缀的数据类型，这些都是元数据类型，由操作系统定义。 一般在sys/types.h 头文件中由typedef声明定义。 size_t 的类型是 unsigned int，ssize_t 的类型是 signed int。 二、套接字类型与协议设置协议就是对话中的通信规则。 2.1 套接字创建函数回顾创建套接字的函数 1234int socket(int domain, int type, int protocol);//成功时返回文件描述符，失败时返回 -1 // domain：采取的协议族，一般为 PF_INET；// type：数据传输方式，一般为 SOCK_STREAM；// protocol：使用的协议，一般设为 0。 创建套接字的函数 socket 的三个参数的含义： domain：使用的协议族。一般只会用到 PF_INET，即 IPv4 协议族。 type：套接字类型，即套接字的数据传输方式。主要是两种：SOCK_STREAM（即 TCP）和 SOCK_DGRAM（即 UDP）。 protocol：选择的协议。一般情况前两个参数确定后，protocol 也就确定了，所以设为 0 即可。 （1）domain参数可选的协议族： （2）type参数 同一个协议族可能有多种数据传输方式，因此在指定了 socket 的第一个参数后，还要指定第二个参数 type，即套接字的传输方式。 最主要的两种方式分别是TCP和UDP。 1234int tcp_socket = socket(PF_INET, SOCK_STREAM, 0);// **SOCK_STREAM** 代表的是 TCP 协议，会创建面向连接的套接字int udp_socket = socket(PF_INET, SOCK_DGRAM, 0);// **SOCK_DGRAM** 代表的是 UDP 协议，会创建面向消息的套接字 （3）protocol参数 这个参数代表协议的最终选择。 有这么一种情况：同一协议族中存在多个数据传输方式相同的协议，所以还需要第三个参数 protocol 来指定具体协议。但是 PF_INET（IPv4 协议族）下的 SOCK_STREAM 传输方式只对应 IPPROTO_TCP 一种协议，SOCK_DGRAM 传输方式也只对应 IPPROTO_UDP 一种协议，所以参数 protocol 只要设为 0 即可。 12int tcp_socket = socket(PF_INET, SOCK_STREAM, 0);int tcp_socket = socket(PF_INET, SOCK_STREAM, IPPROTO_TCP); // 和上面效果一样 三、地址族与数据序列基础知识： IPv4 地址为 4 字节，IPv6 是 16 字节地址族。 端口号 2 字节，范围是 065535。其中 **01023 是熟知端口号**。 3.1 地址信息的表示套接字创建后，我们还需要为它绑定IP地址和端口号。回忆绑定地址的函数： 1int bind(int sockfd, struct sockaddr *myaddr, socklen_t addrlen);// 返回值：成功时返回 0，失败时返回 -1 IP和端口的信息就存在这个结构体sockaddr中。但是这个结构体是通用的设计（考虑到了IPV4和IPV6），IPV4有特定的结构体。 通常使用时将结构体强制类型转换即可。 123struct sockaddr_in serv_addr;if(bind(serv_sock, (struct sockaddr*)&amp;serv_addr, sizeof(serv_addr)) == -1) error_handling(&quot;bind() error&quot;); 3.1.1 通用地址结构体 sockaddrsockaddr 结构体定义如下，它是通用的结构体，并非只为 IPv4 设计。 12345#include &lt;sys/socket.h&gt;struct sockaddr { sa_family_t sin_family; // 地址族 char sa_data[14]; // 地址信息} 3.2.2 IPv4地址结构体sockaddr_in sockaddr_in 是保存 IPv4 地址信息的结构体。除了保存端口号外，还用了一个结构体来存储IP号。 可以看到它和sockaddr一样开头是sin family，并且结构体长度一致，这样才能强制类型转换。 1234567#include &lt;arpa/inet.h&gt;struct sockaddr_in { sa_family_t sin_family; // 地址族 uint16_t sin_port; // 16 位端口号 struct in_addr sin_addr; // 表示 32 位 IP 地址的结构体 char sin_zero[8]; // 不使用} in_addr （用于表示 IP 地址）定义如下：（ 1234#include &lt;arpa/inet.h&gt;struct in_addr { in_addr_t s_addr; // 32 位 IP 地址，实际位为 uint32_t 类型} sockaddr_in结构体成员分析： sin_family 地址族 这个代表地址族，不同协议使用的地址族不同。回忆在创建socket时，使用到了domain这个参数，就用了PF_INET(IPv4 协议族)， PF_INET(IPv4 协议族) 对应的地址族是 **AF_INET( IPv4 地址族)**。 sin_port 端口号 ​ 以网络字节序保存 16 位端口号。后面会讲解网络字节序（大端序） sin_addr IP号 类型为结构体 in_addr，in_addr 的成员 s_addr 按网络字节序保存 32 位 IP 地址。 sin_zero 填充字段 无特殊含义。只是为了使结构体 sockaddr_in 的大小与 sockaddr 结构体一致而插入的成员，必须填充为 0。 3.2 网络字节序3.2.1 字节序CPU 向内存保存数据的方式有两种： 大端序：高位字节存放到低位地址。网络字节序为大端序。 小端序：高位字节存放到高位地址。目前主流的 Intel 系列 CPU 按小端序方式保存数据。 在使用网络发送数据时统一约定要先把数据转化成大端序，接收时也要先转换为主机字节序。 3.2.2 字节序转换函数接下来介绍一些帮助转换字节序的函数 1234567#include &lt;arpa/inet.h&gt;//short 类型，用于端口号的转换unsigned short htons(unsigned short);unsigned short ntohs(unsigned short);//long 类型，用于 IP 地址的转换unsigned long htonl(unsigned long);unsigned long ntohl(unsigned long); htons 中的 h 代表主机字节序，n 代表网络字节序。（主机字节序向网络字节序转换） s 代表 short 类型，处理 2 字节数据，用于端口号转换；l 代表 long 类型（Linux 中 long 占用 4 字节），处理 4 字节数据，用于 IP 地址转换。 除了向 sockaddr_in 结构体变量填充数据时需要进行字节序转换外，其他情况无需考虑字节序问题，会自动转换。 3.3 网络地址的初始化一般我们描述 IP 地址时用的是字符串格式的点分十进制表示法，而sockaddr_in 中保存地址信息的成员是 32 位整型，因此需要将字符串形式的点分十进制 IP 地址转换为 32 位整型数据。 有两个函数可以完成以上功能：inet_addr 函数和 inet_aton 函数。 3.3.1 字符串IP地址转为整数（1）inet_addr 函数 在转换类型的同时也会完成网络字节序的转换，它还可以检测无效的 IP 地址。 1234#include &lt;arpa/inet.h&gt;in_addr_t inet_addr(const char* string); // 功能：将字符串形式的 IP 地址转换为 32 位整型数据并返回。// 返回值：成功时返回 32 位大端序整型值，失败时返回 INADDR_NONE。 （2）inet_aton函数 net_aton 函数和 inet_addr 函数的功能相同，也是将字符串形式的 IP 地址转换为 32 位网络字节序整数，但是它利用了 in_addr 结构体，使用频率更高。 inet_aton 需要传递一个 in_addr 类型结构体的指针，它会将转换结果直接放入该指针所指的 in_addr 结构体中。 1234#include &lt;arpa/inet.h&gt;int inet_aton(const char* string, struct in_addr* addr); // 功能：将字符串形式的 IP 地址转换为 32 位网络字节序整数并存储到 addr 中。// 返回值：成功时返回 1，失败时返回 0 3.3.2 整数型IP地址转为字符串inet_ntoa 函数与 inet_aton 函数相反，它将网络字节序的整数型 IP 地址转换为字符串形式。 1234#include &lt;arpa/inet.h&gt;char* inet_ntoa(struct in_addr adr); // 功能：将网络字节序的整数型 IP 地址转换为字符串形式// 返回值：成功时返回转换的字符串地址值，失败时返回 -1 该函数使用时要小心：返回值类型为 char 指针，返回字符串地址意味着字符串已保存到内存空，但该函数是在内部申请了内存并保存了字符串，因此如果再次调用 inet_ntoa 函数，也有可能覆盖之前保存的字符串信息。 因此要将返回的字符串信息复制到其他内存空间。 3.3.3 常用网络地址初始化操作结合前面所述内容，下面是套接字创建过程中常见的网络地址信息初始化方法： 1234567struct sockaddr_in addr;char *serv_ip = &quot;211.217.168.13&quot;; // 声明 IP 地址字符串char *serv_port = &quot;9190&quot;; // 声明端口号字符串memset(&amp;addr, 0, sizeof(addr)); // 结构体变量 addr 的所有成员初始化为 0，addr.sin_family = AF_INET; // 指定地址族addr.sin_addr.s_addr = inet_addr(serv_ip); // 基于字符串的 IP 地址初始化addr.sin_port = htons(atoi(serv_port)); // 基于字符串的端口号初始化 #include &lt;stdlib.h&gt; 每次创建服务器端套接字都要输入IP地址会很麻烦，可以用常数 INADDR_ANY 自动获取服务器端的 IP 地址。 12addr.sin_addr.s_addr = htonl(INADDR_ANY); // INADDR_ANY 相当于主机字节序的 32 位整型 IP 地址 使用 INADDRY_ANY，如果同一个计算机具有多个 IP 地址，那么可以从不同 IP 地址（的同一端口号）接收数据，因此服务器端中优先使用 INADDR_ANY，而客户端不应该采用。 服务器端和客户端都要进行网络地址信息的初始化，但目的不同： 服务器端要将声明的 sockaddr_in 结构体变量初始化为自己的 IP 地址和端口号，用于在 bind 函数中与自己的套接字相绑定。 客户端也要将声明的 sockaddr_in 结构体变量初始化为服务器端的 IP 地址和端口号，用于在 connect 函数中向服务器发起连接请求。 四、基于TCP的客户端与服务端4.1 理解TCP和UDP自行阅读计算机网络相关知识。 4.2 实现基于TCP的服务器端/客户端基于TCP的服务端/客户端函数调用方式： 前面已经介绍过socket函数和bind函数，下面介绍后面几个过程。 4.2.1 listen函数等待连接请求假设已经调用bind函数为套接字分配地址，接下来就要调用listen函数等待连接请求。只有服务端调用了listen函数后，客户端才能待用connnet函数发起连接请求。 123456#include &lt;sys/socket.h&gt;int listen(int sockfd, int backlog); // 功能：将套接字转换为可接收连接的状态。// 参数：sock：希望进入等待连接请求状态的套接字文件描述符；// backlog：连接请求等待队列的最大长度，最多使 backlog 个连接请求进入队列。// 返回值：成功时返回 0，失败时返回 -1 等待连接请求状态：“服务器处于等待连接请求状态”指让来自客户端的请求处于等待状态。 连接请求等待队列：还未受理的连接请求在此排队，backlog 的大小决定了队列的最大长度，一般频繁接受请求的 Web 服务器的 backlog 至少为 15。 4.2.2 accept函数受理连接请求accept 函数会受理连接请求等待队列中待处理的客户端连接请求，它从等待队列中取出 1 个连接请求，创建套接字并完成连接请求。如果等待队列为空，accpet 函数会阻塞，直到队列中出现新的连接请求才会返回。 1234567#include &lt;sys/socket.h&gt;int accept(int sockfd, struct sockaddr *addr, socklen_t addrlen); / 功能：受理连接请求等待队列中待处理的连接请求。// 参数：sock：服务器套接字的文件描述符；// addr：用于保存发起连接请求的客户端地址信息；// addrlen：第二个参数的长度。// 返回值：成功时返回创建的套接字文件描述符，失败时返回 -1 它会在内部产生一个新的套接字并返回其文件描述符，该套接字用于与客户端建立连接并进行数据 I/O。新的套接字是在 accept 函数内部自动创建的，并自动与发起连接请求的客户端建立连接。 accept 执行完毕后会将它所受理的连接请求对应的客户端地址信息存储到第二个参数 addr 中。 4.2.3 客户端conncet函数发起请求1234567#include &lt;sys/socket.h&gt;int connect(int sockfd, struct sockaddr *serv_addr, socklen_t addrlen); // 功能：请求连接。// 参数：sock：客户端套接字的文件描述符；// serv_addr：保存目标服务器端地址信息的结构体指针；// addrlen：第二个参数serv_addr的长度（单位是字节）// 返回值：成功时返回 0，失败时返回 -1 客户端调用 connect 函数后会阻塞，直到发生以下情况之一才会返回： 服务器端接收连接请求。 发生断网等异常情况而中断连接请求。 注意：上面说的”接收连接请求“并不是服务器端调用了 accept 函数，而是服务器端把连接请求信息记录到等待队列。因此 connect 函数返回后并不立即进行数据交换。 客户端的IP地址和端口在调用connect函数时自动分配，无需调用bind函数进行分配。 再次回顾基于TCP的服务端和客户端函数调用关系： 客户端只有等到服务器端调用 listen 函数后才能调用 connect 函数，否则会连接失败。 客户端调用 connect 函数和服务器端调用 accept 函数的顺序不确定，先调用的要等待另一方。 4.3 实现迭代回声服务端/客户端回声服务器端：它会将客户端传输的字符串数据原封不动地传回客户端，像回声一样。 4.3.1 实现迭代服务器端调用一次 accept 函数只会受理一个连接请求，如果想要继续受理请求，最简单的方法就是循环反复调用 accept 函数，在前一个连接 close 之后，重新 accept。在不使用多进程/多线程情况下，同一时间只能服务于一个客户端。 迭代回声服务器端与回声客户端的基本运行方式： 服务器端同一时刻只与一个客户端相连接，并提供回声服务。 服务器端依次向 5 个客户端提供服务，然后退出。 客户端接收用户输入的字符串并发送到服务器端。 服务器端将接收到的字符串数据传回客户端，即”回声“。 服务器端与客户端之间的字符串回声一直执行到客户端输入 Q 为止。 1//code 4.3.2 回声客户端存在的问题在本章的回声客户端的实现中有下面这段代码，它有一个错误假设：每次调用 read、write 函数时都会执行实际的 I/O 操作。 12write(sock, message, strlen(message));str_len = read(sock, message, BUF_SIZE - 1); 但是注意：TCP 是面向连接的字节流传输，不存在数据边界。所以多次 write 的内容可能一直存放在发送缓存中，某个时刻再一次性全都传递到服务器端，这样的话客户端前几次 read 都不会读取到内容，最后才会一次性收到前面多次 write 的内容。还有一种情况是服务器端收到的数据太大，只能将其分成多个数据包发送给客户端，然后客户端可能在尚未收到全部数据包时旧调用 read 函数。 理解：问题的核心在于 write 函数实际上是把数据写到了发送缓存中，而 read 函数是从接收缓存读取数据。并不是直接对 TCP 连接的另一方进行数据读写。 解决方式见下一章 4.4 回声客户端的完美实现回顾服务端的实现代码： 12while((str_len = read(clnt_sock, message, BUF_SIZE)) != 0) write(clnt_sock, message, str_len); 循环调用read函数，当read函数读成功或失败时，继续读，直至文件尾标志。这是没有问题的。 回顾客户端的代码： 12write(sock, message, strlen(message));str_len = read(sock, message, BUF_SIZE - 1); 回声客户端的问题实际上就是没有考虑拆包和粘包的情况。 4.4.1 回声客户端的解决办法解决方法的核心：提前确定接收数据的大小。 客户端上一次使用 write 从套接字发送了多少字节，紧接着就使用 read 从套接字读取多少字节。 123456789str_len=write(sock, message, strlen(message)); //发送的数据长度recv_len=0; //收到的数据长度while(recv_len&lt;str_len){ recv_cnt=read(sock, &amp;message[recv_len], BUF_SIZE-1); if(recv_cnt==-1) error_handling(&quot;read() error!&quot;); recv_len+=recv_cnt;} 4.4.2 问题的另一视角：应用层协议上面的回声客户端中，假设提前就知道接收数据的长度。但是一般情况下是不知道的，这时解决拆包和粘包的问题，就要定义应用层协议。 之前回声服务端和客户端就定义了协议：“收到Q就终止连接” 应用层协议实际就是在服务器端/客户端的实现过程中逐步定义的规则的集合。在应用层协议中可以定好数据边界的表示方法、数据的长度范围等。 4.5 TCP原理4.5.1 TCP套接字中的I/O缓冲在使用 read/write 函数对套接字进行读写数据时，实际上读写的是套接字输入/输出缓冲中的内容。 套接字 I/O 缓冲的特性： I/O 缓冲在每个套接字中单独存在。 I/O 缓冲在创建套接字时自动生成。 即使关闭套接字也会继续传递输出缓冲中遗留的数据。 关闭套接字将丢失输入缓冲中的数据。 五、基于UDP的服务端与客户端5.1 理解UDP区分 TCP 与 UDP 的一个典型比喻：UDP 好比寄信，TCP 好比打电话： UDP：寄信前要在信封上填好寄信人和收信人的地址，然后放进邮筒。不能确认对方是否收到信件，并且邮寄过程中信件可能丢失。 TCP：首先要拨打电话号码，打通后才能开始通话，但打通后的通话是可靠的。 TCP 和 UDP 最重要的区别在于流控制。 理解：这里的流控制应该包含了 TCP 的可靠传输、流量控制、拥塞控制等机制，这些机制都是在流上实现的。 TCP 是可靠的（面向连接）、按序传递、基于字节的 UDP 不可靠、无序 UDP的高效使用 网络实时传输多媒体数据一般使用 UDP。 TCP 比 UDP 慢的两个原因： TCP 数据传输前后要进行连接的建立与释放。 TCP 数据传输过程中为了保证可靠性而添加的流控制。 当收发的数据量小但需要频繁连接时，UDP 的高效体现地更明显。 5.2 实现基于UDP的服务端/客户端因为 UDP 是无连接的，所以在编程时不需要调用 listen 函数和 accept 函数。 UDP 套接字编程中只有创建套接字和数据交换两个过程。 5.2.1 UDP服务器端和客户端均只需 1 个套接字TCP 中，服务器端和客户端的套接字是一对一的关系，服务器端每向一个客户端提供服务，就需要分配一个新的套接字。 而 UDP 的服务器端和客户端均只需 1 个套接字，服务器端只要有一个 UDP 套接字就可以和多台主机通信。 回忆邮筒的例子，收发信件的邮筒可以比喻成UDP套接字。只要有1个邮筒就可以收到任意地址的信件或者发送信件。 5.2.2 发送UDP数据的函数UDP 套接字不会保持连接状态，因此每次传输数据时都要添加目标地址信息（相当于寄信前在信封上写收信地址）。 1234567891011#include &lt;sys/socket.h&gt;ssize_t sendto(int sock, void* buff, size_t nbytes, int flags, struct sockaddr* to, socklen_t addrlen);// 功能：向 to 中所指明的目标地址发送数据。// 参数：sock：UDP 套接字文件描述符;// buff：用户保存接收的数据; // nbytes：可接收的最大字节数; // flags：可选项参数，没有则为 0; // to：包含目标地址信息; // addrlen：包含目标地址信息的结构体变量的长度// 返回值：成功时返回接收的字节数，失败时返回 -1。 上述函数与TCP输出函数最大的区别在于需要传递目标地址信息。 5.2.3 接收UDP数据的函数1234567891011#include &lt;sys/socket.h&gt;ssize_t recvfrom(int sock, void* buff, size_t nbytes, int flags, struct sockaddr* from, socklen_t *addrlen);// 功能：从 from 中所指明的地址接收数据。// 参数：sock：UDP 套接字文件描述符;// buff：待传输的数据; // nbytes：待传输的数据长度（单位是字节）; // flags：可选项参数，没有则为 0; // from：用来存储发送端的地址信息; // addrlen：包含发送端地址信息的结构体变量的长度// 返回值：成功时返回传输的字节数，失败时返回 -1。 接收端本来是不知道发送端的地址的，但调用完 recvfrom 函数后，发送端的地址信息就会存储到参数 from 指向的结构体中。 5.3 基于UDP的回声服务端/客户端5.3.1 服务端代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354//uecho_server.c#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;sys/socket.h&gt;#define BUF_SIZE 30void error_handling(char *message);int main(int argc, char *argv[]){ int serv_sock; char message[BUF_SIZE]; int str_len; socklen_t clnt_adr_sz; struct sockaddr_in serv_adr, clnt_adr; if(argc!=2){ printf(&quot;Usage : %s &lt;port&gt;\\n&quot;, argv[0]); exit(1); } serv_sock=socket(PF_INET, SOCK_DGRAM, 0); if(serv_sock==-1) error_handling(&quot;UDP socket creation error&quot;); memset(&amp;serv_adr, 0, sizeof(serv_adr)); serv_adr.sin_family=AF_INET; serv_adr.sin_addr.s_addr=htonl(INADDR_ANY); serv_adr.sin_port=htons(atoi(argv[1])); if(bind(serv_sock, (struct sockaddr*)&amp;serv_adr, sizeof(serv_adr))==-1) error_handling(&quot;bind() error&quot;); while(1) { clnt_adr_sz=sizeof(clnt_adr); str_len=recvfrom(serv_sock, message, BUF_SIZE, 0, (struct sockaddr*)&amp;clnt_adr, &amp;clnt_adr_sz); sendto(serv_sock, message, str_len, 0, (struct sockaddr*)&amp;clnt_adr, clnt_adr_sz); } close(serv_sock); return 0;}void error_handling(char *message){ fputs(message, stderr); fputc('\\n', stderr); exit(1);} 5.3.2 客户端代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859//uecho_client.c#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;sys/socket.h&gt;#define BUF_SIZE 30void error_handling(char *message);int main(int argc, char *argv[]){ int sock; char message[BUF_SIZE]; int str_len; socklen_t adr_sz; struct sockaddr_in serv_adr, from_adr; if(argc!=3){ printf(&quot;Usage : %s &lt;IP&gt; &lt;port&gt;\\n&quot;, argv[0]); exit(1); } sock=socket(PF_INET, SOCK_DGRAM, 0); if(sock==-1) error_handling(&quot;socket() error&quot;); memset(&amp;serv_adr, 0, sizeof(serv_adr)); serv_adr.sin_family=AF_INET; serv_adr.sin_addr.s_addr=inet_addr(argv[1]); serv_adr.sin_port=htons(atoi(argv[2])); while(1) { fputs(&quot;Insert message(q to quit): &quot;, stdout); fgets(message, sizeof(message), stdin); if(!strcmp(message,&quot;q\\n&quot;) || !strcmp(message,&quot;Q\\n&quot;)) break; sendto(sock, message, strlen(message), 0, (struct sockaddr*)&amp;serv_adr, sizeof(serv_adr)); adr_sz=sizeof(from_adr); str_len=recvfrom(sock, message, BUF_SIZE, 0, (struct sockaddr*)&amp;from_adr, &amp;adr_sz); message[str_len]=0; printf(&quot;Message from server: %s&quot;, message); } close(sock); return 0;}void error_handling(char *message){ fputs(message, stderr); fputc('\\n', stderr); exit(1);} 5.3.3 进一步理解问题：TCP客户端套接字在调用connect函数时会自动分配IP地址和端口号，那么UDP客户端何时分配IP地址和端口号？ 回答：UDP 中 sendto 函数来完成此功能。如果调用 sendto 函数时发现尚未给套接字分配地址信息，就会在首次调用 sendto 函数时给套接字分配 IP 地址和端口。 5.4 UDP的数据传输特性5.4.1 数据边界UDP数据传输中存在数据边界，UDP 套接字编程时，接收端输入函数的调用次数必须和发送端输出函数的调用次数相同，这样才能接收完发送端发送的数据。 5.4.2 连接的UDP套接字通过 sendto 函数传输数据的过程包括三个阶段： 向 UDP 套接字注册目标 IP 和端口号；（注意：是将 UDP 套接字与目标的地址信息相关联，不是给 UDP 分配地址信息。前者每次 sendto 都会执行，后者只有首次调用且套接字尚未分配地址时才会执行一次）。 传输数据； 删除 UDP 套接字中注册的目标地址信息。 当多次通过 sendto 向同一个目标发送信息时，每次 sendto 都进行上面的步骤 1 和 3，就会很浪费时间。因此当要长时间与同一主机通信时，将 UDP 变为已连接套接字（注册了目标地址的套接字）会提高效率。 利用connect函数注册地址，并不意味着与对方UDP套接字连接。 1connect(sock, (struct sockaddr*)&amp;adr, sizeof(adr)); // 注意：adr 是目标的地址信息 使用已连接的 UDP 套接字进行通信时， sendto 函数就不会再执行步骤 1 和步骤 3，每次只要传输数据即可。 并且已连接的 UDP 套接字也可以通过 write、read 函数进行通信。 1//code 六、优雅地断开套接字6.1 基于TCP的半关闭TCP 的断开连接过程比建立连接过程更重要，因为断开过程更有可能出现意外情况。 Linux 的 close 函数和 Windows 的 closesocket 函数都意味着完全断开连接。完全断开不仅无法发送也无法接收数据。在某些情况下，通信一方完全断开连接就显得很不优雅。 6.1.1 套接字和流建立 TCP 套接字连接后可交换数据的状态可以看成一种流。进行双向通信就需要两个流，输入流和输出流。调用close 将会同时断开两个流。 有一种方法是断开一部分连接：只断开输入流或输出流。shutdown 函数用于只断开其中一个流。 12345#include &lt;sys/socket.h&gt;int shutdown(int sock, int howto);// 功能：半关闭套接字// 参数：sock：需要断开的套接字；howto：断开方式// 返回值：成功时返回 0，失败时返回 -1。 第二个参数 howto 将决定关闭的方式，可取的值如下： SHUT_RD：断开输入流，此后套接字无法接收数据； SHUT_WR：断开输出流，此后套接字无法发送数据； SHUT_RDWR：同时断开 I/O 流。 他们的值按序分别是 0, 1, 2； 为什么需要半关闭？ 一方在发送完所有数据后可以只关闭输出流但保留输入流，这样还可以接收对方的数据。 6.2 半关闭的文件传输程序1234567891011121314151617//file_server.cclnt_sd=accept(serv_sd, (struct sockaddr*)&amp;clnt_adr, &amp;clnt_adr_sz); while(1) { read_cnt=fread((void*)buf, 1, BUF_SIZE, fp);//从文件读取BUF_SIZE长度字符到buf if(read_cnt&lt;BUF_SIZE) { write(clnt_sd, buf, read_cnt); break; } write(clnt_sd, buf, BUF_SIZE); //输出字符 } shutdown(clnt_sd, SHUT_WR); read(clnt_sd, buf, BUF_SIZE); printf(&quot;Message from client: %s \\n&quot;, buf); 12345678910//file_client.c connect(sd, (struct sockaddr*)&amp;serv_adr, sizeof(serv_adr)); while((read_cnt=read(sd, buf, BUF_SIZE ))!=0) fwrite((void*)buf, 1, read_cnt, fp); //写入到文件中 puts(&quot;Received file data&quot;); write(sd, &quot;Thank you&quot;, 10); fclose(fp); close(sd); 七、域名及网络地址7.1 域名系统通常人们很难记住IP地址，但是域名就比较通俗易懂。于是将域名对应一个IP地址。DNS对域名和IP地址进行转换，核心是DNS服务器。 可以通过 ping 命令查看域名对应的 IP 地址。查看本机的默认 DNS 域名服务器地址可以使用 nslookup 命令。 7.2 IP地址和域名之间的转换7.2.1利用域名获取IP地址可以使用以下函数来根据字符串格式的域名获取 IP 地址。 12345#include &lt;netdb.h&gt;struct hostent* gethostbyname(const char* hostname);// 功能：利用域名获取 host 信息，包括绑定的其他域名及所有 IP 地址// 参数：hostname：字符串格式的域名// 返回值：包含 IP 地址信息的结构体的指针 这个函数使用时输入字符串域名，返回装有地址信息的hostent结构体指针。 hostent 结构体的定义如下： 12345678struct hostent{ char* h_name; // 官方域名 char** h_aliases; // 绑定的其他域名，同一IP可能绑定多个域名 int h_addrtype; // 结构体中存储的地址所属的地址族，如果是 IPv4 地址，则此变量为 AF_INET int h_length; // IP 地址的长度，如果是 IPv4 地址，则此变量值为 4 char** h_addr_list;// 地址列表，最重要的成员。以整数形式保存域名对应的 IP 地址（可能有多个）} 调用 gethostbyname 函数后返回的 hostent 结构体的变量结构如下图： 注意：h_addr_list 中存储地址的方式是 char*，而 char* 的内容并不是地址值，实际上是 in_addr 结构体的地址。 因此要取得点分十进制字符串格式的地址，需要先将 char 转换为 in_addr 类型，然后解引用取得整数地址值，再使用 inet_ntoa 将其转换为点分十进制格式的字符串。** 1234host=gethostbyname(argv[1]);for(i=0; host-&gt;h_addr_list[i]; i++) printf(&quot;IP addr %d: %s \\n&quot;, i+1, inet_ntoa(*(struct in_addr*)host-&gt;h_addr_list[i])); 为什么h_addr_list不采用in_addr*类型的数组？ 答：为了通用性，hostent结构体并非只为IPv4准备。 7.2.2 利用IP地址获取域名gethostbyaddr 函数利用 IP 地址获取域名 12345#include &lt;netdb.h&gt;struct hostent* gethostbyaddr(const char* addr, socklen_t len, int family);// 功能：利用 IP 地址获取 host 信息，包括绑定的所有域名及其他 IP 地址// 参数：hostname：字符串格式的域名// 返回值：包含 IP 地址信息的结构体的指针 12addr.sin_addr.s_addr=inet_addr(argv[1]); //inet_addr将字符串形式的IP转化为整数值host=gethostbyaddr((char*)&amp;addr.sin_addr, 4, AF_INET); 八、套接字的多种可选项略 参考 网络编程学习笔记 https://zhuanlan.zhihu.com/p/460399249","link":"/2023/02/05/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"CMake小窥","text":"CMake构建模版 最简单的单级目录123cmake_minimum_required (VERSION 2.6) #版本要求project (Tutorial) #工程名称add_executable(Tutorial tutorial.cpp) #制定生成目标 多级目录头文件和源文件分别存储在include和src中。 123456789101112cmake_minimum_required(VERSION 3.10)project(hello_world)set(CMAKE_CXX_STANDARD 17)# 添加头文件搜索路径include_directories(${PROJECT_SOURCE_DIR}/include)# 添加源文件路径aux_source_directory(${PROJECT_SOURCE_DIR}/src DIR_SRCS)add_executable(Hello ${DIR_SRCS}) 大型项目每个目录下都要有CMakeLists.txt，通过add_subdirectory进行递归构建。 实战：构建gteset进行测验目录结构 123456789101112131415.├── CMakeLists.txt├── build # 用于构建├── code # 代码目录│ ├── CMakeLists.txt # add_subdirectory(source)│ ├── include│ │ └── hello.h│ └── source│ ├── CMakeLists.txt│ └── hello.cpp└── test # 测试代码目录 ├── CMakeLists.txt ├── googletest ├── hello_test.cc └── main.cpp 最外层CMake1234567cmake_minimum_required(VERSION 3.10)project(hello_test)set(CMAKE_CXX_STANDARD 17)add_subdirectory(code)add_subdirectory(test) 没什么好说的，就是添加两个子文件夹内的Cmake。 code目录code目录主要依靠source目录下的CMakeLists。注意这里是构建静态库而不是构建可执行文件，因为我们的可执行文件是在test目录下构建的。 123456# 添加头文件路径include_directories(${CMAKE_CURRENT_SOURCE_DIR}/../include)# 添加源文件aux_source_directory(. src_list)# 构建静态库add_library(hello ${src_list}) test目录我们的目的是测试code目录下的代码，main文件为固定的模版，用于启动所有测试；hello_test文件用于测试code目录下的打印hello函数。 12345678910111213141516171819// main.cpp#include &lt;iostream&gt;#include &lt;gtest/gtest.h&gt;using namespace std;int main(int argc, char *argv[]){ testing::InitGoogleTest(&amp;argc, argv); return RUN_ALL_TESTS();}// hello_test.cpp#include &lt;gtest/gtest.h&gt;#include &quot;hello.h&quot;TEST(HelloTest, BasicAssertions) { print_hello(); EXPECT_STRNE(&quot;hello&quot;, &quot;world&quot;); EXPECT_EQ(7 * 6, 42);} googletest目录通过主动构建形成。 12345git clone https://github.com/google/googletest.git -b v1.15.2cd googletest # Main directory of the cloned repository.mkdir build # Create a directory to hold the build output.cd buildcmake .. # Generate native build scripts for GoogleTest. 那么CMake该怎么写呢？ 123456789101112# 添加头文件include_directories(${CMAKE_CURRENT_SOURCE_DIR}/../code/include)# 添加googleTest的cmake，EXCLUDE_FROM_ALL指示make不要构建googletest目录下的内容（前面已经构建过了）add_subdirectory(googletest EXCLUDE_FROM_ALL)# 添加源文件aux_source_directory(. exe_src)# 设置输出路径（重要，否则将找不到可执行文件）set(EXECUTABLE_OUTPUT_PATH ${CMAKE_SOURCE_DIR}/build)# 链接库add_executable(helloTest ${exe_src})target_link_libraries(helloTest gtest)target_link_libraries(helloTest hello) 执行123$ cd build &amp;&amp; camke ..$ make$ ./helloTest 输出，可以看到中间打印了hello。 1234567891011[==========] Running 1 test from 1 test suite.[----------] Global test environment set-up.[----------] 1 test from HelloTest[ RUN ] HelloTest.BasicAssertionshello[ OK ] HelloTest.BasicAssertions (0 ms)[----------] 1 test from HelloTest (0 ms total)[----------] Global test environment tear-down[==========] 1 test from 1 test suite ran. (0 ms total)[ PASSED ] 1 test.","link":"/2025/01/19/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/CMake%E5%B0%8F%E7%AA%A5/"},{"title":"Makefile学习","text":"多年前初次接触makefile，这里复习下。 https://maxwell-lx.vip/basic-usage-make/ https://zhuanlan.zhihu.com/p/92010728 https://zhuanlan.zhihu.com/p/350297509 Makefile是什么可以理解为一个自动化的编译脚本，避免繁琐的手动编译过程，类似shell脚本。 从小例子入手（1）新建项目文件夹hello，及文件main.cpp，factorial.cpp，printhello.cpp，functions.h。 hello目录的结构如下： 12345hello/├──main.cpp├──factorial.cpp├──printhello.cpp└──functions.h main.cpp 1234567891011121314#define _FUNCTIONS_H_#include &lt;iostream&gt;#include &quot;functions.h&quot;using namespace std;int main(){ printhello(); cout &lt;&lt; &quot;This is main:&quot; &lt;&lt; endl; cout &lt;&lt; &quot;The factorial of 5 is:&quot; &lt;&lt; factorial(5) &lt;&lt; endl; return 0;} printhello.cpp 123456789#include &lt;iostream&gt;#include &quot;functions.h&quot;using namespace std;void printhello(){ int i; cout &lt;&lt; &quot;Hello World!&quot; &lt;&lt; endl;} factorial.cpp 123456789#include &quot;functions.h&quot;int factorial(int n){ if (n==1) return 1; else return n * factorial(n-1);} function.h 12345#ifdef _FUNCTIONS_H_#define _FUNCTIONS_H_void printhello();int factorial(int n);#endif （2）那么我们一般手动执行的命令为： 12g++ main.cpp factorial.cpp printhello.cpp -o main./main 这种方法适用于小型项目。对于大型项目来说，此法编译效率低， （3）新建Makefile 12hello: main.cpp printhello.cpp factorial.cpp g++ -o hello main.cpp printhello.cpp factorial.cpp 在命令行上直接运行make命令就能出现hello可执行文件 Makefile解析大致了解一个Makefile对于一个初学者，大概浏览一个makefile： 1、区分前处理/变量处理（根据规则定义或处理参数） 。 2、找到target: 包含了冒号（colon ：）。arget都是顶格抒写的， “ : &lt;***&gt; “ ， target下面的带[tab]缩进的行,就是它包含的命令，找到所有的target。 3、执行target: 一般是实现第一个target，（也可以用make 指定，如make clean，就只执行”clean” 这个target）。 Makefile的语法简单的分为三个部分：目标、依赖、命令 12[目标]: [依赖](tab制表符)[命令] 目标：规则的目标，可以是 Object File（一般称它为中间文件），也可以是可执行文件，还可以是一个标签； 依赖：可以是生成 targets 需要的文件或者是目标。可以是多个，也可以是没有； 命令：make 需要执行的命令（任意的 shell 命令）。可以有多条命令，每一条命令占一行。 工作原理从第一个target开始，检查它的依赖是否都存在，如果存在的话就执行当前target下的命令。 否则就往下查找，寻找新规则生成依赖。 实战version112hello: main.cpp printhello.cpp factorial.cpp g++ -o hello main.cpp printhello.cpp factorial.cpp 版本1就相当于普通的编译命令。 version2123456789101112131415CXX = g++TARGET = hello OBJ = main.o printhello.o factorial.o$(TARGET): $(OBJ) $(CXX) -o $(TARGET) $(OBJ)main.o: main.cpp $(CXX) -c main.cppprinthello.o: printhello.cpp $(CXX) -c printhello.cppfactorial.o: factorial.cpp $(CXX) -c factorial.cpp 版本2分离编译器、目标、对象，但是还是不够智能。增加一个cpp文件需要改动的地方很多。 version31234567891011121314CXX = g++CXXFLAGS = -c -WallTARGET = hello OBJ = main.o printhello.o factorial.o$(TARGET): $(OBJ) $(CXX) -o $@ $^%.o: %.cpp $(CXX) $(CXXFLAGS) $&lt; -o $@.PHONY: cleanclean: rm -f *.o $(TARGET) 版本3引入了自动变量、通配符、.PONY。 （1）自动变量小撇： 1目标： 依赖 $@ 目标名 $^ 所有依赖的文件名 $&lt; 第一个依赖的文件名 （2）通配符%，匹配0个或多个任意字符。 （3）.PHONY的作用比较特殊，跟在它后面的目标都被称为伪目标。 如果 make 伪目标，不管该目录下是否有伪目标同名的文件（即使有也不会产生冲突），都会执行执行伪目标的依赖的命令。 version412345678910111213141516CXX = g++TARGET = hello SRC = $(wildcard *.cpp)OBJ = $(patsubst %.cpp, %.o, $(SRC))CXXFLAGS = -c -Wall$(TARGET): $(OBJ) $(CXX) -o $@ $^%.o: %.cpp $(CXX) $(CXXFLAGS) $&lt; -o $@.PHONY: cleanclean: rm -f *.o $(TARGET)","link":"/2023/02/01/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/Makefile%E5%AD%A6%E4%B9%A0/"},{"title":"二叉树总结","text":"关于二叉树，最重要的莫过于遍历了。 深度优先遍历和层次遍历（广度优先遍历） 递归实现和迭代实现 前序遍历、后序遍历以及中序遍历 那么一共有（3+2）*2=10种模版之多。先看前序遍历。 前序遍历递归实现这是最简单的前序遍历的递归实现 1234567void dfs（TreeNode* root）{ if(root==nullptr) reutrn root; // 处理root-&gt;val //中 dfs(root-&gt;left); //左 dfs(root-&gt;right); //右 return;} 迭代实现借助栈stack实现前序遍历。 12345678910111213int[] preorderTraversal(TreeNode root){ if(root == null) return root; List&lt;Integer&gt; ans = new ArrayList&lt;Integer&gt;(); Stack&lt;TreeNode&gt; stk = new Stack&lt;&gt;(); stk.push(root); while(!stk.isEmpty()){ TreeNode cur = stk.pop(); ans.add(cur.val); if(cur.right!=null) stk.push(cur.right); if(cur.left!=null) stk.push(cur.left); } return ans;} 注意点： 空节点不入栈（若空节点入栈，则出栈时需要加以校验） 入栈顺序（入栈顺序与前序遍历相反） 层次遍历递归实现1234567891011121314151617// val值存储说明：一层存一个List，所以是二维数组public List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList&lt;&gt;();public void bfs(TreeNode root, int depth){ if(root==null) return ; // 需要判断当前的depth是否是要处理 if(ans.size() == depth) ans.add(new ArrayList&lt;Integer&gt;()); // 处理val ans[depth].add(root.val); // 处理下一层 bfs(root.left, 1+depth); bfs(root.right, 1+depth);}// 调用方式bfs(root, 0); 注意点： 答案的存储方式：一层存一个List，所以是个二维数组； 层次遍历需要传入深度信息，利用二维数组来判断当前遍历到的层数。 迭代实现迭代实现借助队列，由于队列先进先出，可以记录一层的数量。 （1）实现一 12345678910111213public int[] levelOrder(TreeNode root){ if(root==null) return; List&lt;Integer&gt; ans = new ArrayList&lt;&gt;(); Queue&lt;TreeNode&gt; que = new ArrayList&lt;&gt;(); que.offer(root); while(!que.isEmpty()){ TreeNode node = que.poll(); ans.add(node.val); if(node.left!=null) que.offer(node.left); if(node.right!=null) que.offer(node.right); } return ans.toArray()；} 注意点： 空节点不入队或节点出队判空 可以不用二维数组处理答案 （2）实现二 巧妙的利用队列的性质，for 长度遍历。 1234567891011121314151617181920// val值存储说明：一层存一个List，所以是二维数组public List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList&lt;&gt;();public int[] levelOrder(TreeNode root){ if(root==null) return; List&lt;Integer&gt; ans = new ArrayList&lt;&gt;(); Queue&lt;TreeNode&gt; que = new ArrayList&lt;&gt;(); que.offer(root); while(!que.isEmpty()){ int count = que.size(); for(int i=0; i&lt;count;++i){ // 特殊处理！ TreeNode node = que.poll(); ans.add(node.val); if(node.left!=null) que.offer(node.left); if(node.right!=null) que.offer(node.right); } } return ans-to-int-array；} 迭代实现中序遍历12345678910111213141516171819202122vector&lt;int&gt; inorderTraversal(TreeNode* root) { vector&lt;int&gt; result; stack&lt;TreeNode*&gt; st; if (root != NULL) st.push(root); while (!st.empty()) { TreeNode* node = st.top(); st.pop(); // 将该节点弹出，避免重复操作，下面再将右中左节点添加到栈中 if (node != NULL) { if (node-&gt;right) st.push(node-&gt;right); // 添加右节点（空节点不入栈） st.push(node); // 添加中节点 st.push(NULL); // 中节点访问过，但是还没有处理，加入空节点做为标记。 if (node-&gt;left) st.push(node-&gt;left); // 添加左节点（空节点不入栈） } else { // 只有遇到空节点的时候，才将下一个节点放进结果集 node = st.top(); // 重新取出栈中元素 st.pop(); result.push_back(node-&gt;val); // 加入到结果集 } } return result;} 注意处理节点的技巧是：中节点后添加nullptr标志。 在首次遇到节点时，并不首先处理它，而是将它加入栈中，紧跟其后添加一个nullptr标志。而当我们再次取到nullptr时，它提醒我们该处理一个结点了。 这个技巧的思想是：标记，直到遍历完才处理数据。 题目练习每种题目都尝试递归和迭代两种写法！迭代可以实现层序遍历和深度优先遍历（前中后序遍历）。 BFS填充每个节点的下一个右侧指针 https://leetcode.cn/problems/populating-next-right-pointers-in-each-node/ 1234567891011121314151617class Solution { public Node connect(Node root) { if(root==null) return root; Queue&lt;Node&gt; que = new ArrayDeque&lt;&gt;(); que.offer(root); while(!que.isEmpty()){ int count = que.size(); for(int i=0; i&lt;count; ++i){ Node node = que.poll(); if(i!=count-1) node.next = que.peek(); //每层最后一个不需要设置next if(node.left!=null) que.offer(node.left); if(node.right!=null) que.offer(node.right); } } return root; }} 层次遍历的应用。 二叉树的最小深度https://leetcode.cn/problems/minimum-depth-of-binary-tree/description/ 12345678910111213141516171819202122public int minDepth(TreeNode root) { int ans = 0; if(root == null) return ans; Queue&lt;TreeNode&gt; que = new ArrayDeque&lt;&gt;(); que.offer(root); boolean stop = false; while(!que.isEmpty()){ int size = que.size(); // 层次遍历 ++ans; for(int i=0; i&lt;size; ++i){ TreeNode cur = que.poll(); if(cur.left==null &amp;&amp; cur.right==null) //碰到叶子结点就返回 stop = true; if(cur.left != null) que.offer(cur.left); if(cur.right != null) que.offer(cur.right); } if(stop) break; } return ans;} 层次遍历-碰到叶子节点就返回。实际是bfs的应用。 左下角的值 https://leetcode.cn/problems/find-bottom-left-tree-value/ 123456789101112131415161718class Solution { public int findBottomLeftValue(TreeNode root) { if(root==null) return 0; Queue&lt;TreeNode&gt; que = new ArrayDeque&lt;&gt;(); que.offer(root); int ans =-1; while(!que.isEmpty()){ int size = que.size(); for(int i=0; i&lt;size; ++i){ TreeNode node = que.poll(); if(i&lt;1) ans = node.val; if(node.left!=null) que.offer(node.left); if(node.right!=null) que.offer(node.right); } } return ans; }} 什么是左下角？数最深一层的第一个节点！还是层次遍历。 DFS相同的树 https://leetcode.cn/problems/same-tree/ 1234567class Solution { public boolean isSameTree(TreeNode p, TreeNode q) { if(p==null || q==null) return q==p ? true:false; if(p.val != q.val) return false; return isSameTree(p.left, q.left)&amp;&amp;isSameTree(p.right, q.right); }} 翻转二叉树https://leetcode.cn/problems/invert-binary-tree/description/ 1234567891011class Solution { public TreeNode invertTree(TreeNode root) { //递归思想 if(root==null) return root; TreeNode rl = invertTree(root.left); TreeNode rr = invertTree(root.right); root.left = rr; root.right = rl; return root; }} 这道题考的其实是递归的思想。 左叶子之和 https://leetcode.cn/problems/sum-of-left-leaves/ 注意左叶子的定义，需要通过父节点来判断。 12345678class Solution { public int sumOfLeftLeaves(TreeNode root) { if(root==null) return 0; if(root.left!=null &amp;&amp; root.left.left==null &amp;&amp; root.left.right==null) return root.left.val+sumOfLeftLeaves(root.right)+sumOfLeftLeaves(root.left); return sumOfLeftLeaves(root.left)+sumOfLeftLeaves(root.right); }} 123if (node-&gt;left != NULL &amp;&amp; node-&gt;left-&gt;left == NULL &amp;&amp; node-&gt;left-&gt;right == NULL) { 左叶子节点处理逻辑} 路径总和https://leetcode.cn/problems/path-sum/ 12345678910class Solution { public boolean dfs(TreeNode root, int targetSum){ if(root==null) return false; if(root.left==null&amp;&amp;root.right==null&amp;&amp;targetSum==root.val) return true; return dfs(root.left, targetSum-root.val) || dfs(root.right, targetSum-root.val); } public boolean hasPathSum(TreeNode root, int targetSum) { return dfs(root, targetSum); }} 给定一个二叉树和一个目标和，判断该树中是否存在根节点到叶子节点的路径，这条路径上所有节点值相加等于目标和。 路径开始节点固定：根结点。那么很容易利用递归整棵树。 路径总和2https://leetcode.cn/problems/path-sum-ii/ 123456789101112131415161718class Solution { List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList&lt;&gt;(); List&lt;Integer&gt; path = new ArrayList&lt;&gt;(); public void dfs(TreeNode root, int targetSum){ if(root==null) return; path.add(root.val); if(root.left==null&amp;&amp;root.right==null&amp;&amp;targetSum==root.val){ ans.add(new ArrayList&lt;Integer&gt;(path)); } dfs(root.left, targetSum-root.val); dfs(root.right, targetSum-root.val); path.remove(path.size()-1); } public List&lt;List&lt;Integer&gt;&gt; pathSum(TreeNode root, int targetSum) { dfs(root, targetSum); return ans; }} 回溯法来收集路径上的值。 路径总和3 https://leetcode.cn/problems/sum-root-to-leaf-numbers/ 123456789101112131415161718class Solution { int ans=0; List&lt;Integer&gt; path = new ArrayList&lt;&gt;(); public void dfs(TreeNode root, int cur){ if(root==null) return; path.add(root.val); int next_cur = cur*10 +root.val; if(root.left==null&amp;&amp;root.right==null){ ans +=next_cur; } dfs(root.left, next_cur); dfs(root.right, next_cur); path.remove(path.size()-1); } public int sumNumbers(TreeNode root) { dfs(root, 0); return ans; } 二叉树的所有路径 https://leetcode.cn/problems/binary-tree-paths/ （1）字符串普通拼接 1234567891011121314151617class Solution { public List&lt;String&gt; ans = new ArrayList&lt;&gt;(); public void dfs(TreeNode root, String str){ if(root==null) return; if(root!=null &amp;&amp; root.left==null &amp;&amp; root.right==null){ ans.add(str+String.valueOf(root.val)); return; } str = str + String.valueOf(root.val) + &quot;-&gt;&quot;; //这一步新建String dfs(root.left, str); dfs(root.right, str); } public List&lt;String&gt; binaryTreePaths(TreeNode root) { dfs(root, &quot;&quot;); return ans; }} （2）java优化写法 1234567891011121314151617class Solution { public List&lt;String&gt; res = new ArrayList&lt;&gt;(); public List&lt;String&gt; binaryTreePaths(TreeNode root) { if(root==null) return res; dfs(root,new StringBuilder()); return res; } public void dfs(TreeNode r, StringBuilder s){ if(r==null) return; s.append(r.val); if(r.left==null &amp;&amp; r.right==null){ res.add(s.toString()); } dfs(r.left,new StringBuilder(s).append(&quot;-&gt;&quot;)); dfs(r.right,new StringBuilder(s).append(&quot;-&gt;&quot;)); }} 二叉树的直径https://leetcode.cn/problems/diameter-of-binary-tree/description/ （1）暴力DFS 12345678910111213141516171819202122class Solution { Map&lt;TreeNode, Integer&gt; map = new HashMap&lt;&gt;(); public int dfs(TreeNode root){ //dfs求root节点的深度 if(root==null) return 0; int left = 1 + dfs(root.left); int right = 1 + dfs(root.right); int ret = Math.max(left, right); if(!map.containsKey(root)) map.put(root, ret); return ret; } public int diameterOfBinaryTree(TreeNode root) { if(root==null) return 0; int now = dfs(root.left) + dfs(root.right); int l = diameterOfBinaryTree(root.left); int r = diameterOfBinaryTree(root.right); now = Math.max(now, l); now = Math.max(now, r); return now; }} 二叉树的直径：二叉树中从一个节点到另一个节点的最长边数和。 从一个节点到另外一个节点，肯定是会经过过某棵树的根，以这个根将路径分为两部分，左子树的高度和右子树的高度。 定义树的高度：从根节点到叶子节点的最长路径边的个数，叶子节点的高度为0。 由此得到递归公式： 1根节点为root的二叉树的直径 = max(root-&gt;left的直径，root-&gt;right的直径，2 + root-&gt;left高度+root-&gt;right高度) 实际上操作时，我们定义新高度值为高度值都加1，即下面情况 1根节点为root的二叉树的直径 = max(root-&gt;left的直径，root-&gt;right的直径，1+root-&gt;left高度 + 1+root-&gt;right高度) （2）优化DFS 我们利用DFS求高度，遍历了每个节点。同时为了求解答案，我们还需要遍历每个节点的直径。能够将这两个遍历合二为一呢？ 答案是可以！在求高度时，我们得出了左右子树的高度。求当前root节点高度的操作是取max，而求直径的操作是加和，两者互不干预。 123456789101112131415class Solution { int ans = 0; public int dfs(TreeNode root){ if(root==null) return 0; int left = dfs(root.left); int right = dfs(root.right); int depth = 1 + Math.max(left, right); ans = Math.max(ans, left+right); return depth; } public int diameterOfBinaryTree(TreeNode root) { dfs(root); return ans; }} 构建二叉树 最大二叉树 https://leetcode.cn/problems/maximum-binary-tree/description/ 中序与后序构建二叉树 https://leetcode.cn/problems/construct-binary-tree-from-inorder-and-postorder-traversal/ 根据二叉搜索树构建平衡树 https://leetcode.cn/problems/balance-a-binary-search-tree/ 进阶题目 合并两颗二叉树 https://leetcode.cn/problems/merge-two-binary-trees/ 什么？你对合并二叉树有点手足无措？想想合并链表吧，只不过换了一种遍历方式！ 验证二叉搜索树 https://leetcode.cn/problems/validate-binary-search-tree/ 暴力的方法是中序遍历，然后验证递增数组。 更高效的方式是在遍历过程中判断，具体实现时记录前一个节点！ 二叉搜索树的最小绝对差 https://leetcode.cn/problems/minimum-absolute-difference-in-bst/ 二叉搜索树中的众数 https://leetcode.cn/problems/find-mode-in-binary-search-tree/ 小技巧：遍历一遍求递增数组中的众数，返回一个集合。 维护一个count和max-count和返回集合。如果遍历到数与之前不同，就清1count。如果遍历到相同的数，就加1count。如果count大于max-count，就清空集合，加入数。如果count等于max-count，加入数字。 了解数组中的众数求法后，二叉树的众数求法也出来了。无非是遍历二叉树。 二叉树的最近公共祖先 https://leetcode.cn/problems/lowest-common-ancestor-of-a-binary-tree/ 要清楚遍历的方式，自底向上，后序遍历。 必须遍历完整棵树吗，结果是如何上传的？ 其他题目扁平化嵌套列表https://leetcode.cn/problems/flatten-nested-list-iterator/description/ （1）暴力遍历 123456789101112131415161718192021222324252627282930public class NestedIterator implements Iterator&lt;Integer&gt; { private Iterator&lt;Integer&gt; myIt; private List&lt;Integer&gt; myList = new ArrayList&lt;&gt;(); public void traverse(List&lt;NestedInteger&gt; nestedList){ if(nestedList.isEmpty()) return; for(NestedInteger node: nestedList){ if(node.isInteger()) myList.add(node.getInteger()); else traverse(node.getList()); } } public NestedIterator(List&lt;NestedInteger&gt; nestedList) { traverse(nestedList); myIt = myList.iterator(); } @Override public Integer next() { return myIt.next(); } @Override public boolean hasNext() { return myIt.hasNext(); }} 其实是N叉树的深度优先遍历。结合迭代器。 （2）优化 123456789101112131415161718192021222324// 优化解法，迭代器惰性求值public class NestedIterator implements Iterator&lt;Integer&gt; { private LinkedList&lt;NestedInteger&gt; list; public NestedIterator(List&lt;NestedInteger&gt; nestedList) { list = new LinkedList&lt;&gt;(nestedList); } @Override public Integer next() { return list.remove(0).getInteger(); } @Override public boolean hasNext() { while(!list.isEmpty() &amp;&amp; !list.get(0).isInteger()){ List&lt;NestedInteger&gt; nodeList = list.remove(0).getList(); for(int i=nodeList.size()-1; i&gt;=0; --i){ list.addFirst(nodeList.get(i)); } } return !list.isEmpty(); // list非空就有下一个 }} 优化：上述解法将所有叶子节点值存入一个List中，当输入规模非常大时，上述计算会很慢，占用内存。一般迭代器是“惰性”求值的，也就是说，你要一个值，我算一个值，而不是一次将所有结果都求出来。 1234res = []while iterator.hasNext() append iterator.next() to the end of resreturn res 在调用next前会有hasNext来判断是否已经达到尾巴。那么hashNext做的事就是判断list的第一个元素是否是列表，如果是列表就将其拆开。注意列表是嵌套的，所以要用while循环。 滑动谜题https://leetcode.cn/problems/sliding-puzzle/description/ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283class Solution { int ans = 0; public boolean isCompleted(int[][] board){ for(int i=0; i&lt;3;++i){ if(board[0][i] != (i+1)) return false; } if(board[1][0]!=4) return false; if(board[1][1]!=5) return false; return true; } public int slidingPuzzle(int[][] array) { Set&lt;String&gt; set = new HashSet&lt;&gt;(); Queue&lt;int[][]&gt; que = new ArrayDeque&lt;&gt;(); que.offer(array); // 分阶段出队 while(!que.isEmpty()){ int size = que.size(); for(int i=0; i&lt;size; ++i){ int[][] board = que.poll(); if(isCompleted(boarad)) return ans; // 确定0的位置 int m=0,n=0; for(int k=0; k&lt;6; ++k){ if(board[k/3][k%3]==0){ m = k/3; n = k%3; break; } } // 上 if(m == 1){ int[][] tmp = new int[2][3]; tmp[0] = Arrays.copyOf(board[0], 3); tmp[1] = Arrays.copyOf(board[1], 3); tmp[m][n] = tmp[m-1][n]; tmp[m-1][n] = 0; if(!set.contains(Arrays.deepToString(tmp))){ que.offer(tmp); set.add(Arrays.deepToString(tmp)); } } // 下 if(m == 0){ int[][] tmp = new int[2][3]; tmp[0] = Arrays.copyOf(board[0], 3); tmp[1] = Arrays.copyOf(board[1], 3); tmp[m][n] = tmp[m+1][n]; tmp[m+1][n] = 0; if(!set.contains(Arrays.deepToString(tmp))){ que.offer(tmp); set.add(Arrays.deepToString(tmp)); } } // 左 if(n==1 || n==2){ int[][] tmp = new int[2][3]; tmp[0] = Arrays.copyOf(board[0], 3); tmp[1] = Arrays.copyOf(board[1], 3); tmp[m][n] = tmp[m][n-1]; tmp[m][n-1] = 0; if(!set.contains(Arrays.deepToString(tmp))){ que.offer(tmp); set.add(Arrays.deepToString(tmp)); } } // 右 if(n==0 || n==1){ int[][] tmp = new int[2][3]; tmp[0] = Arrays.copyOf(board[0], 3); tmp[1] = Arrays.copyOf(board[1], 3); tmp[m][n] = tmp[m][n+1]; tmp[m][n+1] = 0; if(!set.contains(Arrays.deepToString(tmp))){ que.offer(tmp); set.add(Arrays.deepToString(tmp)); } } } ans++; } return -1; }} 求最短路径：广度优先搜索+回溯法 注意点： 广搜的实现-队列 层次广搜的特定实现方式：for-que.size()， 特别注意要先得到size，否则队列的size会变 为了避免无穷尽的搜索，用set记录走过局面。（这里局面用数组toString的方式记录）","link":"/2024/06/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/Java%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"title":"哈希表算法总结","text":"数组哈希、集合哈希、映射哈希，各有适用场景。 原理（1）哈希表原理 哈希函数将传入的值映射为符号表的索引。 一般来说哈希表都是用来快速判断一个元素是否出现集合里。 （2）哈希碰撞 当不同的值映射为相同的索引时就出现了哈希碰撞。 一般解决方法： 线性探测 二次探测 拉链法 （3）常用的哈希表数据结构 数组 集合 set 映射 map 数组哈希概念阐述数组可以作为简单的哈希表，哈希函数可以就是简单的恒等映射。 （1）数组作哈希表的场景，一般用在元素值范围已知，并且元素个数均衡的情况。 场景：只有小写字母的字符串 （2）不足 稀疏时（元素个数远小于元素范围），空间利用率低 元素个数远大于范围时，哈希碰撞率大 对于哈希碰撞处理能力低（只有线性探测、二次探测） 相关题目 独一无二的数字 https://leetcode.cn/problems/unique-number-of-occurrences/description/ 有多少小于当前的数字 https://leetcode.cn/problems/how-many-numbers-are-smaller-than-the-current-number/ 同构字符串 https://leetcode.cn/problems/isomorphic-strings/ 查找常用字符 https://leetcode.cn/problems/find-common-characters/ 字符串排列https://leetcode.cn/problems/MPnaiL/description/ 12345678910111213141516171819class Solution { public boolean checkInclusion(String s1, String s2) { if(s1.length()&gt; s2.length()) return false; int[] map1 = new int[26]; int[] map2 = new int[26]; for(int i=0; i&lt;s1.length(); ++i){ map1[s1.charAt(i)-'a']++; map2[s2.charAt(i)-'a']++; } if(Arrays.equals(map1, map2)) return true; for(int i=s1.length(); i&lt;s2.length(); ++i){ // 滑动s2的窗口 map2[s2.charAt(i-s1.length())-'a']--; map2[s2.charAt(i)-'a']++; if(Arrays.equals(map1, map2)) return true; } return false; }} 刚好全是英文小写字母，可以用数组哈希。 滑动窗口法。 在判断两个数组是否相同时还可以优化，记录两个数组的差异度，见滑动窗口法。 两数之和被k整除的方案数https://www.nowcoder.com/questionTerminal/52f9ae6aa2ac4b2684af50f15bd897ac 1234567891011121314151617181920212223242526public class Main { public static void main(String[] args) { Scanner sc = new Scanner(System.in); int n = sc.nextInt(); int k = sc.nextInt(); sc.nextLine(); //读取换行符 String s2 = sc.nextLine(); //读取下一行 String[] ss2 = s2.split(&quot;\\\\s&quot;); long [] tong = new long[k]; long re = 0; for (int i = 0; i &lt; n; i++) { tong[Integer.parseInt(ss2[i]) % k]++; } for (int i = 1; i &lt; k / 2; i++) { re += tong[i] * tong[k - i]; } //处理余数为0；Cn2 re += tong[0] * (tong[0] - 1) / 2; // 偶数时，需要考虑2+2=4 if (k % 2 == 0) { re += tong[k / 2] * (tong[k / 2] - 1) / 2; } System.out.println(re); }} 给定一个 n 个元素组成的数组，和一个正整数 k 。求取两个数之和能被 k 整除的方案数（即两数之和为k的倍数的方案数）。 这题比较巧妙，利用了同余的思想，设置了K个桶。能被K整除的两个数，余数肯定是互补的。 特别要注意余数为0和K为偶数的情况。 集合哈希概念阐述Set是不包含重复元素的集合。 （1）集合用作哈希表，适合元素范围不知道的情况。 典型的使用方法是判断一个元素是否在集合内。 （2）不足 输出结果可能无序 只能用来判断是否在集中，无法存储其他信息 Java相关APIJava的Set接口有多个实现类，其中比较常用的有HashSet、LinkedHashSet和TreeSet。 HashSet：基于哈希表实现，没有固定的顺序，可以快速添加、删除和查找元素。 它最适合用于不需要保持顺序的场景。 LinkedHashSet：具有可预测的迭代顺序，它通过链表维护元素的插入顺序。 在迭代访问时，效率略低于HashSet，但在插入和删除时性能较好。 TreeSet：基于红黑树实现，元素按照自然顺序或自定义顺序进行排序。 它提供了一些额外的方法来获取第一个元素、最后一个元素、小于某个值的最大元素、大于某个值的最小元素等。 相关题目求两个数组的交集https://leetcode.cn/problems/intersection-of-two-arrays/ 1234567891011121314151617class Solution { public int[] intersection(int[] nums1, int[] nums2) { if (nums1 == null || nums1.length == 0 || nums2 == null || nums2.length == 0) return new int[0]; Set&lt;Integer&gt; set1 = new HashSet&lt;&gt;(); Set&lt;Integer&gt; resSet = new HashSet&lt;&gt;(); for (int i : nums1) { set1.add(i); } for (int i : nums2) { if (set1.contains(i)) { resSet.add(i); } } return resSet.stream().mapToInt(x -&gt; x).toArray(); }} 映射哈希概念阐述数组作为哈希表的局限：无法处理稀疏情况，空间浪费。 集合作为哈希表的局限：集合只能存放一个key，无法记录个数或下标位置信息。 这就引出了map，它是一种&lt;key, value&gt;的结构，本题可以用key保存数值，用value在保存数值所在的下标。 Java相关API12Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;();Map&lt;String, Integer&gt; map = new TreeMap&lt;&gt;(); 插入put、得到get、包含键containsKey、包含值containsValue、大小size、判空isEmpty 12345678910// 遍历for (Map.Entry&lt;String, Integer&gt; entry : map.entrySet()) { String key = entry.getKey(); Integer value = entry.getValue(); System.out.println(&quot;Key: &quot; + key + &quot;, Value: &quot; + value);}// 第二种方法map.forEach( (k, v) -&gt; {//do something here}); 相关题目两数之和https://leetcode.cn/problems/two-sum/ 123456789101112131415class Solution { public int[] twoSum(int[] nums, int target) { Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); int[] ans = new int[2]; for(int i=0; i&lt;nums.length; ++i){ if(map.containsKey(target - nums[i])){ ans[0] = i; ans[1] = map.get(target-nums[i]); break; } map.put(nums[i], i); } return ans; }} 这道题还是非常巧妙的，利用一个数和target已知的条件，快速确定另外一个数的值。 还有一个点是，不需要预先初始化map，查找过程中，未找到则插入。 单词规律https://leetcode.cn/problems/word-pattern/ 12345678910111213141516171819202122class Solution { public boolean wordPattern(String pattern, String s) { //构造双射 Map&lt;Character, String&gt; p2s = new HashMap&lt;&gt;(); Map&lt;String, Character&gt; s2p = new HashMap&lt;&gt;(); String[] strs = s.split(&quot; &quot;); if(pattern.length()!=strs.length) return false; for(int i=0; i&lt;strs.length; ++i){ char ch = pattern.charAt(i); String word = strs[i]; if(p2s.containsKey(ch)){ if(!p2s.get(ch).equals(word)) return false; }else{ // pattern没出现，那么word也不应该出现 if(s2p.containsKey(word)) return false; s2p.put(word, ch); p2s.put(ch, word); } } return true; }} 判断双射的逻辑，pattern没出现，那么word也不应该出现 和为K的子数组https://leetcode.cn/problems/subarray-sum-equals-k/description/ （1）暴力搜索 123456789101112131415class Solution { public int subarraySum(int[] nums, int k) { //考虑每个由下标i开始的区间，由于数组中存在负数，因此必须遍历整个长度 int ans = 0; for(int i=0; i&lt;nums.length; ++i){ int sum = 0; for(int j=i; j&lt;nums.length; ++j){ // sum维护【i，j】区间和 sum+=nums[j]; if(sum==k) ans++; } } return ans; }} （2）前缀和优化 我们知道前缀和这一技巧计算某个区间的和只需要O（1）时间。 那么题目转化为：求有多少个区间【l，r】和为K，其中l和r范围是0～N-1，且l&lt;r。 具体的解题过程就变成了两层循环： 123456for(int r=0; r&lt;N; ++r){ for(int l=0; l&lt;=r; ++l){ //求l，r区间和 //判断区间和是否与k相等 }} 但是时间复杂度并没有减少，因为枚举区间范围还是N^ 2。 （3）前缀和+哈希表 1234567891011121314151617181920class Solution { public int subarraySum(int[] nums, int k) { int N = nums.length; int[] preSum = new int[N]; preSum[0] = nums[0]; for(int i=1; i&lt;N; ++i){ preSum[i] = preSum[i-1]+nums[i]; } Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); map.put(0, 1); // 很重要，对应preSum[-1]=0 int ans = 0; for(int j=0; j&lt;N; ++j){ if(map.containsKey(preSum[j]-k)) { ans += map.get(preSum[j]-k); } map.put(preSum[j], map.getOrDefault(preSum[j], 0)+1); } return ans; }} 计算公式：$presum[j] - presum[i] = k$ ，那么 $presum[j] -k = presum[i]$ 转换思路：考虑以$j$为右端点的区间，其区间和为K的个数。这等价于求多少个$i&lt;j$，满足 $presum[i] = presum[j] -k $ 等等，这个公式有点熟悉？力扣梦开始的地方，力扣第一题，两数之和 接下来的思路就很明朗了，空间换时间，利用哈希表提前存每个presum[i]。 细节注意：前缀和的下标对应问题，比如preSum[i+1] 为从0到i得区间和。 map.put(0, 1); 的作用：其实还是前缀和下标对应的问题。当我们要计算第一个区间，即[0,0]的区间和时，我们采用了preSum[0]-0的实现。","link":"/2024/06/03/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/Java%E5%93%88%E5%B8%8C%E8%A1%A8/"},{"title":"回溯法总结","text":"回溯法其实就是递归，暴力搜索N叉树。做题画一颗N叉树，适当时剪枝。 回溯法能解决的问题： 组合问题：N个数里面按一定规则找出k个数的集合 排列问题：N个数按一定规则全排列，有几种排列方式 切割问题：一个字符串按一定规则有几种切割方式 子集问题：一个N个数的集合里有多少符合条件的子集 棋盘问题：N皇后，解数独等等 回溯法的基本模版 123456789101112void backtracking(参数) { if (终止条件) { 存放结果; return; } for (选择：本层集合中元素（树中节点孩子的数量就是集合的大小）) { 处理节点; backtracking(路径，选择列表); // 递归 回溯，撤销处理结果 }} 回溯法抽象为树形结构后，其遍历过程就是：for循环横向遍历，递归纵向遍历，回溯不断调整结果集。 组合问题组合https://leetcode.cn/problems/combinations/ 12345678910111213141516171819class Solution { public List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList&lt;&gt;(); public Deque&lt;Integer&gt; path = new ArrayDeque&lt;&gt;(); public void backTrait(int n, int start, int k){ if(path.size()==k){ ans.add(new ArrayList&lt;&gt;(path));//copy return; } for(int i=start; i&lt;=n; ++i){ path.add(i); backTrait(n, i+1, k); path.removeLast(); //回溯 } } public List&lt;List&lt;Integer&gt;&gt; combine(int n, int k) { backTrait(n, 1, k); return ans; }} 给定两个整数 n 和 k，返回 1 … n 中所有可能的 k 个数的组合。 解题思路：树形结构遍历、next greater去重 优化思路：如果剩下元素不足以凑齐K个，不用往下遍历。 1234// 如果path.size加上n-i+1还不够k，那么继续遍历下去也没用// 符合i的条件为 path.size()+n-i+1 &gt;= k// namely i &lt;= n-k+1-path.size()for(int i=start; i&lt;= n-k+1+path.size(); ++i){ 组合2 https://leetcode.cn/problems/combination-sum-iii/ 12345678910111213141516171819202122class Solution { public List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList&lt;&gt;(); public Deque&lt;Integer&gt; path = new ArrayDeque&lt;&gt;(); public void backTrack(int k, int n, int start, int sum){ if(path.size()==k &amp;&amp; sum==n){ ans.add(new ArrayList&lt;&gt;(path)); return; } else if(path.size() &gt; k) return; for(int i=start; i&lt;=9; ++i){ path.add(i); sum+=i; backTrack(k,n, i+1, sum); path.removeLast(); sum-=i; } } public List&lt;List&lt;Integer&gt;&gt; combinationSum3(int k, int n) { backTrack(k, n, 1, 0); return ans; }} 找出所有相加之和为 n 的 k 个数的组合。组合中只允许含有 1 - 9 的正整数，并且每种组合中不存在重复的数字。 本题就是在[1,2,3,4,5,6,7,8,9]这个集合中找到和为n的k个数的组合。与上题相比，就是加了一个和为k的限制。 电话号码的数字组合 https://leetcode.cn/problems/letter-combinations-of-a-phone-number/ 给定一个仅包含数字 2-9 的字符串，返回所有它能表示的字母组合。答案可以按 任意顺序 返回。 难点在于集合的映射,本题每一个数字代表的是不同集合，也就是求不同集合之间的组合. 12输入：digits = &quot;23&quot;输出：[&quot;ad&quot;,&quot;ae&quot;,&quot;af&quot;,&quot;bd&quot;,&quot;be&quot;,&quot;bf&quot;,&quot;cd&quot;,&quot;ce&quot;,&quot;cf&quot;] 12345678910111213141516171819202122232425262728293031323334class Solution { // 匿名内部类 public Map&lt;Character, String&gt; map = new HashMap&lt;&gt;(){{ put('2', &quot;abc&quot;); put('3', &quot;def&quot;); put('4', &quot;ghi&quot;); put('5', &quot;jkl&quot;); put('6', &quot;mno&quot;); put('7', &quot;pqrs&quot;); put('8', &quot;tuv&quot;); put('9', &quot;wxyz&quot;); }}; public List&lt;String&gt; ans = new ArrayList&lt;&gt;(); public void backTrack(String digits, int index, StringBuilder path){ if(path.length() == digits.length()){ ans.add(path.toString()); return; } char num = digits.charAt(index); String alphabet = map.get(num); for(int j=0; j&lt;alphabet.length(); ++j){ char letter = alphabet.charAt(j); path.append(letter); backTrack(digits, index+1, new StringBuilder(path)); path.deleteCharAt(index); } } public List&lt;String&gt; letterCombinations(String digits) { if(digits.isEmpty()) return ans; backTrack(digits, 0, new StringBuilder()); StringBuilder sb = new StringBuilder(); return ans; }} 组合总和给你一个 无重复元素 的整数数组 candidates 和一个目标整数 target ，找出 candidates 中可以使数字和为目标数 target 的 所有 不同组合 ，并以列表形式返回。你可以按 任意顺序 返回这些组合。 candidates 中的 同一个 数字可以 无限制重复被选取 。如果至少一个数字的被选数量不同，则两种组合是不同的。 https://leetcode.cn/problems/combination-sum/ 12输入：candidates = [2,3,6,7], target = 7输出：[[2,2,3],[7]] 123456789101112131415161718192021vector&lt;vector&lt;int&gt;&gt; ret; vector&lt;int&gt; path; void backtrack(vector&lt;int&gt;&amp; candidates, int target, int start){ if(target&lt;0) return; else if (target==0){ ret.push_back(path); return; } for(int i=start; i&lt;candidates.size(); ++i){ int num = candidates[i]; if(target-num&lt;0) break; //剪枝优化 path.push_back(num); backtrack(candidates, target-num, i); //注意这里是重复选取 path.pop_back(); } } vector&lt;vector&lt;int&gt;&gt; combinationSum(vector&lt;int&gt;&amp; candidates, int target) { sort(candidates.begin(), candidates.end()); //不排序会出问题！ backtrack(candidates, target, 0); return ret; } 本题与1.2组合2的区别在于，同一个数字可以无限制重复选取。故区别在递归时，startindex是从i开始（意味着本数字可以重复选取），而不是从i+1开始。 在求和问题中，排序之后加剪枝是常见的套路！ 组合总和2给定一个候选人编号的集合 candidates 和一个目标数 target ，找出 candidates 中所有可以使数字和为 target 的组合。 candidates 中的每个数字在每个组合中只能使用 一次 。 https://leetcode.cn/problems/combination-sum-ii/ 123456输入: candidates = [2,5,2,1,2], target = 5,输出:[[1,2,2],[5]] 123456789101112131415161718192021222324252627vector&lt;vector&lt;int&gt;&gt; ret; vector&lt;int&gt; path; void backtrack(vector&lt;int&gt;&amp; candidates, int target, int start, vector&lt;int&gt;&amp; visited){ if(target&lt;0) return; else if (target==0){ ret.push_back(path); return; } for(int i=start; i&lt;candidates.size(); ++i){ int num = candidates[i]; if(target-num&lt;0) break; //剪纸优化 if(i&gt;0 &amp;&amp; candidates[i]==candidates[i-1] &amp;&amp; visited[i-1]==0) continue; //同一树层剪枝 path.push_back(num); visited[i]= 1; backtrack(candidates, target-num, i+1, visited); visited[i]= 0; path.pop_back(); } } vector&lt;vector&lt;int&gt;&gt; combinationSum2(vector&lt;int&gt;&amp; candidates, int target) { vector&lt;int&gt; visited(candidates.size(), 0); sort(candidates.begin(), candidates.end()); //不排序会出问题！ backtrack(candidates, target, 0, visited); return ret; } 这道题与上一题的区别在于集合中元素是否重复，并且上一题中的元素可以重复选取，这题每个元素只能用一次。 要去重，否则1，2，2的组合会出现3次。去重是难点！ 为了讲解这个去重问题，我自创了两个词汇，“树枝去重”和“树层去重”。 都知道组合问题可以抽象为树形结构，那么“使用过”在这个树形结构上是有两个维度的，一个维度是同一树枝上“使用过”，一个维度是同一树层上“使用过”。 used[i - 1] == true，说明同一树枝candidates[i - 1]使用过 used[i - 1] == false，说明同一树层candidates[i - 1]使用过 12//TODO 另一种去重方式，不用used数组 if(i&gt;start &amp;&amp; candidates[i]==candidates[i-1]) 对于组合问题，什么时候需要startIndex呢？ 如果是一个集合来求组合的话，就需要startIndex，如果是多个集合取组合，各个集合之间相互不影响，那么就不用startIndex. 切割分割回文串给你一个字符串 s，请你将 s 分割成一些子串，使每个子串都是 回文串 。返回 s 所有可能的分割方案。 https://leetcode.cn/problems/palindrome-partitioning/ 12输入：s = &quot;aab&quot;输出：[[&quot;a&quot;,&quot;a&quot;,&quot;b&quot;],[&quot;aa&quot;,&quot;b&quot;]] 12345678910111213141516171819202122232425262728293031vector&lt;vector&lt;string&gt;&gt; ret; vector&lt;string&gt; path; bool is_hui(string&amp; s, int l, int r){ if(l&gt;r) return false; while(l&lt;r){ if(s[l]!=s[r]) return false; ++l; --r; } return true; } void backtrack(string&amp; s, int start){ if(start==s.size()){ ret.push_back(path); return ; } for(int i=start; i&lt;s.size();++i){ if(is_hui(s, start, i)){ path.push_back(s.substr(start, i-start+1)); } else{ continue; } backtrack(s, i+1); //i+1 path.pop_back(); } } vector&lt;vector&lt;string&gt;&gt; partition(string s) { backtrack(s, 0); return ret; } 回溯法怎么应用于切割问题？其实只要想象长度为n的串，分为若干段，每段长度可以相同，各段长度和为n。这不就是组合总和的思路嘛。candidate就是从1到n，target就是n，元素可以重复选取。 复原IP地址https://leetcode.cn/problems/restore-ip-addresses/ 子集问题子集问题给定一组不含重复元素的整数数组 nums，返回该数组所有可能的子集（幂集）。 示例: 输入: nums = [1,2,3] 输出: [ [3], [1], [2], [1,2,3], [1,3], [2,3], [1,2], [] ] https://leetcode.cn/problems/subsets/ 1234567891011121314151617class Solution { public List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); LinkedList&lt;Integer&gt; path = new LinkedList&lt;&gt;();// 用来存放符合条件结果 public void backTrack(int[] nums, int start){ res.add(new ArrayList(path)); if(start==nums.length) return; for(int i=start; i&lt;nums.length; ++i){ path.add(nums[i]); backTrack(nums, i+1); path.removeLast(); } } public List&lt;List&lt;Integer&gt;&gt; subsets(int[] nums) { backTrack(nums, 0); return res; }} 子集问题怎么解？在之前的问题中，我们都是收集叶子节点的结果。现在求子集，我们要收集每一个节点的结果！ 收集结果的代码放在递归的第一行，收集本身。注意空子集在第一次调用时收集。 子集问题2给定一个可能包含重复元素的整数数组 nums，返回该数组所有可能的子集（幂集）。 说明：解集不能包含重复的子集。 12- 输入: [1,2,2]- 输出: [ [2], [1], [1,2,2], [2,2], [1,2], [] ] https://leetcode.cn/problems/subsets-ii/ 1234567891011121314151617181920212223242526class Solution {private: vector&lt;vector&lt;int&gt;&gt; result; vector&lt;int&gt; path; void backtracking(vector&lt;int&gt;&amp; nums, int startIndex) { result.push_back(path); for (int i = startIndex; i &lt; nums.size(); i++) { // 而我们要对同一树层使用过的元素进行跳过 if (i &gt; startIndex &amp;&amp; nums[i] == nums[i - 1] ) { // 注意这里使用i &gt; startIndex continue; } path.push_back(nums[i]); backtracking(nums, i + 1); path.pop_back(); } }public: vector&lt;vector&lt;int&gt;&gt; subsetsWithDup(vector&lt;int&gt;&amp; nums) { result.clear(); path.clear(); sort(nums.begin(), nums.end()); // 去重需要排序 backtracking(nums, 0); return result; }}; 这题与上题的区别在于集合可以包含重复元素，在选子集时会出现重复的情况，所以需要去重。 如何去重？树层去重（需要排序）。 递增子序列给定一个整型数组, 你的任务是找到所有该数组的递增子序列，递增子序列的长度至少是2。 12- 输入: [4, 7, 6, 7]- 输出:[[4,7],[4,7,7],[4,6],[4,6,7],[7,7],[6,7]] https://leetcode.cn/problems/non-decreasing-subsequences/ 12345678910111213141516171819202122232425vector&lt;vector&lt;int&gt;&gt; ret; vector&lt;int&gt; path; void backtrack(vector&lt;int&gt;&amp; nums, int start){ //提前收集 if(path.size()&gt;=2) ret.push_back(path); //判断返回的方式 if(start&gt;=nums.size()) return; unordered_set&lt;int&gt; uset; for(int i=start; i&lt;nums.size();++i){ if((!path.empty() &amp;&amp; nums[i]&lt;path.back()) ||uset.find(nums[i])!=uset.end()) //之前的数字出现过了！ continue; uset.insert(nums[i]); //插入元素 path.push_back(nums[i]); backtrack(nums, i+1); path.pop_back(); } } vector&lt;vector&lt;int&gt;&gt; findSubsequences(vector&lt;int&gt;&amp; nums) { backtrack(nums, 0); return ret; } 这道题类似子集问题2，只不过要求找到的子集长度至少为2，并且递增。 本题不能使用之前的去重逻辑！求自增子序列，是不能对原数组进行排序的，排完序的数组都是自增子序列了。 所以需要利用set去重。 这也是需要注意的点，unordered_set&lt;int&gt; uset; 是记录本层元素是否重复使用，新的一层uset都会重新定义（清空），所以要知道uset只负责本层！ 排列全排列问题给定一个 没有重复 数字的序列，返回其所有可能的全排列。 12- 输入: [1,2,3]- 输出: [ [1,2,3], [1,3,2], [2,1,3], [2,3,1], [3,1,2], [3,2,1] ] https://leetcode.cn/problems/permutations/ 123456789101112131415161718192021222324252627class Solution {public: vector&lt;vector&lt;int&gt;&gt; result; vector&lt;int&gt; path; void backtracking (vector&lt;int&gt;&amp; nums, vector&lt;bool&gt;&amp; used) { // 此时说明找到了一组 if (path.size() == nums.size()) { result.push_back(path); return; } for (int i = 0; i &lt; nums.size(); i++) { if (used[i] == true) continue; // path里已经收录的元素，直接跳过 used[i] = true; path.push_back(nums[i]); backtracking(nums, used); path.pop_back(); used[i] = false; } } vector&lt;vector&lt;int&gt;&gt; permute(vector&lt;int&gt;&amp; nums) { result.clear(); path.clear(); vector&lt;bool&gt; used(nums.size(), false); backtracking(nums, used); return result; }}; 想象一颗N叉树，不能重复选取元素，startindex也没用了，统一从0开始，借助used数组。 大家此时可以感受出排列问题的不同： 每层都是从0开始搜索而不是startIndex 需要used数组记录path里都放了哪些元素了 全排列问题2给定一个可包含重复数字的序列 nums ，按任意顺序 返回所有不重复的全排列。 12- 输入：nums = [1,1,2]- 输出： [[1,1,2], [1,2,1], [2,1,1]] https://leetcode.cn/problems/permutations-ii/ 123456789101112131415161718192021222324252627282930313233343536class Solution {private: vector&lt;vector&lt;int&gt;&gt; result; vector&lt;int&gt; path; void backtracking (vector&lt;int&gt;&amp; nums, vector&lt;bool&gt;&amp; used) { // 此时说明找到了一组 if (path.size() == nums.size()) { result.push_back(path); return; } for (int i = 0; i &lt; nums.size(); i++) { // used[i - 1] == true，说明同一树枝nums[i - 1]使用过 // used[i - 1] == false，说明同一树层nums[i - 1]使用过 // 如果同一树层nums[i - 1]使用过则直接跳过 if (i &gt; 0 &amp;&amp; nums[i] == nums[i - 1] &amp;&amp; used[i - 1] == false) { continue; } if (used[i] == false) { used[i] = true; path.push_back(nums[i]); backtracking(nums, used); path.pop_back(); used[i] = false; } } }public: vector&lt;vector&lt;int&gt;&gt; permuteUnique(vector&lt;int&gt;&amp; nums) { result.clear(); path.clear(); sort(nums.begin(), nums.end()); // 排序 vector&lt;bool&gt; used(nums.size(), false); backtracking(nums, used); return result; }}; 这题需要去重了，否则长度为3的数组全排列应该有3x2x1=6个。 如何去重？sort后再树层去重？ 中途休息性能分析之前并没有分析各个问题的时间复杂度和空间复杂度，这次来说一说。 子集问题分析： 时间复杂度：$O(n × 2^n)$，因为每一个元素的状态无外乎取与不取，所以时间复杂度为$O(2^n)$，构造每一组子集都需要填进数组，又有需要$O(n)$，最终时间复杂度：$O(n × 2^n)$。???? 空间复杂度：$O(n)$，递归深度为n，所以系统栈所用空间为$O(n)$，每一层递归所用的空间都是常数级别，注意代码里的result和path都是全局变量，就算是放在参数里，传的也是引用，并不会新申请内存空间，最终空间复杂度为$O(n)$。 排列问题分析： 时间复杂度：$O(n!)$，这个可以从排列的树形图中很明显发现，每一层节点为n，第二层每一个分支都延伸了n-1个分支，再往下又是n-2个分支，所以一直到叶子节点一共就是 n * n-1 * n-2 * ….. 1 = n!。每个叶子节点都会有一个构造全排列填进数组的操作（对应的代码：result.push_back(path)），该操作的复杂度为$O(n)$。所以，最终时间复杂度为：n * n!，简化为$O(n!)$。 空间复杂度：$O(n)$，和子集问题同理。 组合问题分析： 时间复杂度：$O(n × 2^n)$，组合问题其实就是一种子集的问题，所以组合问题最坏的情况，也不会超过子集问题的时间复杂度。 空间复杂度：$O(n)$，和子集问题同理。 一般说道回溯算法的复杂度，都说是指数级别的时间复杂度，这也算是一个概括吧！ 关于去重 used数组 set集合 普通去重 子集问题2中使用了普通去重。 在全排列2中就使用了used数组去重，set集合去重写法如下： 12345678910111213141516171819202122232425262728293031323334class Solution {private: vector&lt;vector&lt;int&gt;&gt; result; vector&lt;int&gt; path; void backtracking (vector&lt;int&gt;&amp; nums, vector&lt;bool&gt;&amp; used) { if (path.size() == nums.size()) { result.push_back(path); return; } unordered_set&lt;int&gt; uset; // 控制某一节点下的同一层元素不能重复 for (int i = 0; i &lt; nums.size(); i++) { if (uset.find(nums[i]) != uset.end()) { continue; } if (used[i] == false) { uset.insert(nums[i]); // 记录元素 used[i] = true; path.push_back(nums[i]); backtracking(nums, used); path.pop_back(); used[i] = false; } } }public: vector&lt;vector&lt;int&gt;&gt; permuteUnique(vector&lt;int&gt;&amp; nums) { result.clear(); path.clear(); sort(nums.begin(), nums.end()); // 排序 vector&lt;bool&gt; used(nums.size(), false); backtracking(nums, used); return result; }}; 需要注意的是：使用set去重的版本相对于used数组的版本效率都要低很多 主要是因为程序运行的时候对unordered_set 频繁的insert，unordered_set需要做哈希映射（也就是把key通过hash function映射为唯一的哈希值）相对费时间，而且insert的时候其底层的符号表也要做相应的扩充，也是费时的。 使用set去重，不仅时间复杂度高了，空间复杂度也高了，在本周小结！（回溯算法系列三） (opens new window)中分析过，组合，子集，排列问题的空间复杂度都是O(n)，但如果使用set去重，空间复杂度就变成了O(n^2)，因为每一层递归都有一个set集合，系统栈空间是n，每一个空间都有set集合。 其他问题括号生成https://leetcode.cn/problems/generate-parentheses/submissions/ 1234567891011121314151617181920212223class Solution { public List&lt;String&gt; ans = new LinkedList(); public void backTrack(int n, StringBuilder cur, int l_n, int r_n){ if(n==0){ if(l_n==r_n) ans.add(cur.toString()); // 有效的括号组合：左数量等于右数量 return; } // 任何位置，左数量大于右数量 if(l_n &lt; r_n) return; // 生成左括号 cur.append('('); backTrack(n-1, cur, 1+l_n, r_n); cur.deleteCharAt(cur.length()-1); // 生成右扩号 cur.append(')'); backTrack(n-1, cur, l_n, 1+r_n); cur.deleteCharAt(cur.length()-1); } public List&lt;String&gt; generateParenthesis(int n) { backTrack(2*n, new StringBuilder(), 0, 0); return ans; }} 这里的技巧在于用左右括号的数量来判断当前生成括号是否合法。 解数独https://leetcode.cn/problems/sudoku-solver 123456789101112131415161718192021222324252627282930313233class Solution { public boolean isValid(char[][] board, int r, int c, char ch){ for(int i=0; i&lt;9; ++i){ if(board[r][i]==ch) return false; if(board[i][c]==ch) return false; if(board[3*(r/3)+i/3][3*(c/3)+i%3] == ch) return false; } return true; } public boolean backTrack(char[][] board, int i, int j){ // 边界条件，换到下一行搜索 if(j==9) return backTrack(board, i+1, 0); // 停止条件 if(i==9) return true; if(board[i][j] != '.') return backTrack(board, i, j+1); else{ // 遍历 for(char k='1'; k&lt;='9'; ++k){ if(isValid(board, i, j, k)){ board[i][j] = k; if(backTrack(board, i, j+1)) return true; board[i][j] = '.'; } } } return false; } public void solveSudoku(char[][] board) { backTrack(board, 0, 0); }} 代码看着简答，优化可不少： 1、 3x3宫格的有效性判断 2、先做有效性判断，再赋值这个格子； 2、backTrack的返回值是boolean且递归时用if判断，找到一个可行解就直接返回 雀魂启动https://www.nowcoder.com/practice/448127caa21e462f9c9755589a8f2416 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import java.util.*;public class Main { static boolean flag; public static void main(String[] args) { Scanner cin = new Scanner(System.in); int[] nums = new int[10]; for (int i = 0; i &lt; 13; i++) { nums[cin.nextInt()]++; } for (int i = 1; i &lt;= 9; i++) { if (nums[i] &lt;= 3) { int[] card = Arrays.copyOf(nums, nums.length); // 深拷贝一份card card[i]++; if (isHu(card, 1, 0, 0)) { flag = true; System.out.print(i + &quot; &quot;); } } } if(flag == false) // 不能和牌 System.out.print(0); } public static boolean isHu(int[] card, int start, int quetou, int lian){ if(start&gt;=10){ // 胡牌条件：1个雀头，4个顺子或刻子（这里我一起称之为lian） if(quetou==1 &amp;&amp; lian==4) return true; else //全部搜索完都没和牌 return false; } // 从start开始,用作雀头 if(card[start]&gt;=2 &amp;&amp; quetou==0){ card[start] -=2; if(isHu(card, start, 1, lian)) return true; card[start] +=2; } // 从start开始，用作刻子 if(card[start]&gt;=3){ card[start] -=3; if(isHu(card, start, quetou, lian+1)) return true; card[start] +=3; } // 从start开始，用作顺子 if (start + 2 &lt;= 9 &amp;&amp; card[start] &gt; 0 &amp;&amp; card[start + 1] &gt; 0 &amp;&amp; card[start + 2] &gt; 0){ card[start]--; card[start + 1]--; card[start + 2]--; if(isHu(card, start, quetou, lian+1)) return true; card[start]++; card[start + 1]++; card[start + 2]++; } // 当前牌无法组成雀头、顺子或刻子，直接跳到下一个数额的牌 if(isHu(card, 1+start, quetou, lian)) return true; return false; }} 思路剖析：回溯法 1、手头有13张牌，向其中添加1张牌，看能否和牌； 2、遍历1-9大小的牌，每种数字的牌依次尝试用作雀头、顺子、刻子。 N皇后https://leetcode.cn/problems/n-queens/submissions/ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class Solution { List&lt;List&lt;String&gt;&gt; ans = new ArrayList&lt;&gt;(); public void backTrack(char[][] arrs, int n, int row){ // 搜索到了最后一行 if(row == n){ // 收集结果 List&lt;String&gt; tmp = new ArrayList&lt;&gt;(); for(char[] arr: arrs){ tmp.add(new String(arr)); } ans.add(tmp); return; } // row是当前行，对列进行搜索 for(int col=0; col&lt;n; ++col){ if(isValid(arrs, row, col)){ arrs[row][col] = 'Q'; backTrack(arrs, n, 1+row); arrs[row][col] = '.'; } } } public boolean isValid(char[][] arrs, int row, int col){ int n =arrs.length; for(int i=0; i&lt;arrs.length; ++i){ if(arrs[row][i]=='Q') return false; if(arrs[i][col]=='Q') return false; } // 检查45度对角线, 只检查上半部分 for (int i=row-1, j=col-1; i&gt;=0 &amp;&amp; j&gt;=0; i--, j--) { if (arrs[i][j] == 'Q') { return false; } } // 检查135度对角线，只检查上半部分 for (int i=row-1, j=col+1; i&gt;=0 &amp;&amp; j&lt;=n-1; i--, j++) { if (arrs[i][j] == 'Q') { return false; } } return true; } public List&lt;List&lt;String&gt;&gt; solveNQueens(int n) { char[][] arrs = new char[n][n]; for(int i=0; i&lt;n; ++i) Arrays.fill(arrs[i], '.'); backTrack(arrs, n, 0); return ans; }} 几个注意点： 1、 用二维字符矩阵模拟棋盘，最后再转化为List&lt;List&lt;String&gt;&gt; 2、 搜索时有顺序，先按行（自上而下），确定行后自左至右确定列 3、isValid先对未填时进行校验，而且只校验上半部分 –优化解法–：利用boolean数组表示已经占用的直线","link":"/2024/06/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/Java%E5%9B%9E%E6%BA%AF%E6%B3%95/"},{"title":"栈与队列算法总结","text":"栈、单调栈、队列、单调队列 Java中栈的使用1234567891011121314151617181920212223242526272829import java.util.Stack;public class StackExample { public static void main(String[] args) { // 创建一个新的栈对象 Stack&lt;Integer&gt; stack = new Stack&lt;&gt;(); // 入栈操作 stack.push(10); stack.push(20); stack.push(30); // 出栈操作 int topElement = stack.pop(); System.out.println(&quot;出栈元素：&quot; + topElement); // 获取栈顶元素 int peekElement = stack.peek(); System.out.println(&quot;栈顶元素：&quot; + peekElement); // 判断栈是否为空 boolean isEmpty = stack.isEmpty(); System.out.println(&quot;栈是否为空：&quot; + isEmpty); // 获取栈的大小 int size = stack.size(); System.out.println(&quot;栈的大小：&quot; + size); }} 入栈push、出栈pop、栈顶peek、判空isEmpty、大小size 栈括号匹配 https://leetcode.cn/problems/valid-parentheses/ 1234567891011121314151617181920212223242526class Solution { public boolean isValid(String s) { Stack&lt;Character&gt; stk = new Stack&lt;&gt;(); for(char ch: s.toCharArray()){ if(ch == '(' || ch=='[' || ch=='{'){ stk.push(ch); } else if (ch ==')'){ if(!stk.isEmpty() &amp;&amp; stk.peek() == '(') stk.pop(); else return false; } else if (ch =='}'){ if(!stk.isEmpty() &amp;&amp; stk.peek() == '{') stk.pop(); else return false; } else if (ch ==']'){ if(!stk.isEmpty() &amp;&amp; stk.peek() == '[') stk.pop(); else return false; } } return stk.isEmpty() ? true:false; }} 比较含退格的字符串 https://leetcode.cn/problems/backspace-string-compare/ 1234567891011121314151617181920class Solution { public String handle(String s){ Stack&lt;Character&gt; stk = new Stack&lt;&gt;(); for(char ch: s.toCharArray()){ if(ch =='#'){ if(!stk.isEmpty()) stk.pop(); }else stk.push(ch); } StringBuilder sb = new StringBuilder(); while(!stk.isEmpty()) sb.append(stk.pop()); return sb.toString(); } public boolean backspaceCompare(String s, String t) { String hs = handle(s); String ht = handle(t); return hs.equals(ht) ? true:false; }} 字符串去重 https://leetcode.cn/problems/remove-all-adjacent-duplicates-in-string/ 1234567891011121314151617class Solution { public String removeDuplicates(String s) { Stack&lt;Character&gt; stk = new Stack&lt;&gt;(); for(char ch: s.toCharArray()){ if(!stk.isEmpty() &amp;&amp; stk.peek()==ch){ stk.pop(); } else stk.push(ch); } StringBuilder sb = new StringBuilder(); while(!stk.isEmpty()){ sb.append(stk.pop()); } return sb.reverse().toString(); } 逆波兰式求值https://leetcode.cn/problems/evaluate-reverse-polish-notation/description/ 1234567891011121314151617181920class Solution { public int evalRPN(String[] tokens) { Stack&lt;Integer&gt; stk = new Stack&lt;&gt;(); for(int i=0; i&lt;tokens.length; ++i){ String token = tokens[i]; if(token.equals(&quot;+&quot;) || token.equals(&quot;-&quot;) || token.equals(&quot;*&quot;) || token.equals(&quot;/&quot;) ){ int m = stk.pop(); int n = stk.pop(); if(token.equals(&quot;+&quot;)) stk.push(n+m); if(token.equals(&quot;-&quot;)) stk.push(n-m); if(token.equals(&quot;*&quot;)) stk.push(n*m); if(token.equals(&quot;/&quot;)) stk.push(n/m); } else{ stk.push(Integer.valueOf(token)); } } return stk.pop(); }} 遇数字入栈，遇符号出栈。逆波兰式本身就是后序遍历。 栈实现队列 https://leetcode.cn/problems/implement-queue-using-stacks/ 12345678910111213141516171819202122232425262728293031class MyQueue { private Stack&lt;Integer&gt; stkIn; private Stack&lt;Integer&gt; stkOut; public MyQueue() { stkIn = new Stack&lt;&gt;(); stkOut = new Stack&lt;&gt;(); } public void push(int x) { stkIn.push(x); } public int pop() { if(stkOut.isEmpty()){ while(!stkIn.isEmpty()) stkOut.push(stkIn.pop()); } return stkOut.pop(); } public int peek() { if(stkOut.isEmpty()){ while(!stkIn.isEmpty()) stkOut.push(stkIn.pop()); } return stkOut.peek(); } public boolean empty() { return stkIn.isEmpty() &amp;&amp; stkOut.isEmpty(); }} 两个栈，一个栈用于填入元素，另一个栈用于弹出元素。当要弹出元素时，将第一个栈的元素倒入第二个栈中，自然形成了先进先出的顺序。 字符串解码https://leetcode.cn/problems/decode-string/ 1234567891011121314151617181920212223242526class Solution { public String decodeString(String s) { StringBuilder res = new StringBuilder(); // res存字符串解码的内容，即无【】 int num=0; Stack&lt;Integer&gt; num_stk = new Stack&lt;&gt;(); // 数字栈 Stack&lt;String&gt; ch_stk = new Stack&lt;&gt;(); // 字符栈 for(char ch : s.toCharArray()){ if('0'&lt;=ch &amp;&amp; ch&lt;='9'){ num = 10*num + ch-'0'; }else if(ch == '['){ num_stk.push(num); ch_stk.push(res.toString()); // 将【之前的，已经解码完毕的字符入栈 num = 0; res = new StringBuilder(); }else if(ch == ']'){ StringBuilder tmp = new StringBuilder(); int cnt = num_stk.pop(); for(int i=0; i&lt;cnt; ++i) tmp.append(res); // 重复cnt次res的内容 res = new StringBuilder(ch_stk.pop() + tmp.toString()); // 【】之间内容解码完毕，与【之前的拼接 }else{ res.append(ch); } } return res.toString(); }} 这题难点在于处理多位数字以及处理解码的语义。 在实现中，借助两个栈，数字栈和字符栈；同时利用一个局部变量存储当前解码内容。 比如“8[7[a6[bc]]]“，数字栈的使用也是因为会出现数字嵌套的情形。 单调栈原理单调栈就是维护一个单调递增或递减的栈。 那么，它有什么用？求下一个更大的数，就要想到单调栈。 在使用单调栈的时候首先要明确如下两点： 单调栈里存放的元素是什么？是元素的下标还是元素本身。 单调栈里元素是递增呢？ 还是递减呢？ 每日温度https://leetcode.cn/problems/daily-temperatures/ 123456789101112131415class Solution { public int[] dailyTemperatures(int[] tem) { Stack&lt;Integer&gt; stk = new Stack&lt;&gt;(); int[] ans = new int[tem.length]; stk.push(0); for(int i=1; i&lt;tem.length; ++i){ while(!stk.isEmpty() &amp;&amp; tem[i]&gt; tem[stk.peek()]){ int k = stk.pop(); ans[k] = i-k; } stk.push(i); } return ans; } 暴力做法是直接对每个元素后面的元素进行扫描，找到第一个更大的元素为止。这种做法时间复杂度是N^ 2，因为它没有考虑到每次扫描留下的信息。一次扫描后，我们就知道了整个数组的信息，但暴力法在求后一个元素的更大元素时，还是装作什么都不知道，重新再往后扫描一遍。 有什么办法能留住扫描的信息？有，用一个栈来记录我们遍历过的元素，维持单调递减的顺序。从另外一个角度出发，当前元素是哪一个元素的“下一个更大的元素”？ 采用单调栈的算法，遍历到第k个元素时，更新的是k之前的元素的答案。当栈里的元素被弹出时，它就遇到了下一个更大的元素。 下一个更大元素 https://leetcode.cn/problems/next-greater-element-i/ 12345678910111213141516171819202122232425262728class Solution { public int[] nextGreaterElement(int[] nums1, int[] nums2) { // nums1 实际上是查询集 // 哈希映射表，元素值和位置映射 Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); for(int i=0; i&lt;nums2.length; ++i){ map.put(nums2[i], i); } int[] ans = new int[nums2.length]; Arrays.fill(ans, -1); // 求next greater number Stack&lt;Integer&gt; stk = new Stack&lt;&gt;(); for(int i=nums2.length-1; i&gt;=0; --i){ //倒序遍历 while(!stk.isEmpty() &amp;&amp; stk.peek()&lt;=nums2[i]){ stk.pop(); } ans[i] = stk.isEmpty()?-1:stk.peek(); stk.push(nums2[i]); } // 结果返回 for(int i=0; i&lt;nums1.length; ++i){ int num = nums1[i]; int value = map.get(num); nums1[i] = ans[value]; } return nums1; }} 下一个更大的元素2 https://leetcode.cn/problems/next-greater-element-ii/description/ 123456789101112131415class Solution { public int[] nextGreaterElements(int[] nums) { int n = nums.length; int[] ret = new int[n]; Arrays.fill(ret, -1); Deque&lt;Integer&gt; stack = new LinkedList&lt;Integer&gt;(); for (int i = 0; i &lt; n * 2 - 1; i++) { while (!stack.isEmpty() &amp;&amp; nums[stack.peek()] &lt; nums[i % n]) { ret[stack.pop()] = nums[i % n]; } stack.push(i % n); } return ret; }} 题目大意：循环数组的下一个更大元素。 朴素的想法，将数组扩大一倍，然后应用单调栈算法实现。在更新答案时，下标映射回原来下标。 但是不必实际扩大数组，采用取模运算。 接雨水 https://leetcode.cn/problems/trapping-rain-water/ （1）暴力思路 12345678910111213141516171819202122class Solution { public int trap(int[] height) { int N = height.length; int[] left = new int[N]; //left[i] is the highest height from 0 to i int[] right = new int[N]; // right[i] is the highest hegith from i to n left[0] = height[0]; right[N-1] = height[N-1]; for(int i=1; i&lt;N; ++i){ left[i] = Math.max(height[i], left[i-1]); right[N-1-i] = Math.max(height[N-1-i], right[N-i]); } int res = 0; for(int i=1; i&lt;N-1; ++i){ int locHeight = Math.min(left[i-1], right[i+1]); if( height[i] &gt; locHeight) continue; else res += (locHeight - height[i]); } return res; }} 接雨水的本质是什么？这道题是一个数组的有条件计算，计算数组的两个大数之间凹陷的面积。最简单的思路：找出所有凹陷的面积，然后相加。 问题拆解： 一个凹陷的面积怎么计算？ 怎么识别一个凹陷？ 不能指望一个公式计算出凹陷的面积。拆分来看，要么横着算，要么竖着计算。 显然竖着计算比较简单。第k个位置，如果两边有比它大的数，说明它处在一个凹陷处，雨水的高度取决于两边最高的墙的最低那个。在计算雨水高度时，还可以利用动态规划加速。 由于每次都要遍历计算一个数两边比它大的数，可以考虑用数组存起来。 left[i] 计算从0到i最大的数 right[i]计算从i到n最大的数 总体时间复杂度O（N）。 （2）单调栈 123456789101112131415161718192021class Solution { public int trap(int[] height) { // 单调栈 水平计算 Stack&lt;Integer&gt; stk = new Stack&lt;&gt;(); int ans = 0; stk.push(0); for(int i=1; i&lt; height.length; ++i){ while(!stk.isEmpty() &amp;&amp; height[i]&gt;=height[stk.peek()]){ int mid = height[stk.peek()]; stk.pop(); if(!stk.isEmpty() ){ int w = i - stk.peek() -1; int h = Math.min(height[i],height[stk.peek()])-mid; ans += w*h; } } stk.push(i); } return ans; }} 水平计算，矩形水体的长度就是下一个更大的数。怎么理解？当前第k个位置是开始，那么长度就是nextGreate（k）-k。 那么高度怎么计算？高度就是Math.min(height[i],height[stk.peek()])-mid; 相当于两边最高的最低。 柱状图最大矩形 https://leetcode.cn/problems/largest-rectangle-in-histogram/ 123456789101112131415161718192021222324252627282930313233343536373839404142class Solution { public int largestRectangleArea(int[] h) { // first lower / next lower // 往右找第一个小于等于自己的数的下标的距离，若无，为到右边界的距离 // 往左找第一个小于等于自己的数的下标的距离，若无，为到左边界的距离 int[] rLow = new int[h.length]; int[] lLow = new int[h.length]; Stack&lt;Integer&gt; stk = new Stack&lt;&gt;(); //递增单调栈，重复利用 // for right next lower for(int i=0; i&lt;h.length;++i){ while(!stk.isEmpty() &amp;&amp; h[i]&lt;h[stk.peek()]){ int val = stk.pop(); rLow[val] = i-val; } stk.push(i); } while(!stk.isEmpty()){ int val = stk.pop(); rLow[val] = h.length-val; } // for left next lower for(int i=h.length-1; i&gt;=0; i--){ while(!stk.isEmpty() &amp;&amp; h[i]&lt;h[stk.peek()]){ int val = stk.pop(); lLow[val] = val-i; } stk.push(i); } while(!stk.isEmpty()){ int val = stk.pop(); lLow[val] = val+1; } // now walk through every column // System.out.println(Arrays.toString(rLow)); // System.out.println(Arrays.toString(lLow)); int ans = Integer.MIN_VALUE; for(int i=0; i&lt;h.length; ++i){ ans = Math.max(ans, (rLow[i]+lLow[i]-1)*h[i]); } return ans; }} 这题其实与接雨水类似，垂直计算每一个尽可能大的矩形面积。固定矩形的高度为当前元素的值，那么要获取大面积的矩形，则将宽度向两边延伸，自然求下一个更小的数。 队列队列实现栈 https://leetcode.cn/problems/implement-stack-using-queues/ 123456789101112131415161718192021222324252627282930class MyStack { private Queue&lt;Integer&gt; que1; private Queue&lt;Integer&gt; que2; //2用作缓存 public MyStack() { que1 = new LinkedList&lt;&gt;(); que2 = new LinkedList&lt;&gt;(); } public void push(int x) { while(!que1.isEmpty()){ que2.add(que1.remove()); } que1.add(x); while(!que2.isEmpty()){ que1.add(que2.remove()); } } public int pop() { return que1.remove(); } public int top() { return que1.peek(); } public boolean empty() { return que1.isEmpty(); }} 用队列模拟栈，用到了两个队列。这里的思路是：让元素在一个队列内保持栈的排列。利用辅助队列使得第一个队列的队头成为栈头。 单调队列原理维护元素单调递减或单调递增的队列就是单调队列。 主要应用场景： 求滑动窗口的最大最小值。 主要思想：队列没有必要维护窗口里的所有元素，只需要维护有可能成为窗口里最大值的元素就可以了，同时保证队列里的元素数值是由大到小的。 代码： 入队时，将元素与队尾元素比较，直到适合它的位置（保持单调）。 出队时，将滑动窗口最左侧的元素和单调队列队首元素比较，如果是同一个元素就直接出队，否则不用操作。 1234567891011121314151617class MyQueue { Deque&lt;Integer&gt; deque = new LinkedList&lt;&gt;(); void offer(int val) { while (!deque.isEmpty() &amp;&amp; val &gt; deque.peekLast()) { deque.pollLast(); } deque.offer(val); } void poll(int val) { if (!deque.isEmpty() &amp;&amp; val == deque.peekFirst()) { deque.pollFirst(); } } int peek() { return deque.peekFirst(); }} 滑动窗口求最大值https://leetcode.cn/problems/sliding-window-maximum/ 12345678910111213141516class Solution{ public int[] maxSlidingWindow(int[] nums, int k) { MyQueue myQueue = new MyQueue(); int[] ans = new int[nums.length-k+1]; for(int i=0; i&lt;k; ++i){ myQueue.offer(nums[i]); } ans[0] = myQueue.peek(); for(int i=k; i&lt;nums.length; ++i){ myQueue.poll(nums[i-k]); myQueue.offer(nums[i]); ans[i-k+1] = myQueue.peek(); } return ans; }} 优先队列（堆）原理优先队列就是在内部维护一个堆。 堆的典型应用：topK问题，一群数据中求最大的K个数。 Java堆API使用1234// 小顶堆 PriorityQueue&lt;int[]&gt; myQueue = new PriorityQueue&lt;&gt;( (o1, o2) -&gt; {return o1[1]-o2[1];}); 前k个高频元素https://leetcode.cn/problems/top-k-frequent-elements/ 123456789101112131415161718192021222324252627class Solution { public int[] topKFrequent(int[] nums, int k) { //1 统计每个元素的出现频率 Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); for(int num: nums){ map.put(num, 1+map.getOrDefault(num, 0)); } //2 小顶堆 PriorityQueue&lt;int[]&gt; myQueue = new PriorityQueue&lt;&gt;( (o1, o2) -&gt; {return o1[1]-o2[1];} ); for(Map.Entry&lt;Integer, Integer&gt; entry: map.entrySet()){ if(myQueue.size()&lt;k) myQueue.offer(new int[]{entry.getKey(), entry.getValue()}); else{ if(entry.getValue() &gt; myQueue.peek()[1]){ myQueue.poll(); myQueue.offer(new int[]{entry.getKey(), entry.getValue()}); } } } int[] ans = new int[k]; for(int i=0; i&lt;k; ++i) ans[i] = myQueue.poll()[0]; return ans; }} 数据流中位数https://leetcode.cn/problems/find-median-from-data-stream/description 12345678910111213141516171819202122232425262728class MedianFinder { private PriorityQueue&lt;Integer&gt; L; private PriorityQueue&lt;Integer&gt; S; public MedianFinder() { // [L S] 构成了一个数组 L = new PriorityQueue&lt;&gt;(Collections.reverseOrder()); // 大顶堆 S = new PriorityQueue&lt;&gt;(); // 小顶堆 } public void addNum(int num) { // keeping size S &lt;= L &lt;= S+1，即L的大小总是不小于S的大小 // L peek &lt; S peek if(L.size() == S.size()){ // 两个堆数目相等时，L可以再加数，因此将num从S过滤到L S.add(num); L.add(S.poll()); }else{ // 否则将num从L过滤到S L.add(num); S.add(L.poll()); } } public double findMedian() { if(L.size()&gt;S.size()){ //奇数长度取中间 return L.peek(); } return (L.peek()+S.peek())/2.0; }} 注意两个堆构成了一个数组，将数组升序排序，[L S] ，L复杂前半部分，S负责后半部分。 为了取中位数，维护大小 S &lt;= L &lt;= S+1，即L总是大于等于S。 添加数据时，根据L和S的大小情况，选取从S到L，还是从L到S。为什么都需要经过两次堆？因为我们不知道新加的数到底是属于哪个堆。","link":"/2024/06/03/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/Java%E6%A0%88%E4%B8%8E%E9%98%9F%E5%88%97/"},{"title":"贪心法总结","text":"贪心算法，以一个局部最优来靠近全局最优。 一周目 开胃小菜分发饼干https://leetcode.cn/problems/assign-cookies/ 很简单的思路，饼干和胃口排序。升序，类似合并链表。小饼干满足小胃口。 摆动序列 https://leetcode.cn/problems/wiggle-subsequence/ 1234567891011121314151617181920212223class Solution { public int wiggleMaxLength(int[] nums) { int period = 0; //-1 下降 1上升 int ans = 0; int guard = nums[0]; // 哨兵 for(int i=1; i&lt;nums.length;++i){ if(nums[i]&gt;guard){ if(period==-1 || period==0) { ans++; period = 1; } } else if(nums[i]&lt;guard){ if(period==1 || period==0){ ans++; period = -1; } } guard = nums[i]; } return ans+1; }} 如果连续数字之间的差严格地在正数和负数之间交替，则数字序列称为摆动序列。第一个差（如果存在的话）可能是正数或负数。少于两个元素的序列也是摆动序列。给定一个整数序列，返回作为摆动序列的最长子序列的长度。 通过从原始序列中删除一些（也可以不删除）元素来获得子序列，剩下的元素保持其原始顺序。 贪心法：考虑坡度，上坡取头尾两个数，平坡合并为一个数，下坡也只取头尾。 最大子序和 https://leetcode.cn/problems/maximum-subarray/ 给定一个整数数组 nums ，找到一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。 123- 输入: [-2,1,-3,4,-1,2,1,-5,4]- 输出: 6- 解释: 连续子数组 [4,-1,2,1] 的和最大，为 6 贪心法：从左到右，类似滑动窗口。窗口内和大于0仍旧右移。如果窗口内和小于0，窗口从下一个数字开始（left移到i+1）。 思考贪心法的正确性：假设最大和的连续子数组左下标为left，右下标为right。那么 任何在0，left-1这段区间内，以left-1为右边界的连续子数组的和都不会大于0。（否则最大和的连续子数组可以拓展），那么这个滑动窗口必然覆盖到解！ 二周目 贪心的递归（状态转移）买卖股票的最佳时机 https://leetcode.cn/problems/best-time-to-buy-and-sell-stock-ii/ 12345678910111213141516class Solution { public int maxProfit(int[] nums) { // 当天买，如果第二天价格高就卖，否则换成第二天买 int hold = nums[0]; int ans = 0; for(int i=1; i&lt;nums.length; ++i){ if(nums[i]&gt;hold){ ans += nums[i]-hold; hold = nums[i]; }else if(nums[i]&lt; hold){ hold = nums[i]; } } return ans; }} 贪心思路：可以把第x天买，第y天卖，拆成每天一卖。 我们希望获得每个“上坡”的收益，如果第二天价格更高，那就卖。如果第二天价格低，那就放弃第一天的买入。 跳跃游戏 https://leetcode.cn/problems/jump-game/ 12345678910111213class Solution { public boolean canJump(int[] nums) { if (nums.length == 1) return true; //覆盖范围, 初始覆盖范围应该是0，因为下面的迭代是从下标0开始的 int coverRange = 0; //在覆盖范围内更新最大的覆盖范围 for (int i = 0; i &lt;= coverRange; i++) { coverRange = Math.max(coverRange, i + nums[i]); if (coverRange &gt;= nums.length - 1) return true; } return false; }} 贪心思路： 每次取能跳跃的最右边界。在这左右边界内，取能跳到的最右边，作为下一个右边界。下一个左边界为当前右边界+1. 跳跃游戏2 https://leetcode.cn/problems/jump-game-ii/ 给定一个非负整数数组，你最初位于数组的第一个位置。数组中的每个元素代表你在该位置可以跳跃的最大长度。 你的目标是使用最少的跳跃次数到达数组的最后一个位置。 123456789101112131415161718class Solution { public int jump(int[] nums) { if(nums.length&lt;=1) return 0; int step = 1; int begin =0, end =nums[0]; int farest = 0; while(end&lt;nums.length-1){ //当前未到达最后一个元素 // 求在begin，end区间能达到的最远距离 for(int i=begin; i&lt;=end; ++i){ farest = Math.max(farest, i+nums[i]); } begin = end; end = farest; step++; } return step; }} 辨析：这次要求用最少的跳跃次数。和上题思路一致，当前区间找下一个区间的最大覆盖。只不过上题是一步一步走，这次要精确的跳到最大覆盖。 三周目 贪心策略加油站 https://leetcode.cn/problems/gas-station/ 将油量减去消耗量，得到一个数组。如果这个数组和为0，肯定不能环绕一圈。问题是，如果数组和大于等于0，一定能环绕一圈吗？ 证明：数组和大于0，必定存在一个区间和大于0的区间（否则所有区间和都小于0，数组和小于0，矛盾）。这里的区间指尽可能往左右延伸，使得区间和大于零。 如果只存在一个区间和大于0的区间，从这个区间起点出发，必定能环绕一周。 如果存在多个区间和大于0的区间。（不存在） 我们找长度最短的区间I，且I的和大于等于0.这个区间的左右均为负数。 所有区间+左边元素，必定和小于0，矛盾 因此只要找到区间和大于0的区间就行。 分发糖果 https://leetcode.cn/problems/candy/ 这题比较有趣，引出了一个策略：多次贪心。 第一次贪心：从左到右。使得每个孩子与它左边的孩子满足题目要求。 第二次贪心：从右到左。使得每个孩子与它右边的孩子满足题目要求。 这样两边的要求就都满足了。 根据身高重建队列 https://leetcode.cn/problems/queue-reconstruction-by-height/ 这题很有意思，知道每个人的身高，以及多少个人的身高比它高。&lt;身高，序列号&gt; 自然而然想到排序。按什么排序呢？升序还是降序？ 如果按序列号排，序列号小的排前面，序列号大的排后面。后续怎么调整？虽然说这样满足了一些序列号的性质。 按身高排序，从高到低。那么即使后面的人插入前面的人的队列中，前面的人的序列号也不会受到影响（因为后面的人的身高低），这样就提供了一种可供调整的方式。 重排字符串给定一个字符串 s ，检查是否能重新排布其中的字母，使得两相邻的字符不同。 https://leetcode.cn/problems/reorganize-string/description/ 123456789101112131415161718192021222324252627282930313233343536class Solution { public String reorganizeString(String S) { char[] alphabetArr = S.toCharArray(); int[] alphabetCount = new int[26]; int length = S.length(); for (int i = 0; i &lt; length; i++) { alphabetCount[alphabetArr[i] - 'a']++; } int max = 0, alphabet = 0, threshold = (length + 1) &gt;&gt; 1; for (int i = 0; i &lt; alphabetCount.length; i++) { if (alphabetCount[i] &gt; max) { max = alphabetCount[i]; alphabet = i; if (max &gt; threshold) // 无法构成 return &quot;&quot;; } } // 构造返回字符串 char[] res = new char[length]; int index = 0; while (alphabetCount[alphabet]-- &gt; 0) { res[index] = (char) (alphabet + 'a'); index += 2; } for (int i = 0; i &lt; alphabetCount.length; i++) { while (alphabetCount[i]-- &gt; 0) { if (index &gt;= res.length) { index = 1; } res[index] = (char) (i + 'a'); index += 2; } } return new String(res); }} 这道题首先的想法就是获取每个字符的个数。 最初的想法，我先取出个数最多的字符，排成一列。再将其他字符填进去。虽然这个思路成功得出，如果存在个数大于总数一半的字符，则无法构成题目要求的字符串。但后续思路却并不好想，当字符个数接近平均时，后续怎么放字符？ 正确的思考方向是从整体考虑：字符串有多长，坑位就有多少个。坑位是定的。前一种思考方法，坑位是不定的。 （1）为了达到不相邻的效果，字符肯定是隔一位置放一个，那么刚开始怎么放？放第一个位置还是第二个位置？ （2）从奇数位置个数总是大于等于偶数位值个数（下标从1开始），从第一个位置开始放比较好点。 思路：将字符个数排降序，从最多的字符开始，从第一个位置开始，隔一个放一个。奇数位置放满后，放偶数位置。 多数元素2给定一个大小为 n 的整数数组，找出其中所有出现超过 ⌊ n/3 ⌋ 次的元素。 https://leetcode.cn/problems/majority-element-ii/ 1234567891011121314151617181920212223242526272829303132333435class Solution { public List&lt;Integer&gt; majorityElement(int[] nums) { int[] candidate = new int[2]; int[] vote = new int[2]; int[] count = new int[2]; for(int num:nums){ if(candidate[0]==num){ vote[0]++; }else if(candidate[1]==num){ vote[1]++; }else if(vote[0]==0){ candidate[0]=num; vote[0]++; }else if(vote[1]==0){ candidate[1]=num; vote[1]++; }else{ // 相消，放入抽屉 vote[0]--; vote[1]--; } } for(int num:nums){ if(vote[0]&gt;0 &amp;&amp; candidate[0]==num) count[0]++; if(vote[1]&gt;0 &amp;&amp; candidate[1]==num) count[1]++; } List&lt;Integer&gt; ans = new ArrayList&lt;&gt;(); if(vote[0]&gt;0 &amp;&amp; count[0]&gt; nums.length/3) ans.add(candidate[0]); if(vote[1]&gt;0 &amp;&amp; count[1]&gt; nums.length/3) ans.add(candidate[1]); return ans; }} 首先看一道相关题目：lc 169 众数 12345678910111213class Solution { public int majorityElement(int[] nums) { int count = 0; Integer candidate = null; for (int num : nums) { if (count == 0) { candidate = num; } count += (num == candidate) ? 1 : -1; } return candidate; }} 采用摩尔投票算法，只需遍历一遍数组就能知道众数。 怎么从「摩尔投票法」拓展到多数元素2？将消除的过程从一个坑位拓展到两个坑位！ 个人理解摩尔投票法本质上就是宾果消消乐游戏，每次消除3个不同的数。由于数组长度为n，因此消消乐最多进行[n/3]次。因此，我们想要的答案（超过[n/3]的数字）一定没有被消除完，一定存在最后活下来的两个数当中。 但是，存活的两个数不一定都是想要的真正的答案，最后再遍历确认一下这两个数是不是答案即可。 证明的核心就是抽屉原理。（抽屉原理：N+1个苹果放在N个抽屉，至少有一个抽屉有2个及以上的苹果） （1）众数 相消的过程其实就是提取一个相异元素对的过程。我们可以构造容量为2的抽屉，这个抽屉只能放不同的元素。 有多少个抽屉？最多 ⌊ n/2 ⌋个罢了。而我们知道，众数是超过 ⌊ n/2 ⌋个的，每个抽屉最多放1个众数， 最后留下来的自然就是众数。 （2）超过 ⌊ n/3 ⌋ 次的元素 其实上面的过程还有一个逻辑，就是众数只有1个。回到本题，超过 ⌊ n/3 ⌋ 次的元素（这里称之为次众数吧）最多只有2个（证明过程留给读者）。 我们可以仿造上面的证明过程，构造容量为3的抽屉，每个抽屉中的元素互不相同，最多有 ⌊ n/3 ⌋个抽屉。那么超过 ⌊ n/3 ⌋的元素自然在相消的过程中留了下来。 算法：构造容量为2的候选集，遍历数组元素，如果当前元素与候选集都不同，则互相消去（放入一个抽屉）。如果当前元素与候选集中的一个元素相同，则那个元素的计数加一。最后检验候选集里的元素是否满足要求。 时间复杂度O（N），空间复杂度O（1）。 （3）拓展：超过 ⌊ n/k ⌋的元素 算法：构造容量为k-1的候选集，重复上面所述的遍历行为，最后检验一下。 证明：依然是构造容量为k的抽屉，每个抽屉中的元素互不相同，最多有 ⌊ n/k ⌋个抽屉。那么超过 ⌊ n/k ⌋的元素自然在相消的过程中留了下来。 四周目 区间贪心区间贪心原理区间不相交问题：给定N个开区间，找出尽可能多的开区间，两两不相交。 区间选点问题：给定N个闭区间，确定最少需要几个点，使得每个闭区间都覆盖到点。 区间不相交问题（1）排序 区间贪心总是要先排序，假设按照左端点升序排序。 （2）从区间包含讲起 如果区间A包含区间B，那么选不相交的区间时，肯定选B，因为B更小，能够让出更多的空间。在刨除了区间包含的情况后，此时各区间的情况是类似阶梯形。 考虑第一段区间的左端点到第二段区间的左端点部分，这一部分是肯定没有重叠的。考虑去掉它，那么第一段区间就包含第二段区间内了，这时候肯定选第一段区间。 （3）策略 按照区间左端点排序，然后总是选择右端点最小的区间。 123456789//区间不相交问题模版int ans=1; //选中初始区间int last_y = I[0].y;for(int i=1; i&lt;N; ++i){ if(I[i].x &gt;= last_y){ last_y = I[i].y; //更新区间的最右端点 ans++; }} 区间选点问题区间选点问题也是同样的，如果存在区间包含的情况，选择被包含的区间，因为它覆盖到了更多的区间。 排序过后，对于第一段相交区间，选哪个点能够让它覆盖尽可能多的区间？是第一个区间的右端点还是第二个区间的左端点？当然是第一个区间的右端点，因为它更靠右，能够覆盖更多区间。 123456789//区间选点问题模版int ans=1; int last_y = I[0].y;for(int i=1; i&lt;N; ++i){ if(I[i].x &gt; last_y){ //此时区间不相交 last_y = I[i].y; ans++; }} 最少数量的箭引爆气球 https://leetcode.cn/problems/minimum-number-of-arrows-to-burst-balloons/ 1234567891011121314151617181920212223class Solution { public int findMinArrowShots(int[][] points) { // 对points按照左端点升序排序 Arrays.sort(points, (a1, a2) -&gt; { if(a1[0] == a2[0]) return a1[1] &gt; a2[1] ? 1 : -1; return a1[0] &gt; a2[0] ? 1 : -1; }); // System.out.println(Arrays.deepToString(points)); int ans = 1; int last_y = points[0][1]; for(int i=1; i&lt;points.length; ++i){ // 判断区间是否相交 if(points[i][0] &gt; last_y){ ans++; last_y = points[i][1]; }else{ //总是选右端点小的那个,去除包含情况 last_y = Math.min(last_y, points[i][1]); } } return ans; }} 其实就是找最多的不相交区间。不相交的区间都需要一只箭射。其他与之相交的区间可以通过调箭的位置使之射中。 无重叠区间 https://leetcode.cn/problems/non-overlapping-intervals/ 1234567891011121314151617class Solution { public int eraseOverlapIntervals(int[][] intervals) { // 使用Integer内置比较方法，不会溢出 Arrays.sort(intervals, (a, b) -&gt; Integer.compare(a[0], b[0])); int ans = 1; int last_y = intervals[0][1]; for(int i=1; i&lt;intervals.length; ++i){ if(intervals[i][0] &gt;= last_y){ ans++; last_y = intervals[i][1]; }else{ last_y = Math.min(last_y, intervals[i][1]); } } return intervals.length - ans; }} 给定一个区间的集合，找到需要移除区间的最小数量，使剩余区间互不重叠。 思路：其实就是找最多不相交区间。区间总数减去这个数就是要移除的区间数目。 合并区间 https://leetcode.cn/problems/merge-intervals/ 1234567891011121314151617class Solution { public int[][] merge(int[][] intervals) { Arrays.sort(intervals, (a, b) -&gt; Integer.compare(a[0], b[0])); List&lt;int[]&gt; ans = new LinkedList&lt;&gt;(); int left = intervals[0][0]; int right = intervals[0][1]; for(int i=1; i&lt;intervals.length; ++i){ if(intervals[i][0] &gt; right){ ans.add(new int[]{left, right}); left = intervals[i][0]; } right = Math.max(right, intervals[i][1]); } ans.add(new int[]{left, right}); return ans.toArray(new int[0][0]); }} 这个就是贪心思路，相交区间一直合并，直到遇到不相交的区间。 划分字母区间 https://leetcode.cn/problems/partition-labels/ 字符串 S 由小写字母组成。我们要把这个字符串划分为尽可能多的片段，同一字母最多出现在一个片段中。返回一个表示每个字符串片段的长度的列表。 123- 输入：S = &quot;ababcbacadefegdehijhklij&quot;- 输出：[9,7,8] - 解释： 划分结果为 &quot;ababcbaca&quot;, &quot;defegde&quot;, &quot;hijhklij&quot;。 每个字母最多出现在一个片段中。 像 &quot;ababcbacadefegde&quot;, &quot;hijhklij&quot; 的划分是错误的，因为划分的片段数较少。 1234567891011121314151617181920class Solution { public List&lt;Integer&gt; partitionLabels(String s) { //有点像跳跃区间,jump[i] 记录字母i最后出现的位置 int[] jump = new int[26]; for(int i=0; i&lt;s.length();++i){ jump[s.charAt(i)-'a'] = i; } List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); // 以l，r区间开始查找 int l=0, r=0; for(int i=0; i&lt;s.length(); ++i){ r = Math.max(r, jump[s.charAt(i)-'a']); if(i==r){ list.add(r-l+1); l = r+1; } } return list; }} 思路：这道题类似合并区间。将每个字母第一次出现的位置看成区间的左端点，最后一次出现的位置看成区间的右端点。那么重叠的区间就必须合并（否则一个字母出现在两个划分中）。 具体实现有技巧。 统计每一个字符最后出现的位置 从头遍历字符，并更新字符的最远出现下标，如果找到字符最远出现位置下标和当前下标相等了，则找到了分割点 五周目单调递增的数字https://leetcode.cn/problems/monotone-increasing-digits/description/ 给定一个非负整数 N，找出小于或等于 N 的最大的整数，同时这个整数需要满足其各个位数上的数字是单调递增。 1 从后往前调整，如果k+1位的数字小于第k位的数字，那么调整第k+1位的数字为9，第k位数字减一。重复这个过程，直至遍历完。 监控二叉树 https://leetcode.cn/problems/binary-tree-cameras/ 1 这个贪心策略就是：隔一层放一个摄像头。让叶子结点的父亲放置摄像头。","link":"/2024/06/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/Java%E8%B4%AA%E5%BF%83%E6%B3%95/"},{"title":"链表总结","text":"链表的题目多涉及指针操作，需要画图显示步骤，不然容易搞混。 常用的套路有： 双指针（前驱后继指针、快慢指针、奇偶指针） 虚拟头节点（好处：需要前驱节点时，总能找到前驱节点。比如在删除头节点时，我们可以找到头节点的前驱。） 设计链表 https://leetcode.cn/problems/design-linked-list/description/ 从0开始设计一个链表，实现get、add、delete方法 链表首先要声明链表节点 123456789class ListNode { int val; ListNode next; ListNode(){} ListNode(int val) { this.val = val; this.next = null; }} 再设计链表类 123456789101112131415161718192021class MyLinkedList { int size; //长度 ListNode head; //虚拟头节点 public MyLinkedList() { //假设链表中的所有节点下标从 0 开始。 size = 0; head = new ListNode(-1); } public int get(int index) { //如果下标无效，则返回 -1 } public void addAtIndex(int index, int val) { //将一个值为 val 的节点插入到链表中下标为 index 的节点之前 } public void deleteAtIndex(int index) { //如果下标有效，则删除链表中下标为 index 的节点 }} 我们首先实现get方法。 123456789public int get(int index) { //如果下标无效，则返回 -1 if(index&lt;0 || index&gt;=size) return -1; ListNode cur = head; //链表下标从0开始计算 for(int i=0; i&lt;=index; ++i) cur = cur.next; return cur.val;} 再看delete方法，这里就能看到虚拟头节点的好处了。删除一个节点需要知道它的前驱节点，让它的前驱指向它的后继；如果要删除0号节点即头节点，没有虚拟头节需要额外判断； 12345678910111213public void deleteAtIndex(int index) { //如果下标有效，则删除链表中下标为 index 的节点 if (index &lt; 0 || index &gt;= size) return; ListNode cur = head; //注意要让cur指向index的前驱 //所以判断i&lt;index for(int i=0; i&lt;index; ++i) cur = cur.next; //跳过cur的next cur.next = cur.next.next; //这里需要注意java的自动回收机制，不需要delete --size;} 最后看add方法。 1234567891011121314public void addAtIndex(int index, int val) { //将一个值为 val 的节点插入到链表中下标为 index 的节点之前 if (index &gt; size) return; if (index &lt; 0) index = 0; ListNode cur = head; //注意要让cur指向index的前驱 for(int i=0; i&lt;index; ++i){ cur = cur.next; } ListNode tmp = new ListNode(val); tmp.next = cur.next; cur.next = tmp; ++size;} 双指针应用移除特定链表元素 https://leetcode.cn/problems/remove-linked-list-elements/ 1234567891011121314151617181920class Solution { public ListNode removeElements(ListNode head, int val) { ListNode dummyNode = new ListNode(-1); dummyNode.next = head; ListNode pre = dummyNode; ListNode cur = dummyNode.next; while(cur != null){ // 对cur进行 遍历 if(cur.val == val){ pre.next = cur.next; cur = pre.next; continue; //找下一个 } //找下一个 pre = cur; cur = cur.next; } return dummyNode.next; }} 移除链表中某个特定节点需要知道它的前驱和后继，所以设立前后指针；虚拟头节点方便删除。 删除链表的倒数第N个节点 https://leetcode.cn/problems/remove-nth-node-from-end-of-list/ 123456789101112131415161718class Solution { public ListNode removeNthFromEnd(ListNode head, int n) { ListNode dummyNode = new ListNode(-1); dummyNode.next = head; ListNode first = dummyNode; ListNode second = dummyNode; // second run n step for(int i=0; i&lt;n; ++i){ second = second.next; } while(second != null &amp;&amp; second.next !=null) { //删除节点需要找到它的前驱 second = second.next; first = first.next; } first.next = first.next.next; return dummyNode.next; }} 快慢指针应用，快指针先走N步，然后再走到底。 相交链表https://leetcode.cn/problems/intersection-of-two-linked-lists/ 12345678910111213public class Solution { public ListNode getIntersectionNode(ListNode headA, ListNode headB) { if(headA==null || headB==null) return null; ListNode x=headA, y =headB; while(x!=y) { if (x==null) x = headB; else x = x.next; if (y==null) y = headA; else y = y.next; } return x; }} 双指针的比较巧妙应用，利用 $x+y = y+x $的思想，走到底之后还可以重头再走一遍。 环形链表https://assets.leetcode-cn.com/aliyun-lc-upload/uploads/2018/12/14/160_statement.png 123456789101112public class Solution { public boolean hasCycle(ListNode head) { if(head==null||head.next==null)return false; ListNode slow=head, fast=head; while(fast!=null){ fast = (fast.next==null)?fast.next:fast.next.next; slow = slow.next; if(fast==slow)return true; } return false; }} 快慢指针的典型应用，判断链表中是否有环。 环形链表入口节点https://leetcode.cn/problems/linked-list-cycle-ii/ 1234567891011121314151617181920212223public class Solution { public ListNode detectCycle(ListNode head) { if(head == null) return head; ListNode slow = head; ListNode fast = head; while(fast!=null){ if(fast.next != null) fast = fast.next.next; else fast = fast.next; slow = slow.next; if(fast == slow) break; } if(fast == null) return null; //相遇点 fast = head; while(fast != slow){ fast = fast.next; slow = slow.next; } return fast; }} 这道题难点在于找出环入口节点。解体的关键在于两个点： 假设head到环入口节点的长度为a，环的长度为len，相遇时距离环入口的偏移为offset 当一个指针走 a + k*len步时，它一定在环入口处 推理： f = 2*s s = a + offset + k1*len f = a + offset + k2*len 得到 f-s = k3*len = s 即 s 走了整数倍len，f走了整数倍len。 因此只要相遇后，将fast移到头节点，一步一步走再走a步，一定和slow碰面在入口之处。 迭代法（复杂指针操作）翻转链表 https://leetcode.cn/problems/reverse-linked-list/ (1) 迭代方式反转 123456789101112131415class Solution { public ListNode reverseList(ListNode head) { // 迭代法 ListNode prev = null; ListNode cur = head; ListNode tmp = null; while(cur != null){ tmp = cur.next; cur.next = prev; prev = cur; cur = tmp; } return prev; }} 迭代方式翻转，自然需要两个指针; 需要注意的是翻转前后的尾巴null处理 pre指向已经翻转的链表头节点，初始为null； cur指向下一个要翻转的节点，初始为head （2）递归方式反转 1234567891011121314class Solution { public ListNode reverseList(ListNode head) { //空链表和单个链表无需反转，直接返回 if(head==null) return null; if(head.next==null) return head; //这里假设head.next的开头的链表完成了反转，返回反转后的头节点 ListNode prev = reverseList(head.next); //now we have to do is //reverse head.next and head head.next.next = head; head.next = null; return prev; }} 翻转部分链表 https://leetcode.cn/problems/reverse-linked-list-ii/ 123456789101112131415161718192021222324252627class Solution { public ListNode reverseBetween(ListNode head, int left, int right) { //o(n)的算法 ListNode dummyHead = new ListNode(-1); dummyHead.next = head; ListNode pre = dummyHead; //1 找到left的前驱 for(int i=0; i&lt;left-1; ++i){ pre = pre.next; } ListNode tmp1 = pre; ListNode tmp2 = pre.next; // 2 反转部分 ListNode prev = null; ListNode curr = pre.next; //注意这里多反转一单位长度 for(int i=0; i&lt;= right-left; ++i){ ListNode tmp = curr.next; curr.next = prev; prev = curr; curr = tmp; } tmp1.next = prev; tmp2.next = curr; return dummyHead.next; }} 反转特定范围内的链表，需要注意边界条件。 两两交换链表节点 迭代方式自然需要保存多个指针，修改互相的引用，然后顺序遍历下去。 为了使得处理更加顺畅，引入虚拟头节点 如果被指针指向的顺序搞懵，不如多声明几个变量，保存节点 两两反转需要两个变量 迭代处理，需要前驱和后继，又要两个变量 总共四个变量 12345678910111213141516171819202122232425class Solution { public ListNode swapPairs(ListNode head) { ListNode dummyHead = new ListNode(-1); dummyHead.next = head; ListNode prev = dummyHead; ListNode curr = prev.next; if(curr==null || curr.next==null) return head; ListNode nest = curr.next; ListNode tmp = nest.next; while(curr!=null){ // reverse nest.next = curr; curr.next = tmp; prev.next = nest; // iteration prev = curr; if(prev.next==null) break; curr = prev.next; if(curr==null||curr.next==null) break; nest = curr.next; tmp = nest.next; } return dummyHead.next; }} 简洁写法 12345678910111213141516171819class Solution { public ListNode swapPairs(ListNode head) { ListNode dummyHead = new ListNode(-1); dummyHead.next = head; ListNode prev = dummyHead; while(prev.next!=null &amp;&amp; prev.next.next!=null){ ListNode curr = prev.next; ListNode nest = curr.next; ListNode tmp = nest.next; // reverse nest.next = curr; curr.next = tmp; prev.next = nest; // iteration prev = curr; } return dummyHead.next; }} 巧妙递归翻转部分链表 https://leetcode.cn/problems/reverse-linked-list-ii/ 12345678910111213141516171819class Solution { // 反转head开头的N个节点 ListNode reverseN(ListNode head, int N){ if(head==null || N==1) return head; ListNode rHead = reverseN(head.next, N-1); ListNode tmp = head.next.next; head.next.next = head; head.next = tmp; return rHead; } public ListNode reverseBetween(ListNode head, int left, int right) { if(left == 1){ return reverseN(head, right); } // 索引减1 ListNode rHead = reverseBetween(head.next, left-1, right-1); head.next = rHead; return head; } 主要思想：将left和right堪称相对于头节点的索引。当left为1时，题目归化为反转开头N个节点。 K个一组翻转链表 https://leetcode.cn/problems/reverse-nodes-in-k-group/description/ 123456789101112131415161718192021222324class Solution { // 反转开头N个节点，并返回反转后的头节点 public ListNode reverseN(ListNode head, int N){ if(N==1) return head; ListNode rHead = reverseN(head.next, N-1); ListNode tmp = head.next.next; head.next.next = head; head.next = tmp; return rHead; } public ListNode reverseKGroup(ListNode head, int k) { // 不足N个直接返回 ListNode count = head; for(int i=0; i&lt;k; ++i){ if(count!=null) count = count.next; else return head; } // 先反转开头N个 ListNode rHead = reverseN(head, k); // 递归反转 head.next = reverseKGroup(head.next, k); return rHead; }} 思想：反转前K个后，第K+1个节点还是一样处理。 两两交换链表中的节点 https://leetcode.cn/problems/swap-nodes-in-pairs/ 1234567891011class Solution { public ListNode swapPairs(ListNode head) { if(head==null||head.next==null) return head; ListNode headNext = head.next; ListNode tmp = swapPairs(headNext.next); headNext.next = head; head.next = tmp; return headNext; }} 其实就是K一组翻转链表，K=2的情形。 判断回文链表123456789101112131415class Solution { public ListNode left; public boolean isPalindrome(ListNode head) { left = head; return traverse(head); } public boolean traverse(ListNode head){ if(head == null) return true; boolean res = traverse(head.next); if(left.val != head.val) return false; left = left.next; return res; }} 这个写法比较邪门，将链表想象成一颗退化的树，借助left存储最左端的点，递归一直到最右端，然后判断左右是否相等。 合并链表合并两个有序链表https://leetcode.cn/problems/merge-two-sorted-lists 1234567891011121314151617181920212223class Solution { public ListNode mergeTwoLists(ListNode list1, ListNode list2) { if(list1==null) return list2; if(list2==null) return list1; ListNode dummyHead = new ListNode(-1); ListNode op = dummyHead; while(list1!=null &amp;&amp; list2!=null){ ListNode tmp = new ListNode(-1); if(list1.val &lt; list2.val){ tmp.val = list1.val; list1 = list1.next; }else{ tmp.val = list2.val; list2 = list2.next; } op.next = tmp; op = op.next; } if(list1!=null) op.next =list1; if(list2!=null) op.next =list2; return dummyHead.next; }} 合并K个有序链表https://leetcode.cn/problems/vvXgSW/ 1234567891011121314151617181920212223242526272829303132class Solution { public ListNode meregeTowListInplace(ListNode head1, ListNode head2){ ListNode op1 = head1; ListNode op2 = head2; ListNode dummyHead = new ListNode(-1); ListNode op3 = dummyHead; while(op1!=null &amp;&amp; op2!=null){ if(op1.val &lt; op2.val){ op3.next = op1; op1=op1.next; }else{ op3.next = op2; op2=op2.next; } op3 = op3.next; } if(op1!=null) op3.next = op1; if(op2!=null) op3.next = op2; return dummyHead.next; } public ListNode MergeSort(ListNode[] lists, int start, int end){ if(start&gt;=end) return lists[start]; int mid = (end-start)/2 + start; ListNode head1 = MergeSort(lists, start, mid); ListNode head2 = MergeSort(lists, mid+1, end); return meregeTowListInplace(head1, head2); } public ListNode mergeKLists(ListNode[] lists) { if(lists.length==0) return null; return MergeSort(lists, 0, lists.length-1); }} 链表合并，天然适合二路归并算法。合并两条链表算法很简单，并且原地操作。合并2条链表后，可以再合并4条链表，8条链条，最终合并全部链表！ 解法二：堆 12345678910111213141516171819202122232425class Solution { public ListNode mergeKLists(ListNode[] lists) { if (lists == null || lists.length == 0) return null; PriorityQueue&lt;ListNode&gt; pq = new PriorityQueue&lt;&gt;(lists.length, new Comparator&lt;ListNode&gt;() { @Override public int compare(ListNode o1, ListNode o2) { if (o1.val &lt; o2.val) return -1; else if (o1.val == o2.val) return 0; else return 1; } }); for(ListNode node: lists){ if(node!=null) pq.offer(node); } ListNode dummyHead = new ListNode(-1); ListNode op = dummyHead; while(!pq.isEmpty()){ op.next = pq.poll(); op = op.next; if(op.next!=null) pq.add(op.next); } return dummyHead.next; }} 想清楚操作的顺序，再写代码，不然逻辑混乱，越改越错！ 算法思想：K个升序链表，每次我们都要取最小的。利用升序的特性，我们可以知道最小元素只在每个链表的头部产生。 这个过程抽象为从一个候选集合中取最小值，自然想到堆数据结构。 算法步骤： 1、先取K个链表头部元素建立堆； 2、从堆中取一个，那下一个最小的元素，只可能从取中节点所在的链表产生。所以从那个链表头部取一个节点。 3、不断取一个补一个，最后再将堆中的元素全部取出的即可。 排序链表https://leetcode.cn/problems/sort-list 1234567891011121314151617181920212223242526272829303132333435363738394041class Solution { public ListNode meregeTowListInplace(ListNode head1, ListNode head2){ ListNode op1 = head1; ListNode op2 = head2; ListNode dummyHead = new ListNode(-1); ListNode op3 = dummyHead; while(op1!=null &amp;&amp; op2!=null){ if(op1.val &lt; op2.val){ op3.next = op1; op1=op1.next; }else{ op3.next = op2; op2=op2.next; } op3 = op3.next; } if(op1!=null) op3.next = op1; if(op2!=null) op3.next = op2; return dummyHead.next; } public ListNode mergeSort(ListNode head){ if(head==null||head.next==null) return head; // 首先将一条链表分为前后两半链表 // 偶数长度链表的中间节点在后一半的第一个节点上 ListNode slow =head, fast =head.next; while(fast!=null &amp;&amp; fast.next!=null){ fast = fast.next.next; slow = slow.next; } // 此时slow指向前一半的最后个节点 // 根据slow将链表分为两半 ListNode secondHead = slow.next; slow.next=null; ListNode head1 = mergeSort(head); ListNode head2 = mergeSort(secondHead); return meregeTowListInplace(head1, head2); } public ListNode sortList(ListNode head) { return mergeSort(head); }} 重排链表https://leetcode.cn/problems/reorder-list/description/ 123456789101112131415161718192021222324252627282930313233class Solution { public ListNode reverse(ListNode head){ if(head==null || head.next ==null) return head; ListNode tmp = reverse(head.next); head.next.next = head; head.next =null; return tmp; } public void reorderList(ListNode head) { // 获取后一半链表 if(head==null || head.next ==null) return ; ListNode slow = head; ListNode fast = head.next; while(fast!=null &amp;&amp; fast.next!=null){ slow = slow.next; fast = fast.next.next; } // 反转后一半 ListNode head2 = reverse(slow.next); slow.next =null; // 合并两条链表 ListNode head1 = head; while(head2!=null){ ListNode tmp1 = head1.next; ListNode tmp2 = head2.next; head1.next = head2; head2.next = tmp1; head1 = tmp1; head2 = tmp2; } return ; }} 技术细节：快慢指针+反转链表 其他判断回文链表 https://leetcode.cn/problems/palindrome-linked-list/ 123456789101112131415161718192021222324252627class Solution { public ListNode reverseList(ListNode head){ if(head==null || head.next==null) return head; ListNode tmp = reverseList(head.next); head.next.next = head; head.next =null; return tmp; } public boolean isPalindrome(ListNode head) { if(head==null || head.next==null) return true; ListNode slow =head, fast = head; // 排除了空节点和单节点的情况后，剩下至少两个节点 while(fast!=null &amp;&amp; fast.next!=null){ fast = (fast.next==null)? fast.next:fast.next.next; slow = slow.next; } ListNode LastHalfNode = reverseList(slow); while(LastHalfNode!=null &amp;&amp; head!=null){ if (LastHalfNode.val != head.val){ return false; } LastHalfNode = LastHalfNode.next; head = head.next; } return true; }} 暴力的做法是开辟额外空间存储遍历后数组的值，再用双指针前后夹击判断。思考空间复杂读O（1）的算法，自然的想法是翻转一半的链表，然后比较两条链表。 （1）获取中间节点 方法是快慢指针。问题来了，奇数长度中间节点是确定的，偶数长度链表的中间节点是哪一个？答案是取决于快慢指针的具体实现，有可能是前一半的最后一个节点，也有可能是后一半的第一个节点。 12345ListNode slow =head, fast = head;while(fast!=null &amp;&amp; fast.next!=null){ fast = (fast.next==null)? fast.next:fast.next.next; slow = slow.next;} （2）偷懒的一个技巧 直接比较两条链表，不比较长度，奇数长度情况下最后一个节点不会被比较。 升序矩阵寻找第K个大小的元素https://leetcode.cn/problems/kth-smallest-element-in-a-sorted-matrix/description/ 12345678910111213141516171819202122232425262728293031323334353637class Solution { class Status implements Comparable&lt;Status&gt;{ public int val; public int x; public int y; Status(int val, int x, int y){ this.val = val; this.x = x; this.y = y; } @Override public int compareTo(Status st){ if(this.val &lt; st.val) return -1; if(this.val &gt; st.val) return 1; return 0; } } public int kthSmallest(int[][] matrix, int k) { PriorityQueue&lt;Status&gt; pq = new PriorityQueue&lt;&gt;(); int N = matrix.length; //添加第一列 for(int i=0; i&lt;N; ++i) pq.offer(new Status(matrix[i][0], i, 0)); //然后每次取一个，加一个 while(k&gt;1){ Status st = pq.poll(); if(st.y &lt; N-1){ // 如果这一行还没取完，就继续取 int new_x = st.x; int new_y = st.y+1; pq.offer(new Status(matrix[new_x][new_y], new_x, new_y)); } k--; } Status st = pq.poll(); return st.val; }} 这道题的思想和合并K个升序链表一摸一样。但是忽略了列间的单调上升关系。","link":"/2023/12/12/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/Java%E9%93%BE%E8%A1%A8%E6%80%BB%E7%BB%93/"},{"title":"关于教育","text":"中国教育 中国教育 一个很可悲的事实，我们的教育，是筛选制，不是培养制，并不是想着把你培养成人才，而是替企业筛选出尖子，一层一层的筛选。那怎么筛选呢？就应试教育，靠分数。但是你说你有什么天赋，需要培养。对不起，看你的家庭。如果你父母不培养你，不给你砸钱，那你这个天赋基本白搭。 初高中选拔制度不仅仅是高中生，中国年轻一代的所有人，最缺的是试错机会 试错机会无比重要原因只在于，极少有人能够一生下来就目标明确知道自己这辈子想要什么想做什么。试图找到自己想做的事情，明确自己的人生目标和意义所在，靠想，迷茫，都不会得到结果，只有去行动，去试错，去尝试，才可能去发现自己的天赋特长和热爱 但不幸的是从初中开始，尝试和试错的机会教育制度和学校就不愿意提供给你，从一生下来开始就固定一条路上走着，教育系统不鼓励你尝试，更不会提供选择：高中文理科开始分班，想再调回去是不可能的，高中没有任何一个人会告诉你大学专业设置的意义和实际所学以及就业前景，高考结束后大部分人都是在不了解不清楚想当然的情况下填报了志愿，到了大学之后如果发现不喜欢该专业，想换专业更是难上加难，而大学毕业时候同样没有人会在乎你，会跟你提到就业情况和商业社会的实际情况，也不会有足够多的实习机会向你提供 与其说是你一开始选择了专业，不如说专业定义了你的人生道路，不管你是否擅长是否热爱 中国的教育不仅仅是和实际就业断层的，甚至基础教育跟高等教育互相之间都是断层的，高中开始是圈养，大学开始是放养，在这之中，任何一个人想要去试错的成本都非常高，天资聪颖的人在浪费时间，天资一般的人在饱受煎熬。除非一个学生的家境财力达到足够无视一切制度的程度，能够让他去不断试错和尝试，否则大部分人，都找不到自己的热爱，只好苟且的茫茫然过一生。 https://www.zhihu.com/question/23933304/answer/26143004 大学教育​ XXX的教学质量奇差无比，教学目的根本不是让学生学会知识，而是老师完成任务打卡交差。能考上XXX这种名校的学生都是学习能力很强的人，学生完全自学也能学的不错。然而XXX的教学模式不仅对学生学习帮助极小，而且简直是故意拖你的后腿，给你的学习计划添乱。 ​ 绝大部分老师上课只是为了完成任务，根本不管教学效果如何。这些老师很多科研水平很强，但是在教学方面却完全不行。上课完全是照本宣科，90分钟的上课时间把书上20页的东西总结一下念完即可。要知道大学的课本知识密度本来就很大，20页逻辑关系很复杂的文字，即便看上一整天，能完全理解也不容易。而老师上课就是念完一个公式念下一个公式，念完一个定义念下一个定义。如果你能听懂，那只有一种可能，就是你上课之前就已经会了。我在科大学了4年，几乎没有听懂过课，全靠看书自学。我当然怀疑是自己的水平有问题，但是为什么我的成绩能比一半以上的人高呢？结论就是大家都听不懂。老师讲课就不是为了让你听懂，而是工作打卡，老师也从来不会调查大家听没听懂，因为学生听不懂这件事老师心知肚明。 ​ 留作业的目的完全不是教学，而是产生正态分布的成绩用来期末评定GPA。作业量极大，难度极高，且不提供答案，老师不会讲解作业。平均两个月开一次习题课，由高年级学生担任助教来讲解。作业够多够难才能保证不是所有学生都能完成，成绩才会是正态分布。而留这些作业不讲又容易遭人质疑，所以每两个月开一次习题课吧，堵上质疑作业者的嘴。助教讲习题课的质量参差不齐，不排除有少部分助教很负责任讲的很好，但也有一半以上的助教习题课讲的很敷衍。敷衍的方式比如一边拿黑板当草稿纸演算一边嘴里嘟嘟囔囔，前言不搭后语，或者把大部分试题一句话带过，随便摆一两个公式然后直接出结果。试问难度相当于高考数学导数大题的作业题，这么个讲法真是为了让学生听懂？试问100道难度相当于高考数学导数大题的作业，两个月之后花1小时讲完，不说你能不能听懂，你还记得题是什么么？你还记得2个月前自己什么地方有疑问么？ ​ 其实作业安排的不合理与成绩评定规则有关。XXX要求任何一门课85分以上为优秀，一个班级优秀率不能超过40%。不论大家学得多么努力，都注定有大部分人无法取得满意的成果。而且如果大家都能做好作业、考好期末，那只能靠强行向下调分，有可能引起学生的不满。所以老师布置作业考试的时候，其目的就不是为了帮助学生学习，而是为了让一部分学生无法完成，方便成绩评定。所以作业才会又多又难不给答案。我认为做作业题遇到困难马上有详细解答参考是非常有助于学习的，然而学生要是都能学会，都能写出作业，还怎么卡40%优秀率？所以这个答案万万不能给，习题课也万万不能产生pdf习题解，那样下一届学生有了这个就都能写出作业了！老师就是觉得反正我40%优秀率卡的好，提交成绩时候教务处就不会找我麻烦。至于学生能不能学会，那跟我有什么关系，反正我已经完成完成教学任务溜之大吉了！ ​ 成绩评定规则还助长内卷。还有大家为了拿到好成绩，会在意义不大的地方内卷。比如大学物理实验，有些学生会写很长很长的实验报告，而且故意不用打字而是手写，成段成段的手抄百度词条，显得自己工作量很大，比别人做的好。谁不知道这样做没有意义，但是规则就是这样。谁愿意做这个没有意义的工作，谁就能拿到好成绩。其实我在校时一直在各个学生论坛呼吁，写这种又臭又长的报告应该倒扣分，但是响应者寥寥。 不知道是不是我的错觉。我总感觉有干货的牛人，总担心自己的知识不能广为流传。 这些MIT，Stanford，Berkeley，CMU等等大学的牛逼教授（比如CSAPP的作者，比如计算机组成与设计-硬件软件接口的作者，比如龙书的作者，还有吴恩达，还有算法那本书的作者，无一例外）都有种免费送知识的习惯，生怕自己的干货懂的人少了，于是都偷偷留下些后门。反而是大学，为了收高额的学费，用尽心思保护知识，各种验证，导致免费且完整的课程总是需要花些力气才能获得。 —- 题外话 学生思维学生群体总喜欢攀比学校、专业排名，甚至高考成绩，然而出了学校你会发现，这些都没什么意义。 自我救赎指责制度千百遍，也只有一种一切都无法改变的无力感和苍白感，臭水沟之中不可能孕育出美丽的生物，如果你坚信不自救，毋宁死，那么作为年轻人，起码有这几件事情可以做 1，在保证高考充分准备的前提下，尽量保持一个比较大的阅读量，但是需要注意的是，尽量少读虚构类作品，多读社科类作品 2，高考之后多在网上搜搜，试着去弄清你感兴趣的专业的真实情况，不管是在知乎问，还是问身边的哥哥姐姐，如果分数低不能考上一所好学校，那么起码可以选择一个自己喜爱的专业 3，大学绝对不是用来好好玩的，学习求知磨练技能永远都是最重要的主职，在相对较为宽松的学习氛围下，要主动去为自己创造足够多的试错机会 4，试错的第一条路是抛弃英文学习的腐朽观念，请把英文和自己感兴趣的专业相关方向结合起来，在图书馆或者互联网，你可以找到各专业的introductory的书籍教参和视频类教程，不会很深入，但是起码会让你知道老外在各个领域到底在玩什么——事实上绝大部分专业，都能找到大量英文原文的研究材料，只是要看你愿不愿意找 5，试错的第二条路是尽可能的去多实习，各种行业，各种function的实习。 6，互联网改变一切，各种MOOC课程，公开课，国外教科书，各种社科类书籍应有尽有，虽然盗版是政治不正确，但是感谢互联网让知识和技能变的如此廉价，任何人都可以获得，只要看你愿不愿意扎进去罢了 7，永远保持旺盛的求知欲，各种好书，好课程，好的视频，多的根本学不过来，各类创业项目，国内比赛，实习机会，多的恨不能分身去一一尝试，我很难理解这个时候，仍然有人觉得迷茫痛苦的 8，给我影响相当大的是王小波和李笑来两个人，前者推崇的是思维的乐趣，科学和理性至上，后者则是不断的强调学习求知。旺盛的精力和求知欲贯穿了他的博客文章。所以不断试错，思维的乐趣，科学理性，学习求知，这是我们能得到最好的自我激励 作者：匿名用户链接：https://www.zhihu.com/question/23933304/answer/26143004来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 就我这几年看到的而言，往往越穷的家庭越喜欢大谈特谈家国情怀，集体主义。很简单也很直白的道理就是，这些东西都跟个人目标实现毫无关系，沉浸在宏大叙事中，只不过是想用集体的崇高掩饰个人的失败。 所以一定程度上，我看不起世俗意义上的“学霸”“好学生”，他们根本不知道为什么而学，更多的是事到临头了，才会想我要干什么，在此之前就是行尸走肉一样跟着集体走。 先跟着学，到大三大四就跟着考研，以后要干什么不知道，先学着看嘛。 在大一的时候就该设立自己的职业目标，然后花时间去了解所在学校的潜规则，比如哪个竞赛加分高，保研的独特技巧，提前联系导师。然后通过4年持续不断的矫正目标，矢志不渝管理自身的行动。提醒自己不要陷入垃圾人际关系，不要沉迷抖音和网游，有条不紊计划自己大学每一个阶段应该改什么。 稳扎稳打，步步为营，毅然决然，当断立断。要有不破楼兰终不还的少年心气和英雄气魄，这是穷人家庭子弟唯一的自我救赎之道。 https://www.zhihu.com/question/604936279/answer/3064813947","link":"/2024/06/09/%E7%94%9F%E6%B4%BB%E5%93%B2%E5%AD%A6/%E4%B8%AD%E5%9B%BD%E6%95%99%E8%82%B2/"},{"title":"人生经验","text":"人生 人生人生三大事人生有三件大事：吃饭、睡觉、运动。这三件大事一定要办好。吃不好饭、睡不着觉对一个人的伤害是巨大的，直接影响到人一天的活力。而运动则是好活力、好胃口、好睡眠的一大保障。有氧运动30-50分钟，每周3-5次。 认知人生 人生的划分的一个基本角度，工作、生活和学习。所有思考问题的方式都必须按照这三个领域进行划分，每一个领域的道德逻辑和评判标准，社会形成的一般性认知，自身的成长路径都是不同的。既不能割裂，也不能混为一谈。 工作这个领域是大学生们毕业后进入公司才真正体会到的一种全新领域，这一领域从入职开始，贯彻始终一直到退休。内容上既有专业建树，也有日常细碎，既有背锅甩锅，也有光荣成就。但是，就我们公司来说，归结到几个核心概念就是： 这本质上是个痛苦的领域。吃苦是必然的，不存在快乐工作，要么是吃肉体上的苦，要么是吃心理上的苦。也就是，工作不是费力那就是操心。偶尔点缀着一些成就感和价值感而已。 价值衡量标准就是薪资。长期看，薪资水平取决于稀缺程度，稀缺程度取决于需求和供给的比例。 提高工作能力的重点是提交效率，也就是付出的同等的时间，产生更大的工作成果。一般来说团队协同会比单枪匹马的效率更高，但是组织难度非常大。 生活这个领域是贯彻人类始终的领域，每个人一出生到死亡，都熟悉这一领域。不管世界怎样改变，生活的本质和特点都不会发生太大的变化。 生活的目标就是追求幸福，如果生活充满痛苦，那么一个人必须尽快改变生活的方式来调整自己的状态。不存在为了追求幸福而舍弃幸福，要么是伪幸福，要么是违背了生活的本质。 生活的衡量标准是满足需求过程中，内在的体验的程度，自己鞋子自己穿，舒不舒服自己才知道。必须是不可告人的快乐，而不是在别人面前表演的快乐，即使这种幸福感来自于别人对你的行为。 生活的重点是不断的满足自己的需求，从简单的肉体到高端的精神等等不一，每个人也是不同的。 学习这个领域是人从3岁左右就开始的一种天性，但是很多人会轻易的放弃这一能力领域。 学习的本质就是自身的成长，如果人停止学习，那么人就会停止成长。 学习包含身体上的和精神层面上的学习，这两种学习的评价标准并没有什么不同，就是看人有没有在某个领域成长。 学习的重点就是顺从天性的去做，既要顺从学习这个人类的天性，也要顺从自身特征的天性，也就是找到自己擅长的领域进行学习。另一点就是必须是去做，而不是臆想，幻想一点用没有的。 工作生活学习的权衡 人生意义找寻寻找答案是一个需要不断刷新认知推倒重来的过程。 在这个过程中，你要不停地质问自己，根据你的阅读、思考、经历、体验、自我观察等，去修改自己最初那个可能并不成熟的想法，在这个修改的过程中，你才可以不断明确自己想要的东西。 （1）你理想中的人生状态是什么样的？ （2）在这个想象的人生状态中，你每天在做什么？ （3）回想一下，生活中哪些时刻让你最有成就感？别人一般会表扬你的什么成就？ （4）什么事情是你从小到大一直都有自发去做的？ （5）什么事情是你花了最多时间去做的？https://www.zhihu.com/question/20093001/answer/550087653 兴趣曾仕强先生曾经说过：那个不给你钱你也要干，也喜欢干的事就是你的使命。一个人活着追求什么？钱，名，异性，信仰，艺术？我觉得这些答案都对，也都不对，人活着其实追求的是某种意义，意义感 (Purpose)。而数学对我来说能给我一种意义感。 金钱很重要，兴趣也重要。 体验123456梅：你求学的目的是什么啊？吴：我只知道不管我将来做什么，在这个年纪，读书，学习，都是对的。我何用管我学什么，每天把自己交给书本，就有种踏实。梅：但是，你还忽略了一件事——真实。人把自己置身于忙碌当中，有一种麻木的踏实，但丧失了真实。你的青春，也不过只有这些日子，吴：什么是真实？梅：你看到什么，听到什么，做什么，和谁在一起，有一种，从心灵深处满溢出来的不懊悔，也不羞耻的平和与喜悦。你慢慢想，转系与否那倒是小事。——《无问西东》 年轻时有人对我讲“人生不过是体验”，我还不懂这句话的意思，只是笑嘻嘻觉得好玩。而这几年在谷底躺了许久后悟得其中的奥义。若可未卜先知，我不会把时间梭哈在科研项目上，而是会做点对得起自己的选择，比如早些为硕士毕业找工作做准备，剩余时间全花在陪猫猫打游戏上。因为未来不一定会更好，往后的日子或许都是下坡路。遇到开心的事儿那就一定要抓紧体验，过去了的就再也回不来。https://zhuanlan.zhihu.com/p/568280879 人活一生其实没什么意义，尽可能多的体验世间的美好才是最重要的事，没必要为了那些世俗的羁绊烦恼和压抑自己。 这里一定要区分清晰虚荣和幸福，方法也很简单，没有任何人知道，自己也能感到愉快的就是幸福，必须有人知道，自己也能感到愉快的就是虚荣。 还要区分习得感和幸福感，非常像，不太好区分，主要的不同就是学习带来的习得感非常自我，是自我获取到的一种体验，而幸福感大都是别人给自己带来的一种体验。 https://www.zhihu.com/question/613975022/answer/3190871464 赚钱后来我回忆了一下，那晚我俩虽然聊了很多，但始终都在谈论一件事情，就是赚钱。这种既庸俗又重要的东西，不知道从什么时候开始，竟然变成了中年人的主角，一旦你开始远离它，就会觉得无聊和空虚，对什么事情都提不起兴致。 赚钱的目的是什么？是为了更好地生活！ 然而，为了赚钱，你却失去了生活！ 那些曾经的梦想和追求、诗意和远方、兴趣和爱好、休息和放松，现在是不是都没有了？ 我们期待演绎自己的剧本，但却成了别人剧本中的小角色。 金钱这个没有栏杆的牢笼，你可以随时进来，也可以随时出去，然而你一旦进来，就会被各种幻象所迷惑，再也不甘心逃离。 束缚你的不是牢笼，而是各种物欲和面子。 N 年之前我也是一个清高的人，瞧不上那些捞偏门的小垃圾，但是现在，我也开始崇拜金钱和权利，总觉得男人没有这两样东西，就是妥妥的 loser。 钱能解决 90% 的问题，剩下的问题可以靠权利解决，或者靠更多钱解决。 那个有理想的少年，如今已经被生活打败，成了金钱的奴隶 中文系探寻的是对人生最深刻、最隐秘、最有境界的认识。 https://www.zhihu.com/question/388965792/answer/1947610247 我的评价：狗屁自我感动。听君一席话，当场很感动，实际没啥用. 这些年我一直提醒自己一件事情，千万不要自己感动自己。大部分人看似的努力，不过是愚蠢。什么熬夜看书到天亮，连续几天只睡几小时，多久没放假了，如果这些东西也值得夸耀，那么富士康流水线上任何一个人都比你努力多了。人难免天生有自怜的情绪，唯有时刻保持清醒，才能看清真正的价值在哪里。” ——于宙.《我们这一代人的困惑》 没有钱，没有社会地位，没有文化，人很难掌握自己的命运。 ——《沉默的大多数》 成长任何寻求安慰的行为都不会让你成⻓；宿醉、旅行、甚至和朋友促膝⻓谈，因为这些都只是让你在⻓期停留的茧房里感觉安全、良好。 成⻓其实是特别艰难的自省，你必须抛弃所有说给别人和自己听的漂亮话，正视你的无能和劣根，甚至一遍又一遍被打破、割裂、推翻以前的所有观念和认知再重组。然后你才懂得成⻓真正需要的改变。https://www.zhihu.com/question/47436256/answer/2865926752 自律规律的生活容易陷入枯燥的陷阱，但随意的作息却会使人懊恼，后悔，感叹一天怎过得如此之快！一方面是沉溺于当前的享乐，另一方面却是感叹自己的慵懒，想着明天再努力，殊不知，这第二天的努力有多难。 世界上最厉害的人，是说起床就起床，说睡觉就睡觉，说做事就做事，说玩就玩，说收心就收心，说不爱 就不爱。 专注人的精力是有限的，往往那些成功比较早的人都是在年纪轻轻的时候就知道人一辈子只能把有限的几件事甚至是一件事做好，然后就找准了自己想做的事，集中全部精力去做，然后通过⻓时 间(相对于整个人生⻓度而言，其实很短)的积累，在一个自己热爱的领域持续深耕5年以上，时 间的复利效应 让他们把同龄人甩得远远的。遵循二八原则 ，将其中20%最􏰜要的事自己做，其 他不􏰜要的事交给别人做。如果所有的事自己做，事情是不可能做成的。请把你一半以上的精力 放在你的职业发展上(如果不知道精力如何评估，请把它修改成时间。 注:职业发展不等于工作 时间，没跟你说一定要你每天工作12小时以上。) 灵活努力来弥补天分的不足，面对可以想见的事态，预先准备好对策便能迎刃而解。 但是如果是从未见过的事件，这时候应变能力便不够灵活。 什么是应变能力？遇到过的事情自然可以用同样的手段解决。如果是没遇到过的突发情况，能否稍加修改其他事件的解决方式来解决突发情况呢？在我看来，这就是应变能力。 复盘复盘有以下两个要点： 及时：总结复盘应该在结束后尽快进行，以便更好地回忆事情的细节和问题。 客观：总结复盘应该客观、公正地评估事情成果和不足，不应该有个人情感和偏见的影响。 复盘的目的是为了提升自我，为了能够再下一次做的更好，而不是为了总结而总结。与其总结得失，细节，不如通过这些来总结，怎么让下一次更加Better。 不要害怕做选择When I was 17, I read a quote that went something like: “ If you live each day as if it was your last, someday you’ll most certainly be right.” It made an impression on me, and since then, for the past 33 years, I have looked in the mirror every morning and asked myself: “ If today were the last day of my life, would I want to do what I am about to do today? “ And whenever the answer has been “ No” for too many days in a row, I know I need to change something. Remembering that I’ll be dead soon is the most important tool I’ve ever encountered to help me make the big choices in life. Because almost everything — all external expectations, all pride, all fear of embarrassment or failure - these things just fall away in the face of death, leaving only what is truly important. Remembering that you are going to die is the best way I know to avoid the trap of thinking you have something to lose. You are already naked. There is no reason not to follow your heart. ——乔布斯 沉没成本沉没成本代指已经付出且不可收回的成本。比如排了一个小时的队、谈了两年的感情、亏损80%的股票。 因为沉没成本的存在，人很容易合理化自己的投资行为，偏离理性。已经排了一个小时的队伍，这时放弃太可惜；已经谈了两年的，这时候放弃可惜；已经亏损80%的股票，这时候放弃太可惜。 沉没成本是人类独有的一种非理性的心理谬误。人与人之间情感联系的基础其实就是投资造成的沉没成本，E对F投资越多，因为沉没成本，E就会越想亲近F、越离不开F。在一般健康的情感中，投资应该是对等的。 毫无疑问，完全无视沉没成本、理性地决策就能使利益最大化。但人类是非理性的生物，并不是其“意志”怎么想，他的“心理”就能怎么想。 无视沉没成本的方法是用大量的时间与精力将自己培养成一个几乎完全理性决策的机器人，或者是完全可以用意志控制心理的唯心主义者，这样沉没成本才不会变成真实的心理成本。而一个普通人，即使知道这个道理，沉没成本造成的大量心理痛苦依然存在，他依然无法做出经济学中利益最大化的选择。 https://zhuanlan.zhihu.com/p/76715766 社会阶层阶级金字塔你以为的社会金字塔： 实际上的社会金字塔： 更加绝望的结构（连上升通道都没有）： ——https://www.zhihu.com/question/628715474/answer/3291246636 2018年以来，中国内地，个人净资产2000万元，属于什么阶级？ - 漫读的回答 - 知乎https://www.zhihu.com/question/267579955/answer/3160182157 认知 在这个充满机会的时代，要跨越阶级的障碍之一，是从小耳濡目染的原生家庭的生活习惯。https://www.zhihu.com/question/381318794/answer/2603799132 要知道如何经营感情，如何混社会，很大一部分都要归结于我们跟父母的耳濡目染，以及他们给我们提供的物质条件和思维方式。https://www.zhihu.com/question/402966298/answer/2717373145 归根到底，青少年时代形成的思维方式会影响人的一生，这种后期主动的思维方式转变才是最难的。https://www.zhihu.com/question/367736654/answer/3338250117 家庭、学校、社会，某种程度上是三位一体的。换句话说，什么样的社会环境，什么样的家庭需求，就有什么样的学习氛围。他们不是元凶首恶，但客观上起到了一定的帮闲作用。 https://www.zhihu.com/question/638695143 自我救赎 不要抱怨自己的出身，不要羞于你出身富足，就像不要羞于承认自己出身贫穷一样。也不要羞于自己天生得到的许多帮助，就像不要羞于自己无所依靠。三分天注定，七分靠打拼。出身只是一个方面，这是无法选择也无法改变的。平静的接受它，不刻意提及也不刻意回避。 脱离底层人的思维惯性，不要随波逐流，即使被周围人误解、孤立、嘲笑，也要坚持做正确的事情；摆脱底层人的习惯和圈子，避免无谓的消费跟负债，防止自己落入消费陷阱。 学会独立，深度思考，心无旁骛，只专注自己的学习和成长，并接触高能量场的贵人，利用贵人的人脉和资源，一旦发现机会，要迅速积累第一桶金。竭尽所能让自己变得有价值，并真诚拥抱你遇到的贵人，所谓自助者天助。 学会储蓄，不要攀比，只为真正刚需的东西花钱。不要有投机心理，不要轻易投资和创业。这个时代已经不适合普通人创业，不要让自己变成绿油油的韭菜。 链接：https://www.zhihu.com/question/402966298/answer/2717373145","link":"/2024/06/09/%E7%94%9F%E6%B4%BB%E5%93%B2%E5%AD%A6/%E4%BA%BA%E7%94%9F%E7%BB%8F%E9%AA%8C/"},{"title":"关于伴侣","text":"伴侣 性是肉体生活，遵循快乐原则；爱情是精神生活，遵循理想原则；婚姻是社会生活，遵循现实原则。是三个完全不同的东西。 ——周国平 《婚姻与爱情》 该怎么说呢，精神层次越高的人对感情越专一，因为善于处理自己内心欲望，因而不会把类似找备胎、和谁玩、玩过谁，这种肤浅的价值观当作得意的谈资。他们更愿意跟某个人担起生活的风雨，因为时间都用来做正经的事情，所以左顾右盼不代表你赢了，花哨是因为你层次太低。欲望是人性，克制是教养，新欢旧爱迎来送往，你以为的魅力难挡实则廉价百搭，得陇望蜀、骑驴找马、悲凉得让人生厌且鄙弃。道德不能杀掉带给我痛苦的人，所以我只能杀死理智和感性的自己。忠诚和专一是最基本的原则和底线，但它也只是三观正且有教养的人对感情中的自我约束。 意义随着年龄的增大，愈发感到一个人的吃力。不论是学习还是生活中，多一个人总能节省很多精力。一个人干事情，啥都要白手起家（from scratch），会踩很多坑。数学中，看过的题目很多，却不知道重要的有应用的题目是啥。有一个老师带着，能避免走很多弯路；医院看病，挂号-&gt;科室诊断-&gt;出药方-&gt;缴费-&gt;药房拿药-&gt;用药；穿搭，运动装-&gt;休闲。生活中，有一个人能互相帮助，总是好的。 情绪价值 情绪价值 = 积极情绪体验 - 负面情绪体验。https://www.zhihu.com/question/326968879/answer/1685871767 情商在知乎上面有人是这么描述的：高情商的人，在和周围人相处的时候，可以让周围的人感受到一种轻松、舒适、愉悦、积极的情绪和感受；低情商的人，在和周围人相处的时候，周围人会感受到一种压抑、烦躁、负面、消极的情绪和感受。https://zhuanlan.zhihu.com/p/100433097 家庭财富管理男朋友给正在同居的我们列了一个预算表，所有东西AA，我看完很不舒服，是我太自私吗？ - 曹小灵的回答 - 知乎https://www.zhihu.com/question/599884016/answer/3039956043 家庭教育劝退【鱼和熊掌不可兼得，自己取舍好】 https://www.bilibili.com/video/BV1a142127uM/?share_source=copy_web&amp;vd_source=f263eddd9c6fc88c2b8c3f4f1f660922 家庭教育你见过哪些父母惊艳到你的教育方式？ - 知乎https://www.zhihu.com/question/264918610/answer/2650518341 1234567如果你3岁的儿子想穿女性服装，你会怎么劝道？我儿子跟我要裙子穿的时候，我一开始以为他是无心 说说，后来他又跟我要了几次，我琢磨了一下，就淘 宝买了件童装的汉服男子襦裙。我儿子穿出去那个回 头率是很高的，他主要是痩而且挺拔，汉服会把他那 个小腰勒得细细的，衬得出一股子翩翩小君子的气 质。 我儿子很满意，穿裙子满足了他想要的漂亮形象，路 人的夸赞也给了他足够的自信。他丝毫不觉得男孩子 穿裙子是耻辱的事情，路人也不觉得他是个奇怪的小 孩。我们做家长的，不要完全被孩子牵着鼻子走，他说要 穿裙子，你就真的去找粉粉公主裙给他?他自己别扭， 旁人也别扭。你要学会思考，学会去引导孩子的审 美，而不是慌不择路的批判孩子或者干脆带偏。我儿子现在是知道了，古时候的男人留长发扎辫子还 穿裙子，现代的男人因为时间宝贵耗不起所以一切从简了。 1234567891011孩子报复父母送别人自己的手办的行为，倒光茅台，你怎么看？我觉得孩子做的没毛病啊。我带娃去亲戚家的时候，第一件事先跟人家打招呼，孩子有可能调皮，贵重的限量版的东西请收好。当然我也会看好孩子，就怕万一没看住，别说孩子弄坏别人心爱的东西，就是玩了别人心爱的东西，人家大概率也不会高兴。但是我不双标，谁家孩子到我家玩，玩我儿子的东西，也必须取得我儿子的同意。从小让孩子知道什么是别人的，什么是自己的。他自己的东西他有绝对的权力，是同时要尊重别人的权力。所以我儿子拆家的时候，会先问某些东西他可不可以拿出来玩。如果我老公要是把孩子玩具没经过孩子同意拿出去丢掉或者送人，我会联合儿子把他珍藏的茶叶送人。同样如果我要是做了这种事情，我儿子把我首饰送人，我也没什么可抱怨的。&gt; 人的悲喜并不互通，实际感受一下就都懂了","link":"/2024/06/09/%E7%94%9F%E6%B4%BB%E5%93%B2%E5%AD%A6/%E5%85%B3%E4%BA%8E%E4%BC%B4%E4%BE%A3/"},{"title":"学习经验","text":"认知学习 要超过别人其实还是比较简单的，尤其在今天的中国，更是简单。因为，你只看看中国的互联网，你就会发现，他们基本上全部都是在消费大众，让大众变得更为地愚蠢和傻瓜。所以，在今天的中国，你基本上不用做什么，只需要不使用中国互联网，你就很自然地超过大多数人了。当然，如果你还想跟他们彻底拉开，甩他们几个身位，把别人打到底层，下面的这些“技巧”你要多多了解一下。 在知识学习和技能训练上，让他们不得要领并产生幻觉 让他们混淆认识和知识，以为开阔认知就是学习，让他们有学习和成长的幻觉…… 培养他们要学会使用碎片时间学习。等他们习惯利用碎片时间吃快餐后，他们就会失去精读一本书的耐性…… 不断地给他们各种各样“有价值的学习资料”，让他们抓不住重点，成为一个微信公众号或电子书“收藏家”…… 让他们看一些枯燥无味的基础知识和硬核知识，这样让他们只会用“死记硬背”的方式来学习，甚至直接让他们失去信心，直接放弃…… 玩具手枪是易用的，重武器是难以操控的，多给他们一些玩具，这样他们就会对玩具玩地得心应手，觉得玩玩具就是自己的专业…… 让他们喜欢直接得到答案的工作和学习方式，成为一个伸手党，从此学习再也不思考…… 告诉他们东西做出来就好了，不要追求做漂亮，做优雅，这样他们就会慢慢地变成劳动密集型…… 让他们觉得自己已经很努力了，剩下的就是运气，并说服他们去‘及时行乐’，然后再也找不到高阶和高效率学习的感觉…… 让他们觉得“读完书”、“读过书”就行了，不需要对书中的东西进行思考，进行总结，或是实践，只要囫囵吞枣尽快读完就等同于学好了…… 如何超过大多数人 | 酷 壳 - CoolShell 学习技巧费曼技巧费曼技巧是一种「以教为学」的学习方式，能够帮助你提高知识的吸收效率，真正理解并学会运用知识。这个学习方法其实很简单，就是验证你是否真正掌握一个知识，看你能否用直白浅显的语言把复杂深奥的问题和知识讲清楚。 具体应用方式如下： 1、向不熟悉某议题的人解释该议题，用他们能理解的方式及最简单的语言向他们解释； 2、发现自己不能理解的地方或不能简单解释某议题的地方并记录； 3、回头查看资讯来源并研读自己薄弱的地方直到能用简单的语言来解释； 4、重复前面三项步骤直到能够专精这个议题。 以输出作为输入 每天坚持看书两小时能否真的提升自己？ - 猫叔的回答 - 知乎https://www.zhihu.com/question/451546101/answer/2343045822 「如果你不能简单地解释一件事，那你就还没有弄懂它。」 很多时候我们自以为已经掌握了某个知识，但其实并没有。如果你不能讲清楚，也就说明你没有掌握。这时候你就需要更深度地了解知识。理解和复述是相互促进的作用，费曼技巧就是在不断强化这个过程。 周期重复记忆艾宾浩斯遗忘曲线告诉我们：人的记忆是不靠谱的，一周过后会忘记80%的内容。然而，只要每周坚持复习，就能达到记忆80%的内容。 由此可见：背单词最好的方法是小批量、间隔时间记忆（比如早晨背20分钟，傍晚在背20分钟；而不是早上一次性背一个小时） 构建第二大脑｜笔记 1946 年，美国学者埃德加·戴尔提出了「学习金字塔」理论。之后，美国缅因州国家训练实验室也通过实验发布了「学习金字塔」报告，报告称：人的学习分为被动学习和主动学习两个层次（见图 5-1）。 被动学习：如听讲、阅读、视听、演示，这些活动对学习内容的平均留存率为 5%、10%、20% 和 30%。 主动学习：如通过讨论、实践、教授给他人，将被动学习的内容留存率提升到 50%、75% 和 90%。 https://www.zhihu.com/question/371093805/answer/1583430303 构建第二大脑的步骤：保存信息-&gt;整理分类。在日常生活中，碰见有用的信息便记录下来，然后在周末整理笔记。 保存信息前问问自己这三个问题： 这个信息对我有启发吗？ 这个信息以后能派上用场吗？ 这个信息是与我当前息息相关的吗？ 整理：为知识构建索引，当你想某方面的知识时，应该快速想到几个关键词。 螺旋式上升/层次了解：噢，这个名词/算法/历史我听过。 理解：噢，再次看到这个算法能看懂。 记忆：噢，再次看到这个算法我能给你讲/写出来。 运用：噢，这个算法我能自己写出来，并运用到其他情况下。 再理解：噢，原来我运用错了，再看算法，原来有这个细节（原来算法还有其他运用方式）。 再运用：噢，我终于能用对了。 总结：瞧，我可以给你介绍这个算法、背后的思想。 学而不思则罔，说的就是学习停留在记忆的阶段。 思而不学则殆， 直接跳过学习的前三阶段，没有前人的知识总结自己瞎琢磨（可能伟人就能自己创造总结出一些知识，但普通人还是老老实实学知识吧）。创新是在模仿的基础上的。 举例子举例子是一个能增进专精程度并学习同理的好方法，这促使你用对方的程度来理解并透过与他们熟悉的议题有关的方式给予他们新的知识。你在理解和简化知识的过程中会不知不觉用到类比、举例、概括、对比等深度学习的方法。 学习经常碰见的问题1、拖延症：明明有件事情很重要，却哪怕看这剧，也迟迟不愿开始，怎么办？ 2、没法长期坚持做一件事：比如跑步，要求自己每天跑1小时，靠意志力坚持了一周，后面还是中断了。类似的事还有很多，比如背单词… 3、注意力集中问题：工作、学习 没法集中注意力，一堆内容，每天都是心烦意乱，怎么办？ 由此，对应给出有效学习的3个要点： 1、“最小行动门槛”原则—让自己开始 九边老师分享过一个技巧，看书的时候，就定2页，最少看2页，愿意看多看少 随你自己，结果执行下来发现，经常看到2页后进入状态，经常一下能看好多； 无论做什么，先想办法让自己开始，没有比这更每秒的方法！ 2、拆解目标—难度匹配 ※※※ 比如跑步，之前我要求自己每天跑步1小时，靠意志力坚持了蛮长一段时间，后面还是中断了。 最近调整为每次30分钟，不少于一周4次。调整后发现，不用太靠意志力做这件事，会主动想办法坚持，跑完后会很放松，不像之前那样连续跑1小时会很累、很难受。感觉到‘主动做’和原先‘靠意志力做’完全不一样； 比如学英语，原来每天学习1小时我会烦躁，但现在改为每天学习30分钟，时间一到就不学了。这样，我反而可以坚持每天学，不厌倦； 学习的时候，梳理“会做但特别容易错，或不会做但稍努力就能懂”的内容，然后在这个区域内努力； 找一个自己能坚持做下去的方式，比单纯按照标准化的时间和方式做更重要。 这些行为本质上都是拆解目标：把大目标拆分为小目标，任务就会立即从困难区转移到拉伸区。几乎所有的行动达人都是拆解任务的高手。 长期坚持里最重要的拆解目标一定认真看待，太多人总是兴冲冲地开始，热火朝天地做上几天，然后很快就没劲了——做事情半途而废就是这个原因。 3、设定目标时要有关注点-寻求反馈 发现和收集要点，即每次行动的小目标。比如： 练习弹钢琴的时候，不是一遍一遍地重复，而是只练出错最多的地方； 背单词的时候，不是一遍一遍地重复，而是看完之后合上书进行自我测试，把出错的单词找出来，然后不停地重复记这些出错的单词，直到全部掌握； 这里有个万能的底层方法论：成长是不可能速成的。 不管做什么，不管你当前会不会，只要在舒适区的边缘持续练习，舒适区就会不断扩大，拉伸区也就会不断扩展，原先的困难区也会慢慢变成拉伸区或舒适区，这就是成长的底层原理； 专治拖延症！ 终身学习Finally, keep in mind that no one can cram everything they need to know over a weekendor even a month. EveryoneIknow who’s great at machinelearning is a lifelong learner. In fact, given how quickly our fieldis changing, there’s little choicebut to keep learning if you want maintain a steady pace of learning for years? I’ve written about the value of habits. If you cultivate the habit of learning alittle bit every week, you canmake significant progress withwhat feels like less effort.Keep learning!——Andrew 多维度学习 对声音的抽象记忆，是语言学习的捷径。但不出国，或没有外国朋友亲密互动交流，很难形成对声音的记忆吧。我个人认为，语言学习的本质是，某人在成长过程中，当受到外界刺激（声音、气味、对方表情）时，与特定声音（语言）建立联系。也就是，（外界刺激）＋（人类发生）＝（形成语言）。 语言学习的顺序:1先能听懂对方 2.自己也能说了。3.学习这个国家的文字 4.进行文字创作。 对语言的认识 语言的学习是多维度多方面的，一方面是交流沟通（声音），另一方面是文字阅读（视觉）。 从幼稚园孩子作画角度看待学习在有限的认知里发挥联想。 孩子们认识的事物有限，但是通过组合、创造将有限的事物拓展出来。 名曰：创造力。 另一个角度：积累、模仿、创造。 作为教材我系统地学习一门理论，通俗的意义解释的同时要对应着严谨的数学推导；给出实例纠正一些没有注意到的细节；给出图示进行生动化地理解记忆；给出应用回归理论的背景。 重要的知识在脑海中形成体系结构，能完整的复述一遍，包括原因和过程。 作为教师There is no stupid question, only stupid answers. https://mp.weixin.qq.com/s/97CND1xKplQU7A7pZDFHLA 无论学生基础如何，只要愿意去学，就能把他教懂，最忌讳的就是产生「你这都不懂？」的想法。","link":"/2024/06/09/%E7%94%9F%E6%B4%BB%E5%93%B2%E5%AD%A6/%E5%AD%A6%E4%B9%A0%E7%BB%8F%E9%AA%8C/"},{"title":"我的生活哲学","text":"总结一下我的生活哲学。 计算机人生我想将生活比喻成计算机，为什么？ 因为人脑好比于CPU、人要做的事情就好比于计算机中的进程（任务）、任务所需要的数据就好比于生活上需要的工具。 由此引出一系列生活哲学： 任务调度（怎么安排事情？） 多线程运行（怎么处理多件事情？） 怎么优化事情，让事情快点完成？（存储优化、多线程优化） 性能平衡（时间与空间取舍） 计算机体系结构的知识比较多。 Amdahl定律Amdahl定律指：系统中对某一部件采用更快执行方式所能获得的系统性能改进程度，取决于这种执行方式被使用的频率，或所占总执行时间的比例。 说人话就是：对于整个系统的性能改进程度，取决于你改进的操作占所有操作的比例。 举个例子：你每天都会使用微信，那么你肯定是将微信APP放在手机上最显眼的位置而不是犄角旮旯。 Amdahl定律是我最喜欢的一个定律，它指出了你该优化什么（最频繁的操作），优化后能达到多少程度等等。有了该定律后，你就能知道生活上收纳该怎么进行。 譬如你有一个置物架，但是置物架的每一层的存取时间并不是相等的（最上面一层和最底下一层的存取最麻烦，而胸口位置最方便），这时候，你应该将平时用的小工具放在中层，方便拿取。最上面一层和最底下一层应该放纸巾等备用物品（这些东西几个月可能用不到一次）； 置物架可以替换为衣柜、书柜、鞋柜等等； 有些人以为的收纳就是将东西摆放整齐，摆放在一起，占满房屋的边边角角，其实不然。收纳是为了方便下一次的存取。高频操作需要省力、省时间。 模块化模块化原则可以很好的解除耦合，什么意思呢？就是物品分类存放，成为一个模块。相同功能、相同用途的东西可以放在一个箱子里。 有什么好处？ 方便存取。你知道你要拿的东西放在哪里，你可以很快的检索到它。 方便整体搬运，有利于搬家。 模块化其实还涉及到另一个哈希表优化，这讲的是你的东西要放在固定的场所。哈希优化，相当于你用物品名称检索物品地点，如果你是那种随用随放的人，那么你可能想不起来工具放在哪里。但是如果遵循模块化原则，工具都收纳在工具箱，每次用完都放回，那么你第二次就能非常快拿到工具。人脑的短期记忆非常不可靠，相当于RMA易失性存储。 时空原则时间和空间可以互换。什么意思？你可以用时间换取空间，也可以用空间换取时间。 比如你的仓库面积有限，那你不得不将仓库堆满，那么你找东西的时间将大大增加，这就是用时间换空间。 如果你有非常大的仓库，那么你可以通过有序的编排，使得你找到东西的时间大大缩短。 当然，如果你有个大得离谱的house，有可能你上个厕所就要走半天，哈哈哈。 最小试错原则等同于此句名言：过早的优化是万恶之源。 为什么？因为很多人都“认不清”自己的需求，“认不清”什么是高频操作！比如： 购买电子产品，想着一步到位，买大存储高配置的型号，结果发现自己用不着。 体验新运动，比如滑板、羽毛球、钓鱼想着买好点的装备，结果玩了几天放弃了。 学习书法、钢琴等兴趣课程，购买昂贵的钢笔、钢琴。 开店铺，大肆装修，结果无人问津。 以上列举几点，完全可以依靠最小试错原则避免。现如今，20%价格的装备已经足够拥有80%的体验。新跨入一个领域，需要不断试错，如何降低这个成本，就需要最小试错。 该原则的另一指导（其实就是Amdahl定律）在于：你熟知的领域的操作就要不断优化。譬如你是个码农，你就应该购买大存储高性能的计算机，购买大显示器，因为它们是你的生产力！ 投资自己很多人害怕花钱，但我认为，投资自己（在自己身上花钱）就是最好的选择。 还是Amdahl定律，你一生的时间并不是等价的，你的生产力（体力与脑力）在青年黄金时段是最丰盛（高频）的操作。幼年时期的你什么都不懂，也不具备与付出相比合理的生产力。如果这个时候你去做一些垃圾事（打零工etc），成年时期可能尝尽辛酸。那么我们需要优化成年时期需要做的操作（打工:blush:或者创业或者其他)，所以应该在青少年时期积累相应的知识与技能。问题是很多人都不清楚自己未来要干什么，因为他们认不清自己的需求（过早地优化是万恶之源）。所以在最小试错原则的帮助下，我们需要尽可能尝试多种可能，投资自己。 还有一条就是：钱是工具而不是目的。在小事上肯花钱，这会带来专业的回报。没有免费午餐，看似的小便宜，实际浪费了时间与精力。 加减法原则人生先做加法再做减法。加法就是尝试尽可能多选择、学习多的知识、购买新的装备等；减法就是要选择合适自己的方向、总结凝练出自己的方法论、选择合适有用的装备。 人生譬如容量，是有限的。只做加法会撑爆容器，一昧地选择是在浪费时间。 长期主义均衡时间投入，不是临时突击。 临时突击的事情只是应付，在做这件事情前要想清楚这件事的重要性。大学的许多课程都可以临时突击，但某些知识则是需要实打实掌握的。 这一点的另一个侧面就是毅力与坚持。 坚持每天投入一点时间做对的事情，这需要坚持的毅力。 摈弃学生思维 什么都学 什么都要学懂 学懂了才动手 中国的教育容易让学生丧失自我，没有主见。在一昧地投入一件事情（做题，解题，考试）中很容易丧自己的判断力，变得只会按照课程安排，极其功利。 人生三大事吃饭、睡觉、运动。","link":"/2025/01/05/%E7%94%9F%E6%B4%BB%E5%93%B2%E5%AD%A6/%E6%88%91%E7%9A%84%E7%94%9F%E6%B4%BB%E5%93%B2%E5%AD%A6/"},{"title":"Hexo搭建静态博客","text":"Hexo 搭建静态博客记录 1234- hexo命令补全- night模式如SEO、评论系统、个人头像、博客分享、订阅功能、High功能、404网页设置 Hexo 快速入门Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用MarkDown解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 官网：https://hexo.io/zh-cn/ 安装（1）安装准备 安装 Hexo 只需要先安装：Node.js、Git。Mac推荐使用Homebrew安装。 （2）安装Hexo 1$ npm install -g hexo-cli 1$ npm install hexo 注：npm可能需要换源，自行搜索。新手推荐全局安装，即第一条命令。 初始化使用（1）初始化一个目录 123$ hexo init &lt;folder&gt;$ cd &lt;folder&gt;$ npm install 大概意思就是初始化一个目录，切换到这个目录下，然后执行相关依赖安装。 初始化完成后，目录下文件有： 1234567891011.├── _config.yml #网站的配置信息├── package.json #应用程序的信息├── scaffolds #模版文件夹，里面存放的是新建文章自动填充的内容| ├── draft.md| ├── page.md| └── post.md├── source #md文章存放处| ├── _drafts| └── _posts└── themes #主题文件夹 （2）简单运行查看效果 1$ hexo server 浏览器访问 http://localhost:4000/ 即可查看效果，默认有一篇hello world的文章。 基本配置_config.yml 这个文件是 hexo 的基本配置文件，里面的内容： title：网站标题 subtitle：副标题 description：网站描述 keywords：网站关键词 author：作者 language：语言 timezone：时区 更多配置请看官网文档：https://hexo.io/zh-cn/docs/configuration 写作流程（1）hexo写作非常简单，只需在目录下执行 1$ hexo new &lt;title&gt; 就会在source目录下生成一篇同名的md文件，比如source/_posts/my-first-blog.md，接下来只需要在这个md文件下写作就行了。 （2）了解更多 打开这个文件可以看到一下内容，这是用来帮助hexo了解文章内容的必要信息。 12345---title: my_first_blogdate: 2023-10-27 15:17:19tags:--- 前述scaffolds文件保存了新建文章自动发布填充的内容（称之为布局），到这个目录下浏览 post.md 信息 12345---title: {{ title }}date: {{ date }}tags:--- 不难发现与之前内容十分对应，后续也可自定义修改这个文件，配置更多关于文章的信息。 分类与标签 推荐阅读https://hexo.io/zh-cn/docs/front-matter 在md文章的顶部有两条水平线组成的元信息区域，在这里可以设置文章的分类与标签信息。 12345678910---title: 标题date: 2024-6-1 10:00:00toc: truecategories: - 数据结构 - 二叉树tag: - 深度优先搜索--- 可以添加多个标签。 部署先认识一些简单的hexo命令与原理。 Hexo命令1234567hexo n &quot;我的博客&quot; == hexo new &quot;我的博客&quot; #新建文章hexo g == hexo generate #生成hexo s == hexo server #启动服务预览hexo d == hexo deploy #部署hexo server #Hexo会监视文件变动并自动更新，无须重启服务器hexo clean #清除缓存，若是网页正常情况下可以忽略这条命令 关于部署，有两种部署方式。一种是本地利用hexo部署，每次写文章后都要重新部署一遍。另一种是利用GitHub Action自动部署，每次只需提交源代码。 生成式部署（1）安装插件 （2）修改配置 1234deploy:- type: git repo: https://github.com/.../... branch: master 然后通过 hexo d（hexo deploy）来部署到 GitHub pages 上。 个性化配置主题 推荐主题 ppoffice/hexo-theme-icarus 上手文档 https://ppoffice.github.io/hexo-theme-icarus/uncategorized/getting-started-with-icarus/ 整个主题基本上是用 jsx 来写的，样式是用 styl 写的。 Icarus 主题配置 12$ npm install hexo-theme-icarus$ hexo config theme icarus 插件安装插件都可以通过 npm install ... --save 来安装 hexo-abbrlink 生成一个短的永久链接 hexo-blog-encrypt 文章加密 Hero-generator-index/archive/category/tag 生成主页 / 归档 / 分类 / 标签文件夹 Hero-generator-feed RSS订阅生成 Hexo-generator-index-pintop 置顶文章 主题魔改优化icarus主题备份（1）创建项目 12345hexo init myBolgcd myBlogcd themesgit clone https://github.com/ppoffice/hexo-theme-icarus.gitmv hexo-theme-icarus icarus （2）安装依赖 1234yarn installnpm installnpm install semveryarn add bulma-stylus@0.8.0 hexo-component-inferno@^2.0.2 hexo-pagination@^2.0.0 hexo-renderer-inferno@^0.1.3 hexo-renderer-stylus@^2.0.0 inferno@^7.3.3 inferno-create-element@^7.3.3 （3）运行 1hexo server 文章两栏主题默认是三栏布局，在阅读文章时显得有些拥挤，可以通过配置的方式把所有文章变为两栏布局。 新建_config.post.yml，然后配置widget。但这样做文章仍然只有一栏的宽度，因此直接修改主题样式文件。 123456diff:layout/layout.jsx &lt;Head site={site} config={config} helper={helper} page={page} /&gt;- &lt;body class={`is-${columnCount}-column`}&gt;+ &lt;body class={`is-3-column`}&gt; &lt;Navbar config={config} helper={helper} page={page} /&gt; 123456diff:layout/layout.jsx 'is-12': columnCount === 1,- 'is-8-tablet is-8-desktop is-8-widescreen': columnCount === 2,+ 'is-8-tablet is-8-desktop is-9-widescreen': columnCount === 2, 'is-8-tablet is-8-desktop is-6-widescreen': columnCount === 3 12345678910diff:layout/common/widgets.jsx function getColumnSizeClass(columnCount) { switch (columnCount) { case 2:- return 'is-4-tablet is-4-desktop is-4-widescreen';+ return 'is-4-tablet is-4-desktop is-3-widescreen'; case 3: return 'is-4-tablet is-4-desktop is-3-widescreen'; } 优化不同屏幕大小下的宽度 12345678910111213141516171819diff:include/style/responsive.styl +widescreen()+ .is-3-column .container+ max-width: $widescreen - $gap+ width: $widescreen - $gap+ .is-1-column .container, .is-2-column .container max-width: $desktop - 2 * $gap width: $desktop - 2 * $gap +fullhd()+ .is-3-column .container+ max-width: $fullhd - 2 * $gap+ width: $fullhd - 2 * $gap+ .is-2-column .container max-width: $widescreen - 2 * $gap width: $widescreen - 2 * $gap 修改主页的宽度1234567diff:layout/layout.jsx 'is-12': columnCount === 1,- 'is-8-tablet is-8-desktop is-8-widescreen': columnCount === 2,+ 'is-8-tablet is-8-desktop is-9-widescreen': columnCount === 2,- 'is-8-tablet is-8-desktop is-6-widescreen': columnCount === 3+ 'is-9-tablet is-9-desktop is-6-widescreen': columnCount === 3 增加一个关于界面1hexo new page about 然后就会产生一个 source/about/index.md 文件，直接编辑这个文件就行。 经谷歌，可以直接在index.md中写html代码， 又搜索之后，找到了答案：将index.md改名为index.html。修改之后，马上显示正常了。 还有，默认页面中title为about，不要忘记修改为你想要的标题。 修改底部 footer（1）_config.icarus.yml文件新增 123beian： title：xx url：xx （2）node_modules\\hexo-theme-icarus\\layout\\common\\footer.jsx 123456789101112131415161718const { logo, logoUrl, siteUrl, siteTitle, siteYear, author, links, showVisitorCounter, visitorCounterTitle, /* 添加下面这行代码 */ beian } = this.props;&lt;a href=&quot;https://github.com/ppoffice/hexo-theme-icarus&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Icarus&lt;/a&gt;{/* 添加下面这行代码 */}&lt;br /&gt;&lt;a href={beian.url}&gt;{beian.title}&lt;/a&gt;","link":"/2024/06/10/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/Hexo%20%E6%90%AD%E5%BB%BA%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2/"},{"title":"博客绑定域名二三事","text":"为你的博客注册域名需要注意的事情。 域名购买域名随便找一家云服务厂商。 解析域名域名服务器DNS Name Servers 是负责解析你的域名的服务器。切换阿里云域名解析服务到Cloudflare的域名解析服务，也就是需要切换域名服务器。 DNS解析使用cloudflare免费加速github page | MonkeyWie’s Blog 域名解析的过程就是将域名绑定到一个IP地址的过程，但是也能够将域名解析到另外一个域名。 A记录 AAAA记录 CNAME记录 A记录和AAAA记录都是将域名解析到一个IP地址，不过A记录是解析到IPv4，AAAA记录解析到IPv6。 CNAME记录则是将一个域名解析到另一个域名。 那么，为什么配置了域名解析还要配置CNAME 文件呢？实际上，个人域名是名字，github pages相当于网站空间。试想，如果不在网站空间配置CNAME，就可以成功绑定域名，那么岂不是可以给别随便一个的网站绑定上自己的域名？相同，如果只需配置github pages的CNAME，而不用域名解析，那不是也可以将自己的网站绑在人和别人的域名上？所以，域名绑定是需要“双方同意”的。 用dig命令能够观察域名解析的过程（Get a detailed answer for a given domain (A records)） 1dig +noall +answer example.com CDN 加速Content Deliver Network 内容分发网络，用来应对国内访问GitHub慢的情况。 主要原理是将网站的内容缓存到全国各地的服务器上，访问网站时先访问缓存服务器。 Github源七牛云CDN加速教程（详细） 图床服务关于图床的一些使用心得总结 - 掘金 七牛云图床有免费的http流量，但是需要搭配备案域名使用。 网站备案个人网站备案通过啦，小记一下过程中遇到的问题 - 知乎 使用七牛云服务都需要一个国内备案的域名。现在域名备案已经简化很多，一个月左右就能完成。 域名备案还需要实体服务器，这里我直接用闲鱼购买的阿里服务码进行备案。","link":"/2024/06/10/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90/"},{"title":"技术总结","text":"这里总结一下我的技术历程，主要分享我遇到的好书、好教程。 深以为然：“CS里面随便一个领域单独拿出来，水都可以深得超过外行的想象，但在工程的场景下，更重要的是投入恰到好处的技能点去实现你现阶段的目标。” https://www.zhihu.com/question/53539039/answer/435412199 还有一个点就是：CS是抽象的学科，是工程经验，只学理论而不实际编程就会变得空洞。 CSAPPbook：深入理解计算机系统(Computer Systems A Programmer’s Perspective)。 课程：CMU CS15213: CSAPP 课程内容覆盖了汇编语言、体系结构、操作系统、编译链接、并行、网络等，作为系统入门课，兼具深度和广度。 非常不错的系统入门课程，读完大黑书并且坐完相应实验，就能有一个非常不错的计算机基础。 缺点：广而杂的系统，跨度大，需要耐心，并且自己上网补充相应领域知识。如果在校学过（上过）体系结构、操作系统，这门课看下来会有一个好的认识（将计算机串起来，复习知识等），并且对国外课程有新的认识。 数据结构邓俊辉 C++ 第三版 清华大学出版社 链接：https://dsa.cs.tsinghua.edu.cn/~deng/ds/dsacpp/index.htm 点评：适合上过一遍数据结构复习使用，不适合小白。有代码比较硬核，c++偏向与竞赛。总体我看下来觉得是不错的。 算法leetcode、代码随想录 算法的学习我觉得是搭配数据结构一起，数据结构主要关心结构的实现，而算法更多利用现成的结构，主要关系结构的特性与使用。 算法就是多刷题，分类刷、多总结。 计算机网络小林图解计算机网络。 关于计算机网络的学习，我的见解是不需要学太深（硬件层面，作为coder、互联网从业），更多关心软件实现。 汇编语言王爽 第四版 清华大学出版社 评价：当之无愧我遇到的最适合入门的教材。绝对值得由浅入深这四个字，抛弃无用知识，循序渐进。 操作系统首推 MIT6.S081 xv6操作系统，看完这门课以及xv6小型操作系统的源码就很足够了。 其次是南京大学蒋岩炎的操作系统课程，中文友好，缺点是比较硬核。 The Missing Semester of Your CS Educationhttps://missing.csail.mit.edu 计算机系统工作工具常识。十分推荐。 分布式系统MIT6.824 非常不错的系统，尤其是lab。 数据库CMU15445 比较硬核，实现一个数据库。如今数据库求职者人手一个。 深度学习首推 Coursera吴恩达深度学习课程。个人跟着学完，通俗易懂，还有很好的lab实现。 其次就是李沐大神的动手学习深度学习。","link":"/2025/01/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%B7%A5%E7%A8%8B/%E6%88%91%E7%9A%84%E6%8A%80%E6%9C%AF%E6%80%BB%E7%BB%93/"},{"title":"A __FILE__ Macro Which Does Not Contain the Whole Source File Path","text":"编译时计算短文件名的宏。 转载自：https://galowicz.de/2016/02/20/short_file_macro/ A FILE Macro Which Does Not Contain the Whole Source File Path February 20, 2016 c++ The __FILE__ macro expands to the current source file name at compile time. It is not really useful if the source file paths which the build system uses, are very long, as this would bloat log output with long path names. It would be useful to have a shortened version, which only contains the file name without the whole path. This article describes how to implement a __SHORT_FILE__ macro, that does not add any run time overhead. Making Strings shorter at Compile TimeIt is of course easy, to find the last slash in a string like /home/user/src/project/src/file.cpp, and return a pointer to the token file.cpp. This could be done at run time, and the overhead would most probably be neglibible in most thinkable situations, but it is no hassle to do it at compile time with C++11 using a constexpr function: 1234567891011121314using cstr = const char * const;static constexpr cstr past_last_slash(cstr str, cstr last_slash){ return *str == '\\0' ? last_slash : *str == '/' ? past_last_slash(str + 1, str + 1) : past_last_slash(str + 1, last_slash);}static constexpr cstr past_last_slash(cstr str){ return past_last_slash(str, str);} This is certainly not the most elegant way to express a substring search. A nicer way would be to search for the last slash in a loop, or simply use library functions. In this context, however, it would not be possible to execute such code at compile time. This function in the presented form can be executed by a C++11 compiler at compile time, and then it is possible to directly embed the returned substring in the binary. (With C++14, it is possible to express this the easier to read loop way) One could now write printf or std::cout (or whatever) to print just the file name via past_last_slash(__FILE__), which is nice, but has two flaws: It is still not as comfortable as a macro would be, i.e. __SHORT_FILE__ There is no guarantee, that the compiler would not call this function at runtime! #1 can be fixed just by wrapping the function call into a #define, but that doesn’t fix #2. I wrote a small program which just does a puts(__SHORT_FILE__) using this bad macro, and it produced the following assembly output: 123callq __ZL15past_last_slashPKc ## past_last_slash(char const*)movq %rax, %rdicallq 0x100000f58 ## symbol stub for: _puts In order to obtain the short version of __FILE__, a function is called. This function is also called without parameters, which means that the compiler generated a function which is hard coded to this specific string. When compiling with -O2, this code disappeared, but there is no guarantee for that. Important: The return values of functions marked constexpr are only guaranteed to be calculated at compile time, if they are put into variables which are also marked constexpr. The following macro, which looks strange, fixes both: 1#define __SHORT_FILE__ ({constexpr cstr sf__ {past_last_slash(__FILE__)}; sf__;}) This macro uses a {} scope, to instantiate a new helper variable on the fly, in order to force the return value of the helper function into a constexpr variable. At this point it is guaranteed, that the compiler will embed the return value into the binary, without generating a run time function call. The parentheses around that allow for transforming this scope block into an expression. ({int x = f(a, b); ...; x}) will just return the value of x, which was determined inbetween. It is now possible to put this macro into any expression which would also accept __FILE__ for logging, or printing. The assembly of the example program also looks better: 12leaq 0x45(%rip), %rdi ## literal pool for: &quot;main.cpp&quot;callq 0x100000f54 ## symbol stub for: _puts I found this macro pretty cool, as it reduces binary- and code size. And it even does this if optimization flags are disabled, in order to have a close look at the assembly while debugging.","link":"/2025/05/18/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%B7%A5%E7%A8%8B/%E7%9F%AD%E6%96%87%E4%BB%B6%E5%AE%8F/"},{"title":"Linux命令学习","text":"学习思路： 大类相关：系统资源查看、文件操作 命令基本知识，比如选项参数、输出情况 应用场景：针对特定需求写命令 你应该知道的linux技巧 https://coolshell.cn/articles/8883.html 文件管理查看： ls head、tail less、more、cat 管理 chmod、chown 系统资源管理ps命名 a: 显示终端上的所有进程，包括其他用户的进程。 u: 显示进程的详细用户/拥有者信息。 x: 显示没有控制终端的进程。 p: 显示进程的PID（进程ID） 查询指定名称的进程pid，cpu 占用率和 memory 使用率 1ps aux | grep example 杀死指定pid进程 1kill process_pid 查看cpu使用情况 12topps -ef top命令top命令可以实时地展示系统当前的进程状态，它会不断更新，提供系统进程的动态信息。而ps命令则是系统在过去执行的进程的静态快照，它不能实时更新。 此外，top命令还具有交互性，允许用户输入控制命令，比如在top命令的模式下输入n5，就显示此时的5个最活跃的进程，top会持续运行直到用户按下“q”，退出top。 网络管理查看端口占用1lsof -i:8080 文本操作grep查找，sed编辑，awk对数据分析并生成报告。 grep更适合单纯的查找或匹配文本，sed更适合编辑匹配到的文本，awk更适合格式化文本。 grepGrep能使用正则表达式搜索文本，并把匹配的行打印出来，全称是 Global Regular Expression Print，全局正则表达式打印。grep通过返回一个状态值来说明搜索的状态，如果模板搜索成功，则返回0，如果搜索不成功，则返回1，如果搜索的文件不存在，则返回2。 命令的基本格式： 1grep [option] pattern file 常见参数： -i：忽略大小写进行匹配。 -v：反向查找，只打印不匹配的行。 -n：显示匹配行的行号。 -r：递归查找子目录中的文件。 -l：只打印匹配的文件名。 实际例子： 1、系统报警显示了时间，但是日志文件太大无法直接 cat 查看。(查询含有特定文本的文件，并拿到这些文本所在的行) 1grep -n '2019-10-24 00:01:11' *.log 2、在文件夹 dir 中递归查找所有文件中匹配正则表达式 “pattern” 的行，并打印匹配行所在的文件名和行号： 1grep -r -n pattern dir/ awkAWK是文本处理命令( pattern-directed scanning and processing language)，名称取自三位创始人首字符。awk的大致逻辑是逐行读入文件，以空格为默认分隔符将每行切片，再对切开的部分再进行各种分析处理。 基本用法： 1awk '[pattern] {action}' {filenames} # 行匹配语句 awk '' 只能用单引号 pattern 是要匹配的模式，通常是基于正则表达式； action 是当模式匹配时要执行的动作； filename 是您要处理的文件名。 过滤(1) 例子 提取第1列与第4列 1$ awk '{print $1, $4}' netstat.txt 亦可格式化输出，格式化语义与C语言的printf语义一致 1$ awk '{printf &quot;%-8s %-8s %-8s %-18s %-22s %-15s\\n&quot;,$1,$2,$3,$4,$5,$6}' netstat.tx 提取第3列为0且第6列为LISTEN的行的第1列信息 1$ awk '$3==0 &amp;&amp; $6==&quot;LISTEN&quot;{print $1} ' netstat.txt 取出文件中的第一万至两万行 1awk 'NR&gt;=10000 &amp;&amp; NR&lt;=20000' &lt;filename&gt; （2）基本知识 比较运算符：!=, &gt;, &lt;, &gt;=, &lt;=, == 内建变量 名称 作用 $0 当前记录（这个变量中存放着整个行的内容） $1~$n 当前记录的第n个字段，字段间由FS分隔 FS 输入字段分隔符 默认是空格或Tab NF 当前记录中的字段个数，就是有多少列 NR 已经读出的记录数，就是行号，从1开始，如果有多个文件话，这个值也是不断累加中。 FNR 当前记录数，与NR不同的是，这个值会是各个文件自己的行号 RS 输入的记录分隔符， 默认为换行符 OFS 输出字段分隔符， 默认也是空格 ORS 输出的记录分隔符，默认为换行符 FILENAME 当前输入文件的名字 123456789- FS(Field Separator)：输入字段分隔符， 默认为空白字符- OFS(Out of Field Separator)：输出字段分隔符， 默认为空白字符- RS(Record Separator)：输入记录分隔符(输入换行符)， 指定输入时的换行符- ORS(Output Record Separate)：输出记录分隔符（输出换行符），输出时用指定符号代替换行符- NF(Number for Field)：当前行的字段的个数(即当前行被分割成了几列)- NR(Number of Record)：行号，当前处理的文本行的行号。- FNR：各文件分别计数的行号- ARGC：命令行参数的个数- ARGV：数组，保存的是命令行所给定的各参数 使用：打印首行 1$ awk '$3==0 &amp;&amp; $6==&quot;ESTABLISHED&quot; || NR==1 {printf &quot;%s %s\\n&quot;,NR,$4}' netstat.txt 指定分割符，利用短选项-F 1$ awk -F: '{print $1,$3,$6}' /etc/passwd 统计脚本awk其实是一门脚本语言，有自己的语法结构，变量定义、条件循环等流程控制。 参考：https://www.bookstack.cn/books/junmajinlong-awk （1）BEGIN 与 END BEGIN：当awk开始处理任何输入行之前，BEGIN模式下的代码块会执行一次。 END：当awk处理完所有输入行后，END模式被触发。 BEGIN 和 END都放在要执行的代码块之前。 （2）自定义变量与流程控制 自定义变量，统计文件中含有字符串 abc 的总行数 1awk '/abc/ {count++} END {print count}' filename.txt 自定义变量，统计目录下所有的C文件，CPP文件和H文件的文件大小总和。 1$ ls -l *.cpp *.c *.h | awk '{sum+=$5} END {print sum}' 自定义数组，统计各个connection状态的个数 1awk 'NR!=1 {a[$6]++;} END { for (i in a) print i &quot;, &quot; a[i]; }' netstat.txt 自定义数组，统计每个用户的进程的占了多少内存 1ps aux | awk 'NR!=1{a[$1]+=$6;} END { for(i in a) print i &quot;, &quot; a[i]&quot;KB&quot;;}' 自定义数组，统计一个文件(IP TIME) 的每个IP出现次数，并按次数排序 1awk '{ip[$1]++} END {for (i in ip) print ip[i], i}' access.log | sort -k2 sed命令sed全称（stream editor）流式编辑器，主要逻辑也是逐行匹配，编辑。玩sed主要还得熟练正则表达式。 sed最主要的场景就是匹配并替换。 // todo","link":"/2023/12/22/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux%E5%91%BD%E4%BB%A4/"},{"title":"CSAPP第7章 链接","text":"链接的通俗概念链接就是将各种代码和数据片段收集并组合为一个单一文件的过程。 因为链接器的存在，它使得分离式编译成为可能。 静态链接静态链接的输入通常是一组可重定位的目标文件，输出是一个完全链接、可以加载和运行的可执行目标文件。 链接的两个主要任务： 符号解析 重定位 符号解析的过程是将符号引用和定义关联的过程。这里符号解析单纯连接符号定义和符号引用，而不是编译原理中的解析语法符号。 符号可以指：函数、全局变量、静态变量 重定位是将符号定义与内存地址关联的过程，并且每个符号引用也要替换为相应的地址（重新定位符号的地址）。 可重定位目标文件首先了解一下典型的ELF可执行可链接文件的格式，因为链接器的输入就是它。 ELF 全称 “Executable and Linkable Format”，即可执行可链接文件格式，目前常见的Linux、 Android可执行文件、共享库（.so）、目标文件（ .o）以及Core 文件（吐核）均为此格式。 典型的ELF文件由一个ELF header、若干个节以及Section Header Table（节头部表）组成。 ELF header主要是一些文件的元信息，而Section Header Table节头部表描述了不同节的大小和位置。 ELF其中重要的是若干个节，我们现在需要了解的是symtab符号表，它存放了程序中定义和引用的函数和全局变量的信息。 符号和符号表每个ELF文件（模块m）都有一个符号表，它包含了当前文件定义和应用的符号信息，这些符号可以分为： 全局符号：在m中定义，能被其他模块引用的符号。 比如非静态的C函数和全局变量。 外部符号：由其他模块定义，但是被m使用的符号。 比如其他模块定义的非静态的C函数和全局变量。 局部符号：只被m定义和使用的符号。 比如带static的C函数的全局变量。 需要注意到函数内部的局部变量不归符号表管辖，因为它们由运行时的栈管理。 而静态的局部变量还是会被符号表记录。 符号解析解析的过程就是将符号引用和符号表中的定义相关联（具体怎么关联母鸡）。 局部符号的解析简单明了，全局符号和外部符号的解析比较麻烦。 在编译器生成目标文件的过程中，如果它遇到一个不再当前模块定义的符号（变量/函数名），那么它就会生成一个链接器符号条目（编译器会假设这个符号由其他模块定义，并生成了一个填空让链接器来填）。 链接器解析多重定义符号链接器的输入是一组可重定位目标模块。每个模块定义一组符号，有些是局部的（只对定义该符号的模块可见），有些是全局的（对其他模块也可见）。 如果多个模块定义同名的全局符号，会发生什么呢？下面是 Linux编译系统采用的方法。 在编译时，编译器向汇编器输出每个全局符号，或者是强（ strong）或者是弱（weak），而汇编器把这个信息隐含地编码在可重定位目标文件的符号表里。函数和已初始化的全局变量是强符号，未初始化的全局变量是弱符号。 根据强弱符号的定义， Linux链接器使用下面的规则来处理多重定义的符号名 规则1：不允许有多个同名的强符号。 规则2：如果有一个强符号和多个弱符号同名，那么选择强符号。 规则3：如果有多个弱符号同名，那么从这些弱符号中任意选择一个。 一强一弱的符号会产生意想不到的错误，建议编译时带上GCC-fno-common表示来使得任何遇见多重定义的符号时，编译器能发出警告信息。 静态库静态库概念是指将所有的目标文件打包成一个共享文件，它可以作为链接器的输入。 它的概念起源于一些标准函数的调用，用户希望能直接使用。一种方式是让编译器认出标准函数，但这么做的代价就是库函数的开发和编译器的开发耦合。另一种方式，是将所有的标准C函数都放在一个可重定位的目标模块中。但这么做有两个缺点：1、牵一发而动全身（对单个函数的改动需要重新编译整个文件）2、冗余复制（每个可执行文件将不需要的目标函数也一起链接了）。 所以，静态库的概念就是将每个标准函数单独编译为目标模块，然后再将这些目标模块再次打包成一个静态库文件。链接器链接时，只复制被程序引用的目标模块。 链接器使用静态库解析引用在符号解析阶段，链接器会从左往右按照它们在编译器驱动程序命令行上的出现顺序来扫描文件。 在命令行中，如果定义一个符号的库出现在引用这个符号的目标文件之前，那么引用就不能被解析，链接就会失败。 链接准则：符号定义的库要放在符号引用的文件之后。 所以将静态库放在命令行最尾部。还有一方面，如果库函数互相引用，可以在命令行上重复库来满足依赖关系。 重定位在重定位中，将合并输入模块，并为每个符号分配运行时地址。具体来说，有两个步骤： 重定位节和符号定义 链接器将所有相同类型的节合并为同一类型的节。然后将运行时地址赋给每个聚合节以及符号定义。 重定位节中的符号引用 在这一步中，链接器修改代码节和数据节中对每个符号的引用，使得它们指向正确的运行时地址（这主要依靠重定位条目）。 重定位条目在符号解析的过程中，在编译器生成目标文件的过程中，如果它遇到一个不再当前模块定义的符号（变量/函数名），那么它就会生成一个链接器符号条目，这里其实就是重定位条目。 重定位这块跳过 加载可执行目标文件加载的过程其实就是搭建进程的内存映像。 在程序头部表的引导下，加载器将可执行文件的片（ chunk）复制到代码段和数据段。接下来，加载器跳转到程序的入口点，也就是 _start 函数的地址。这个函数是在系统目标文件ctrl.o中定义的，对所有的C程序都是一样的。 _start 函数调用系统启动函数 __libc_start_main，该函数定义在libc.so中。它初始化执行环境，调用用户层的main函数，处理main函数的返回值，并且在需要的时候把控制返回给内核。 动态链接静态库的缺点 更新麻烦，需要显式的下载最新库，然后再与更新的库链接 内存浪费（几乎每个C程序都用标准库函数，这些代码会被复制到每个运行进程的文本段中，这会造成内存资源的极大浪费） 动态链接是怎么解决静态库缺点的动态库的思想就是共享，而不是复制和嵌入。明白这一点需要理解虚拟内存以及内存映射。 在链接时，链接器只复制一些重定位和符号表信息，在运行时解析这些对于代码和数据的引用。 具体的工作由动态链接器执行，可执行文件包含一个.interp节，这个节包含了动态链接器的路径名。当加载程序时，这个动态链接器就会执行，它来重定位动态库的文本和数据。","link":"/2024/01/30/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/csapp%E7%AC%AC7%E7%AB%A0%E9%93%BE%E6%8E%A5/"},{"title":"CSAPP第八章信号部分","text":"信号基本含义linux中信号就是一段消息，通知进程发生了某些事情，类比软件层面的异常（软中断）。 信号是一种软件形式的异常，允许进程和内核中断其他进程，可以用来通知用户进程发生了某些异常 Linux系统基本信号及其行为常见的信号有： SIGINT（利用ctrl+c键发送给前台组的每个进程，默认是终止进程） SIGCHLD（子进程终止时，内核会发送这个信号给父进程） 信号术语发送信号：内核更新进程的某个上下文； 接收信号：一个进程可以忽略一个信号，或者执行一段处理程序。 内核为每个进程维护了两个位向量，一个用来标记待处理信号pending，一个标记被阻塞信号blocked。只要传送了一个类型为k的信号，那么进程的pending的第k位就会设置为1。 这个实现有什么问题？一个信号没有被及时处理，那么后面几个信号就会丢失。对一个进程而言，同一时刻，同种类型的信号最多只能有一个处于待处理状态，多余的会被直接抛弃。 发送信号在了解发送信号的方式前，需要了解两个概念：进程组和前后台作业 进程组每个进程都属于且只属于一个进程组，一个进程组由一个正整数标识。 前后台作业作业这个概念其实就是进程。不过作业是加了限定词的进程：unix shell用作业表示对一条命令行求值而创建的进程。 在任何时刻，至多有一个前台作业和0至多个后台作业。 发送信号的方式（1）/bin/kill程序 linux&gt; /bin/kill -9 15213 表示发送信号9（SIGKILL）给进程24818 linux&gt; /bin/kill -9 -15213 表示发送信号9（SIGKILL）给进程组24818 （2）键盘发送 Crtl+C会导致内核发送一个SIGINT信号到前台进程组中的每一个进程。 （3）标准库接口 可以在函数中调用kill函数来对目的进程发送信号 123#include &lt;sys/types.h&gt;#include &lt;signal.h&gt;int kill(pid_t pid, int sig); 用alarm函数发送SIGALARM信号 12#include &lt;unistd.h&gt;unsigned int alarm(unsigned int secs); 接收信号接收信号：当目的进程被内核强迫以某种方式对信号的发送做出反应时，它就接收了信号。 接收信号的时机：内核把进程从内核模式切换到用户模式时（例如系统调用返回），它会检查进程的未被阻塞的待处理信号的集合（pending &amp; ~blocked），如果集合非空，那么就会选择某个信号k，强制进程处理信号k。 接收信号的默认行为： 进程终止 忽略该信号 通过用户层函数信号处理程序捕获这个信号 修改信号的默认行为12345#include &lt;signal.h&gt;typedef void (*sighandler_t)(int); sighandler_t signal(int signum, sighandler_t handler); signum为信号序号，handler为信号处理程序。我们可以使用自定义的信号处理程序，也可以使用预定义的几个处理程序（SIG_IGN进程忽略该信号、SIG_DFL恢复该信号的默认行为）。 用户自定义的信号处理程序要遵从sighandler_t的信号处理原型，接收一个整数入参，无出参。 例子： 12345678910#include &lt;signal.h&gt;void handler(int sig){ if((waitpid(-1, NULL, 0)) &lt; 0) unix_error(&quot;waitpid error&quot;);}int main(){ if(signal(SIGCHLD, handler) == SIG_ERR) unix_error(&quot;signal error&quot;); return 0;} 这里只要在main函数开始调用一次signal，就相当于从此以后改变了SIGCHLD信号的默认行为，让它去执行handler处理程序。当子进程终止或停止时，内核就会发送一个SIGCHLD信号到父进程中，此时就能让父进程去执行自己的工作，当子进程终止或停止时，发送SIGCHLD信号到父进程，则父进程会调用handler函数来对该子进程进行回收。 阻塞信号Linux提供阻塞信号的隐式和显示的机制： 隐式阻塞机制：内核默认阻塞当前正在处理信号类型的待处理信号。 显示阻塞机制：应用程序通过sigprocmask函数来显示阻塞和解阻塞选定的信号。 12#include &lt;signal.h&gt;int sigprocmask(int how, const sigset_t *set, sigset_t *oldset); 通过how来决定如何改变阻塞的信号集合blocked： 当how=SIG_BLOCK时，blocked = blocked | set 当how=SIG_UNBLOCK时，blocked = blocked &amp; ~set 当how=SETMASK时，block = set 编写健壮的信号处理程序如何编写安全、正确和可移植的信号处理程序？ 并发认知信号也是并发的一个例子，信号处理程序是一个独立的逻辑流（不是进程），与主程序并发运行。比如我们在进程A中执行一个while循环，当该进程受到一个信号时，内核会将控制权转移给该信号的处理程序，所以该信号处理程序是并发执行的，当信号处理程序结束时，再将控制转移给主程序。由于信号处理程序与主程序在同一进程中，所以具有相同的上下文，所以会共享程序中的所有全局变量。 原则 处理程序尽可能简单 处理程序使用异步信号安全的函数 所谓异步信号安全，要么可重入，要么不可中断。 保存和恢复errno 暂时阻塞所有信号，保护对全局数据结构的访问 volatile声明全局变量 sig_atomic_t 声明全局标志，确保原子操作 正确的信号处理信号位向量的特性导致同类型信号丢弃现象 处理方法：一次信号处理函数调用尽可能多的处理信号 可移植的信号处理不同的系统有不同的信号处理语义： signal函数的语义各有不同。 系统调用可以被中断。 要解决这些问题，定义了sigaction函数，它允许用户在设置信号处理时，明确指定他们想要的信号处理语义。 1int sigaction(int signum, struct sigaction *act, struct sigaction *oldact) 信号同步案例一：父子进程竞争场景：子进程结束出发SIGCHLD信号，导致信号处理函数先运行，造成同步错误。 解决方法：在fork之前，阻塞SIGCHLD信号，等到某个特定位置运行完，再解锁信号。 启发：如果想要确保某些code（比如addjob）能在信号handler之前被运行，那么就阻塞该信号，直到该code执行完毕。 缺点：子进程需要额外解锁该信号。 案例二：显式等待某信号场景：父进程等待子进程执行完毕。 12while(!pid) ; 浪费CPU 12while(!pid) pause(); 死锁风险：在while后收到信号，然后pause，永远收不到信号，无法返回。 12while(!pid) sleep(1); sleep无法确定睡眠间隔 最佳实践：12while(!pid) sigsuspend(&amp;prev); 解读sigsuspend： 从语义上看，表示对某信号延迟处理，等待一段时间 从代码上来看，sigsuspend(&amp;mask)等价于原子版本的以下三句组合： 123sigprocmask(SIG_SETMASK, &amp;mask, &amp;prev);pause();sigprocmask(SIG_SETMASK, &amp;prev, NULL); 其中原子性是第一句和第二句，这两者之间的执行不会被中断。 实际使用在调用sigsuspend前阻塞SIGCHLD信号 在调用sigsuspend时取消阻塞SIGCHLD信号（利用mask），那么SIGCHLD信号都会被等到pause执行完处理，然后又恢复阻塞SIGCHLD信号。","link":"/2024/02/17/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/csapp%E7%AC%AC8%E7%AB%A0%E4%BF%A1%E5%8F%B7/"},{"title":"协程理论认识","text":"笔记取自： 【协程革命】理论篇 https://www.bilibili.com/video/BV1K14y1v7cw 主旨协程是可以暂停和恢复的函数。 在一个地方暂停后，又在同样的地方恢复。 为什么需要暂停？一些场景 等待资源就绪（网络IO） UI渲染时处理业务逻辑 游戏技能计算，每一帧计算飞行轨迹然后处理其他逻辑 可以归纳为有其他优先级更高的事件发生时，交处执行权。但这不是线程的切换，协程只是一个函数，协程的切换是函数间的切换（可能切换到另一个线程内的协程）。 暂停与恢复协程暂停了，然后恢复的是哪个协程？ 普遍来说，有一个调度器控制协程切换的整个行为，它负责挑选合适的协程进行运行。 一个协程暂停，它可能返回上层调用它的函数，可能直接返回调度器，也可能切换到另一个协程。 回到调度器，协程调用链得到保存 回到上层调用，比如说python的yield产生一个数据 直接恢复其他协程而不通知调用器，这个最危险（对称式协程） 协程与线程 调度器存放了许多被暂停的协程，多线程争抢协程运行。 实现协程一个协程要做到再恢复，就必须有个地方存上次离开的信息（上下文信息），根据地方的不同，分为有栈协程和无栈协程。 无栈协程对应一个结构体，这个结构体保存了所有协程必要的信息。有栈协程对应了一个2000字节的内存空间，这2000字节的空间可以当作栈使用。 两者优缺点： 有栈申请空间浪费，空间大小不好确定。无栈内存紧凑 有栈递归快，无栈慢 协程切换为什么比线程快在用户级线程中，线程由程序通过线程库实现，线程管理由应用负责，线程切换只需要在用户态完成。 1）协程切换完全在用户空间进行，线程切换涉及特权模式切换，需要在内核空间完成； 2）协程切换相比线程切换做的事情更少。 当前协程的 CPU 寄存器状态，称之为CPU上下文 除了和协程相同基本的 CPU 上下文，还有线程私有的栈和寄存器等，说白了就是上下文比协程多一些。","link":"/2023/12/02/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%8D%8F%E7%A8%8B%E7%90%86%E8%AE%BA%E8%AE%A4%E8%AF%86/"},{"title":"MIT6.S081 xv6book chapter1","text":"第一章从操作系统接口方面认识操作系统，以摘要的形式介绍几个关键点，详情请看xv6book。 我的学习经验是：这一章的主要目的就是从整体上把握操作系统，认识几个系统调用。如果你没看懂这一章的一些细节，这是ok的，因为这些细节会逐渐在后面的章节披露，这一章只需要理解系统调用（操作系统为你提供的服务）。 前言操作系统的工作是 (1)将计算机的资源在多个程序间共享，并且给程序提供一系列比硬件本身更有用的服务。 (2)管理并抽象底层硬件，举例来说，一个文字处理软件（比如 word）不用去关心自己使用的是何种硬盘。 (3)多路复用硬件，使得多个程序可以(至少看起来是)同时运行的。 (4)最后，给程序间提供一种受控的交互方式，使得程序之间可以共享数据、共同工作。 操作系统通过接口向用户程序提供服务。一方面我们希望接口设计得简单和精准，使其易于正确地实现；另一方面，我们可能忍不住想为应用提供一些更加复杂的功能。答案是接口的组合，通过这些机制的组合提供强大、通用的功能。 然后就是认识shell、进程，内存，文件描述符，管道和文件系统。 shellThe shell is an ordinary program that reads commands from the user and executes them. The fact that the shell is a user program, and not part of the kernel, illustrates the power of the system call interface: there is nothing special about the shell. It also means that the shell is easy to replace; as a result, modern Unix systems have a variety of shells to choose from, each with its own user interface and scripting features. code design： The xv6 shell uses the above calls to run programs on behalf of users. The main structure of the shell is simple; see main (user/sh.c:145). The main loop reads a line of input from the user with getcmd. Then it calls fork, which creates a copy of the shell process. The parent calls wait, while the child runs the command. For example, if the user had typed “echo hello” to the shell, runcmd would have been called with “echo hello” as the argument. runcmd (user/sh.c:58) runs the actual command. For “echo hello”, it would call exec (user/sh.c:78). If exec succeeds then the child will execute instructions from echo instead of runcmd. At some point echo will call exit, which will cause the parent to return from wait in main (user/sh.c:145). 在shell中，经常使用fork+exec的方式执行用户程序。你可能会觉得这很浪费，毕竟fork拷贝了一份进程资源，为什么不把这两个系统调用合并在一起？ fork的好处是能够简单的实现IO重定向。 同时，为了避免拷贝进程然后马上替换它的浪费，fork采用了copy-on-write技术来优化拷贝过程。 进程和内存An xv6 process consists of user-space memory (instructions, data, and stack) and per-process state private to the kernel. Xv6 time-shares processes: it transparently switches the available CPUs among the set of processes waiting to execute. When a process is not executing, xv6 saves its CPU registers, restoring them when it next runs the process. The kernel associates a process identifier, or PID, with each process. Some system call： fork exit wait exec I/O 和文件描述符文件描述符是一个整数，它代表了一个进程可以读写的被内核管理的对象 每个进程都有一张表，而 xv6 内核就以文件描述符作为这张表的索引，所以每个进程都有一个从0开始的文件描述符空间。 按照惯例，进程从文件描述符0读入（标准输入），从文件描述符1输出（标准输出），从文件描述符2输出错误（标准错误输出）。 shell 保证在任何时候都有3个打开的文件描述符，他们是控制台（console）的默认文件描述符。 Some system call： read write close open dup user program： cat 重要概念：IO重定向，这是shell的一个思想。 File descriptors are a powerful abstraction, because they hide the details of what they are con- nected to: a process writing to file descriptor 1 may be writing to a file, to a device like the console, or to a pipe. 管道A pipe is a small kernel buffer exposed to processes as a pair of file descriptors, one for reading and one for writing 管道是一个小的内核缓冲区，它以文件描述符对的形式提供给进程，一个用于写操作，一个用于读操作。从管道的一端写的数据可以从管道的另一端读取，管道提供了一种进程间交互的方式。 user program： wc Pipes may seem no more powerful than temporary files: the pipeline 1echo hello world | wc could be implemented without pipes as 1echo hello world &gt;/tmp/xyz; wc &lt;/tmp/xyz Pipes have at least four advantages over temporary files in this situation. First, pipes automatically clean themselves up; with the file redirection, a shell would have to be careful to remove /tmp/xyz when done. Second, pipes can pass arbitrarily long streams of data, while file redirection requires enough free space on disk to store all the data. Third, pipes allow for parallel execution of pipeline stages, while the file approach requires the first program to finish before the second starts. Fourth, if you are implementing inter-process communication, pipes’ blocking reads and writes are more efficient than the non-blocking semantics of files. 文件系统文件是一个简单的字节数组，目录包含指向文件和其他目录的引用。目录是一棵树，它的根节点是一个特殊的目录 root 概念：inode、links system call： mknod fstat link unlink user program： mkdir ln rm cd 总结UNIX 将“标准”的文件描述符，管道，和便于操作它们的 shell 命令整合在一起，这是编写通用、可重用程序的重大进步，这个想法激发了 UNIX 强大和流行的“软件工具”文化，而且 shell 也是首个所谓的“脚本语言”。 UNIX 的系统调用接口在今天仍然存在于许多操作系统中，诸如 BSD，Linux，以及 Mac OS X。","link":"/2024/01/07/MIT6.S081/book/chapter1/"},{"title":"MIT6.S081 xv6book chapter2","text":"第二章以操作系统三个要求：复用、隔离和交互展开讲述了内核设计、进程设计，还描述了xv6的启动流程。 看完这一章还是很笼统抽象，一些细节还是需要等到后续披露，但这时候你大致把握到操作系统的整体设计了。 隔离的设计——用户态与内核态；复用的设计——用户进程；交互设计——进程通信。 物理资源的抽象 禁止应用程序直接访问敏感的硬件资源，而是将资源抽象为服务。 比如 open, read, write, and close系统调用，文件系统的抽象让应用程序只需提供path name就能访问资源的便利，而底层硬盘的读写全都有操作系统进行。 Unix 透明地在进程之间切换硬件 CPU，根据需要保存和恢复寄存器状态，因此应用程序不必担心共享。 用户态与内核态强隔离型要求应用程序和操作系统有一个硬边界，我们不希望一个失败的应用程序影响其他应用程序，甚至是操作系统。 那么，CPU在硬件级别上提供了强隔离型的支持：三种模态 machine mode 通常是用于系统启动，配置； supervisor mode 用于执行特权命令，内核运行在kernel space； user mode 应用程序运行在user space。 如果一个应用程序想要调用一个内核函数（比如说系统调用），那么必须切换模式到内核态（比如riscv 提供的ecall指令），有内核执行系统调用。 用户态与内核态就是一个隔离，用户进程不能直接执行特权指令，这也就避免了危险发生。 内核设计A key design question is what part of the operating system should run in supervisor mode. 操作系统的哪一部分应该常驻在内核中呢？根据设计的不同，内核设计也分为 monolithic kernel和micro kernel。 一体化内核中，操作系统全部运行在内核中，因此只要出现一个错误，操作系统整个完蛋。而微内核设计只将必要的代码运行在内核中。 微内核设计与一体化内核的不同：微内核充当消息转发者，比如shell想要读写某个文件，微内核将这个消息发送给file server。 在微内核中，内核接口由一些低级函数组成，用于启动应用程序、发送消息、访问设备硬件等。这种组织方式使内核相对简单，因为大多数操作系统都驻留在用户级服务器中。 不管微内核还是一体化内核，重要的是它们都实现一些key ideas： They implement system calls, they use page tables, they handle interrupts, they support processes, they use locks for concurrency control, they implement a file system, etc. 这些key idea是值得我们去学习借鉴的。 进程总览进程是实现隔离性的一个单元。进程抽象可防止一个进程破坏或监视另一个进程的内存、CPU、文件描述符等。它还可以防止进程破坏内核本身，因此进程无法破坏内核的隔离机制。 为了实现隔离性，进程为用户程序提供了一个幻觉，在程序看来，它好像掌握了整台机器。用户程序独占了机器一整片的地址空间，其他用户程序无法读写。用户程序还觉得自己独占了CPU来执行自己的指令。 地址空间地址空间的幻觉由页表实现（第三章将详细讲述）。简单来说，进程看到的是虚拟地址空间，通过页表映射到真实的物理空间。xv6 为每个进程维护了不同的页表，这样就能够合理地定义进程的地址空间了。 进程的地址空间从零开始，一直到最大虚拟地址。 地址空间的布局：Instructions come first, followed by global variables, then the stack, and finally a “heap” area (for malloc) that the process can expand as needed. At the top of the address space xv6 reserves a page for a trampoline and a page mapping the process’s trapframe. Xv6 uses these two pages to transition into the kernel and back; the trampoline page contains the code to transition in and out of the kernel and mapping the trapframe is necessary to save/restore the state of the user process xv6 使用结构体 struct proc 来维护一个进程的状态，其中最为重要的状态是进程的页表，内核栈，当前运行状态。 线程每个进程都有一个执行线程（或简称线程），用于执行进程的指令。线程可以挂起，以后再恢复。 为了在进程之间透明地切换，内核会挂起当前正在运行的线程并恢复另一个进程的线程。 线程的大部分状态（局部变量、函数调用返回地址）都存储在线程的堆栈中。 xv6大概是一个进程只有一个线程，因此两者的区别不大。 两个栈Each process has two stacks: a user stack and a kernel stack (p-&gt;kstack). When the process is executing user instructions, only its user stack is in use, and its kernel stack is empty. When the process enters the kernel (for a system call or interrupt), the kernel code executes on the process’s kernel stack; while a process is in the kernel, its user stack still contains saved data, but isn’t actively used. 每个进程都有两个栈，用户栈和内核栈。程序在运行时只有用户栈在使用，内核栈为空。当程序进入内核时，内核栈被使用，用户栈可以被使用。 总结In summary, a process bundles two design ideas: an address space to give a process the illusion of its own memory, and, a thread, to give the process the illusion of its own CPU. In xv6, a process consists of one address space and one thread. In real operating systems a process may have more than one thread to take advantage of multiple CPUs. 总之，进程捆绑了两个设计思想：一个是地址空间，用于为进程提供其自身内存的错觉，另一个是线程，用于为进程提供其自身 CPU 的错觉。 在 xv6 中，进程由一个地址空间和一个线程组成。在实际操作系统中，一个进程可能具有多个线程来利用多个 CPU。 编译运行kernel首先，Makefile（XV6目录下的文件）会读取一个C文件，例如proc.c；之后调用gcc编译器，生成一个文件叫做proc.s，这是RISC-V 汇编语言文件；之后再走到汇编解释器，生成proc.o，这是汇编语言的二进制格式。 Makefile会为所有内核文件做相同的操作，比如说pipe.c，会按照同样的套路，先经过gcc编译成pipe.s，再通过汇编解释器生成pipe.o。 之后，系统加载器（Loader）会收集所有的.o文件，将它们链接在一起，并生成内核文件。这里生成的内核文件就是我们将会在QEMU中运行的文件。 我们来看传给QEMU的几个参数： -kernel：这里传递的是内核文件（kernel目录下的kernel文件），这是将在QEMU中运行的程序文件； -m：这里传递的是RISC-V虚拟机将会使用的内存数量； -smp：这里传递的是虚拟机可以使用的CPU核数； -drive：传递的是虚拟机使用的磁盘驱动，这里传入的是fs.img文件。 xv6，启动！To make xv6 more concrete, we’ll outline how the kernel starts and runs the first process. 不必拘泥于细节，掌握启动流程。","link":"/2024/01/07/MIT6.S081/book/chapter2/"},{"title":"MIT6.S081 xv6book chapter3","text":"第三章的主题是页表，单看页表会很抽象，但页表背后的思想是地址空间的隔离。让每个进程都有自己的地址空间，保护地址空间不受他人侵犯。同时，页表管理的“页”，页内地址连续，以页为单位，避免页表过于庞大（多级页表也是为了实现这个目标）。同时，虚拟空间到物理空间的映射，多了几分实用trick，比如内核采用直接映射、内核页表下的guard page（未映射）、内核和用户相同的映射（trampoline page，多对一映射）。 本节融合了课程lec04的内容。虚拟地址的抽象是为了程序的隔离性，理解这点后就很容易了。 地址空间先回顾一下，我们期望得到什么样的隔离结果？ 我们期望的是，每个用户程序都被装进一个盒子里，这样它们就不会彼此影响了，同时它们与操作系统也相互独立。这样，如果某个应用程序无意或故意做了一些坏事，也不会影响到操作系统。这就是我们对于隔离性的期望。 所以，我们想要某种机制，能够将不同程序之间的内存隔离开来，这样类似的事情就不会发生。一种实现方式是地址空间（Address Spaces）。 这里的基本概念也很简单直观，我们给包括内核在内的所有程序专属的地址空间。每个应用程序都能看到0～n的地址空间，同时它们都认为这些地址空间都是自己专有的，其他进程无法访问。换句话说，这些地址空间彼此独立。 所以现在我们的问题是如何在一个物理内存上，创建不同的地址空间，因为归根到底，我们使用的还是一堆存放了内存信息的DRAM芯片。如何在一个物理内存上，创建不同的地址空间？最常见的方法，同时也是非常灵活的一种方法就是使用页表（Page Tables）。 页表页表是在硬件中通过处理器和内存管理单元（Memory Management Unit）实现。 对于任何一条带有地址的指令，其中的地址应该认为是虚拟内存地址而不是物理地址。虚拟内存地址会被转到内存管理单元，内存管理单元会将虚拟地址翻译成物理地址。之后这个物理地址会被用来索引物理内存，并从物理内存加载，或者向物理内存存储数据。 从CPU的角度来说，一旦MMU打开了，它执行的每条指令中的地址都是虚拟内存地址。 怎么完成虚拟地址到物理地址的翻译呢？答案就是页表。MMU会有一个表单，表单中，一边是虚拟内存地址，另一边是物理内存地址。 同时，这张表单也需要保存在物理地址中，在运行时加载进内存。所以，CPU中需要有一些寄存器用来存放表单在物理内存中的地址（假设这个位置的物理内存地址是0x10，那么在RISC-V上一个叫做SATP的寄存器会保存地址0x10）。这样，CPU就可以告诉MMU，可以从哪找到将虚拟内存地址翻译成物理内存地址的表单。 那么，地址隔离的基本想法是每个应用程序都有自己独立的表单，并且这个表单定义了应用程序的地址空间。当操作系统将CPU从一个应用程序切换到另一个应用程序时，同时也需要切换SATP寄存器中的内容，从而指向新的进程保存在物理内存中的地址对应表单。这样的话，cat程序和Shell程序中相同的虚拟内存地址，就可以翻译到不同的物理内存地址，因为每个应用程序都有属于自己的不同的地址对应表单。 还有一个细节，表单是如何映射虚拟地址到物理地址的？如果为每个虚拟地址建立一个条目，那么64位的cpu内存很快就会被耗光。实际情况是以页为单位，每一页对应一条表单条目，每一次地址翻译都是针对一页。所以对于虚拟内存地址，我们可以将它划分为两个部分，index和offset，index用来查找page，offset对应的是一个page中的哪个字节。 学生提问：我想知道4096字节作为一个page，这在物理内存中是连续的吗？ Frans教授：是的，在物理内存中，这是连续的4096个字节。所以物理内存是以4096为粒度使用的。 同一个学生：所以offset才是12bit，这样就足够覆盖4096个字节？ Frans教授：是的，page中的每个字节都可以被offset索引到。 物理页是连续的，单个页面内是一片连续的空间。 多级页表首先就是要理解单级页表的实现。 所谓页表，就是一个连续的数组，这个数组的元素是PTE（Page Table Entries）。 在xv6的实现上，一个进程都有自己的一个页表，这个页表就是一个64位的指针，指向数组开头地址。单级页表使用27位bit作为索引，这意味着，页表的大小也必须是这么大。在进程初始化时，必须分配2^27 * PTE大小的一个连续空间，作为存放PTE的仓库。这个仓库一开始是空的，尽管能通过索引访问仓库中的第k个PTE，但这个PTE的有效标识位是false，此时分配一个物理地址，将物理地址的高44位分配给PPN，这个PTE就有效了。 再看多级页表，xv6上实现的是3级页表，每个页表的大小是2^9PTE大小。SATP寄存器会指向最高一级的page directory的物理内存地址，之后我们用虚拟内存中index的高9bit用来索引最高一级的page directory，这样我们就能得到一个PPN，也就是物理page号。这个PPN指向了中间级的page directory。当我们在使用中间级的page directory时，我们通过虚拟内存地址中的L1部分完成索引。接下来会走到最低级的page directory，我们通过虚拟内存地址中的L0部分完成索引。*在最低级的page directory中，我们可以得到对应于虚拟内存地址的物理内存地址。 多级页表的好处就在于能够按需分配小页表。如果进程使用很少的地址空间，譬如只需要一个页面，那么在多级页表下只需要分配3个页表，大小是$3512PTE$。而在单级页表下，尽管我们只需要一个页，但仍然需要分配2^ 27*PTE大小的一个页表。 多级页表的坏处就在于访问内存多次。 a potential downside of three levels is that the CPU must load three PTEs from memory to perform the translation of the virtual address in the load/store instruction to a physical address PTE为什么存的是物理地址而不是虚拟地址？其实PTE存的是物理地址的高44位。 Frans教授：让我来问自己的一个有趣的问题，为什么是PPN存在这些page directory中？为什么不是一个虚拟内存地址？ 某学生回答：因为我们需要在物理内存中查找下一个page directory的地址。 Frans教授：是的，我们不能让我们的地址翻译依赖于另一个翻译，否则我们可能会陷入递归的无限循环中。所以page directory必须存物理地址。那SATP呢？它存的是物理地址还是虚拟地址？ 某学生回答：还是物理地址，因为最高级的page directory还是存在物理内存中，对吧。 Frans教授：是的，这里必须是物理地址，因为我们要用它来完成地址翻译，而不是对它进行地址翻译。所以SATP需要知道最高一级的page directory的物理地址是什么。 为什么中间页表能通过最高级页表的44位物理地址找到56位的物理地址？剩下的12位偏移量从哪来的？ 学生提问：我想知道我们是怎么计算page table的物理地址，是不是这样，我们从最高级的page table得到44bit的PPN，然后再加上虚拟地址中的12bit offset，就得到了完整的56bit page table物理地址？ Frans教授：我们不会加上虚拟地址中的offset，这里只是使用了12bit的0。所以我们用44bit的PPN，再加上12bit的0，这样就得到了下一级page directory的56bit物理地址。这里要求每个page directory都与物理page对齐（也就是page directory的起始地址就是某个page的起始地址，所以低12bit都为0）。 我：这其实也是困惑我蛮久的一个问题。其实一个页表的地址就是一个数组的开头地址，偏移量就是0。44位高位加上12位0，就能得到真实页表物理地址了。 三次索引，有一次没成功怎么办？ 学生提问：当一个进程请求一个虚拟内存地址时，CPU会查看SATP寄存器得到对应的最高一级page table，这级page table会使用虚拟内存地址中27bit index的最高9bit来完成索引，如果索引的结果为空，MMU会自动创建一个page table吗？ Frans教授：不会的，MMU会告诉操作系统或者处理器，抱歉我不能翻译这个地址，最终这会变成一个page fault。如果一个地址不能被翻译，那就不翻译。就像你在运算时除以0一样，处理器会拒绝那样做。 页表缓存To avoid the cost of loading PTEs from physical memory, a RISC-V CPU caches page table entries in a Translation Look-aside Buffer (TLB). 对于一个虚拟内存地址的寻址，需要读三次内存，这里代价有点高。所以实际中，几乎所有的处理器都会对于最近使用过的虚拟地址的翻译结果有缓存。这个缓存被称为：Translation Lookside Buffer（通常翻译成页表缓存）。 当处理器第一次查找一个虚拟地址时，硬件通过3级page table得到最终的PPN，TLB会保存虚拟地址到物理地址的映射关系。这样下一次当你访问同一个虚拟地址时，处理器可以查看TLB，TLB会直接返回物理地址，而不需要通过page table得到结果。 我：这个缓存感觉有点鸡肋，只能查相同虚拟地址。原本以为可以实现相同页的缓存。 Frans教授：有很多种方法都可以实现TLB，对于你们来说最重要的是知道TLB是存在的。TLB实现的具体细节不是我们要深入讨论的内容。这是处理器中的一些逻辑，对于操作系统来说是不可见的，操作系统也不需要知道TLB是如何工作的。 你们需要知道TLB存在的唯一原因是，如果你切换了page table，操作系统需要告诉处理器当前正在切换page table，处理器会清空TLB。因为本质上来说，如果你切换了page table，TLB中的缓存将不再有用，它们需要被清空，否则地址翻译可能会出错。所以操作系统知道TLB是存在的，但只会时不时的告诉操作系统，现在的TLB不能用了，因为要切换page table了。 在RISC-V中，清空TLB的指令是sfence_vma。 地址转换是通过硬件进行的To tell the hardware to use a page table, the kernel must write the physical address of the root page-table page into the satp register. Instructions use only virtual addresses, which the paging hardware translates to physical addresses, and then sends to the DRAM hardware to read or write storage 学生提问：3级的page table是由操作系统实现的还是由硬件自己实现的？ Frans教授：这是由硬件实现的，所以3级 page table的查找都发生在硬件中。MMU是硬件的一部分而不是操作系统的一部分。在XV6中，有一个函数也实现了page table的查找，因为时不时的XV6也需要完成硬件的工作，所以XV6有这个叫做walk的函数，它在软件中实现了MMU硬件相同的功能。 学生提问：之前提到，硬件会完成3级 page table的查找，那为什么我们要在XV6中有一个walk函数来完成同样的工作？ Frans教授：非常好的问题。这里有几个原因， 首先XV6中的walk函数设置了最初的page table，它需要对3级page table进行编程所以它首先需要能模拟3级page table。 另一个原因或许你们已经在syscall实验中遇到了，就是内核与用户的交互。 在XV6中，内核有它自己的page table，用户进程也有自己的page table，用户进程指向sys_info结构体的指针存在于用户空间的page table，但是内核需要将这个指针翻译成一个自己可以读写的物理地址。如果你查看copy_in，copy_out，你可以发现内核会通过用户进程的page table，将用户的虚拟地址翻译得到物理地址，这样内核可以读写相应的物理内存地址。这就是为什么在XV6中需要有walk函数的一些原因。 学生提问：对于walk函数，我有一个比较困惑的地方，在写完SATP寄存器之后，内核还能直接访问物理地址吗？在代码里面看起来像是通过page table将虚拟地址翻译成了物理地址，但是这个时候SATP已经被设置了，得到的物理地址不会被认为是虚拟地址吗？ Frans教授：让我们来看kvminithart函数，这里的kernel_page_table是一个物理地址，并写入到SATP寄存器中。从那以后，我们的代码运行在一个我们构建出来的地址空间中。在之前的kvminit函数中，kvmmap会对每个地址或者每个page调用walk函数。 学生提问：我想知道，在SATP寄存器设置完之后，walk是不是还是按照相同的方式工作？ Frans：是的。它还能工作的原因是，内核设置了虚拟地址等于物理地址的映射关系，这里很重要，因为很多地方能工作的原因都是因为内核设置的地址映射关系是相同的。 一旦将page table的物理地址写入satp寄存器，以后代码中所有的地址都会被视为虚拟地址进行地址翻译。而内核还能正常工作的原因是它设置了恒等映射，虚拟地址与物理地址相同。 内核地址空间的映射 图中的右半部分的结构完全由硬件设计者决定。如你们上节课看到的一样，当操作系统启动时，会从地址0x80000000开始运行，这个地址其实也是由硬件设计者决定的。主板的设计人员决定了，在完成了虚拟到物理地址的翻译之后，如果得到的物理地址大于0x80000000会走向DRAM芯片，如果得到的物理地址低于0x80000000会走向不同的I/O设备。 回到最初那张图的右侧：物理地址的分布。可以看到最下面是未被使用的地址，这与主板文档内容是一致的（地址为0）。地址0x1000是boot ROM的物理地址，当你对主板上电，主板做的第一件事情就是运行存储在boot ROM中的代码，当boot完成之后，会跳转到地址0x80000000，操作系统需要确保那个地址有一些数据能够接着启动操作系统。 地址0x02000000对应CLINT，当你向这个地址执行读写指令，你是向实现了CLINT的芯片执行读写。这里你可以认为你直接在与设备交互，而不是读写物理内存。 学生提问：为什么物理地址最上面一大块标为未被使用？ Frans教授：物理地址总共有2^56那么多，但是你不用在主板上接入那么多的内存。所以不论主板上有多少DRAM芯片，总是会有一部分物理地址没有被用到。实际上在XV6中，我们限制了内存的大小是128MB。 接下来我会切换到第一张图的左边，这就是XV6的虚拟内存地址空间。当机器刚刚启动时，还没有可用的page，XV6操作系统会设置内核使用的虚拟地址空间，也就是这张图左边的地址分布。因为我们想让XV6尽可能的简单易懂，所以这里的虚拟地址到物理地址的映射，大部分是相等的关系。比如说内核会按照这种方式设置page table，虚拟地址0x02000000对应物理地址0x02000000。这意味着左侧低于PHYSTOP的虚拟地址，与右侧使用的物理地址是一样的。 除此之外，这里还有两件重要的事情： 第一件事情是内核栈的映射。 kernel stack下有一个未映射的guard page，用来处理栈溢出 kernel stack对应的物理地址被映射两次，一次是在高位的PHYSTOP下，另一次是在Kernel data中。就是说，有两个虚拟地址对应同一个物理地址。实际只用高位的虚拟地址，因为有guard page，更加安全。 这是众多你可以通过page table实现的有意思的事情之一。你可以向同一个物理地址映射两个虚拟地址，你可以不将一个虚拟地址映射到物理地址。可以是一对一的映射，一对多映射，多对一映射。 第二件事情是权限。例如Kernel text page被标位R-X，意味着你可以读它，也可以在这个地址段执行指令，但是你不能向Kernel text写数据。通过设置权限我们可以尽早的发现Bug从而避免Bug。对于Kernel data需要能被写入，所以它的标志位是RW-，但是你不能在这个地址段运行指令，所以它的X标志位未被设置。（注，所以，kernel text用来存代码，代码可以读，可以运行，但是不能篡改，kernel data用来存数据，数据可以读写，但是不能通过数据伪装代码在kernel中运行） 学生提问：对于不同的进程会有不同的kernel stack吗？ Frans：答案是的。每一个用户进程都有一个对应的kernel stack。 物理空间的分配 xv6 uses the physical memory between the end of the kernel and PHYSTOP for run-time allocation。 学生提问：用户程序的虚拟内存会映射到未使用的物理地址空间吗？ Frans教授：在kernel page table中，有一段Free Memory，它对应了物理内存中的一段地址。XV6使用这段free memory来存放用户进程的page table，text和data。如果我们运行了非常多的用户进程，某个时间点我们会耗尽这段内存，这个时候fork或者exec会返回错误。 同一个学生提问：这就意味着，用户进程的虚拟地址空间会比内核的虚拟地址空间小的多，是吗？ Frans教授：本质上来说，两边的虚拟地址空间大小是一样的。但是用户进程的虚拟地址空间使用率会更低。 我：这只是实际能使用的物理空间小而已。各个进程看到的虚拟地址空间大小是一样的。 物理空间的分配通过free list进行，每次从free list分配一个页面大小的内存给进程。 free list通过链表的形式追踪空闲页面。 Frans教授：当kernel创建了一个进程，针对这个进程的page table也会从Free memory中分配出来。内核会为用户进程的page table分配几个page，并填入PTE。在某个时间点，当内核运行了这个进程，内核会将进程的根page table的地址加载到SATP中。从那个时间点开始，处理器会使用内核为那个进程构建虚拟地址空间。","link":"/2024/01/07/MIT6.S081/book/chapter3/"},{"title":"MIT6.S081 xv6book chapter4","text":"第四章的主题是陷阱与系统调用。关键问题：系统调用是怎么从用户态切换到内核态的？ 从中断角度看，系统调用是一软中断，发生中断后由中断向量处理，其中中断向量的地址又在寄存器stvec上。 这里融合了lec06的内容 和lec08的内容，lec08讲述了page fault中断处理的妙用，核心思想都是懒分配：给你虚拟页但不实际分配物理页，等到实际要用时再分配。 前言什么时候需要用户态到内核态的切换？ 程序执行系统调用； 程序出现了类似page fault、运算时除以0的错误； 一个设备触发了中断使得当前程序运行需要响应内核设备驱动。 这里用户空间和内核空间的切换通常被称为trap，而trap涉及了许多小心的设计和重要的细节，这些细节对于实现安全隔离和性能来说非常重要。trap机制要尽可能的简单来应对频繁的切换。 我们需要清楚如何让程序的运行，从只拥有user权限并且位于用户空间的Shell，切换到拥有supervisor权限的内核。在这个过程中，硬件的状态将会非常重要，因为我们很多的工作都是将硬件从适合运行用户应用程序的状态，改变到适合运行内核代码的状态。 应用程序的用户寄存器，像a0如此的有32个，此外还有一些特别的寄存器： stvec：The kernel writes the address of its trap handler here sepc：When a trap occurs, RISC-V saves the program counter here scause：RISC-V puts a number here that describes the reason for the trap. sscratch sstatus：硬件中断、一些标识位 satp：保存pagetable的地址 这些寄存器的值表明了执行系统调用时的计算机状态。那么执行trap时，我们需要做的事： 保存状态（包括32个寄存器、pc等） 将mode切换为supervisor，这样才能执行特权指令 切换satp页表为内核页表 设置堆栈寄存器指向内核中一个地址，这样内核的C函数才能使用栈 一旦设置好以上状态，跳入内核的C代码开始执行 要怎么实现？操作系统的一些high-level的目标能帮我们过滤一些实现选项。其中一个目标是安全和隔离，我们不想让用户代码介入到这里的user/kernel切换，否则有可能会破坏安全性。所以这意味着，trap中涉及到的硬件和内核机制不能依赖任何来自用户空间的东西。XV6的trap机制不会查看这些寄存器，而只是将它们保存起来。 Supervisor mode下能够执行的操作： 其中的一件事情是，你现在可以读写控制寄存器了。比如说，当你在supervisor mode时，你可以：读写SATP寄存器，也就是page table的指针；STVEC，也就是处理trap的内核指令地址；SEPC，保存当发生trap时的程序计数器；SSCRATCH等等。在supervisor mode你可以读写这些寄存器，而用户代码不能做这样的操作。 另一件事情supervisor mode可以做的是，它可以使用PTE_U标志位为0的PTE。当PTE_U标志位为1的时候，表明用户代码可以使用这个页表；如果这个标志位为0，则只有supervisor mode可以使用这个页表。 需要特别指出的是，supervisor mode中的代码并不能读写任意物理地址。在supervisor mode中，就像普通的用户代码一样，也需要通过page table来访问内存。如果一个虚拟地址并不在当前由SATP指向的page table中，又或者SATP指向的page table中PTE_U=1，那么supervisor mode不能使用那个地址。所以，即使我们在supervisor mode，我们还是受限于当前page table设置的虚拟地址。 shell执行write系统调用 上图是系统调用的大致流程。//todo 简述每一个过程 ecall12345.global writewrite: li a7, SYS_write ecall ret shell执行write系统调用实际是执行usys.S中的这段代码，其中透过ecall指令执行系统调用。 ecall指令做的事情：（实际上对应book第44页末尾那段硬件操作） ecall将mode从user mode改到supervisor mode； ecall将程序计数器的值保存在了SEPC寄存器； ecall会跳转到STVEC寄存器指向的指令。 所以现在，ecall帮我们做了一点点工作，但是实际上我们离执行内核中的C代码还差的很远。接下来： 我们需要保存32个用户寄存器的内容，这样当我们想要恢复用户代码执行时，我们才能恢复这些寄存器的内容。 因为现在我们还在user page table，我们需要切换到kernel page table。 我们需要创建或者找到一个kernel stack，并将Stack Pointer寄存器的内容指向那个kernel stack。这样才能给C代码提供栈。 我们还需要跳转到内核中C代码的某些合理的位置。 为什么ecall不多做点工作来将代码执行从用户空间切换到内核空间呢？为什么ecall不会保存用户寄存器，或者切换page table指针来指向kernel page table，或者自动的设置Stack Pointer指向kernel stack，或者直接跳转到kernel的C代码，而不是在这里运行复杂的汇编代码？ 原因是RISC的设计思想，尽可能的简单且通用，让用户完成自定义的操作。然后这样做的代价就是性能不是特别好。 uservec现在指令来到了TRAMPOLINE的vuservec。为什么会来这？是因为内核设置了stvec寄存器的值为这里。每个进程创建时都会映射TRAMPOLINE页面在虚拟地址的最高处，内容初始化为trampoline.S的代码。 12345678910111213141516171819202122232425.globl uservecuservec: # part1 保存状态 csrrw a0, sscratch, a0 sd ra, 40(a0) .... csrr t0, sscratch sd t0, 112(a0) # part2 加载内核sp指针 ld sp, 8(a0) # 确认自己是在哪个cpu核心上 ld tp, 32(a0) # part3 设置 address of usertrap(), p-&gt;trapframe-&gt;kernel_trap ld t0, 16(a0) # part4 切换页表 ld t1, 0(a0) csrw satp, t1 # 用户进程的页表物理地址保存在了t1寄存器中,p-&gt;pagetable仍然是用户进程的页表 sfence.vma zero, zero # jump to usertrap(), which does not return jr t0 现在已经是supervisor mode，但还没完成状态保存。 怎么保存状态？或许直接将32个寄存器中的内容写到物理内存中某些合适的位置，但此时还没完成页表的切换，并且在trap代码当前的位置，也就是trap机制的最开始，我们并不知道kernel page table的地址。并且更改SATP寄存器的指令，要求写入SATP寄存器的内容来自于另一个寄存器。 答案是用户地址空间的trapframe页。在创建用户进程时预先分配好这个页面来保存寄存器的值。 怎么知道trapframe页的虚拟地址？答案是SSCRATCH寄存器。所以uservec的第一条指令是csrrw a0, sscratch, a0交换寄存器的值，然后就能用a0寄存器干活儿了。保存完其他寄存器值后，还要记得保存原始a0寄存器的值（目前在SScRATCH寄存器上）。 然后加载内核sp指针，trapframe中的kernel_sp是由kernel在进入用户空间之前就设置好的，它的值是这个进程的kernel stack。 然后就是核心的保存，设置跳转地址，切换内核页表，最后跳转到内核C代码。 为什么切换内核页表后，还能正确的执行跳转指令？ 答：因为我们还在trampoline代码中，而trampoline代码在用户空间和内核空间都映射到了同一个地址。 usertrap()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// kernel/trap.cvoid usertrap(void){ int which_dev = 0; if((r_sstatus() &amp; SSTATUS_SPP) != 0) panic(&quot;usertrap: not from user mode&quot;); // part1 send interrupts and exceptions to kerneltrap(), // since we're now in the kernel. w_stvec((uint64)kernelvec); struct proc *p = myproc(); // part2 save user program counter. p-&gt;trapframe-&gt;epc = r_sepc(); // part3 判断中断原因并作相应处理 if(r_scause() == 8){ // system call if(p-&gt;killed) exit(-1); // sepc points to the ecall instruction, // but we want to return to the next instruction. p-&gt;trapframe-&gt;epc += 4; // an interrupt will change sstatus &amp;c registers, // so don't enable until done with those registers. intr_on(); syscall(); } else if((which_dev = devintr()) != 0){ // ok } else { printf(&quot;usertrap(): unexpected scause %p pid=%d\\n&quot;, r_scause(), p-&gt;pid); printf(&quot; sepc=%p stval=%p\\n&quot;, r_sepc(), r_stval()); p-&gt;killed = 1; } if(p-&gt;killed) exit(-1); // give up the CPU if this is a timer interrupt. if(which_dev == 2) yield(); // part4 执行返回流程 usertrapret();} usertrap最主要的作用就是判断中断类型，根据中断类型做出相应的处理。 这里看系统调用的流程， p-&gt;trapframe-&gt;epc += 4;是为了能在中断返回时返回到下一条指令，也就是ecall下一条指令ret。然后就调用syscall函数。 sysycall()1234567891011121314// kernel/syscall.cvoid syscall(void){ int num; struct proc *p = myproc(); num = p-&gt;trapframe-&gt;a7; if(num &gt; 0 &amp;&amp; num &lt; NELEM(syscalls) &amp;&amp; syscalls[num]) { p-&gt;trapframe-&gt;a0 = syscalls[num](); } else { printf(&quot;%d %s: unknown sys call %d\\n&quot;, p-&gt;pid, p-&gt;name, num); p-&gt;trapframe-&gt;a0 = -1; }} 这段代码写得非常简单，从a7寄存器中获取系统调用号然后根据哈希表查询执行相应的系统调用，将返回值保存在a0寄存器中。 usertrapret() 返回12345678910111213141516171819202122232425262728293031323334// kernel/trap.cvoid usertrapret(void){ struct proc *p = myproc(); // part1 关中断 intr_off(); // part2 设置用户中断向量 w_stvec(TRAMPOLINE + (uservec - trampoline)); // part3 reset trapframe p-&gt;trapframe-&gt;kernel_satp = r_satp(); // kernel page table p-&gt;trapframe-&gt;kernel_sp = p-&gt;kstack + PGSIZE; // process's kernel stack p-&gt;trapframe-&gt;kernel_trap = (uint64)usertrap; p-&gt;trapframe-&gt;kernel_hartid = r_tp(); // hartid for cpuid() // part4 设置mode状态 unsigned long x = r_sstatus(); x &amp;= ~SSTATUS_SPP; // clear SPP to 0 for user mode x |= SSTATUS_SPIE; // enable interrupts in user mode w_sstatus(x); // part5 设置sepc，ret指令会用到 w_sepc(p-&gt;trapframe-&gt;epc); // part6 提前准备好页表切换的参数 uint64 satp = MAKE_SATP(p-&gt;pagetable); // jump to trampoline.S at the top of memory, which // switches to the user page table, restores user registers, // and switches to user mode with sret. uint64 fn = TRAMPOLINE + (userret - trampoline); ((void (*)(uint64,uint64))fn)(TRAPFRAME, satp);} usertrapret最主要的作用就是设置返回到用户空间之前内核要做的工作。 重新设置stvec为用户中断向量，然后就是几个内核相关的寄存器值（这样下一次从用户空间转换到内核空间时可以用到这些数据）。 接下来我们要设置SSTATUS寄存器，这是一个控制寄存器。这个寄存器的SPP bit位控制了sret指令的行为，该bit为0表示下次执行sret的时候，我们想要返回user mode而不是supervisor mode。这个寄存器的SPIE bit位控制了，在执行完sret之后，是否打开中断。因为我们在返回到用户空间之后，我们的确希望打开中断，所以这里将SPIE bit位设置为1。修改完这些bit位之后，我们会把新的值写回到SSTATUS寄存器。 trampoline代码的最后执行了sret指令。这条指令会将程序计数器设置成SEPC寄存器的值。所以现在设置sepc为epc值，用于返回到正确位置。 倒数第二行的作用是计算出我们将要跳转到汇编代码的地址。我们期望跳转的地址是tampoline中的userret函数，这个函数包含了所有能将我们带回到用户空间的指令。所以这里我们计算出了userret函数的地址。 倒数第一行，将fn指针作为一个函数指针，执行相应的函数（也就是userret函数）并传入两个参数，两个参数存储在a0，a1寄存器中。 实际上，我们会在汇编代码trampoline中完成page table的切换，并且也只能在trampoline中完成切换，因为只有trampoline中代码是同时在用户和内核空间中映射。但是我们现在还没有在trampoline代码中，我们现在还在一个普通的C函数中，所以这里我们将page table指针准备好，并将这个指针作为第二个参数传递给汇编代码，这个参数会出现在a1寄存器。 userret12345678910111213141516171819userret: # part1 切换页表 csrw satp, a1 sfence.vma zero, zero # part2 保存a0到sscratch ld t0, 112(a0) csrw sscratch, t0 # part3 恢复各个寄存器的值 restore all but a0 from TRAPFRAME ld ra, 40(a0) .... # part4 restore user a0, and save TRAPFRAME in sscratch csrrw a0, sscratch, a0 # return to user mode and user pc. # usertrapret() set up sstatus and sepc. sret 现在程序执行又回到了trampoline代码。 第二步中，a0是上一步传入的trampoline地址，然后通过trampoline找到a0寄存器（保存了系统调用返回值），再保存在sscratch中。 第四步，让sscratch保存trampframe（这样下一次trap又能用了），同时恢复a0。 sret是我们在kernel中的最后一条指令，当我执行完这条指令： 程序会切换回user mode SEPC寄存器的数值会被拷贝到PC寄存器（程序计数器） 重新打开中断 这将会返回到ret指令，ret指令位于ecal指令下一条。 ret现在我们回到了用户空间，执行完ret指令之后我们就可以从write系统调用返回到Shell中了。或者更严格的说，是从触发了系统调用的write库函数中返回到Shell中。 最后总结一下，系统调用被刻意设计的看起来像是函数调用，但是背后的user/kernel转换比函数调用要复杂的多。之所以这么复杂，很大一部分原因是要保持user/kernel之间的隔离性，内核不能信任来自用户空间的任何内容。 另一方面，XV6实现trap的方式比较特殊，XV6并不关心性能。但是通常来说，操作系统的设计人员和CPU设计人员非常关心如何提升trap的效率和速度。 PageFault首先，我们需要思考的是，什么样的信息对于page fault是必须的。或者说，当发生page fault时，内核需要什么样的信息才能够响应page fault。 引起page fault的内存地址 引起page fault的原因类型 引起page fault时的程序计数器值，这表明了page fault在用户空间发生的位置 当出现page fault的时候，XV6内核会打印出错的虚拟地址，并且这个地址会被保存在STVAL寄存器中。 我们需要知道的第二个信息是出错的原因，比如因为load指令触发的page fault、因为store指令触发的page fault又或者是因为jump指令触发的page fault。出错原因存在SCAUSE寄存器中，其中总共有3个类型的原因与page fault相关，分别是读、写和指令。 我们或许想要知道的第三个信息是触发page fault的指令的地址。从上节课可以知道，作为trap处理代码的一部分，这个地址存放在SEPC寄存器中，并同时会保存在trapframe-&gt;epc中。 由于页表提供了一种非常有用的抽象，隔离性与抽象管理，这使得我们有许多优化可以进行，这些优化基本都是按照懒加载的思想进行。 在进行这些优化时，我们需要时常思考，page fault什么时候会产生以及产生page fault时的行为。 Lazy Allocation我们首先来看一下内存allocation，或者更具体的说sbrk，它使得用户应用程序能扩大自己的heap。当一个应用程序启动的时候，sbrk指向的是heap的最底端，同时也是stack的最顶端。这个位置通过代表进程的数据结构中的sz字段表示，这里以p-&gt;sz表示。 这意味着，当sbrk实际发生或者被调用的时候，内核会分配一些物理内存，并将这些内存映射到用户应用程序的地址空间，然后将内存内容初始化为0，再返回sbrk系统调用。 在XV6中，sbrk的实现默认是eager allocation，这表示，一旦调用了sbrk，内核会立即分配应用程序所需要的物理内存。 但是实际上，应用程序来说很难预测自己需要多少内存。通常来说，应用程序倾向于申请多于所需的内存。这意味着，进程的内存消耗会增加许多，但是有部分内存永远也不会被应用程序所使用到。 lazy allocation的核心思想非常简单，sbrk系统调基本上不做任何事情，唯一需要做的事情就是提升p-&gt;sz，将p-&gt;sz增加n，其中n是需要新分配的内存page数量。但是内核在这个时间点并不会分配任何物理内存。之后在某个时间点，应用程序使用到了新申请的那部分内存，这时会触发page fault，因为我们还没有将新的内存映射到page table。 所以，如果我们解析一个大于旧的p-&gt;sz，但是又小于新的p-&gt;sz（注，也就是旧的p-&gt;sz + n）的虚拟地址，我们希望内核能够分配一个内存page，并且重新执行指令。 实际上，lazy allocation会复杂一些。如果我们扩大用户内存而没实际分配页面时，要注意进程结束释放未分配的页面内存回收（实际上会回收空值）；如果sbrk传入负数，也要注意回收的内存是否实际分配页面。 Zero Fill On Demand首先，当你查看一个用户程序的地址空间时，存在text区域，data区域，同时还有一个BSS区域（BSS区域包含了未被初始化或者初始化为0的全局或者静态变量）。 之所以这些变量要单独列出来，是因为例如你在C语言中定义了一个大的全局变量，它的元素初始值都是0，为什么要为这个变量分配内存呢？其实只需要记住这个变量的内容是0就行。 通常可以调优的地方是，我有如此多的内容全是0的page，在物理内存中，我只需要分配一个page，这个page的内容全是0。然后将所有虚拟地址空间的全0的page都map到这一个物理page上。这样至少在程序启动的时候能节省大量的物理内存分配。 当然这里的mapping需要非常的小心，我们不能允许对于这个page执行写操作，因为所有的虚拟地址空间page都期望page的内容是全0，所以这里的PTE都是只读的。之后在某个时间点，应用程序尝试写BSS中的一个page时，比如说需要更改一两个变量的值，我们会得到page fault。 那么，对于这个特定场景中的page fault我们该做什么呢？ 学生回答：我认为我们应该创建一个新的page，将其内容设置为0，并重新执行指令。 假设store指令发生在BSS最顶端的page中。我们想要做的是，在物理内存中申请一个新的内存page，将其内容设置为0，因为我们预期这个内存的内容为0。之后我们需要更新这个page的mapping关系，首先PTE要设置成可读可写，然后将其指向新的物理page。这里相当于更新了PTE，之后我们可以重新执行指令。 好处： 假设程序申请了一个大的数组，来保存可能的最大的输入，并且这个数组是全局变量且初始为0。但是最后或许只有一小部分内容会被使用。 第二个好处是在exec中需要做的工作变少了。程序可以启动的更快，这样你可以获得更好的交互体验，因为你只需要分配一个内容全是0的物理page。 坏处是多次page fault代价更大。 Copy On Write Fork当Shell处理指令时，它会通过fork创建一个子进程。Shell的子进程执行的第一件事情就是调用exec运行一些其他程序，比如运行echo。现在的情况是，fork创建了Shell地址空间的一个完整的拷贝，而exec做的第一件事情就是丢弃这个地址空间，取而代之的是一个包含了echo的地址空间。这里看起来有点浪费。 所以对于这个特定场景有一个非常有效的优化：当我们创建子进程时，与其创建，分配并拷贝内容到新的物理内存，其实我们可以直接共享父进程的物理内存page。所以这里，我们可以设置子进程的PTE指向父进程对应的物理内存page。 一旦子进程想要修改这些内存的内容，相应的更新应该对父进程不可见，因为我们希望在父进程和子进程之间有强隔离性，所以这里我们需要更加小心一些。为了确保进程间的隔离性，我们可以将这里的父进程和子进程的PTE的标志位都设置成只读的。 在某个时间点，当我们需要更改内存的内容时，我们会得到page fault。在得到page fault之后，我们需要拷贝相应的物理page。假设现在是子进程在执行store指令，那么我们会分配一个新的物理内存page，然后将page fault相关的物理内存page拷贝到新分配的物理内存page中，并将新分配的物理内存page映射到子进程。这时，新分配的物理内存page只对子进程的地址空间可见，所以我们可以将相应的PTE设置成可读写，并且我们可以重新执行store指令。实际上，对于触发刚刚page fault的物理page，因为现在只对父进程可见，相应的PTE对于父进程也变成可读写的了。 学生提问：我们如何发现父进程写了这部分内存地址？是与子进程相同的方法吗？ Frans教授：是的，因为子进程的地址空间来自于父进程的地址空间的拷贝。如果我们使用了特定的虚拟地址，因为地址空间是相同的，不论是父进程还是子进程，都会有相同的处理方式。 学生提问：对于一些没有父进程的进程，比如系统启动的第一个进程，它会对于自己的PTE设置成只读的吗？还是设置成可读写的，然后在fork的时候再修改成只读的？ Frans教授：这取决于你。实际上在lazy lab之后，会有一个copy-on-write lab。在这个lab中，你自己可以选择实现方式。当然最简单的方式就是将PTE设置成只读的，当你要写这些page时，你会得到一个page fault，之后你可以再按照上面的流程进行处理。 学生提问：当发生page fault时，我们其实是在向一个只读的地址执行写操作。内核如何能分辨现在是一个copy-on-write fork的场景，而不是应用程序在向一个正常的只读地址写数据。是不是说默认情况下，用户程序的PTE都是可读写的，除非在copy-on-write fork的场景下才可能出现只读的PTE？ Frans教授：内核必须要能够识别这是一个copy-on-write场景。几乎所有的page table硬件都支持了这一点。我们之前并没有提到相关的内容，下图是一个常见的多级page table。对于PTE的标志位，我之前介绍过第0bit到第7bit，但是没有介绍最后两位RSW。这两位保留给supervisor software使用，supervisor softeware指的就是内核。内核可以随意使用这两个bit位。所以可以做的一件事情就是，将bit8标识为当前是一个copy-on-write page。 对于这里的物理内存page，现在有多个用户进程或者说多个地址空间都指向了相同的物理内存page，举个例子，当父进程退出时我们需要更加的小心，因为我们要判断是否能立即释放相应的物理page。如果有子进程还在使用这些物理page，而内核又释放了这些物理page，我们将会出问题。那么现在释放内存page的依据是什么呢？ 我们需要对于每一个物理内存page的引用进行计数，当我们释放虚拟page时，我们将物理内存page的引用数减1，如果引用数等于0，那么我们就能释放物理内存page。 Demand Paging我们回到exec，在未修改的XV6中，操作系统会加载程序内存的text，data区域，并且以eager的方式将这些区域加载进page table。 为什么我们要以eager的方式将程序加载到内存中？为什么不再等等，直到应用程序实际需要这些指令的时候再加载内存？程序的二进制文件可能非常的巨大，将它全部从磁盘加载到内存中将会是一个代价很高的操作。又或者data区域的大小远大于常见的场景所需要的大小，我们并不一定需要将整个二进制都加载到内存中。 所以对于exec，在虚拟地址空间中，我们为text和data分配好地址段，但是相应的PTE并不对应任何物理内存page。对于这些PTE，我们只需要将valid bit位设置为0即可。 接下来思考什么时候会触发page fault：应用程序是从地址0开始运行，位于地址0的指令会出发第一个page fault。 然后就是触发page fault的行为：首先我们可以发现，这些page是on-demand page。我们需要在某个地方记录了这些page对应的程序文件，我们在page fault handler中需要从程序文件中读取page数据，加载到内存中；之后将内存page映射到page table；最后再重新执行指令。 在最坏的情况下，用户程序使用了text和data中的所有内容，那么我们将会在应用程序的每个page都收到一个page fault。但是如果我们幸运的话，用户程序并没有使用所有的text区域或者data区域，那么我们一方面可以节省一些物理内存，另一方面我们可以让exec运行的更快。 在lazy allocation中，如果内存耗尽了该如何办？一个选择是撤回page（evict page）。比如说将部分内存page中的内容写回到文件系统再撤回page。一旦你撤回并释放了page，那么你就有了一个新的空闲的page，你可以使用这个刚刚空闲出来的page，分配给刚刚的page fault handler，再重新执行指令。 问题又来了，什么样的page可以被撤回？并且该使用什么样的策略来撤回page？常用的策略，Least Recently Used，或者叫LRU，除了这个策略之外，还有一些其他的小优化。如果你要撤回一个page，你可以在dirty page和non-dirty page中做选择。 如果你们再看PTE，还有其他信息。当硬件向一个page写入数据，会设置dirty bit，之后操作系统就可以发现这个page曾经被写入了。类似的，还有一个Access bit，任何时候一个page被读或者被写了，这个Access bit会被设置。 为什么这两个信息重要(access bit &amp; dirty bit)呢？它们能怎样帮助内核呢？ 学生回答：没有被Access过的page可以直接撤回，是吗？ Frans教授：是的，或者说如果你想实现LRU，你需要找到一个在一定时间内没有被访问过的page，那么这个page可以被用来撤回。而被访问过的page不能被撤回。所以Access bit通常被用来实现这里的LRU策略。 学生提问：那是不是要定时的将Access bit恢复成0？ Frans教授：是的，这是一个典型操作系统的行为。操作系统会扫描整个内存，这里有一些著名的算法例如clock algorithm，就是一种实现方式。 另一个学生提问：为什么需要恢复这个bit？ Frans教授：如果你想知道page最近是否被使用过，你需要定时比如每100毫秒或者每秒清除Access bit，如果在下一个100毫秒这个page被访问过，那你就知道这个page在上一个100毫秒中被使用了。而Access bit为0的page在上100毫秒未被使用。这样你就可以统计每个内存page使用的频度，这是一个成熟的LRU实现的基础。（注，可以通过Access bit来决定内存page 在LRU中的排名） Memory Mapped Files这里的核心思想是，将完整或者部分文件加载到内存中，这样就可以通过内存地址相关的load或者store指令来操纵文件，避免缓慢的文件系统交互读写read/write。 现代操作系统一般会提供一个mmap系统调用，这个系统调用会接收一个虚拟内存地址（VA），长度（len），protection，一些标志位，一个打开文件的文件描述符，和偏移量（offset）。语义是，从文件描述符对应的文件的偏移量的位置开始，映射长度为len的内容到虚拟内存地址VA，同时我们需要加上一些保护，比如只读或者读写。 假设文件内容是读写并且内核实现mmap的方式是eager方式（不过大部分系统都不会这么做），内核会从文件的offset位置开始，将数据拷贝到内存，设置好PTE指向物理内存的位置。之后应用程序就可以使用load或者store指令来修改内存中对应的文件内容。当完成操作之后，会有一个对应的unmap系统调用，参数是虚拟地址（VA），长度（len）。来表明应用程序已经完成了对文件的操作，在unmap时间点，我们需要将dirty block写回到文件中。 当然，在任何聪明的内存管理机制中，所有的这些都是以lazy的方式实现。你不会立即将文件内容拷贝到内存中，而是先记录一下这个PTE属于这个文件描述符。相应的信息通常在VMA结构体中保存，VMA全称是Virtual Memory Area。例如对于这里的文件f，会有一个VMA，在VMA中我们会记录文件描述符，偏移量等等，这些信息用来表示对应的内存虚拟地址的实际内容在哪，这样当我们得到一个位于VMA地址范围的page fault时，内核可以从磁盘中读数据，并加载到内存中。 学生提问：如果其他进程直接修改了文件的内容，那么是不是意味着修改的内容不会体现在这里的内存中？ Frans教授：是的。但是如果文件是共享的，那么你应该同步这些变更。我记不太清楚在mmap中，文件共享时会发生什么。","link":"/2024/01/07/MIT6.S081/book/chapter4/"},{"title":"MIT6.S081 xv6book chapter5","text":"第五章主要讲述的是外部设备的中断，不同于软件中断，外部设备中断可以与CPU处理并行。 这里要特别理解外设的驱动，驱动的top部分一般是驱动提供给用户的接口服务，驱动的bottom部分则是interrupt handler。top部分和bottom部分通过buffer解藕，top部分往设备的缓冲区读写完事儿，待设备处理完成发送一个中断，bottom部分则处理中断，bottom亦能读写缓冲区。 值得注意的是：一个中断是如何产生，又如何被CPU处理的（这里会有多个CPU）；设备与CPU的并行。 这节融合了lec09的内容，通过追踪以下两个场景来分析中断过程： console中的提示符“$ ” 是如何显示出来的； 如果你在键盘输入“ls”，这些字符是怎么最终在console中显示出来的。 前言中断对应的场景很简单，就是硬件想要得到操作系统的关注。例如网卡收到了一个packet，网卡会生成一个中断；用户通过键盘按下了一个按键，键盘会产生一个中断。操作系统需要做的是，保存当前的工作，处理中断，处理完成之后再恢复之前的工作。系统调用，page fault，中断，都使用相同的机制。 中断与系统调用主要有3个小的差别： asynchronous。异步，当硬件生成中断时，Interrupt handler与当前运行的进程在CPU上没有任何关联。 concurrency。并行，对于中断来说，CPU和生成中断的设备是并行的在运行。比如，网卡自己独立的处理来自网络的packet，然后在某个时间点产生中断，但是同时，CPU也在运行。 program device。设备编程，每个设备都有一个编程手册，设备的编程手册包含了它有什么样的寄存器，它能执行什么样的操作，在读写控制寄存器的时候，设备会如何响应。根据这些手册对设备进行编程。 通常来说，编程是通过memory mapped I/O完成的。设备地址出现在物理地址的特定区间内，这个区间由主板制造商决定。操作系统需要知道这些设备位于物理地址空间的具体位置，然后再通过普通的load/store指令对这些地址进行编程。load/store指令实际上的工作就是读写设备的控制寄存器。 ![image-20240111091130275](/Users/mac/Library/Application Support/typora-user-images/image-20240111091130275.png) 中断是从哪里产生的？外设中断来自于主板上的设备（我们主要关心的是外部设备的中断，而不是定时器中断或者软件中断） 中断是怎么被CPU处理的？处理器上是通过PLIC（Platform Level Interrupt Control）来处理设备中断。PLIC会管理来自于外设的中断。 从左上角可以看出，我们有53个不同的来自于设备的中断。这些中断到达PLIC之后，PLIC会路由这些中断。图的右下角是CPU的核，PLIC会将中断路由到某一个CPU的核。如果所有的CPU核都正在处理中断，PLIC会保留中断直到有一个CPU核可以用来处理中断。所以PLIC需要保存一些内部数据来跟踪中断的状态。 uart会产生什么样的中断？ 接收中断（比如键盘按下一个按键，那么这个字符会存入到uart的RHR寄存器，uart产生一个接收中断） 发送完成中断（往uart的THR寄存器存入字符，当uart发送THR寄存器中的一个字符到console完成时，产生一个中断） 驱动driverA driver is the code in an operating system that manages a particular device: it configures the device hardware, tells the device to perform operations, handles the resulting interrupts, and interacts with processes that may be waiting for I/O from the device. 驱动大部分都分为两个部分，bottom和top。 bottom部分通常是Interrupt handler。当一个中断送到了CPU，并且CPU设置接收这个中断，CPU会调用相应的Interrupt handler。Interrupt handler并不运行在任何特定进程的context中，它只是处理中断。 top部分，是用户进程或者内核的其他部分调用的接口。对于UART来说，这里有read/write接口，这些接口可以被更高层级的代码调用。 通常情况下，驱动中会有一些队列（或者说buffer），top部分的代码会从队列中读写数据，而Interrupt handler（bottom部分）同时也会向队列中读写数据。这里的队列可以将并行运行的设备和CPU解耦开来。 设置中断(中断初始化)RISC-V有许多与中断相关的寄存器： SIE（Supervisor Interrupt Enable）寄存器。这个寄存器中有一个bit（E）专门针对例如UART的外部设备的中断；有一个bit（S）专门针对软件中断，软件中断可能由一个CPU核触发给另一个CPU核；还有一个bit（T）专门针对定时器中断。我们这节课只关注外部设备的中断。 SSTATUS（Supervisor Status）寄存器。这个寄存器中有一个bit来打开或者关闭中断。每一个CPU核都有独立的SIE和SSTATUS寄存器，除了通过SIE寄存器来单独控制特定的中断，还可以通过SSTATUS寄存器中的一个bit来控制所有的中断。 SIP（Supervisor Interrupt Pending）寄存器。当发生中断时，处理器可以通过查看这个寄存器知道当前是什么类型的中断。 xv6启动之初，首先设置uartinit()，使得uart设备能够产生中断。 然后设置plic设备，使得plic能够路由中断。 最后是打开cpu的中断开关（设置sstatus寄存器），使得cpu能够处理中断。 top部分（“$”的输出）sh.c 中调用fprintf(2, &quot;$ &quot;) user/printf.c文件中，fprintf代码只是调用了write系统调用，最终走到sys_write函数。 sysfile.c文件中的sys_write函数fetch参数，然后调用file.c文件的filewrite函数。 file.c文件的filewrite函数首先会判断文件描述符的类型，然后调用console.c中的consolewrite函数。 12345678//file.cint filewrite(struct file *f, uint64 addr, int n) { if(f-&gt;type == FD_DEVICE){ if(f-&gt;major &lt; 0 || f-&gt;major &gt;= NDEV || !devsw[f-&gt;major].write) return -1; ret = devsw[f-&gt;major].write(1, addr, n); //每个device都有对应的read write函数 }} console.c文件中的consolewrite函数先通过either_copyin将字符拷入，之后调用uart.c文件中的uartputc函数。 1234567891011// console.cint consolewrite(int user_src, uint64 src, int n){ int i; for(i = 0; i &lt; n; i++){ char c; if(either_copyin(&amp;c, user_src, src+i, 1) == -1) // Copy to either a user address, or kernel address break; uartputc(c); } return i;} uart.c文件中的uartputc函数，主要逻辑就是将字符写入uart的环形缓冲区，然后调用uartstart()。uartstart函数主要逻辑是不断从环形缓冲读数据，然后发送到console，WriteReg(THR, c);。 1234567891011121314151617181920212223242526272829303132// uart.cvoid uartputc(int c){ acquire(&amp;uart_tx_lock); if(panicked){ for(;;); } while(1){ if(uart_tx_w == uart_tx_r + UART_TX_BUF_SIZE){ // buffer is full. wait for uartstart() to open up space in the buffer. sleep(&amp;uart_tx_r, &amp;uart_tx_lock); }else { uart_tx_buf[uart_tx_w % UART_TX_BUF_SIZE] = c; uart_tx_w += 1; uartstart(); release(&amp;uart_tx_lock); return; } }}void uartstart() { while(1){ if(uart_tx_w == uart_tx_r){ return; } if((ReadReg(LSR) &amp; LSR_TX_IDLE) == 0){return;} // whether THR can accept another character to send int c = uart_tx_buf[uart_tx_r % UART_TX_BUF_SIZE]; uart_tx_r += 1; wakeup(&amp;uart_tx_r); // maybe uartputc() is waiting for space in the buffer. WriteReg(THR, c); }} 至此，一个$就打印在屏幕上了。一旦WriteReg完成，系统调用会返回，用户应用程序Shell就可以继续执行。 12#define RHR 0 // receive holding register (for input bytes) 接收寄存器#define THR 0 // transmit holding register (for output bytes) 发送寄存器 这里来理解top部分，主要的作用就是写到uart设备的缓冲区，然后再写到uart的寄存器，通知uart开始发送数据。 后续uart数据发送完成，uart就会产生一个发送完成中断，处理中断的代码就是bottom部分。 bottom部分bottom部分就是cpu处理中断的代码，我们来看cpu是怎么响应一个中断的。 假设键盘生成了一个中断并且发向了PLIC，PLIC会将中断路由给一个特定的CPU核，并且如果这个CPU核设置了SIE寄存器的E bit（针对外部中断的bit位），那么会发生以下事情： 清除SIE寄存器相应的bit，这样可以阻止CPU核被其他中断打扰； 设置SEPC寄存器为当前的PC（保存PC）； 保存当前的mode 设置为supervior mode 设置PC指向STVEC（指向中断向量地址，要么uservec要么kernelvec，uservec在Trampoline页面中） 执行指令 我们知道uservec最终会走向trap.c文件usertrap函数，usertrap会根据中断类型（系统调用or外部中断or计时器中断）作出相应处理。 1which_dev = devintr() 在trap.c的devintr函数中，首先会通过SCAUSE寄存器判断当前中断是否是来自于外设的中断。如果是的话，再调用plic_claim函数来获取中断。 12345678910111213141516171819202122232425262728// check if it's an external interrupt or software interrupt,// and handle it.// returns 2 if timer interrupt,// 1 if other device,// 0 if not recognized.int devintr() { uint64 scause = r_scause(); if((scause &amp; 0x8000000000000000L) &amp;&amp; (scause &amp; 0xff) == 9){ // this is a supervisor external interrupt, via PLIC. // irq indicates which device interrupted. int irq = plic_claim(); if(irq == UART0_IRQ){ uartintr(); } else if(irq == VIRTIO0_IRQ){ virtio_disk_intr(); } else if(irq){ printf(&quot;unexpected interrupt irq=%d\\n&quot;, irq); } // the PLIC allows each device to raise at most one // interrupt at a time; tell the PLIC the device is // now allowed to interrupt again. if(irq) plic_complete(irq); return 1; } ...} 在uartintr函数中，处理uart产生的中断（这个中断可能是发送完成中断，也可能是接收中断）。 123456789101112131415161718192021222324// handle a uart interrupt, raised because input has arrived, // or the uart is ready for more output, or both.void uartintr(void){ // read and process incoming characters. while(1){ int c = uartgetc(); if(c == -1) break; consoleintr(c); } // send buffered characters. acquire(&amp;uart_tx_lock); uartstart(); release(&amp;uart_tx_lock);}int uartgetc(void){ if(ReadReg(LSR) &amp; 0x01){ // input data is ready. return ReadReg(RHR); } else { return -1; }} 我们可以看到uartintr其实是完成两件事情的，读和写。读自己的接收寄存器（uartgetc）和写发送寄存器（userstart）。其中，读完寄存器后，调用consoleintr向console输出键盘。 简要的时钟中断计时器中断发生在机器模式下，在start.c中对CLINT计时器硬件进行编程，然后设置一个scratch区域，类似于trapframe,来存储信息。 The machine-mode timer interrupt handler is timervec (kernel/kernelvec.S:93). It saves a few registers in the scratch area prepared by start, tells the CLINT when to generate the next timer interrupt, asks the RISC-V to raise a software interrupt, restores registers, and returns. There’s no C code in the timer interrupt handler. 总结“$ “传送到屏幕的过程“$ “传送到屏幕的过程其实就是drive驱动的top部分，不过当$发送完成后，uart还会产生一个发送完成中断。此时，恰好有一个并行时序，使得$后的空格被写进uart设备缓冲区，同时cpu处理中断调用uartintr发送缓冲区里数据。此时驱动的top和bottom就解耦了（这里意思是top和bottom不再是串行时序，两者可以并行进行）。 在发送完$后的空格后其实也会产生一个发送完成中断，由于这个中断既无键盘输入，uart的缓冲区又无字符，所以并不会做什么。 刚刚执行shell的core，此时也返回了进程空间，并且继续执行shell。shell又执行gets，最终到sys_read，consoleread，consoleread会一直阻塞自己等待键盘中断传进来字符，所以我们看到启动xv6之后，输出完$ 之后便一直阻塞。 ls\\n的输出过程当我们敲击键盘ls,每一个字符会产生一个接收中断，这里触发中断traps,调用uartintr,调用uartgetc将 l 从寄存器中读出，然后调用consoleintr。 1234567891011121314151617default: if(c != 0 &amp;&amp; cons.e-cons.r &lt; INPUT_BUF){ c = (c == '\\r') ? '\\n' : c; // echo back to the user. consputc(c); // store for consumption by consoleread(). cons.buf[cons.e++ % INPUT_BUF] = c; if(c == '\\n' || c == C('D') || cons.e == cons.r+INPUT_BUF){ // wake up consoleread() if a whole line (or end-of-file) // has arrived. cons.w = cons.e; wakeup(&amp;cons.r); } } The job of consoleintr is to accumulate input characters in cons.buf until a whole line arrives. consoleintr treats backspace and a few other characters specially. When a newline arrives, consoleintr wakes up a waiting consoleread (if there is one). Once woken, consoleread will observe a full line in cons.buf, copy it to user space, and return (via the system call machinery) to user space. cosoleintr默认会将每个字符回显到console，同时也会存储这个字符到cons的buf中，这是为了一旦读到换行时能唤醒consoleread线程（如果有的话），这样consoleread便能返回。于是shell便能解析命令，然后执行。 关于解耦的问题 解耦：谁也不会影响谁 1.进程与设备解耦 2.生产者和消费者解耦 核心就是通过缓冲区和中断机制实现 1.进程不必等待设备输入，干自己的事情就好，设备输入会中断进来。设备也不必等着进程的输出，他要是想输出了把字符放在缓冲区就好。 2.生产者和消费者亦是如此。 谁想干什么事找缓冲区去~ 过buffer将consumer和producer之间解耦，这样它们才能按照自己的速度，独立的并行运行。如果某一个运行的过快了，那么buffer要么是满的要么是空的，consumer和producer其中一个会sleep并等待另一个追上来。 学生提问：这里的buffer对于所有的CPU核都是共享的吗？ Frans教授：这里的buffer存在于内存中，并且只有一份，所以，所有的CPU核都并行的与这一份数据交互。所以我们才需要lock。","link":"/2024/01/12/MIT6.S081/book/chapter5/"},{"title":"MIT6.S081 xv6book chapter6","text":"第六章主要是讲并发编程，为什么要用锁、什么时候使用锁、锁范围、加锁顺序、死锁、可重入锁等知识，还介绍了xv6中自旋锁的实现。 特别要注意xv6中持有锁就不允许中断；内存屏障用于避免指令重排，这些都是锁实现的细节。 本节融合了lec13的内容，总体上属于并发编程入门，信号量、条件变量等多进程同步机制没有介绍，后续章节会涉及。 竞态条件A race condition is a situation in which a memory location is accessed concurrently, and at least one access is a write. 锁是如何避免race condition的，这里有两个很好的描述词：序列化、原子化， You can think of a lock as serializing concurrent critical sections so that they run one at a time, and thus preserve invariants (assuming the critical sections are correct in isolation). You can also think of critical sections guarded by the same lock as being atomic with respect to each other, so that each sees only the complete set of changes from earlier critical sections, and never sees partially-completed updates. 锁的使用什么时候使用锁、使用多少个锁： A hard part about using locks is deciding how many locks to use and which data and invariants each lock should protect. There are a few basic principles. First, any time a variable can be written by one CPU at the same time that another CPU can read or write it, a lock should be used to keep the two operations from overlapping. Second, remember that locks protect invariants: if an invariant involves multiple memory locations, typically all of them need to be protected by a single lock to ensure the invariant is maintained 大内核锁： A simple kernel can do this on a multiprocessor by having a single lock that must be acquired on entering the kernel and released on exiting the kernel (though system calls such as pipe reads or wait would pose a problem). Many uniprocessor operating systems have been converted to run on multiprocessors using this approach, sometimes called a “big kernel lock”, but the approach sacrifices parallelism: only one CPU can execute in the kernel at a time. 如果内核中只有一把大锁，我们暂时将之称为big kernel lock。基本上所有的系统调用都会被这把大锁保护而被序列化。系统调用会按照这样的流程处理：一个系统调用获取到了big kernel lock，完成自己的操作，之后释放这个big kernel lock，再返回到用户空间，之后下一个系统调用才能执行。这样的话，如果我们有一个应用程序并行的调用多个系统调用，这些系统调用会串行的执行， 死锁与锁顺序it is important that all code paths acquire those locks in the same order. 获取锁的顺序很重要，如果所有获锁的代码都遵从相同的获锁顺序，那么是不会造成死锁的，但现实中获锁的顺序取决于代码逻辑。 对于一个系统设计者，你需要确定对于所有的锁对象的全局的顺序。例如在这里的例子中我们让d1一直在d2之前，这样我们在rename的时候，总是先获取排序靠前的目录的锁，再获取排序靠后的目录的锁。如果对于所有的锁有了一个全局的排序，这里的死锁就不会出现了。 不过在设计一个操作系统的时候，定义一个全局的锁的顺序会有些问题。如果一个模块m1中方法g调用了另一个模块m2中的方法f，那么m1中的方法g需要知道m2的方法f使用了哪些锁。因为如果m2使用了一些锁，那么m1的方法g必须集合f和g中的锁，并形成一个全局的锁的排序。这意味着在m2中的锁必须对m1可见，这样m1才能以恰当的方法调用m2。 但是这样又违背了代码抽象的原则。在完美的情况下，代码抽象要求m1完全不知道m2是如何实现的。但是不幸的是，具体实现中，m2内部的锁需要泄露给m1，这样m1才能完成全局锁排序。所以当你设计一些更大的系统时，锁使得代码的模块化更加的复杂了。 可重入锁The idea is that if the lock is held by a process and if that process attempts to acquire the lock again, then the kernel could just allow this (since the process already has the lock), instead of calling panic, as the xv6 kernel does But if re-entrant locks are allowed, and h happens to call g, call_once will be called twice. If re-entrant locks aren’t allowed, then h calling g results in a deadlock, which is not great either. 可重入锁有优点有缺点，缺点就是它使得并发编程更加复杂了，优点是至少能避免一些死锁的情况。 自旋锁的实现：原子指令锁的特性就是只有一个进程可以获取锁，在任何时间点都不能有超过一个锁的持有者。 1234567struct spinlock { uint locked; // Is the lock held? 1 is held. // For debugging: char *name; // Name of lock. struct cpu *cpu; // The cpu holding the lock.}; 实现锁的难点就在于看的动作和写的动作的不连续，中间可能被打断。 1234567void acquire(struct spinlock *lk) // does not work!{ for(;;) { if(lk-&gt;locked == 0) { lk-&gt;locked = 1; break; }} } 上面这段代码并不能实现acquire语义，问题就出在两个进程可以同时进入到判断锁的那一行，此时locked都为0，两个进程会同时将locked设置为1。这其实是三个操作（读locked、判断locked、写locked）的原子性，如果这三个操作是合在一起的， 便能保证正确性。 解决的方法是依赖于一个特殊的硬件指令，这个特殊的硬件指令会保证一次test-and-set操作的原子性，在RISC-V上，这个特殊的指令就是amoswap（atomic memory swap）原子交换。 The acquire function wraps the swap in a loop, retrying (spinning) until it has acquired the lock. Each iteration swaps one into lk-&gt;locked and checks the previous value; if the previous value is zero, then we’ve acquired the lock, and the swap will have set lk-&gt;locked to one. If the previous value is one, then some other CPU holds the lock, and the fact that we atomically swapped one into lk-&gt;locked didn’t change its value. 在获取锁时用1去交换，然后判断获取的旧值是否为0，为0说明获得了锁，为1说明此时有其他进程获得了锁，那么交换的1没有改变着之前的值。 这其实就是保证了锁的唯一性。将1看成苹果，将0看成锁，锁放在桌子上。每个都用苹果换桌子上的东西，如果换到锁，那么说明我拿到锁了，并且这个锁不会再被别人拿到。如果换到苹果，那也只是等价交换，桌子上还是苹果。 acquire12345678910void acquire(struct spinlock *lk) { push_off(); // disable interrupts to avoid deadlock. if(holding(lk)) panic(&quot;acquire&quot;); while(__sync_lock_test_and_set(&amp;lk-&gt;locked, 1) != 0) ; __sync_synchronize(); lk-&gt;cpu = mycpu();} 这里先忽略push_off的作用，可以看到在函数中有一个while循环，这就是刚刚提到的test-and-set循环。实际上C的标准库已经定义了这些原子操作，所以C标准库中已经有一个函数__sync_lock_test_and_set。 12345while(__sync_lock_test_and_set(&amp;lk-&gt;locked, 1) != 0) 800061b4: 87ba mv a5,a4 800061b6: 0cf4a7af amoswap.w.aq a5,a5,(s1) 800061ba: 2781 sext.w a5,a5 800061bc: ffe5 bnez a5,800061b4 &lt;acquire+0x22&gt; release1234567891011121314void release(struct spinlock *lk) { if(!holding(lk)) panic(&quot;release&quot;); lk-&gt;cpu = 0; __sync_synchronize(); // On RISC-V, sync_lock_release turns into an atomic swap: // s1 = &amp;lk-&gt;locked // amoswap.w zero, zero, (s1) __sync_lock_release(&amp;lk-&gt;locked); pop_off();} 释放锁的过程就是将locked字段原子更新为0的过程。为什么需要原子更新？ 因为更新的操作其实有三个步骤：读地址值到寄存器、修改寄存器的值、再将寄存器的值写回到内存。 锁与中断处理程序123456789101112131415161718192021222324252627// Per-CPU state.struct cpu { struct proc *proc; // The process running on this cpu, or null. struct context context; // swtch() here to enter scheduler(). int noff; // Depth of push_off() nesting. push off的嵌套层次 int intena; // Were interrupts enabled before push_off()? 中断是否开启};void push_off(void){ int old = intr_get(); intr_off(); if(mycpu()-&gt;noff == 0) mycpu()-&gt;intena = old; mycpu()-&gt;noff += 1;}void pop_off(void){ struct cpu *c = mycpu(); if(intr_get()) panic(&quot;pop_off - interruptible&quot;); if(c-&gt;noff &lt; 1) panic(&quot;pop_off&quot;); c-&gt;noff -= 1; if(c-&gt;noff == 0 &amp;&amp; c-&gt;intena) intr_on();} acquire calls push_off (kernel/spinlock.c:89) and release calls pop_off (kernel/spinlock.c:100) to track the nesting level of locks on the current CPU. When that count reaches zero, pop_off restores the interrupt enable state that existed at the start of the outermost critical section. 第二个细节是，在acquire函数的最开始，会先关闭中断。为什么会是这样呢？先来假设acquire在一开始并没有关闭中断。在uartputc函数中，首先会acquire锁，如果不关闭中断会发生什么呢？uartputc函数会acquire锁，UART本质上就是传输字符，当UART完成了字符传输它会做什么？是的，它会产生一个中断之后会运行uartintr函数，在uartintr函数中，会获取同一把锁，但是这把锁正在被uartputc持有。如果这里只有一个CPU的话，那这里就是死锁。 所以spinlock需要处理两类并发，一类是不同CPU之间的并发，一类是相同CPU上中断和普通程序之间的并发。 更深层次的原因是：锁会在各种各样的地方被用到，从用户程序到中断处理程序。而中断又是时时刻刻发生的，如果用户程序持有锁的同时发生中断，中断处理程序又要求获得同一把锁，就会发生死锁。 xv6解决的方法粗暴有效：when a CPU acquires any lock, xv6 always disables interrupts on that CPU. 哪个CPU持有锁就不允许那个CPU处理中断。 还要注意点的是： 关中断在获锁前，开中断在释放锁后； noff追踪了锁嵌套的层次（track the nesting level of locks on the current CPU），只有最后一个锁释放后才能开中断。 指令重排It is natural to think of programs executing in the order in which source code statements appear. Many compilers and CPUs, however, execute code out of order to achieve higher performance.The CPU’s ordering rules are called the memory model. 简单来说，CPU或编译器为了更好的执行性能，通常会调整一些代码的执行顺序。而这会使得锁失效，因为关键区的代码可能会被移到关键区外。 避免指令重排是通过一条硬件指令，内存屏障（memory fence或者叫做synchronize指令）来确定指令的移动范围。对于synchronize指令，任何在它之前的load/store指令，都不能移动到它之后。 那么，通过两个内存屏障，加锁时一个，释放锁时一个，就能避免指令乱排带来的后果。 学生提问：有没有可能在锁acquire之前的一条指令被移到锁release之后？或者说这里会有一个界限不允许这么做？ Frans教授：在这里的例子中，acquire和release都有自己的界限（注，也就是__sync_synchronize函数的调用点）。所以发生在锁acquire之前的指令不会被移到acquire的__sync_synchronize函数调用之后，这是一个界限。在锁的release函数中有另一个界限。所以在第一个界限之前的指令会一直在这个界限之前，在两个界限之间的指令会保持在两个界限之间，在第二个界限之后的指令会保持在第二个界限之后。 学生提问：在一个处理器上运行多个线程与在多个处理器上运行多个进程是否一样？ Frans教授：差不多吧，如果你有多个线程，但是只有一个CPU，那么你还是会想要特定内核代码能够原子执行。所以你还是需要有critical section的概念。你或许不需要锁，但是你还是需要能够对特定的代码打开或者关闭中断。如果你查看一些操作系统的内核代码，通常它们都没有锁的acquire，因为它们假定自己都运行在单个处理器上，但是它们都有开关中断的操作。 Sleep locksHolding a spinlock that long would lead to waste if another process wanted to acquire it, since the acquiring process would waste CPU for a long time while spinning. Another drawback of spinlocks is that a process cannot yield the CPU while retaining a spinlock; we’d like to do this so that other processes can use the CPU while the process with the lock waits for the disk. Yielding while holding a spinlock is illegal because it might lead to deadlock if a second thread then tried to acquire the spinlock; since acquire doesn’t yield the CPU, the second thread’s spinning might prevent the first thread from running and releasing the lock. Yielding while holding a lock would also violate the requirement that interrupts must be off while a spinlock is held. Thus we’d like a type of lock that yields the CPU while waiting to acquire, and allows yields (and interrupts) while the lock is held. 自旋锁的坏处在于尝试获取锁时必须让CPU自旋重试，因此自旋锁不能用于持锁时间长的场景。那么我们会想要这么一种锁：尝试获锁能够让出CPU，而在持有锁时又允许中断，这将会在后来介绍。","link":"/2024/01/13/MIT6.S081/book/chapter6/"},{"title":"MIT6.S081 xv6book chapter7","text":"第七章讲述了xv6中线程调度的机制，核心就是swtch函数以及调度器内核线程。在线程调度的基础上，讲述了线程同步的一个机制：sleep&amp;wakeup（其实就是条件变量）。有了同步机制后，继续展开讲进程退出、资源回收等知识。fork+exec+wait 一套流程。 融合了lec11和lec13的内容，两节课的内容，收获颇丰。 线程概述首先，线程可以认为是一种在有多个任务时简化编程的抽象。线程是串行执行代码的单元，尽管有许多不同线程的定义，在这里我们可以认为线程就是但个串行执行代码的单元，它只占用一个CPU并且以普通的方式一个接一个执行指令。 除此之外，线程还具有状态，我们可以随时保存线程的状态并暂停线程的运行，并在之后通过恢复状态来恢复线程的运行。 线程的状态包括： 程序计数器 寄存器 栈（Stack记录了函数调用的记录，并反映了当前线程的执行点） 多线程的并行运行主要有两个策略： 多核处理器，每个CPU对应运行一个线程，每个线程自动的根据所在CPU就有了程序计数器和寄存器。 一个CPU对应多个线程，一个CPU在多个线程之间来回切换。 实际上，与大多数其他操作系统一样，XV6结合了这两种策略，首先线程会运行在所有可用的CPU核上，其次每个CPU核会在多个线程之间切换，因为通常来说，线程数会远远多于CPU的核数。xv6的线程切换主要是时间片轮转（先运行一个线程，之后将线程的状态保存，再切换至运行第二个线程，然后再是第三个线程，依次类推直到每个线程都运行了一会，再回来重新执行第一个线程） 不同线程系统之间的一个主要的区别就是，线程之间是否会共享内存。一种可能是你有一个地址空间，多个线程都在这一个地址空间内运行，并且它们可以看到彼此的更新。 XV6内核共享了内存，并且XV6支持内核线程的概念，对于每个用户进程都有一个内核线程来执行来自用户进程的系统调用。所有的内核线程都共享了内核内存，所以XV6的内核线程的确会共享内存。 多核能够进行线程切换的前提是：多个CPU核心共享同一套内存。 xv6线程调度线程调度的难点： 第一个是如何实现线程间的切换。这里停止一个线程的运行并启动另一个线程的过程通常被称为线程调度（Scheduling）。 第二个挑战是，当你想要实际实现从一个线程切换到另一个线程时，你需要保存并恢复线程的状态，所以需要决定线程的哪些信息是必须保存的，并且在哪保存它们。 最后一个挑战是如何处理运算密集型线程（compute bound thread）。对于线程切换，很多直观的实现是由线程自己自愿的保存自己的状态，再让其他的线程运行。但是如果我们有一些程序正在执行一些可能要花费数小时的长时间计算任务，这样的线程并不能自愿的出让CPU给其他的线程运行。所以这里需要能从长时间运行的运算密集型线程撤回对于CPU的控制，将其放置于一边，稍后再运行它。 处理运算密集线程的答案就是定时器中断，定时器中断（比如说每隔10ms触发），能将程序运行的控制权从用户空间代码切换到内核中的中断处理程序。这里的基本流程是，定时器中断将CPU控制权给到内核，内核再自愿的出让CPU。 在执行线程调度的时候，调度程序需要能区分几类线程： 当前在CPU上运行的线程 RUNNING 一旦CPU有空闲时间就想要运行在CPU上的线程 RUNABLE 以及不想运行在CPU上的线程，因为这些线程可能在等待I/O或者其他事件 SLEEPING 对于RUNNING状态下的线程，它的程序计数器和寄存器位于正在运行它的CPU硬件中。UNABLE线程需要保存它的状态信息，我们需要拷贝的信息就是程序计数器（Program Counter）和寄存器。当线程调度器决定要运行一个RUNABLE线程时，这里涉及了很多步骤，但是其中一步是将之前保存的程序计数器和寄存器拷贝回调度器对应的CPU中。 学生提问：当一个线程结束执行了，比如说在用户空间通过exit系统调用结束线程，同时也会关闭进程的内核线程。那么线程结束之后和下一个定时器中断之间这段时间，CPU仍然会被这个线程占有吗？还是说我们在结束线程的时候会启动一个新的线程？ Robert教授：exit系统调用会出让CPU。尽管我们这节课主要是基于定时器中断来讨论，但是实际上XV6切换线程的绝大部分场景都不是因为定时器中断，比如说一些系统调用在等待一些事件并决定让出CPU。exit系统调用会做各种操作然后调用yield函数来出让CPU，这里的出让并不依赖定时器中断。 线程切换过程 xv6实现线程切换相当曲折： 首先用户程序会因为定时器中断陷入内核（走到内核线程），此时用户空间的状态已经保存在trapframe中； 从第一个用户内核线程切换到内核线程调度线程； 线程调度程序再切换到第二个用户内核线程； 第二个用户进程从内核态返回到用户态。 其中，从一个内核线程切换到另一个内核线程，需要保存旧线程的状态到context对象中，然后恢复从新的contex对象恢复另一个内核线程的状态（其实就是调用swtch函数） 学生提问：context保存在哪？ Robert教授：每一个内核线程都有一个context对象。但是内核线程实际上有两类。每一个用户进程有一个对应的内核线程，它的context对象保存在用户进程对应的proc结构体中。 每一个调度器线程，它也有自己的context对象，但是它却没有对应的进程和proc结构体，所以调度器线程的context对象保存在cpu结构体中。在内核中，有一个cpu结构体的数组，每个cpu结构体对应一个CPU核，每个结构体中都有一个context字段。 学生提问：为什么不能将context对象保存在进程对应的trapframe中？ Robert教授：context可以保存在trapframe中，因为每一个进程都只有一个内核线程对应的一组寄存器，我们可以将这些寄存器保存在任何一个与进程一一对应的数据结构中。对于每个进程来说，有一个proc结构体，有一个trapframe结构体，所以我们可以将context保存于trapframe中。但是或许出于简化代码或者让代码更清晰的目的，trapframe还是只包含进入和离开内核时的数据。而context结构体中包含的是在内核线程和调度器线程之间切换时，需要保存和恢复的数据。 学生提问：出让CPU是由用户发起的还是由内核发起的？ Robert教授：对于XV6来说，并不会直接让用户线程出让CPU或者完成线程切换，而是由内核在合适的时间点做决定。有的时候你可以猜到特定的系统调用会导致出让CPU，例如一个用户进程读取pipe，而它知道pipe中并不能读到任何数据，这时你可以预测读取会被阻塞，而内核在等待数据的过程中会运行其他的进程。 内核会在两个场景下出让CPU。当定时器中断触发了，内核总是会让当前进程出让CPU，因为我们需要在定时器中断间隔的时间点上交织执行所有想要运行的进程。另一种场景就是任何时候一个进程调用了系统调用并等待I/O，例如等待你敲入下一个按键，在你还没有按下按键时，等待I/O的机制会触发出让CPU。 学生提问：每一个CPU的调度器线程有自己的栈吗？ Robert教授：是的，每一个调度器线程都有自己独立的栈。实际上调度器线程的所有内容，包括栈和context，与用户进程不一样，都是在系统启动时就设置好了。如果你查看XV6的start.s（注：是entry.S和start.c）文件，你就可以看到为每个CPU核设置好调度器线程。 学生提问：我们这里一直在说线程，但是从我看来XV6的实现中，一个进程就只有一个线程，有没有可能一个进程有多个线程？ Robert教授：我们这里的用词的确有点让人混淆。在XV6中，一个进程要么在用户空间执行指令，要么是在内核空间执行指令，要么它的状态被保存在context和trapframe中，并且没有执行任何指令。这里该怎么称呼它呢？你可以根据自己的喜好来称呼它，对于我来说，每个进程有两个线程，一个用户空间线程，一个内核空间线程，并且存在限制使得一个进程要么运行在用户空间线程，要么为了执行系统调用或者响应中断而运行在内核空间线程 ，但是永远也不会两者同时运行。 线程调度代码yield12345678// Give up the CPU for one scheduling round.void yield(void) { struct proc *p = myproc(); acquire(&amp;p-&gt;lock); p-&gt;state = RUNNABLE; sched(); release(&amp;p-&gt;lock);} 线程切换的第一步（实际是内核线程的第一步），放弃CPU，调用sched切换到调度器程序。 sched123456789101112131415161718192021222324// Switch to scheduler.// Must hold only p-&gt;lock and have changed proc-&gt;state.// Saves and restores intena because// intena is a property of this kernel thread, not this CPU.// It should be proc-&gt;intena and proc-&gt;noff, but that would// break in the few places where a lock is held but// there's no process.void sched(void) { int intena; struct proc *p = myproc(); if(!holding(&amp;p-&gt;lock)) panic(&quot;sched p-&gt;lock&quot;); if(mycpu()-&gt;noff != 1) // 禁止持有p-&gt;lock以外的其他锁 panic(&quot;sched locks&quot;); if(p-&gt;state == RUNNING) panic(&quot;sched running&quot;); if(intr_get()) // 持有锁时不允许中断开启 panic(&quot;sched interruptible&quot;); intena = mycpu()-&gt;intena; swtch(&amp;p-&gt;context, &amp;mycpu()-&gt;context); mycpu()-&gt;intena = intena;} 这里其实有几个问题：为什么线程切换的时候禁止持有除了进程锁之外的其他锁？为什么要持有进程锁进行线程切换？ usually the thread that acquires a lock is also responsible for releasing the lock, which makes it easier to reason about correctness 一个进程持有锁同时也负有责任去释放锁 For context switching it is necessary to break this convention because p-&gt;lock protects invariants on the process’s state and context fields that are not true while executing in swtch. 但是context switch打破了这个常规。 One example of a problem that could arise if p-&gt;lock were not held during swtch: a different CPU might decide to run the process after yield had set its state to RUNNABLE, but before swtch caused it to stop using its own kernel stack. The result would be two CPUs running on the same stack, which would cause chaos. 因为yield将进程状态设置为runnable，如果提前释放锁，其他CPU就有可能运行这个进程，而此时进程还没完成内核栈的切换。两个CPU使用同一个内核栈会造成错误。 More reading One way to think about the structure of the scheduling code is that it enforces a set of invariants about each process, and holds p-&gt;lock whenever those invariants are not true. One invariant is that if a process is RUNNING, a timer interrupt’s yield must be able to safely switch away from the process; this means that the CPU registers must hold the process’s register values (i.e. swtch hasn’t moved them to a context), and c-&gt;proc must refer to the process. Another invariant is that if a process is RUNNABLE, it must be safe for an idle CPU’s scheduler to run it; this means that p-&gt;context must hold the process’s registers (i.e., they are not actually in the real registers), that no CPU is executing on the process’s kernel stack, and that no CPU’s c-&gt;proc refers to the process. Observe that these properties are often not true while p-&gt;lock is held. Maintaining the above invariants is the reason why xv6 often acquires p-&gt;lock in one thread and releases it in another, for example acquiring in yield and releasing in scheduler. Once yield has started to modify a running process’s state to make it RUNNABLE, the lock must remain held until the invariants are restored: the earliest correct release point is after scheduler (running on its own stack) clears c-&gt;proc. Similarly, once scheduler starts to convert a RUNNABLE pro- cess to RUNNING, the lock cannot be released until the kernel thread is completely running (after the swtch, for example in yield). Swtch.S123456789101112131415161718192021222324252627282930313233.globl swtchswtch: sd ra, 0(a0) sd sp, 8(a0) sd s0, 16(a0) sd s1, 24(a0) sd s2, 32(a0) sd s3, 40(a0) sd s4, 48(a0) sd s5, 56(a0) sd s6, 64(a0) sd s7, 72(a0) sd s8, 80(a0) sd s9, 88(a0) sd s10, 96(a0) sd s11, 104(a0) ld ra, 0(a1) ld sp, 8(a1) ld s0, 16(a1) ld s1, 24(a1) ld s2, 32(a1) ld s3, 40(a1) ld s4, 48(a1) ld s5, 56(a1) ld s6, 64(a1) ld s7, 72(a1) ld s8, 80(a1) ld s9, 88(a1) ld s10, 96(a1) ld s11, 104(a1) ret 真正执行切换的其实是switch汇编代码，swtch函数会将当前的内核线程的寄存器保存到p-&gt;context中。swtch函数的另一个参数c-&gt;context，c表示当前CPU的结构体。CPU结构体中的context保存了当前CPU核的调度器线程的寄存器。所以swtch函数在保存完当前内核线程的内核寄存器之后，就会恢复当前CPU核的调度器线程的寄存器，并继续执行当前CPU核的调度器线程。 注意两个特殊的寄存器ra和sp。ra寄存器保存的是当前函数的返回地址，所以调度器线程中的代码会返回到ra寄存器中的地址，sp则切换了内核栈。 这里有个有趣的问题，或许你们已经注意到了。swtch函数的上半部分保存了ra，sp等等寄存器，但是并没有保存程序计数器pc（Program Counter），为什么会这样呢？ 学生回答：因为程序计数器不管怎样都会随着函数调用更新。 是的，程序计数器并没有有效信息，我们现在知道我们在swtch函数中执行，所以保存程序计数器并没有意义。但是我们关心的是我们是从哪调用进到swtch函数的，因为当我们通过switch恢复执行当前线程并且从swtch函数返回时，我们希望能够从调用点继续执行。 另一个问题是，为什么RISC-V中有32个寄存器，但是swtch函数中只保存并恢复了14个寄存器？ 学生回答：因为switch是按照一个普通函数来调用的，对于有些寄存器，swtch函数的调用者默认swtch函数会做修改，所以调用者已经在自己的栈上保存了这些寄存器，当函数返回时，这些寄存器会自动恢复。所以swtch函数里只需要保存Callee Saved Register就行。（注，详见5.4） Caller saved寄存器，在函数调用中需要caller主动保存的寄存器。因此，callee可以直接自由更改这些寄存器，而不需要其他额外操作。 Callee saved寄存器则对称相反，caller可以直接修改这些寄存器而不用保存。 scheduler12345678910111213141516171819202122232425262728293031323334// Per-CPU process scheduler.// Each CPU calls scheduler() after setting itself up.// Scheduler never returns. It loops, doing:// - choose a process to run.// - swtch to start running that process.// - eventually that process transfers control// via swtch back to the scheduler.void scheduler(void) { struct proc *p; struct cpu *c = mycpu(); c-&gt;proc = 0; for(;;){ // Avoid deadlock by ensuring that devices can interrupt. intr_on(); for(p = proc; p &lt; &amp;proc[NPROC]; p++) { acquire(&amp;p-&gt;lock); if(p-&gt;state == RUNNABLE) { // Switch to chosen process. It is the process's job // to release its lock and then reacquire it // before jumping back to us. p-&gt;state = RUNNING; c-&gt;proc = p; swtch(&amp;c-&gt;context, &amp;p-&gt;context); // Process is done running for now. // It should have changed its p-&gt;state before coming back. c-&gt;proc = 0; } release(&amp;p-&gt;lock); } }} 可以看到调度器程序其实就是一个无限循环，不断从所有进程中挑选能够运行的程序，然后swtch到那个程序。同理，其他程序会swtch到scheduler调用swtch函数的那一行。每个CPU都有调度器，在xv6启动过程中kernel/main.c会调用scheduler。 然后我们还注意到 acquire(&amp;p-&gt;lock);，因为要修改进程的状态，但是在swtch之前我们都没有释放锁，这是为什么？与前面同理。 The only place a kernel thread gives up its CPU is in sched, and it always switches to the same location in scheduler, which (almost) always switches to some kernel thread that previously called sched. Thus, if one were to print out the line numbers where xv6 switches threads, one would observe the following simple pattern: (kernel/proc.c:456), (kernel/proc.c:490), (kernel/proc.c:456), (kernel/proc.c:490), and so on. 线程调用swtch总是切换到另一个线程调用swtch的地方，那么第一个线程调用swtch它切换到哪里？在第一个线程之前，没有其他线程之前调用过swtch。 学生提问：当调用swtch函数的时候，实际上是从一个线程对于switch的调用切换到了另一个线程对于switch的调用。所以线程第一次调用swtch函数时，需要伪造一个“另一个线程”对于switch的调用，是吧？因为也不能通过swtch函数随机跳到其他代码去。 Robert教授：是的。我们来看一下第一次调用switch时，“另一个”调用swtch函数的线程的context对象。proc.c文件中的allocproc函数会被启动时的第一个进程和fork调用，allocproc会设置好新进程的context，如下所示： 12345// Set up new context to start executing at forkret,// which returns to user space.memset(&amp;p-&gt;context, 0, sizeof(p-&gt;context));p-&gt;context.ra = (uint64)forkret;p-&gt;context.sp = p-&gt;kstack + PGSIZE; 再看forkret 123456789101112131415161718// A fork child's very first scheduling by scheduler()// will swtch to forkret.void forkret(void) { static int first = 1; // Still holding p-&gt;lock from scheduler. release(&amp;myproc()-&gt;lock); if (first) { // File system initialization must be run in the context of a // regular process (e.g., because it calls sleep), and thus cannot // be run from main(). first = 0; fsinit(ROOTDEV); } usertrapret();} 从代码中看，它的工作其实就是释放调度器之前获取的锁。函数最后的usertrapret函数其实也是一个假的函数，它会使得程序表现的看起来像是从trap中返回，但是对应的trapframe其实也是假的，这样才能跳到用户的第一个指令中。 学生提问：与之前的context对象类似的是，对于trapframe也不用初始化任何寄存器，因为我们要去的是程序的最开始，所以不需要做任何假设，对吧？ Robert教授：我认为程序计数器还是要被初始化为0的。 线程切换持锁限制xv6切换中，进程在调用switch函数的过程中，必须要持有p-&gt;lock（注，也就是进程对应的proc结构体中的锁），但是同时又不能持有任何其他的锁。 这是为什么？构建一个场景： 我们有进程P1，P1的内核线程持有了p-&gt;lock以外的其他锁，这些锁可能是在使用磁盘，UART，console过程中持有的。之后内核线程在持有锁的时候，通过调用switch/yield/sched函数出让CPU，这会导致进程P1持有了锁，但是进程P1又不在运行。 假设我们在一个只有一个CPU核的机器上，假设P2也想使用磁盘，UART或者console，它会对P1持有的锁调用acquire，这是对于同一个锁的第二个acquire调用。当然这个锁现在已经被P1持有了，所以这里的acquire并不能获取锁。但是很明显进程P2的acquire不会返回，所以即使进程P2稍后愿意出让CPU，P2也没机会这么做。这就造成了死锁。 Sleep &amp; Wakeup当你在写一个线程的代码时，有些场景需要等待一些特定的事件，或者不同的线程之间需要交互。比如 读pipe，等待pipe的非空事件 读磁盘，等待磁盘读完成 wait函数，等待子进程推出 怎么能让进程或者线程等待一些特定的事件呢？一种非常直观的方法是通过循环实现busy-wait，但是浪费CPU。 123456789101112131415struct semaphore { struct spinlock lock; int count;}void V(struct semaphore* s){ acquire(&amp;s-&gt;lock); s-&gt;count += 1; release(&amp;s-&gt;lock);}void P(struct semaphore* s){ while(s-&gt;count==0) ; //busy-waitting acquire(&amp;s-&gt;lock); s-&gt;count-=1; release(&amp;s-&gt;lock);} 我们希望能够在等待的时候让出CPU，然后在事件完成时重新获取CPU。Coordination就是出让CPU，直到等待的事件发生再恢复执行。人们发明了很多不同的Coordination的实现方式，但是与许多Unix风格操作系统一样，XV6使用的是Sleep&amp;Wakeup这种方式。 这里的机制是，如果一个线程需要等待某些事件，比如说等待UART硬件愿意接收一个新的字符，线程调用sleep函数并等待一个特定的条件。当特定的条件满足时，代码会调用wakeup函数。这里的sleep函数和wakeup函数是成对出现的。还需要注意：sleep和wakeup函数需要通过某种方式链接到一起。也就是说，如果我们调用wakeup函数，我们只想唤醒正在等待刚刚发生的特定事件的线程。所以，sleep函数和wakeup函数都带有一个叫做sleep channel的参数，我们在调用wakeup的时候，需要传入与调用sleep函数相同的sleep channel。 以信号量为例谈实现The basic idea is to have sleep mark the current process as SLEEPING and then call sched to release the CPU; wakeup looks for a process sleeping on the given wait channel and marks it as RUNNABLE. sleep函数做的事情很简单，将进程标记为sleep，记录channel（p-&gt;ch)到进程然后调用sched让出CPU；wakeup查找在相应channel（p-&gt;ch)上睡眠的进程，然后将其标记为runnable。 12345678910111213void V(struct semaphore* s){ acquire(&amp;s-&gt;lock); s-&gt;count += 1; wakeup(s); //唤醒 release(&amp;s-&gt;lock);}void P(struct semaphore* s){ while(s-&gt;count==0) sleep(s); //睡眠 acquire(&amp;s-&gt;lock); s-&gt;count-=1; release(&amp;s-&gt;lock);} 但如果sleep和wakeup都只带一个channel参数会出现lost wakeup问题：P刚判断完count为0，V就调整count值加一并且执行了wakeup，此时P还未睡眠，这个wakeup就丢失了。也就是说，P的判断count和sleep之间不是原子的。 解决这个问题也很简单，将锁上移，保护count。 12345678910111213void V(struct semaphore* s){ acquire(&amp;s-&gt;lock); s-&gt;count += 1; wakeup(s); //唤醒 release(&amp;s-&gt;lock);}void P(struct semaphore* s){ acquire(&amp;s-&gt;lock); // 锁上移 while(s-&gt;count==0) sleep(s); //睡眠 s-&gt;count-=1; release(&amp;s-&gt;lock);} 但这就带来了严重的问题：死锁。P带着锁睡眠，count将永远得不到更新，其他进程也得不到锁。 所以sleep的实现需要修改：增加一个额外参数，条件锁。在它将进程标记为sleep后要能够释放锁，然后在sleep返回时，还需要能获得锁。 正确实现1234567891011121314151617181920212223242526272829303132333435// Atomically release lock and sleep on chan.// Reacquires lock when awakened.void sleep(void *chan, struct spinlock *lk) { struct proc *p = myproc(); acquire(&amp;p-&gt;lock); release(lk); // Go to sleep. p-&gt;chan = chan; p-&gt;state = SLEEPING; sched(); //放弃CPU // Tidy up. p-&gt;chan = 0; release(&amp;p-&gt;lock); // Reacquire original lock. acquire(lk);}// Wake up all processes sleeping on chan.// Must be called without any p-&gt;lock.void wakeup(void *chan) { struct proc *p; for(p = proc; p &lt; &amp;proc[NPROC]; p++) { if(p != myproc()){ acquire(&amp;p-&gt;lock); if(p-&gt;state == SLEEPING &amp;&amp; p-&gt;chan == chan) { p-&gt;state = RUNNABLE; } release(&amp;p-&gt;lock); } }} 注意点： sleep依靠线程切换sched来放弃CPU的控制权； sleep在内部使用了两把锁：一把进程锁，一把是参数的条件锁； 参数中的条件锁提示sleep要和锁一起使用； sleep和wakeup通过一个channel参数联系在一起； sleep在sched返回后，还需要自动获得条件锁。 It is sometimes the case that multiple processes are sleeping on the same channel; for example, more than one process reading from a pipe. A single call to wakeup will wake them all up. One of them will run first and acquire the lock that sleep was called with, and (in the case of pipes) read whatever data is waiting in the pipe. The other processes will find that, despite being woken up, there is no data to be read. From their point of view the wakeup was “spurious,” and they must sleep again. For this reason sleep is always called inside a loop that checks the condition. xv6中的sleep和wakeup机制其实就是条件变量。 使用例子：pipe123456789101112131415161718192021222324int piperead(struct pipe *pi, uint64 addr, int n){ int i; struct proc *pr = myproc(); char ch; acquire(&amp;pi-&gt;lock); while(pi-&gt;nread == pi-&gt;nwrite &amp;&amp; pi-&gt;writeopen){ //DOC: pipe-empty if(pr-&gt;killed){ release(&amp;pi-&gt;lock); return -1; } sleep(&amp;pi-&gt;nread, &amp;pi-&gt;lock); //DOC: piperead-sleep } for(i = 0; i &lt; n; i++){ //DOC: piperead-copy if(pi-&gt;nread == pi-&gt;nwrite) break; ch = pi-&gt;data[pi-&gt;nread++ % PIPESIZE]; if(copyout(pr-&gt;pagetable, addr + i, &amp;ch, 1) == -1) break; } wakeup(&amp;pi-&gt;nwrite); //DOC: piperead-wakeup release(&amp;pi-&gt;lock); return i;} 代码第7行，如果pipe为空，需要等待写事件。需要注意的是，直接用nread作为sleep和wakeup的联系，因为nread只会在pipread中得到更新。 1234567891011121314151617181920212223242526int pipewrite(struct pipe *pi, uint64 addr, int n){ int i = 0; struct proc *pr = myproc(); acquire(&amp;pi-&gt;lock); while(i &lt; n){ if(pi-&gt;readopen == 0 || pr-&gt;killed){ release(&amp;pi-&gt;lock); return -1; } if(pi-&gt;nwrite == pi-&gt;nread + PIPESIZE){ //DOC: pipewrite-full wakeup(&amp;pi-&gt;nread); sleep(&amp;pi-&gt;nwrite, &amp;pi-&gt;lock); } else { char ch; if(copyin(pr-&gt;pagetable, &amp;ch, addr + i, 1) == -1) break; pi-&gt;data[pi-&gt;nwrite++ % PIPESIZE] = ch; i++; } } wakeup(&amp;pi-&gt;nread); release(&amp;pi-&gt;lock); return i;} 进程相关exit系统调用每个进程最终都需要退出，我们需要清除进程的状态，释放栈。在XV6中，一个进程如果退出的话，我们需要释放用户内存，释放page table，释放trapframe对象，将进程在进程表单中标为REUSABLE，这些都是典型的清理步骤。 两大问题： 不能直接单方面的摧毁另一个线程（指kill），如果我们直接就把线程杀掉了，我们可能在线程完成更新复杂的内核数据过程中就把线程杀掉了。 即使一个线程调用了exit系统调用是自己决定要退出，但它仍然持有运行代码所需要的一些资源，例如它的栈，以及它在进程表单中的位置。当它还在执行代码，它就不能释放正在使用的资源。 123456789101112131415161718192021222324252627282930313233343536373839void exit(int status) { struct proc *p = myproc(); if(p == initproc) panic(&quot;init exiting&quot;); // Close all open files. for(int fd = 0; fd &lt; NOFILE; fd++){ if(p-&gt;ofile[fd]){ struct file *f = p-&gt;ofile[fd]; fileclose(f); p-&gt;ofile[fd] = 0; } } begin_op(); iput(p-&gt;cwd); end_op(); p-&gt;cwd = 0; acquire(&amp;wait_lock); // Give any children to init. reparent(p); // Parent might be sleeping in wait(). wakeup(p-&gt;parent); acquire(&amp;p-&gt;lock); p-&gt;xstate = status; p-&gt;state = ZOMBIE; release(&amp;wait_lock); // Jump into the scheduler, never to return. sched(); panic(&quot;zombie exit&quot;);} 首先exit函数关闭了所有已打开的文件。接下来是类似的处理，进程有一个对于当前目录的记录，这个记录会随着你执行cd指令而改变。在exit过程中也需要将对这个目录的引用释放给文件系统。 如果一个进程要退出，但是它又有自己的子进程，接下来需要设置这些子进程的父进程为init进程(父进程中的wait系统调用会完成进程退出最后的几个步骤。所以如果父进程退出了，那么子进程就不再有父进程，当它们要退出时就没有对应的父进程的wait。所以在exit函数中，会为即将exit进程的子进程重新指定父进程为init进程，也就是PID为1的进程)。 之后，我们需要通过调用wakeup函数唤醒当前进程的父进程，当前进程的父进程或许正在等待当前进程退出。 接下来，进程的状态被设置为ZOMBIE。现在进程还没有完全释放它的资源，所以它还不能被重用。 现在我们还没有结束，因为我们还没有释放进程资源。我们在还没有完全释放所有资源的时候，通过调用sched函数进入到调度器线程。 到目前位置，进程的状态是ZOMBIE，并且进程不会再运行，因为调度器只会运行RUNNABLE进程。同时进程资源也并没有完全释放，如果释放了进程的状态应该是UNUSED。但是可以肯定的是进程不会再运行了，因为它的状态是ZOMBIE。所以调度器线程会决定运行其他的进程。 wait系统调用12345678910111213141516171819202122232425262728293031323334353637383940414243444546// Wait for a child process to exit and return its pid.// Return -1 if this process has no children.int wait(uint64 addr) { struct proc *np; int havekids, pid; struct proc *p = myproc(); acquire(&amp;wait_lock); for(;;){ // Scan through table looking for exited children. havekids = 0; for(np = proc; np &lt; &amp;proc[NPROC]; np++){ if(np-&gt;parent == p){ // make sure the child isn't still in exit() or swtch(). acquire(&amp;np-&gt;lock); havekids = 1; if(np-&gt;state == ZOMBIE){ // Found one. pid = np-&gt;pid; if(addr != 0 &amp;&amp; copyout(p-&gt;pagetable, addr, (char *)&amp;np-&gt;xstate, sizeof(np-&gt;xstate)) &lt; 0) { release(&amp;np-&gt;lock); release(&amp;wait_lock); return -1; } freeproc(np); // free a proc structure and the data hanging from it, userpage release(&amp;np-&gt;lock); release(&amp;wait_lock); return pid; } release(&amp;np-&gt;lock); } } // No point waiting if we don't have any children. if(!havekids || p-&gt;killed){ release(&amp;wait_lock); return -1; } // Wait for a child to exit. sleep(p, &amp;wait_lock); //DOC: wait-sleep }} 它里面包含了一个大的循环。当一个进程调用了wait系统调用，它会扫描进程表单，找到父进程是自己且状态是ZOMBIE的进程。从上一节可以知道，这些进程已经在exit函数中几乎要执行完了。之后由父进程调用的freeproc函数，来完成释放进程资源的最后几个步骤。 12345678910111213141516static void freeproc(struct proc *p){ if(p-&gt;trapframe) kfree((void*)p-&gt;trapframe); p-&gt;trapframe = 0; if(p-&gt;pagetable) proc_freepagetable(p-&gt;pagetable, p-&gt;sz); p-&gt;pagetable = 0; p-&gt;sz = 0; p-&gt;pid = 0; p-&gt;parent = 0; p-&gt;name[0] = 0; p-&gt;chan = 0; p-&gt;killed = 0; p-&gt;xstate = 0; p-&gt;state = UNUSED;} 如果由正在退出的进程自己在exit函数中执行这些步骤，将会非常奇怪。这里释放了trapframe，释放了page table。如果我们需要释放进程内核栈，那么也应该在这里释放。但是因为内核栈的guard page，我们没有必要再释放一次内核栈。不管怎样，当进程还在exit函数中运行时，任何这些资源在exit函数中释放都会很难受，所以这些资源都是由父进程释放的。 在Unix中，对于每一个退出的进程，都需要有一个对应的wait系统调用，这就是为什么当一个进程退出时，它的子进程需要变成init进程的子进程。init进程的工作就是在一个循环中不停调用wait。每个进程都需要对应一个wait，这样它的父进程才能调用freeproc函数，并清理进程的资源。当父进程完成了清理进程的所有资源，子进程的状态会被设置成UNUSED，之后，fork系统调用才能重用进程在进程表单的位置。 kill系统调用123456789101112131415161718int kill(int pid) { struct proc *p; for(p = proc; p &lt; &amp;proc[NPROC]; p++){ acquire(&amp;p-&gt;lock); if(p-&gt;pid == pid){ p-&gt;killed = 1; if(p-&gt;state == SLEEPING){ // Wake process from sleep(). p-&gt;state = RUNNABLE; } release(&amp;p-&gt;lock); return 0; } release(&amp;p-&gt;lock); } return -1;} 最后我想看的是kill系统调用。Unix中的一个进程可以将另一个进程的ID传递给kill系统调用，并让另一个进程停止运行。 如果我们不够小心的话，kill一个还在内核执行代码的进程，会有一些我几分钟前介绍过的风险，比如我们想要杀掉的进程的内核线程还在更新一些数据，比如说更新文件系统，创建一个文件。如果这样的话，我们不能就这样杀掉进程。所以kill系统调用不能就直接停止目标进程的运行。实际上，在XV6和其他的Unix系统中，kill系统调用基本上不做任何事情。 它先扫描进程表单，找到目标进程。然后只是将进程的proc结构体中killed标志位设置为1。如果进程正在SLEEPING状态，将其设置为RUNNABLE。 而目标进程运行到内核代码中能安全停止运行的位置时，会检查自己的killed标志位，如果设置为1，目标进程会自愿的执行exit系统调用。 这里需要注意的是sleep的进程被唤醒的问题： 通常sleep的进程都会等待某个事件，sleep的代码会被包含在一个loop条件检查中。当sleep被再次唤醒时，loop的条件检查还需要检查进程是否killed。 1234567while(pi-&gt;nread == pi-&gt;nwrite &amp;&amp; pi-&gt;writeopen){ //DOC: pipe-empty if(pr-&gt;killed){ release(&amp;pi-&gt;lock); return -1; } sleep(&amp;pi-&gt;nread, &amp;pi-&gt;lock); //DOC: piperead-sleep} 也就是说，现在进程被唤醒的原因多了一个：它可能是被杀死了，而不是等待的事件完成了。我们需要小心的检查进程唤醒后的状态。 学生提问：这节课可能没有怎么讲到，但是如果关闭一个操作系统会发生什么？ Robert教授：这个过程非常复杂，并且依赖于你运行的是什么系统。因为文件系统是持久化的，它能在多次重启之间保持数据，我们需要保持文件系统的良好状态，如果我们正在更新文件系统的过程中，例如创建文件，然后我们想关闭操作系统，断电之类的。我们需要一个策略来确保即使我们正在一个复杂的更新文件系统的过程中，我们并不会破坏磁盘上的文件系统数据。文件系统其实就是一个位于磁盘的数据结构。所以这里涉及到了很多的机制来确保如果你关闭操作系统或者因为断电之类，我们可以恢复磁盘上的文件系统。 其他的，你是否需要做一些特殊的操作来关闭系统，取决于你正在运行什么进程。如果你正在运行一些重要的服务器，例如数据库服务器，并且许多其他计算机依赖这个数据库并通过网络使用它。那谁知道呢？答案或许是你不能就这么直接关闭操作系统，因为你正在提供一个对于其他计算机来说非常关键的服务。 如果你的计算机并没有在做任何事情，那么你可以直接关闭它。或许对于你的问题来说，如果你想关闭一个计算机，确保文件系统是正确的，之后停止执行指令，之后就可以关闭计算机了。 总结xv6的线程调度确实蛮曲折的，所谓线程调度就是一个线程让出CPU，然后决定另外一个线程运行的过程。 我们需要知道一个线程会在什么场景让出CPU，一个是定时器中断，线程的时间片到期；另一个场景是等待事件，比如等待管道、等待外设等。第二个场景是通过sleep和wakeup做到让出CPU和恢复运行。 调度器程序本身就是个无限循环，从进程表中挑出可运行的线程，然后再交出CPU到可运行线程。线程切换需要保存上下文到contex，contex包括ra和sp寄存器以及14个callee save寄存器，然后恢复新线程的上下文。第一个线程会返回到forkret的位置，假装调用swtch。 有了同步机制后，我们就能理解fork+wait的威力。进程退出由自己释放资源显得有点奇怪，因为代码运行还是需要依靠一些资源（比如栈、页表等）。这就给进程的ZOMBIE状态一个很好的解释：进程打算退出了，有一些资源还没释放，它等待父进程来释放这些资源。同样的，父进程需要主动调用wait来清理子进程的剩余资源。wait并不仅仅是等待子进程结束那么简单。 kill调用反而最无力，只能标记进程的killed字段，唤醒沉睡的进程。如此一来，进程在任何唤醒的地方都要增加进程是否被杀死的条件检验。","link":"/2024/01/16/MIT6.S081/book/chapter7/"},{"title":"MIT6.S081 xv6book chapter8","text":"这八章讲述了xv6的文件系统，这个文件系统的实现很简单，有许多可以优化的地方，但也有很多复杂的地方。从磁盘组织、缓存、日志、Inode、目录、文件名与文件描述符。其实可以简单分为三部分： 底层存储（磁盘组织、磁盘缓存、Inode、Directory） 持久层（日志事务） 用户层（文件名、文件描述符） 本节融合了lec14和lec15的内容，收获颇丰。 前言文件系统的有趣性： 抽象：如何对硬件的抽象 崩溃恢复——文件系统的持久性 文件组织——如何在磁盘上排布文件系统 性能——读取磁盘通常比较慢，如何取得性能的提升 文件系统分层： 最底层是磁盘，也就是一些实际保存数据的存储设备，正是这些设备提供了持久化存储。 在这之上是buffer cache或者说block cache，这些cache可以避免频繁的读写磁盘。这里我们将磁盘中的数据保存在了内存中。 为了保证持久性，再往上通常会有一个logging层。 longging层之上有inode cache，这主要是为了同步（synchronization）。 再往上就是inode本身了。它实现了read/write。 再往上，就是文件名，和文件描述符操作。 文件究竟维护了怎样的数据结构呢？核心的数据结构就是inode和file descriptor。后者主要与用户进程进行交互。 最重要的就是Inode，它代表了一个文件。文件名只是一个link，Inode之间通过编号进行区分。 inode必须有一个link count来跟踪指向这个inode的文件名的数量。一个文件（inode）只能在link count为0的时候被删除。 实际中还有一个openfd count，也就是当前打开了文件的文件描述符计数。一个文件只能在这两个计数器都为0的时候才能被删除。 文件描述符必然自己悄悄维护了对于文件的offset。 磁盘组织屏蔽不同磁盘的区别，我们可以将磁盘看成block或setor的数组，每个block大小固定，这样我们就能通过块号读取一个块的内容。 block0要么没有用，要么被用作boot sector来启动操作系统。 block1通常被称为super block，它描述了文件系统。它可能包含磁盘上有多少个block共同构成了文件系统这样的信息。 在XV6中，log从block2开始，到block32结束。实际上log的大小可能不同，这里在super block中会定义log就是30个block。 接下来在block32到block45之间，XV6存储了inode。我之前说过多个inode会打包存在一个block中，一个inode是64字节。 之后是bitmap block，这是我们构建文件系统的默认方法，它只占据一个block。它记录了数据block是否空闲。 之后就全是数据block了，数据block存储了文件的内容和目录的内容。 On-disk inode structureInode代表一个文件，那Inode究竟是怎么组织的呢？ Inode有两种形式，一种是在磁盘上，一种是在内存上。稍后将会解释为什么会有两种Inode模型，以及这两种Inode之间的同步。 123456789// On-disk inode structurestruct dinode { short type; // File type， files, directories, and special files (devices) or zero short major; // Major device number (T_DEVICE only) short minor; // Minor device number (T_DEVICE only) short nlink; // Number of links to inode in file system uint size; // Size of file (bytes) uint addrs[NDIRECT+1]; // Data block addresses #define NDIRECT 12}; The type field distinguishes between files, directories, and special files (devices). A type of zero indicates that an on- disk inode is free. The nlink field counts the number of directory entries that refer to this inode, in order to recognize when the on-disk inode and its data blocks should be freed. The addrs array records the block numbers of the disk blocks holding the file’s content.The last entry in the addrs array gives the address of the indirect block. dinode 最令人不解的通常就是addrs数组了，它其实类似多级页表。首先，addrs数组存储了所有文件内容所在块的块号。它分为两级索引，第一级索引是直接映射，意思是我得到的块号就是文件内容真实的块号。第二级索引是addrs[12]的内容，它得到块号指向一个数据块，这个数据块才真正指向了文件内容块号。所以在xv6中，文件大小最多是 （12 + 256）* block size 这么大。 当dinode的type字段为T_DIR时，表明这个dinode是目录。目录的数据内容存的是目录条目，包含2字节的inode编号和14字节的文件名。 1234struct dirent { ushort inum; char name[DIRSIZ]; // #define DIRSIZ 14}; 看完On-disk inode structure我们就知道了，文件内容是放在data区，Inode用来索引这些文件，并区分文件类型。这是通常的设计，文件的元信息和文件内容分离存储。 in-memory copy of an inode123456789101112131415// in-memory copy of an inodestruct inode { uint dev; // Device number uint inum; // Inode number int ref; // Reference count 指向inode的指针个数 struct sleeplock lock; // protects everything below here int valid; // inode has been read from disk? short type; // copy of disk inode short major; short minor; short nlink; //指向inode的目录项个数 uint size; uint addrs[NDIRECT+1];}; struct inode is the in-memory copy of a struct dinode on disk. The kernel stores an inode in memory only if there are C pointers referring to that inode 为什么会有in-memory copy of an inode 的存在？其实就是方便操作系统管理inode，提供更多关于inode的信息，比如引用计数等。 Buffer Cache文件创建文件的过程其实就是创建inode，然后写inode的内容，最后同步到磁盘。通过inode代表文件。 12345678910111213141516171819202122// Allocate an inode on device dev.// Mark it as allocated by giving it type.// Returns an unlocked but allocated and referenced inode.struct inode* ialloc(uint dev, short type) { int inum; struct buf *bp; struct dinode *dip; for(inum = 1; inum &lt; sb.ninodes; inum++){ // sb == super block bp = bread(dev, IBLOCK(inum, sb)); // 读取缓存 dip = (struct dinode*)bp-&gt;data + inum%IPB; // 地址+偏移 if(dip-&gt;type == 0){ // a free inode memset(dip, 0, sizeof(*dip)); dip-&gt;type = type; log_write(bp); // mark it allocated on the disk brelse(bp); return iget(dev, inum); } brelse(bp); } panic(&quot;ialloc: no inodes&quot;);} superblock记录了inode的数量，遍历所有创建好的inode，然后查看是否是空闲的inode（其type字段为0），然后使用它。 重点看这两行： 12bp = bread(dev, IBLOCK(inum, sb)); dip = (struct dinode*)bp-&gt;data + inum%IPB; 1234// Inodes per block.#define IPB (BSIZE / sizeof(struct dinode))// Block containing inode i#define IBLOCK(i, sb) ((i) / IPB + sb.inodestart) 通过bread函数，我们读取了特定设备dev上的第IBLOCK(inum, sb)个block的内容到buf上。通过宏定义我们能够知道IBLOCK(inum, sb)就是第inum 个 inode所在的块号，inum%IPB则是inode在块内的偏移量。 bread函数将读取磁盘的过程作了一层封装，我们再看bread函数: 1234567891011// Return a locked buf with the contents of the indicated block.struct buf* bread(uint dev, uint blockno){ struct buf *b; b = bget(dev, blockno); if(!b-&gt;valid) { // 如果没在cache中找到，就读取磁盘 virtio_disk_rw(b, 0); b-&gt;valid = 1; } return b;} 可以看到bread其实是先调用bget 1234567891011121314151617181920212223242526272829303132// Look through buffer cache for block on device dev.// If not found, allocate a buffer.// In either case, return locked buffer.static struct buf* bget(uint dev, uint blockno){ struct buf *b; acquire(&amp;bcache.lock); // Is the block already cached? for(b = bcache.head.next; b != &amp;bcache.head; b = b-&gt;next){ if(b-&gt;dev == dev &amp;&amp; b-&gt;blockno == blockno){ b-&gt;refcnt++; // 增加引用计数 release(&amp;bcache.lock); acquiresleep(&amp;b-&gt;lock); return b; // returns the locked buffer } } // Not cached. 回收一个buf // Recycle the least recently used (LRU) unused buffer. for(b = bcache.head.prev; b != &amp;bcache.head; b = b-&gt;prev){ if(b-&gt;refcnt == 0) { b-&gt;dev = dev; b-&gt;blockno = blockno; b-&gt;valid = 0; b-&gt;refcnt = 1; release(&amp;bcache.lock); acquiresleep(&amp;b-&gt;lock); return b; } } panic(&quot;bget: no buffers&quot;);} bget读取的是bcache（缓存），如果缓存中没有，返回一个加锁的buf（containing a copy of a block which can be read or modified in memory)，如果buf失效，最后才从磁盘读。 bcache12345678910111213141516struct buf { int valid; // has data been read from disk? int disk; // does disk &quot;own&quot; buf? uint dev; uint blockno; struct sleeplock lock; uint refcnt; struct buf *prev; // LRU cache list struct buf *next; uchar data[BSIZE];};struct { struct spinlock lock; struct buf buf[NBUF]; // 30 struct buf head;} bcache; bcache就是个大小为30的LRU链表，链表的元素为buf。buf具有引用计数，表明有多少个线程正在使用它。blockno块号的内容就存在data里。 The buffer cache has two jobs: (1) synchronize access to disk blocks to ensure that only one copy of a block is in memory and that only one kernel thread at a time uses that copy; (2) cache popular blocks so that they don’t need to be re-read from the slow disk. buffer cache作为缓存能有效的减少访问磁盘的时间，同时buffer cache必须保证一个磁盘block之对应一个buf，一个buf只能被一个线程使用，否则就会出问题。 如果buffer cache中有两份block 33的cache将会出现问题。假设一个进程要更新inode19，另一个进程要更新inode20。如果它们都在处理block 33的cache，并且cache有两份，那么第一个进程可能持有一份cache并先将inode19写回到磁盘中，而另一个进程持有另一份cache会将inode20写回到磁盘中，并将inode19的更新覆盖掉。所以一个block只能在buffer cache中出现一次。 从bget返回加锁的buf这点来看，xv6并不支持多个线程同时读写一块block。第二个获取相同block的线程需要等待第一个线程释放，acquiresleep确保线程能够睡眠。 Logging Layerlogging的目标：实现原子的系统调用，快速恢复和高性能。 持久化的基本思想xv6 系统调用不直接写入磁盘上的文件系统数据结构。相反，它会在磁盘上的日志中放置它希望进行的所有磁盘写入的描述。一旦系统调用记录了其所有写入操作，它就会将一条特殊的提交记录写入磁盘，指示该日志包含完整的操作。此时，系统调用将写入复制到磁盘文件系统数据结构中。完成这些写入后，系统调用将擦除磁盘上的日志。 简单来说：就是系统调用先写log区，log区写完后写一条提交记录。提交记录写完，再将log区的block搬回到data区，搬运完之后擦除磁盘的日志。 遵循write ahead rule，也就是说在写入commit记录之前，你需要确保所有的写操作都在log中。 日志设计 1234567891011121314151617// Contents of the header block, used for both the on-disk header block// and to keep track in memory of logged block# before commit.struct logheader { int n; // log blocks int block[LOGSIZE];};struct log { struct spinlock lock; int start; // log信息在磁盘上的位置（开始的block块的索引号) int size; // log区的总的block块的数目。 int outstanding; // 当前正在使用LOG机制的文件系统调用数目(目的是别超过了LOG系统总容量) int committing; // 当前是不是正处于LOG的提交中,也就是正在写LOG进入磁盘呢 int dev; struct logheader lh; // 磁盘logheader在内存中的一份映射};struct log log; log主要由两部分组成，log header和log block。header里有一个数组追踪每个log block。 日志基本调用流程1234567begin_op(); // 第一步...bp = bread(...);bp-&gt;data[...] = ...;log_write(bp); // 中间步骤，记录写的buf块...end_op(); //最后一部 begin_op表示开启一次日志记录，这里暂时不揭示内容。 bread读缓存然后对data进行修改，此时需要调用log_write来记录修改到log。让我们来看看： 1234567891011121314151617181920212223// Caller has modified b-&gt;data and is done with the buffer.// Record the block number and pin in the cache by increasing refcnt.// commit()/write_log() will do the disk write.void log_write(struct buf *b){ int i; acquire(&amp;log.lock); if (log.lh.n &gt;= LOGSIZE || log.lh.n &gt;= log.size - 1) panic(&quot;too big a transaction&quot;); if (log.outstanding &lt; 1) panic(&quot;log_write outside of trans&quot;); for (i = 0; i &lt; log.lh.n; i++) { if (log.lh.block[i] == b-&gt;blockno) // log absorption break; } log.lh.block[i] = b-&gt;blockno; if (i == log.lh.n) { // Add new block to log? bpin(b); log.lh.n++; } release(&amp;log.lock);} 当在内存中修改了一个磁盘数据后，如果想从缓存真正写入的磁盘上， 有bwirte()函数。但是，xv6支持了log机制，使用log_write()代替了bwrite()函数来完成这个工作。 该函数其实只完成：在logheader中记录要写入的block块。(如果已经记录过，就无需再次添加，称之为log absorbtion)。这里注意，还调用bpin让这个buf的引用计数增一，避免这个脏块在回写前被bget给回收掉。 真正的写磁盘的动作在end_op()函数中来完成。 12345678910111213141516171819202122232425262728void end_op(void) { int do_commit = 0; acquire(&amp;log.lock); log.outstanding -= 1; if(log.committing) panic(&quot;log.committing&quot;); if(log.outstanding == 0){ do_commit = 1; log.committing = 1; } else { // begin_op() may be waiting for log space, // and decrementing log.outstanding has decreased // the amount of reserved space. wakeup(&amp;log); } release(&amp;log.lock); if(do_commit){ // call commit w/o holding locks, since not allowed // to sleep with locks. commit(); acquire(&amp;log.lock); log.committing = 0; wakeup(&amp;log); release(&amp;log.lock); }} 代码最前端有一些复杂情况处理，直接跳过，看commit函数。 1234567891011121314151617181920212223242526272829303132static void commit(){ if (log.lh.n &gt; 0) { write_log(); // Write modified blocks from cache to log write_head(); // Write header to disk -- the real commit install_trans(0); // Now install writes to home locations log.lh.n = 0; write_head(); // Erase the transaction from the log }}static void write_log(int dev){ int tail; for (tail = 0; tail &lt; log[dev].lh.n; tail++) { struct buf *to = bread(dev, log[dev].start+tail+1); // log block struct buf *from = bread(dev, log[dev].lh.block[tail]); // cache block memmove(to-&gt;data, from-&gt;data, BSIZE); bwrite(to); // write the log brelse(from); brelse(to); }}static void write_head(int dev) { struct buf *buf = bread(dev, log[dev].start); struct logheader *hb = (struct logheader *) (buf-&gt;data); int i; hb-&gt;n = log[dev].lh.n; for (i = 0; i &lt; log[dev].lh.n; i++) { hb-&gt;block[i] = log[dev].lh.block[i]; } bwrite(buf); brelse(buf);} write_log将缓冲块写入到磁盘的日志区，完成脏块的持久化。 write_head则将logheader进行持久化。 install_trans负责使用日志覆盖掉对应的盘块。该方法读取logheader.blocks数组，将每个对应的日志区的盘块安装到文件区。 当成功用日志覆盖掉对应的盘块后，系统已经无需再继续持有这些日志，因此会再次调用write_head修改日志区的logheader来清除日志，并设定log[dev].lh.n = 0。 日志挑战第一个挑战是bcache不能撤回已经在日志transaction中的buf，这么做会破坏原子性。所以有一个buf_pin操作会将buf固定在cache中（实际上就是增加一个引用计数） 第二个挑战是文件系统操作受限于log大小。这里意思是说xv6的log区大小为30，这就限制一次系统调用最多写的block数量。如果写入的block数超过了30，那么一个写操作会被分割成多个小一些的写操作。 123456int max = ((MAXOPBLOCKS-1-1-2) / 2) * BSIZE;int i = 0;while(i &lt; n){ int n1 = n - i; if(n1 &gt; max) n1 = max; 第三个挑战就是并发操作。 log的并发还挺有意思的，除了加锁保护外，还限制于log的空间大小。 比如，现在有两个并发的transaction，其中t0在log的前半部分，t1在log的后半部分，可是用完了log空间但一个transcation都没完成。这样就陷入了死锁，任何一个transaction 都期待另一个提交释放空间，但一个都不能提交。 所以说还要保证多个并发transaction也适配log的大小。当我们还没有完成一个文件系统操作时，我们必须在确保可能写入的总的log数小于log区域的大小的前提下，才允许另一个文件系统操作开始。 XV6通过限制并发文件系统操作的个数来实现这一点。在begin_op中，我们会检查当前有多少个文件系统操作正在进行。如果有太多正在进行的文件系统操作，我们会通过sleep停止当前文件系统操作的运行，并等待所有其他所有的文件系统操作都执行完并commit之后再唤醒。这里的其他所有文件系统操作都会一起commit。有的时候这被称为group commit，因为这里将多个操作像一个大的transaction一样提交了，这里的多个操作要么全部发生了，要么全部没有发生。 12345678910111213141516// called at the start of each FS system call.void begin_op(void){ acquire(&amp;log.lock); while(1){ if(log.committing){ sleep(&amp;log, &amp;log.lock); } else if(log.lh.n + (log.outstanding+1)*MAXOPBLOCKS &gt; LOGSIZE){ // this op might exhaust log space; wait for commit. sleep(&amp;log, &amp;log.lock); } else { log.outstanding += 1; release(&amp;log.lock); break; } }} 首先，如果log正在commit过程中，那么就等到log提交完成，因为我们不能在install log的过程中写log；其次，如果当前操作是允许并发的操作个数的后一个，那么当前操作可能会超过log区域的大小，我们也需要sleep并等待所有之前的操作结束；最后，如果当前操作可以继续执行，需要将log的outstanding字段加1，最后再退出函数并执行文件系统操作。 12345678910111213141516void end_op(void) { int do_commit = 0; acquire(&amp;log.lock); log.outstanding -= 1; if(log.committing) panic(&quot;log.committing&quot;); if(log.outstanding == 0){ do_commit = 1; log.committing = 1; } else { wakeup(&amp;log); } release(&amp;log.lock); ...} 最后再看end_op的前半部分。在最开始首先会对log的outstanding字段减1，因为一个transaction正在结束；其次检查committing状态，当前不可能在committing状态，所以如果是的话会触发panic；如果当前操作是整个并发操作的最后一个的话（log.outstanding == 0），接下来立刻就会执行commit；如果当前操作不是整个并发操作的最后一个的话，我们需要唤醒在begin_op中sleep的操作，让它们检查是不是能运行。 所以，即使是XV6中这样一个简单的文件系统，也有一些复杂性和挑战。 崩溃恢复过程崩溃恢复的过程也很简单，只需要读log里未提交的日志就行。那什么是真正的提交节点呢？在commit函数中已经指示了，write head就是那么一个节点。 123456789static void commit(){ if (log.lh.n &gt; 0) { write_log(); // Write modified blocks from cache to log write_head(); // Write header to disk -- the real commit install_trans(0); // Now install writes to home locations log.lh.n = 0; write_head(); // Erase the transaction from the log }} write_head将n不为0的head写入log区。下次开机启动时，扫描log区的head，查看其n字段是否为0. 123456static void recover_from_log(void){ read_head(); install_trans(1); // if committed, copy from log to disk log.lh.n = 0; write_head(); // clear the log} Path name 命名空间我们知道，inode代表文件，但是为了便于使用，我们还管理一个命令空间。命名空间是以”/“为起点的树，每个目录下有”.”代表自身，有”..”代表上一级目录。怎么实现呢？ 一般来说，根目录是固定在磁盘上某个块上的，比如1号块。遍历路径逻辑就是从根目录开始读取目录条目，然后逐个查找。 12if(*path == '/') ip = iget(ROOTDEV, ROOTINO); xv6没有对目录查找进行优化，只是简单的线性查找。 1234567891011121314151617181920212223242526272829303132static struct inode* namex(char *path, int nameiparent, char *name){ struct inode *ip, *next; if(*path == '/') ip = iget(ROOTDEV, ROOTINO); else ip = idup(myproc()-&gt;cwd); while((path = skipelem(path, name)) != 0){// skiplem相当于将path分为两部分，name是前一个部分，path是后一部分 ilock(ip); if(ip-&gt;type != T_DIR){ iunlockput(ip); return 0; } if(nameiparent &amp;&amp; *path == '\\0'){ // Stop one level early. iunlock(ip); return ip; } if((next = dirlookup(ip, name, 0)) == 0){ iunlockput(ip); return 0; } iunlockput(ip); // avoid 死锁 ip = next; // 通过name目录找到当前的path } if(nameiparent){ iput(ip); return 0; } return ip;} File descriptor layerUnix 界面的一个很酷的方面是 Unix 中的大多数资源都表示为文件，包括控制台、管道等设备，当然还有真实文件。文件描述符层是实现这种通用性的层。 具体来说，就是用一个file结构体来包裹文件、管道、设备。 12345678910struct file { //万物皆文件，就是这里了 enum { FD_NONE, FD_PIPE, FD_INODE, FD_DEVICE } type; int ref; // reference count char readable; char writable; struct pipe *pipe; // FD_PIPE struct inode *ip; // FD_INODE and FD_DEVICE uint off; // FD_INODE, io offset short major; // FD_DEVICE}; 进程有一个打开文件的数组，数组下标就是文件描述符。 12345struct proc { ... struct file *ofile[NOFILE]; // Open files ...}; 当我们使用文件描述符进行读写时，实际上是通过文件描述符作为索引得到file结构体，再通过file结构体进行相应type的读写。 ftable12345678// file.cstruct file* filealloc(void);void fileclose(struct file*);struct file* filedup(struct file*);void fileinit(void);int fileread(struct file*, uint64, int n);int filestat(struct file*, uint64 addr);int filewrite(struct file*, uint64, int n); xv6对于file结构体的使用，也采用了一个池化的思想。 1234struct { struct spinlock lock; struct file file[NFILE];} ftable; 123456789101112131415// Allocate a file structure.struct file* filealloc(void){ struct file *f; acquire(&amp;ftable.lock); for(f = ftable.file; f &lt; ftable.file + NFILE; f++){ if(f-&gt;ref == 0){ f-&gt;ref = 1; release(&amp;ftable.lock); return f; } } release(&amp;ftable.lock); return 0;} 让我们看看打开文件的过程：open系统调用，如果传入的是 O_CREATE 标志，说明要新创建文件。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465uint64 sys_open(void){ char path[MAXPATH]; int fd, omode; struct file *f; struct inode *ip; int n; if((n = argstr(0, path, MAXPATH)) &lt; 0 || argint(1, &amp;omode) &lt; 0) return -1; begin_op(); if(omode &amp; O_CREATE){ ip = create(path, T_FILE, 0, 0); if(ip == 0){ end_op(); return -1; } } else { //否则就通过name打开相应的inode if((ip = namei(path)) == 0){ end_op(); return -1; } ilock(ip); if(ip-&gt;type == T_DIR &amp;&amp; omode != O_RDONLY){ iunlockput(ip); end_op(); return -1; } } if(ip-&gt;type == T_DEVICE &amp;&amp; (ip-&gt;major &lt; 0 || ip-&gt;major &gt;= NDEV)){ iunlockput(ip); end_op(); return -1; } if((f = filealloc()) == 0 || (fd = fdalloc(f)) &lt; 0){ if(f) // 这里可能分配的file结构体，所以还需要释放它 fileclose(f); iunlockput(ip); end_op(); return -1; } if(ip-&gt;type == T_DEVICE){ f-&gt;type = FD_DEVICE; f-&gt;major = ip-&gt;major; } else { f-&gt;type = FD_INODE; f-&gt;off = 0; } f-&gt;ip = ip; f-&gt;readable = !(omode &amp; O_WRONLY); f-&gt;writable = (omode &amp; O_WRONLY) || (omode &amp; O_RDWR); if((omode &amp; O_TRUNC) &amp;&amp; ip-&gt;type == T_FILE){ itrunc(ip); } iunlock(ip); end_op(); return fd;} 再看看create函数，其实就是找到父级目录，然后分配inode结构体，增加目录项。 1234567891011121314151617181920212223242526272829303132333435363738394041424344//creates a new name for a new inodestatic struct inode*create(char *path, short type, short major, short minor){ struct inode *ip, *dp; char name[DIRSIZ]; // find path‘s parent，return inode if((dp = nameiparent(path, name)) == 0) return 0; ilock(dp); // look in directory first，file类型在dp中找到name是合理的 if((ip = dirlookup(dp, name, 0)) != 0){ // Look for a directory entry in a directory. iunlockput(dp); ilock(ip); if(type == T_FILE &amp;&amp; (ip-&gt;type == T_FILE || ip-&gt;type == T_DEVICE)) return ip; iunlockput(ip); return 0; } // then create it if((ip = ialloc(dp-&gt;dev, type)) == 0) panic(&quot;create: ialloc&quot;); ilock(ip); ip-&gt;major = major; ip-&gt;minor = minor; ip-&gt;nlink = 1; iupdate(ip); if(type == T_DIR){ // Create . and .. entries. dp-&gt;nlink++; // for &quot;..&quot; iupdate(dp); // No ip-&gt;nlink++ for &quot;.&quot;: avoid cyclic ref count. if(dirlink(ip, &quot;.&quot;, ip-&gt;inum) &lt; 0 || dirlink(ip, &quot;..&quot;, dp-&gt;inum) &lt; 0) panic(&quot;create dots&quot;); } if(dirlink(dp, name, ip-&gt;inum) &lt; 0) panic(&quot;create: dirlink&quot;); iunlockput(dp); return ip;} 再回到sys_open，这里才是分配fd的地方：先分配file结构体，然后分配fd文件描述符。 1if((f = filealloc()) == 0 || (fd = fdalloc(f)) &lt; 0){ 分配文件描述符的过程就是遍历文件的openfiletable，找到未使用的下标。这样我们就能理解一个进程打开的文件描述符是有限的这句话。 1234567891011121314// Allocate a file descriptor for the given file.// Takes over file reference from caller on success.static int fdalloc(struct file *f){ int fd; struct proc *p = myproc(); // 遍历进程的open file table，find an unused slot for(fd = 0; fd &lt; NOFILE; fd++){ if(p-&gt;ofile[fd] == 0){ p-&gt;ofile[fd] = f; return fd; } } return -1;} 总结通过这一章的学习，xv6的架构基本已经完成。我们学习了文件块在磁盘上的组织，读取磁盘块时的LRU缓存，为文件系统操作系统持久化的日志块，为用户提供友好的命名空间以及文件描述符，这都是unix很精髓的一部分。 文件系统的学习，主要有以下几个思想吧： 文件系统的设计（磁盘块具体存储分布、Inode文件、file统一文件） 缓存池化思想（bcache、itable、ftable） 日志持久化思想（transaction） 当然，文件系统还需应对并发处理，这里讲得内容很少。其中一个点是磁盘读取时用了sleeplock而不是spinlock，这是因为磁盘读取通常是一个持续时间较长的操作。更多关于加锁控制，比如ilock加锁，namex不加锁等等有具体的原因，这点也需要继续深入。 同时xv6的很多实现都可以继续优化，比如目录项查找以及日志性能等。这些下一章会讲。 推荐阅读：https://www.cnblogs.com/KatyuMarisaBlog/p/14385792.html","link":"/2024/01/18/MIT6.S081/book/chapter8/"},{"title":"MIT6.S081 lab1 utilities","text":"实验一的目的是熟悉系统调用以及有限的C标准库使用，借此实现一些经典的unix命令。 在其中碰到了一些bug，大多与字符串解析有关。只记录了几个有意思点的实验。 搭建环境 : docker+目录映射 pingpong用一个管道就能完成父子进程通信，子进程fork也会复制打开的文件描述符，我看网上好多实现都是双管道。 123456789101112131415161718192021222324252627282930#include &quot;kernel/types.h&quot;#include &quot;kernel/stat.h&quot;#include &quot;user/user.h&quot;int main(int argc, char *argv[]){ int p[2]; char buf[128]; // buffer for parent &amp;&amp; child process if(pipe(p)&lt;0){ fprintf(2, &quot;Please enter a number!\\n&quot;); } if(fork()==0){ // child process read(p[0], buf, 1); // read one byte from read end of pipe printf(&quot;%d: received ping\\n&quot;, getpid()); char send = 'a'; write(p[1], &amp;send, 1); close(p[0]); close(p[1]); exit(0); } write(p[1], &quot;x&quot;, 1); // send one byte to write end of pipe wait(0); read(p[0], buf, 1); printf(&quot;%d: received pong\\n&quot;, getpid()); close(p[1]); close(p[0]); exit(0);} Primes素数筛思想 首先看图，一个直观的感受就是数字像水一样从左到右流过，中间有一道道关卡，这些关卡会拦截数字，被拦截的数字将不能继续往右走。在这里，一道关卡就是一个进程，它接受来自左边进程的输出，然后它自己再输出给右边的进程。注意到每个进程都只输出一个质数到标准输出。 123456p = get a number from left neighborprint ploop: n = get a number from left neighbor if (p does not divide n) send n to right neighbor 更正式地描述：每个进程都从左边得到一个数。进程将得到的第一个数（记作A）输出，然后持续从左边拿到一个数（记作Ak）进行判断。如果Ak被A整除了，那么Ak不是质数，丢弃。否则将Ak传递给下一个进程。第一个进程的输出是所有数字（2～N，N取决于你想要的素质范围）。 实现利用管道作为父子进程的通信，worker函数抽象一个进程的执行流。 在这个实验中，需要额外注意文件描述符的关闭，否则就会因为系统资源不够而无法新开管道。 1234567891011121314151617181920212223242526272829303132333435363738394041424344#include &quot;kernel/types.h&quot;#include &quot;kernel/stat.h&quot;#include &quot;user/user.h&quot;void worker(int* p){ close(p[1]); // 关闭写端 int first_num; // step1 先从父进程读取一个数 if(read(p[0], &amp;first_num, sizeof(int))==0){ //如果读不到上一个输入，退出 close(p[0]); exit(0); } printf(&quot;prime %d\\n&quot;, first_num); int next_p[2]; if(pipe(next_p)&lt;0) {fprintf(2, &quot;create pipe error!\\n&quot;); exit(-1);} // step2 创建子进程 if(fork()==0) worker(next_p); // step3 持续从父进程读取数字，判断是否被整除 close(next_p[0]); int next_num; while(read(p[0], &amp;next_num, sizeof(int)) != 0){ if(next_num % first_num == 0) continue; write(next_p[1], &amp;next_num, sizeof(int)); // 否则传递给下一个进程 } close(p[0]); //关闭读端 close(next_p[1]); wait(0); exit(0);}int main(int argc, char *argv[]){ // 开辟管道 int p[2]; if(pipe(p)&lt;0) fprintf(2, &quot;create pipe error!\\n&quot;); // 创建子进程干活，其中worker函数调用了exit，从而避免了后续代码执行 if(fork()==0){ worker(p); } // 父进程干活了 for(int i=2; i&lt;=35; ++i){ if(write(p[1], &amp;i, 4)!=4) fprintf(2, &quot;write pipe error!\\n&quot;); } close(p[0]); close(p[1]); wait(0); exit(0);} find这个实验主要目的是熟悉目录项的数据结构，它是一个包含了目录条目的数组，可以看作树的结构。深度优先搜索。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374#include &quot;kernel/types.h&quot;#include &quot;kernel/stat.h&quot;#include &quot;user/user.h&quot;#include &quot;kernel/fs.h&quot;char* fmtname(char * path){ static char buf[DIRSIZ+1]; char *p; for (p = path + strlen(path); p &gt;= path &amp;&amp; *p != '/'; p--); p ++; if (strlen(p) &gt;= DIRSIZ) return p; memmove(buf, p, strlen(p)); buf[strlen(p)] = 0; return buf;}void find(char *root_path, char *file_name){ int fd; char buf[512], *p; struct dirent de; struct stat st; if((fd = open(root_path, 0)) &lt; 0){ fprintf(2, &quot;ls: cannot open %s\\n&quot;, root_path); return; } if(fstat(fd, &amp;st) &lt; 0){ fprintf(2, &quot;ls: cannot stat %s\\n&quot;, root_path); close(fd); return; } // ----file if(st.type==T_FILE) { if(strcmp(file_name, fmtname(root_path))==0) printf(&quot;%s\\n&quot;, root_path); close(fd); return; } // ----directory if(strlen(root_path) + 1 + DIRSIZ + 1 &gt; sizeof buf){ // kernel/fs.h #define DIRSIZ 14 printf(&quot;ls: path too long\\n&quot;); } strcpy(buf, root_path); p = buf+strlen(buf); *p++ = '/'; //此时p已经指向/的后一个 while(read(fd, &amp;de, sizeof(de)) == sizeof(de)){ if(de.inum == 0 || !strcmp(de.name, &quot;.&quot;) || !strcmp(de.name, &quot;..&quot;)) // 去除空目录以及. .. continue; memmove(p, de.name, DIRSIZ); //从p开始14位复制文件名 p[DIRSIZ] = 0; //作结尾 if(stat(buf, &amp;st) &lt; 0){ printf(&quot;ls: cannot stat %s\\n&quot;, buf); continue; }// printf(&quot;read buf:%s\\n&quot;, buf); if(st.type==T_FILE) { if(strcmp(file_name, de.name)==0) printf(&quot;%s\\n&quot;, buf); }else if (st.type == T_DIR){ find(buf, file_name); } } close(fd); return;}intmain(int argc, char *argv[]){ if(argc &lt; 2){ fprintf(2, &quot;argc &lt; 2!&quot;); exit(0); } find(argv[1], argv[2]); exit(0);} xargs解读不熟悉xargs命令可能会有点懵，它其实是读取标准输出中的字符，然后把它当作命令行的额外参数。 1echo hello too | xargs echo bye 它会输出 1bye hello too 相当于执行了命令 1echo bye hello too 这个实验要注意的一点就是输入数据可能有多行，需要一行一行的解析参数，然后这些参数都要复制执行一遍。有n行就要执行n个命令。 实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#include &quot;kernel/types.h&quot;#include &quot;kernel/stat.h&quot;#include &quot;kernel/param.h&quot;#include &quot;user/user.h&quot;void copy(char **p1, char *p2){ *p1 = malloc(strlen(p2) + 1); strcpy(*p1, p2);}int read_parse_one_line(char** argv, int argc){ // read one line int i=0; char buffer[1024]; char* buf = buffer; while(read(0, buf+i, 1)){ if(buf[i]=='\\n') break; ++i; } if(i==0) return -1; // no more input buf[i] = ' ';// replace '\\n' with ' ' // parse one line char* delim;// buf[strlen(buf)-1] = ' '; // replace '\\n' with ' ' while(*buf &amp;&amp; (*buf==' ')) buf++; //ignore the leading space while((delim = strchr(buf, ' '))) { *delim = 0; copy(&amp;argv[argc], buf); buf = delim+1; argc = argc+1; while(*buf &amp;&amp; (*buf==' ')) buf++; //ignore the leading space } argv[argc] = 0; // debug// for(int j=0; j&lt;argc; ++j){// printf(&quot;%s &quot;, argv[j]);// }// printf(&quot;|\\n&quot;); return argc;}int main(int argc, char *argv[]){ // “echo hello too｜xargs echo bye” output：bye hello too if (argc &lt; 2){ printf(&quot;Please enter more parameters!\\n&quot;); exit(1); } char *pars[MAXARG]; // copy “xargs echo bye” to “echo bye” for (int i = 1; i &lt; argc; i++){ copy(&amp;pars[i - 1], argv[i]); } // copy extra parameters while(read_parse_one_line(pars, argc-1)!=-1){ if (fork() == 0){ exec(pars[0], pars); exit(1); }else{ wait(0); } } exit(0);} 踩坑这里的parseline其实是修改了csapp的图8-25解析shell的一个输入行的代码。 但是有一点不同是csapp通过fgets函数读取一行的输入，fgets读取的输入将包括换行符。而strlen函数计算字符串长度时，也会将换行符计算在内，所以这里的buf[strlen(buf)-1] = ' ';取代换行符的操作就出错了。 总结难点实验一的难点在于熟悉系统调用以及C系统库。熟悉系统调用其实就是熟悉进程、管道、文件描述符这些核心概念。 12345678910int fork(void);int exit(int) __attribute__((noreturn));int wait(int*);int pipe(int*);int write(int, const void*, int);int read(int, void*, int);int close(int);int exec(char*, char**);int open(const char*, int);int sleep(int); 系统调用的实现可能会有点困难，此时只需要理解如何使用，下一章会详细其实现。 123456789101112131415int atoi(const char*);uint strlen(const char*);char* strcpy(char*, const char*);char* strchr(const char*, char c);int strcmp(const char*, const char*);char* gets(char*, int max);void printf(const char*, ...);void fprintf(int, const char*, ...);void* memset(void*, int, uint);void* memmove(void*, const void*, int);void* memcpy(void *, const void *, uint);int memcmp(const void *, const void *, uint); C标准库的实现有必要好好读一读。 关于C阻碍可读性的一个很大关键问题就是C的指针以及类型不安全特性。 （1）类型不安全 类型不安全一个经典的场景在于if的判断条件，可以把整数转换为布尔值，只有0是失败，其他都是成功。 （2）指针 1234*p++char* arr[] // 指针的数组void (*fun)(void) // 函数指针void (*fun[])(void) // 函数指针的数组 *和++一起用就很有迷惑性，到底是哪个先作用？答案是++。 1*p++ = *(p++) 利用指针操作字符串也需要谨慎操作。","link":"/2023/12/29/MIT6.S081/lab/lab1/"},{"title":"MIT6.S081 lab10 file system","text":"文件系统的试验比较简单，第一个实验是扩展文件大小，第二个实验则是实现软链接。 Large File 原本的文件只有一级索引块，现在要改造成二级索引块，大小变成 11 + 256 + 256*256. 12345#define NDIRECT 11#define NINDIRECT (BSIZE / sizeof(uint))#define NSINDIRECT (BSIZE / sizeof(uint))*(BSIZE / sizeof(uint))#define MAXFILE (NDIRECT + NINDIRECT + NSINDIRECT) 修改宏定义，然后多级读即可 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100static uint bmap(struct inode *ip, uint bn){ uint addr, *a; struct buf *bp; if(bn &lt; NDIRECT){ if((addr = ip-&gt;addrs[bn]) == 0) ip-&gt;addrs[bn] = addr = balloc(ip-&gt;dev); return addr; } bn -= NDIRECT; if(bn &lt; NINDIRECT){ // Load indirect block, allocating if necessary. if((addr = ip-&gt;addrs[NDIRECT]) == 0) ip-&gt;addrs[NDIRECT] = addr = balloc(ip-&gt;dev); bp = bread(ip-&gt;dev, addr); a = (uint*)bp-&gt;data; if((addr = a[bn]) == 0){ a[bn] = addr = balloc(ip-&gt;dev); log_write(bp); } brelse(bp); return addr; } bn -= NINDIRECT; if(bn &lt; NSINDIRECT){ int first_index = bn / 256; int second_index = bn % 256; if((addr = ip-&gt;addrs[1+NDIRECT]) == 0) ip-&gt;addrs[1+NDIRECT] = addr = balloc(ip-&gt;dev); // first index bp = bread(ip-&gt;dev, addr); a = (uint*)bp-&gt;data; if((addr = a[first_index])==0){ a[first_index] = addr = balloc(ip-&gt;dev); log_write(bp); } brelse(bp); // second index bp = bread(ip-&gt;dev, addr); a = (uint*)bp-&gt;data; if((addr = a[second_index])==0){ a[second_index] = addr = balloc(ip-&gt;dev); log_write(bp); } brelse(bp); return addr; } panic(&quot;bmap: out of range&quot;);}void itrunc(struct inode *ip){ int i, j, k; struct buf *bp, *cp; uint *a, *b; for(i = 0; i &lt; NDIRECT; i++){ if(ip-&gt;addrs[i]){ bfree(ip-&gt;dev, ip-&gt;addrs[i]); ip-&gt;addrs[i] = 0; } } if(ip-&gt;addrs[NDIRECT]){ bp = bread(ip-&gt;dev, ip-&gt;addrs[NDIRECT]); a = (uint*)bp-&gt;data; for(j = 0; j &lt; NINDIRECT; j++){ if(a[j]) bfree(ip-&gt;dev, a[j]); } brelse(bp); bfree(ip-&gt;dev, ip-&gt;addrs[NDIRECT]); ip-&gt;addrs[NDIRECT] = 0; } if(ip-&gt;addrs[1+NDIRECT]){ bp = bread(ip-&gt;dev, ip-&gt;addrs[1+NDIRECT]); a = (uint*)bp-&gt;data; for(j=0; j&lt; 256; ++j){ cp = bread(ip-&gt;dev, a[j]); b = (uint*)cp-&gt;data; for(k=0; k&lt;256; ++k){ if(b[k]) bfree(ip-&gt;dev, b[k]); } brelse(cp); bfree(ip-&gt;dev,a[j]); a[j] = 0; } brelse(bp); bfree(ip-&gt;dev, ip-&gt;addrs[1+NDIRECT]); ip-&gt;addrs[NDIRECT] = 0; } ip-&gt;size = 0; iupdate(ip);} Symbolic links区别软链接与硬链接： 软链接：它是一个t特殊的文件，文件的内容是一个路径，这个路径指向被链接的文件 硬链接：它是一个目录项，这个目录项指向了目标文件 1234struct dirent { ushort inum; char name[DIRSIZ]; // #define DIRSIZ 14}; name是目录项的名字，inum则是它指向的inode块号，那么就是通过inum指向目标文件。 open调用123456789101112131415161718192021222324252627282930313233343536373839404142uint64 sys_open(void) { ... if (omode &amp; O_CREATE) { ip = create(path, T_FILE, 0, 0); if (ip == 0) { end_op(); return -1; } } else { if ((ip = namei(path)) == 0) { end_op(); return -1; } ilock(ip); if (ip-&gt;type == T_DIR &amp;&amp; omode != O_RDONLY) { iunlockput(ip); end_op(); return -1; } // 至多10次递归查找 int count = 0; while (ip-&gt;type == T_SYMLINK &amp;&amp; omode != O_NOFOLLOW) { if(count &gt; 10 ){ iunlockput(ip); end_op(); return -1; } if (readi(ip, 0, (uint64)path, 0, MAXPATH)==-1) { iunlockput(ip); end_op(); return -1; } iunlockput(ip); if ((ip = namei(path)) == 0) { end_op(); return -1; } ilock(ip); count++; } ... } 对于软链接还需要recursively查找，限制递归深度来模拟递归。 symbolic调用1234567891011121314151617181920uint64 sys_symlink(void) { char target[MAXPATH], path[MAXPATH]; if (argstr(0, target, MAXPATH) &lt; 0 || argstr(1, path, MAXPATH) &lt; 0) return -1; struct inode* ip; begin_op(); if((ip=create(path, T_SYMLINK, 0, 0)) == 0){ end_op(); return -1; } if(writei(ip, 0, (uint64)target, 0, strlen(target)) == -1){ iunlockput(ip); end_op(); return -1; } iunlockput(ip); end_op(); return 0;} 实现symblic，先创建inode，然后再将链接路径名写进去。","link":"/2024/02/06/MIT6.S081/lab/lab10/"},{"title":"MIT6.S081 lab2 system calls","text":"lab2是实现几个系统调用，但此时阅读的资料其实有限，我觉得还是读到手册的第四章会比较好。 System call tracing这个命令是追踪系统调用的过程。怎么追踪呢？其实这里就要求熟悉xv6发起一个系统调用的过程，仅仅阅读第二章还不能清楚地明白从用户态发起系统调用到内核态的整个过程，但就完成实验来说，靠一些猜测已经足够。 123456789print &quot;#include \\&quot;kernel/syscall.h\\&quot;\\n&quot;;sub entry { my $name = shift; print &quot;.global $name\\n&quot;; print &quot;${name}:\\n&quot;; print &quot; li a7, SYS_${name}\\n&quot;; print &quot; ecall\\n&quot;; print &quot; ret\\n&quot;;} 通过这段代码我们能够知道是：系统调用的号码预先定义在 kernel/syscall.h中，a7寄存器存储了系统调用的号码，通过ecall进入到内核态。 1234567891011121314151617181920static uint64 (*syscalls[])(void) = {[SYS_fork] sys_fork,[SYS_exit] sys_exit, ...}voidsyscall(void){ int num; struct proc *p = myproc(); num = p-&gt;trapframe-&gt;a7; if(num &gt; 0 &amp;&amp; num &lt; NELEM(syscalls) &amp;&amp; syscalls[num]) { p-&gt;trapframe-&gt;a0 = syscalls[num](); } else { printf(&quot;%d %s: unknown sys call %d\\n&quot;, p-&gt;pid, p-&gt;name, num); p-&gt;trapframe-&gt;a0 = -1; }} 然后经过一些中断调用，我们来到了syscall.c，这里可以得知：通过这个号码查表得知是哪个系统调用，并将返回值存储在 p-&gt;trapframe-&gt;a0。 System call implementations in the kernel need to find the arguments passed by user code. Because user code calls system call wrapper functions, the arguments are initially where the RISC-V C calling convention places them: in registers. 系统调用的参数存储在a0～a6寄存器上。 到这里，我们就能完成实验了。思路：从寄存器中取出用户态出入的掩码参数，然后保存位掩码到当前进程，以后每一个系统调用返回时，都要比较一次掩码来决定是否打印信息。 那为什么执行一个trae设置掩码后，再执行新的系统调用命令后就不会打印信息了呢，掩码又没被清零。是的，确实没有做掩码清零的操作。但shell执行进程的方式是fork+exec，这意味着每执行一个新的命令都会新开一个进程，命令结束后，这个进程也结束了。 Sysinfo这个实验说实话是有点坑的，因为此时你还不熟悉虚拟内存、进程调度。最大的作用我想就是熟悉copyout函数，从内核拷贝内容到用户。 （1）在/kernel/proc.c文件中 一开始就定义了一个数组 1struct proc proc[NPROC]; 这个数组就保存着所有的进程，所以只要遍历这个数组判断状态就好了， （2）在/kernel/kalloc.c文件中 定义了一个链表，每个链表都指向上一个可用空间，这个kmem就是一个保存最后链表的变量。 1234567struct run { struct run *next;};struct { struct spinlock lock; struct run *freelist;} kmem; 遇到的错误1panic: acquire 原因： 1printf(&quot;%s: syscall %s -&gt; %d&quot;, p-&gt;pid, syscall_names[num], p-&gt;trapframe-&gt;a0); 在打印进程pid时，格式占位符写成了%s，使得输出以上错误。 详细原因，需要了解设备输出才能排查。","link":"/2024/01/05/MIT6.S081/lab/lab2/"},{"title":"MIT6.S081 lab3 page tables","text":"lab3主要是帮助复习页表、PTE、物理页之间的关系。 Speed up system callsWhen each process is created, map one read-only page at USYSCALL (a VA defined in memlayout.h). At the start of this page, store a struct usyscall (also defined in memlayout.h), and initialize it to store the PID of the current process. 实验指导已经很直白了，在进程创建时映射一块共享页，用来存储进程id。过程：从freelist分配一页空间，然后映射到用户进程指定地址，然后初始化这个页（存入当前进程的pid）。 Print a page table实际上就是熟悉三级页表的过程。 123456789101112131415161718192021222324252627void recursive_vmprint(pagetable_t pagetable, int level){ if(level&gt;=3) return; char* prefix = &quot;x&quot;; switch (level) { case 0: prefix = &quot;..&quot;; break; case 1: prefix = &quot;.. ..&quot;; break; case 2: prefix = &quot;.. .. ..&quot;; } for(int i=0; i&lt;512; ++i){ pte_t pte =pagetable[i]; if(pte &amp; PTE_V){ uint64 child = PTE2PA(pte); printf(&quot;%s%d: pte %p pa %p\\n&quot;, prefix, i, pte, child); recursive_vmprint((pagetable_t) child, level+1); } }}void vmprint(pagetable_t pagetable){ // 深度优先遍历，打印页表 printf(&quot;page table %p\\n&quot;, pagetable); recursive_vmprint(pagetable, 0);} 从PTE到PA的过程 uint64 child = PTE2PA(pte);，然后将它用作页表入口地址(pagetable_t) child。 12typedef uint64 pte_t;typedef uint64* pagetable_t; xv6中的指针就是64位无符号整数。 Detecting which pages have been accessed 阅读手册可以知道PTE的第6位是访问标志位，通过观察这个标志就可以知道这个页面是否被访问。 硬件在执行访存指令后就会自动把相应页的PTE_A置为1. 注意：Be sure to clear PTE_A after checking if it is set. Otherwise, it won’t be possible to determine if the page was accessed since the last time pgaccess() was called (i.e., the bit will be set forever). 1234567891011121314151617181920212223int pgaccess(pagetable_t pagetable, uint64 addr, int n, uint64 uaddr) { if (n &gt; 64) { panic(&quot;too much page to check\\n&quot;); return -1; } uint64 bitmask = 0; int cur_bitmask = 1; uint64 va = addr; pte_t *pte;//由于修改bit位，必须采用指针方式 for (int i = 0; i &lt; n; ++i) { if ((pte = walk(pagetable, va, 0)) == 0) { panic(&quot;pte should exits\\n&quot;); return -1; } if (*pte &amp; PTE_A) { bitmask |= (cur_bitmask &lt;&lt; i); *pte &amp;= ~PTE_A; } va += PGSIZE; } copyout(pagetable, uaddr, (char *) &amp;bitmask, sizeof(bitmask)); return 0;}","link":"/2024/01/06/MIT6.S081/lab/lab3/"},{"title":"MIT6.S081 lab4 traps","text":"lab4其实是lec05的内容加上第四章中断相关内容。 Risc-V assembly这一节需要明白： 系统调用的参数放在a0～a7寄存器中 函数嵌套调用由栈实现 必要的几个寄存器：ra、sp、pc、a0～a7 Caller Saved register和Callee Saved register Caller register就是函数调用方无论如何都会使用的寄存器，比如ra寄存器要保存函数返回的地址，无论在哪个函数调用中都会使用，因为需要函数调用方自己保存。考虑函数A调用函数B：进入A中后，ra中保存了A的返回地址，但在A中使用jal B后，ra中的值就变成了从B返回A的地址，那这样A就永远无法正确返回了。因此，ra是属于“在A调用B之前必须保存”的寄存器。 反之，Callee register就是调用方无需担心的寄存器。比如sp栈指针，在调用函数的过程它会被用到，自动压栈，然后函数返回又自动出栈。sp栈指针无需调用方保存，函数返回时会自动恢复。 为什么要区别Caller 和 Callee 保存？我直接保存所有寄存器不就行了么？ 是的，保存所有寄存器是可以的，但是这样太浪费空间了。 再这么理解Caller Saved Register是会被 Callee 使用的寄存器，比如前述的ra寄存器，如果Caller不保存，ra的值就会丢失。 Callee Saved Register就是会被Caller使用的寄存器，Caller不用担心这部分寄存器，因为在调用的过程它们会自己保存恢复，比如sp寄存器。 register 是大家共享的; caller save 意思其实是这片寄存器不建议 caller 使用，一旦 caller 使用了就记得保存在 stack 上，用完再复原;同理 callee save; 理论上所有的寄存器都 caller save 也是可以愉快地运行，但是这样做的话 stack 使用会很频繁，memory 的代价是比寄存器高很多的，所以得不偿失。 理想的情况是 caller 和 callee 都不用 save，用的时候不用操心。这样的话就需要划分一块区域给 caller，向 caller 保证这些是 callee save 的，您尽管放心存这里。另外一块区域自然对称地给 callee，向 callee 保证这些是 caller save 的。 这样就可以增加两边都不用操心 save-restore 的概率，因为 caller 和 callee 都有一块放心的自留地。 学生提问，为什在最开始要对sp寄存器减16？ TA：是为了Stack Frame创建空间。减16相当于内存地址向前移16，这样对于我们自己的Stack Frame就有了空间，我们可以在那个空间存数据。我们并不想覆盖原来在Stack Pointer位置的数据。 学生提问：为什么不减4呢？ TA：我认为我们不需要减16那么多，但是4个也太少了，你至少需要减8，因为接下来要存的ra寄存器是64bit（8字节）。这里的习惯是用16字节，因为我们要存Return address和指向上一个Stack Frame的地址，只不过我们这里没有存指向上一个Stack Frame的地址。如果你看kernel.asm，你可以发现16个字节通常就是编译器的给的值。 struct的内存布局：你可以认为struct像是一个数组，但是里面的不同字段的类型可以不一样。 Backtrace看明白栈帧的内容，以及以下： fp（frame pointer）指向当前栈帧的指针 sp（stack pointer）指向bottom of stack 实验指导给出了一张栈布局的图片。可以看到栈由一个个栈帧组成，sp指向栈的底部，fp指向当前栈帧的顶部。 一个栈帧从上到下包括： 返回地址（fp-8） 前一个栈帧地址（fp-16） 保存的若干寄存器 局部变量 而S0寄存器保存了fp，因此就能通过fp遍历栈了。 12345678910void backtrace(void){ printf(&quot;backtrace\\n&quot;); uint64 fp = r_fp(); uint64 top = PGROUNDUP(fp); uint64 down = PGROUNDDOWN(fp); while(down&lt;fp &amp;&amp; fp&lt;top){ printf(&quot;%p\\n&quot;, fp); fp = *((uint64*)(fp-16)); }} Alarm这节就是实现一个系统调用，通过调用sigalarm能够触发固定n个ticks调用handler。 怎么实现呢？ 其中一个要点就是理解时钟中断。xv6实现了时间片轮转调度的进程切换算法，依靠的就是trap.c中对于which_dev == 2类型的中断处理。 12345678910void usertrap(void) { ... else if((which_dev = devintr()) != 0){ // ok } ... if(which_dev == 2){ yield(); }} devintr() check if it’s an external interrupt or software interrupt, and handle it. returns 2 if timer interrupt, 1 if other device, 0 if not recognized. yield() 则是让出时间片，将cpu控制权交到调度器手中，然后调度器选择一个可运行的线程进行运行。 test0 invoker handlertest0指导我们完成sigalarm系统调用的stub，但这还不够。我们在进程中需要维护 一个变量bool turn_on来表示是否开启了sigalarm 一个变量int interval来记录sigalarm中的间隔interval 一个变量int ticks表示累积的tick 一个函数地址uint64 handler来存handler 那么实现sigalarm的逻辑就很清晰了： 调用sigalarm就是开启turn_on，然后记录间隔到interval，实际上可以用interval==-1来表示alarm是否开启； 每次时钟中断if(which_dev == 2) , 检查interval，然后累积tick。再判断tick是否达到interval，如果达到，我们需要执行回调函数。 然而其中还有一些细节： 怎么去执行回调函数？怎么在用户态执行函数？ 回调函数执行完，我们还需要返回被中断的代码，这个又怎么实现？ 回调函数执行中也会触发时钟中断，怎么保证我N个tick执行一次回调函数？ 指导中也提示了，当前我们处于内核中断处理程序中，回忆我们是怎么从中断返回的，没错就是设置sepc寄存器。在进程的trapframe的epc中保存了中断时的pc，我们依靠恢复pc来达到返回中断时的代码。 12345void usertrapret(void){ ... // set S Exception Program Counter to the saved user pc. w_sepc(p-&gt;trapframe-&gt;epc);} 那么第一个问题就很好解决了，直接将回调函数的地址填到进程trapframe的epc中。副作用是原先epc的值被覆盖，我们再也找不到这个值了。 test1/test2 resume interrupted code在执行完回调函数数后，我们的代码并不能正确返回用户被中断的函数处，因为原先epc的值被覆盖了:-) 一个直观的想法我在进程的结构体中再开辟一个变量pre_epc保存epc的值。那要怎么将这个变量被重新加载到epc？ 在实验指导中给出这样一个设计：在回调函数的返回前，必须调用sigreturn。这就给我们设置返回地址有了可乘之机，sigreturn就是用来设置返回地址。 实现12345678910if(which_dev == 2){ if(p-&gt;interval != 0){ if(p-&gt;ticks==p-&gt;interval){ *p-&gt;ptrapframe = *p-&gt;trapframe; p-&gt;trapframe-&gt;epc = p-&gt;handler; } p-&gt;ticks++; } yield();} 12345678910111213141516171819uint64 sys_sigalarm(void){ int interval; uint64 handler; struct proc * p; if(argint(0, &amp;interval) &lt; 0 || argaddr(1, &amp;handler) &lt; 0 || interval &lt; 0) { return -1; } p = myproc(); p-&gt;interval = interval; p-&gt;handler = handler; p-&gt;ticks = 0; return 0;}uint64 sys_sigreturn(void){ struct proc * p = myproc(); *p-&gt;trapframe = *p-&gt;ptrapframe; p-&gt;ticks = 0;// re alarm return 0;} 最后保证N个tick执行一次回调函数，则是一个实现上的trick：尽管回调函数还是会被时钟中断，在中断中我们会增加tick，但是ticks==interval的时机只有一个。 这个解答了我在学习操作系统之前的困惑：回调函数也会占用cpu时间片执行，那么说好的N个时间片间隔执行一次回调函数是不准确的。只能说是N个时间片+执行回调函数花费的时间才是每个回调函数之间的时间间隔。 踩坑关于“二次指针”：保存和恢复trapframe。 1234567uint64 sys_sigreturn(void){ struct proc * p = myproc(); //p-&gt;trapframe = p-&gt;ptrapframe; *p-&gt;trapframe = *p-&gt;ptrapframe; p-&gt;ticks = 0;// re alarm return 0;} p是个指针变量，trapframe也是个指针变量。假如我不解引用，我保存的其实是个地址。当我对这个地址上的值作改变，我第二个指针指向相同的地址，这个地址值其实就是同一份，也改变了。说白了， 就是浅拷贝和深拷贝的区别，这里表现得更加隐晦。","link":"/2024/01/06/MIT6.S081/lab/lab4/"},{"title":"MIT6.S081 lab5 lazy allocation","text":"lab5是关于懒分配的实验。前言讲得很好，One of the many neat tricks an O/S can play with page table hardware is lazy allocation of user-space heap memory. LA是用户堆空间上的Trick。 Xv6 applications ask the kernel for heap memory using the sbrk() system call. 利用sbrk系统调用来增长或减少堆空间。 LA的原因，程序角度： some programs allocate more memory than they actually use some programs allocate memory well in advance of use 内核角度： It can take a long time for a kernel to allocate and map memory for a large request 因此更好的做法是 That is, sbrk() doesn’t allocate physical memory, but just remembers which user addresses are allocated and marks those addresses as invalid in the user page table. When the process first tries to use any given page of lazily-allocated memory, the CPU generates a page fault, which the kernel handles by allocating physical memory, zeroing it, and mapping it Eliminate allocation from sbrk()第一步，取消sbrk的空间分配，只记录堆空间的最大分配地址。 123456789101112uint64 sys_sbrk(void){ int addr; int n; if(argint(0, &amp;n) &lt; 0) return -1; addr = myproc()-&gt;sz;// if(growproc(n) &lt; 0)// return -1; myproc()-&gt;sz = myproc()-&gt;sz+n; return addr;} Lazy allocation接下来就是处理LA产生的page fault，读取中断错误类型，然后取出出错的虚拟地址，在这个虚拟地址所在的页面上分配一个物理页面。 123456789101112131415161718192021222324void usertrap(void){ ... else if (r_scause()==13 || r_scause()==15){ uint64 va = r_stval(); struct proc* p = myproc(); do{ // 从空闲链表中取出一页 char *mem; if((mem = kalloc())==0) { p-&gt;killed = 1; break; } // 初始化页为0 memset(mem, 0, PGSIZE); // 映射页 if(mappages(p-&gt;pagetable, PGROUNDDOWN(va), PGSIZE, (uint64)mem, PTE_W|PTE_X|PTE_R|PTE_U)!=0){ kfree(mem); p-&gt;killed =1; break; } }while(0); } ...} 给程序分配的无实际意义的虚拟页可能没被使用，需要修改回收的代码。 1234567891011121314151617181920212223void uvmunmap(pagetable_t pagetable, uint64 va, uint64 npages, int do_free){ uint64 a; pte_t *pte; if((va % PGSIZE) != 0) panic(&quot;uvmunmap: not aligned&quot;); for(a = va; a &lt; va + npages*PGSIZE; a += PGSIZE){ if((pte = walk(pagetable, a, 0)) == 0) continue;// panic(&quot;uvmunmap: walk&quot;); if((*pte &amp; PTE_V) == 0) continue;// panic(&quot;uvmunmap: not mapped&quot;); if(PTE_FLAGS(*pte) == PTE_V) panic(&quot;uvmunmap: not a leaf&quot;); if(do_free){ uint64 pa = PTE2PA(*pte); kfree((void*)pa); } *pte = 0; }} LA下，任何PTE不存在或PTE无效（PTE_V==0）都是被允许的。三级页表walk可能就会出现PTE不存在。 一切顺利的话，echo hi应该就能运行了。 Lazy Tests and Usertest以上只是很naive的实现。我们还需要考虑： 对出错的va进行用户堆空间的校验； sbrk的负参数的处理，即缩小用户堆空间； fork系统调用，地址空间拷贝的处理； read/write系统调用，它们使用了合法的地址，但却没有分配物理内存。 首先查看进程内存地址分配： 说明需要检查栈以上，堆以下。 12345// 校验是否是用户堆空间,即栈以上，堆顶以下if(va &lt; PGROUNDUP(p-&gt;trapframe-&gt;sp) || va &gt;= p-&gt;sz){ p-&gt;killed = 1; break;} 然后应对sbrk的负参数： 123456789101112131415uint64 sys_sbrk(void){ int addr; int n; struct proc *p = myproc(); if(argint(0, &amp;n) &lt; 0) return -1; addr = p-&gt;sz; if(n&gt;0 &amp;&amp; addr+n&gt;0){ // 防止addr+n溢出 p-&gt;sz = p-&gt;sz+n; }else if(n&lt;0){ p-&gt;sz = uvmdealloc(p-&gt;pagetable, p-&gt;sz, p-&gt;sz+n); } return addr;} 再考虑fork时的拷贝地址空间的行为，主要是调用 vm.c/uvmcopy():301，还是和前述一致，PTE不存在或PTE无效（PTE_V==0）都是被允许的，没有PTE的话直接跳过。 123456 if((pte = walk(pagetable, a, 0)) == 0) continue;// panic(&quot;uvmunmap: walk&quot;); if((*pte &amp; PTE_V) == 0) continue;// panic(&quot;uvmunmap: not mapped&quot;); 最后考虑read/write系统调用。read的行为就是从某个文件读取指定内容到我们给出的addr中。想象这样一个场景：我们在堆上申请了缓冲区，然后由于LA并没有实际分配，于是read系统调用就会出错，因为它找不到缓冲区对应的物理地址。 那这里为什么不会产生缺页异常呢？因为read系统调用已经走到了内核区域，页表基地址已经切换到了内核页表地址，这个缺页不是由内核页表产生的，而是用户页表产生的，自然不会在硬件层面产生缺页中断。 查看read/write的代码，核心场景在copyout/copyin时对addr寻找pa的过程，即 walkaddr 函数返回异常的处理。原本的代码是出错直接返回-1，现在我们要分配一页给出错的va，和缺页中断处理一摸一样。 1234567891011121314151617181920212223242526272829303132uint64 walkaddr(pagetable_t pagetable, uint64 va){ pte_t *pte; uint64 pa; struct proc* p = myproc(); if(va &gt;= MAXVA) return 0; pte = walk(pagetable, va, 0); if(pte == 0 || (*pte &amp; PTE_V) == 0){ // 校验是否是用户堆空间,即栈以上，堆顶以下 if(va &lt; PGROUNDUP(p-&gt;trapframe-&gt;sp) || va &gt;= p-&gt;sz){ return 0; } // 从空闲链表中取出一页 char *mem; if((mem = kalloc())==0) { return 0; } // 初始化页为0 memset(mem, 0, PGSIZE); // 映射页 if(mappages(p-&gt;pagetable, PGROUNDDOWN(va), PGSIZE, (uint64)mem, PTE_W|PTE_X|PTE_R|PTE_U)!=0){ kfree(mem); return 0; } } if((*pte &amp; PTE_U) == 0) return 0; pa = PTE2PA(*pte); return pa;} 总结懒分配使得用户堆上的空间在真正使用时才会被分配，要注意其他可能使用堆空间的系统调用，它们也会产生缺页错误。 some reference:https://blog.csdn.net/LostUnravel/article/details/121418421","link":"/2024/01/12/MIT6.S081/lab/lab5/"},{"title":"MIT6.S081 lab6 Copy-on-Write Fork","text":"There is a saying in computer systems that any systems problem can be solved with a level of indirection. 任何计算机系统的问题都可以通过增加一个中间层解决。 COW的思想就是fork时child的PTE指向parent的Physical Page，这样一个PP两个进程共同使用。等到真正要使用时，再拷贝一份出来，避免冲突。需要注意，fork可能在fork，于是一份物理页面可能不止两个进程共享，于是我们需要为每个物理页面额外维护一个引用计数。 S1 引用计数的设计直接用一个大数组，将物理页的页号当作索引，计算使用次数。 1234567891011121314151617struct memcnt{ struct spinlock lock; int cnt;};struct memcnt p_cnt[PHYSTOP/PGSIZE];void increase_cnt(uint64 pa){ int pn = PA2PN(pa); acquire(&amp;p_cnt[pn].lock); p_cnt[pn].cnt += 1; release(&amp;p_cnt[pn].lock);}void set_cnt(uint64 pa){ int pn = PA2PN(pa); acquire(&amp;p_cnt[pn].lock); p_cnt[pn].cnt = 1; release(&amp;p_cnt[pn].lock);} 这里为什么要加锁？我也是看了其他人的博客才知道，应该是有冲突的场景。 然后第一次分配页面时，引用计数初始化为1，归还页面时只减少引用计数，只有引用计数为0时才真正归还页面。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849void kinit(){ for(int i=0; i&lt;PHYSTOP/4096;++i){ initlock(&amp;p_cnt[i].lock, &quot;memref&quot;); p_cnt[i].cnt=0; } initlock(&amp;kmem.lock, &quot;kmem&quot;); freerange(end, (void*)PHYSTOP);}void * kalloc(void){ struct run *r; acquire(&amp;kmem.lock); r = kmem.freelist; if(r) kmem.freelist = r-&gt;next; release(&amp;kmem.lock); if(r){ memset((char*)r, 5, PGSIZE); // fill with junk set_cnt((uint64)r); } return (void*)r;}void kfree(void *pa){ struct run *r; if(((uint64)pa % PGSIZE) != 0 || (char*)pa &lt; end || (uint64)pa &gt;= PHYSTOP) panic(&quot;kfree&quot;); int pn = PA2PN((uint64)pa); // attentino here acquire(&amp;p_cnt[pn].lock); p_cnt[pn].cnt -= 1; if(p_cnt[pn].cnt&gt;0){ release(&amp;p_cnt[pn].lock); return; } release(&amp;p_cnt[pn].lock); // Fill with junk to catch dangling refs. memset(pa, 1, PGSIZE); r = (struct run*)pa; acquire(&amp;kmem.lock); r-&gt;next = kmem.freelist; kmem.freelist = r; release(&amp;kmem.lock);} S2 修改fork时的行为fork不再单独拿出一个新物理页，而是指向parent的pa。注意要修改pte的标识位，去掉可写，增加cow标志。 123456789101112131415161718192021222324int uvmcopy(pagetable_t old, pagetable_t new, uint64 sz){ pte_t *pte; uint64 pa, i; uint flags; for(i = 0; i &lt; sz; i += PGSIZE){ if((pte = walk(old, i, 0)) == 0) panic(&quot;uvmcopy: pte should exist&quot;); if((*pte &amp; PTE_V) == 0) panic(&quot;uvmcopy: page not present&quot;); pa = PTE2PA(*pte); *pte = (*pte &amp; ~PTE_W) | PTE_COW; flags = PTE_FLAGS(*pte); if(mappages(new, i, PGSIZE, pa, flags) != 0){ goto err; } increase_cnt(pa); } return 0; err: uvmunmap(new, 0, i / PGSIZE, 1); return -1;} S3 应对PageFault首先要检查出错的va的合法性，然后要检查cow标识位，再就是分配新物理页，复制内容，然后替换原来的pte。这里有一点需要注意，减少引用计数时用的是kfree函数。 12345678910111213141516171819202122232425262728293031323334353637383940void usertrap(void){ ... else if (r_scause()==13 || r_scause() ==15){ uint64 va = r_stval(); pte_t *pte; uint64 pa; do{ if (va &gt;= MAXVA || va &gt;p-&gt;sz){ p-&gt;killed = 1; break; } if((pte = walk(p-&gt;pagetable, va, 0))==0){ p-&gt;killed = 1; break; } // only cope with cow page fault if((*pte &amp; PTE_COW) == 0){ p-&gt;killed = 1; break; } pa = PTE2PA(*pte); // alloc a new physical page char* pg; if((pg = kalloc()) == 0){ p-&gt;killed = 1; break; } // copy content from old page to new page memmove(pg, (char*)pa, PGSIZE); // change flags uint flags = PTE_FLAGS(*pte); flags = (flags &amp; ~PTE_COW) | PTE_W; // replace PTE with new pa *pte = PA2PTE(pg) | flags; // decrease cnt kfree((void*)pa); } while (0); } ....} 其实这么设计还是有一个缺陷：当最后一个cow页的page fault时，它可以不用复制原来的物理页，而是直接复用这个页面，因为没有其他进程与它共享了。 S4 应对copyoutcopyout的行为和中断处理几乎一样。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849int copyout(pagetable_t pagetable, uint64 dstva, char *src, uint64 len){ uint64 n, va0, pa0; while(len &gt; 0){ va0 = PGROUNDDOWN(dstva); if(va0 &gt;= MAXVA) return -1; pte_t *pte; if((pte = walk(pagetable, va0, 0))==0){ return -1; } if((*pte &amp; PTE_V) == 0){ return -1; } if((*pte &amp; PTE_U) == 0){ return -1; } // cow页则分配新页 if((*pte &amp; PTE_COW)){ uint64 pa = PTE2PA(*pte); // alloc a new physical page char* pg; if((pg = kalloc()) == 0){ return -1; } // copy content from old page to new page memmove(pg, (char*)pa, PGSIZE); // change flags uint flags = PTE_FLAGS(*pte); flags = (flags &amp; ~PTE_COW) | PTE_W; // replace PTE with new pa *pte = PA2PTE(pg) | flags; // decrease cnt kfree((void*)pa); } pa0 = PTE2PA(*pte); if(pa0==0) return -1; n = PGSIZE - (dstva - va0); if(n &gt; len) n = len; memmove((void *)(pa0 + (dstva - va0)), src, n); len -= n; src += n; dstva = va0 + PGSIZE; } return 0;} 细节cow标志位与计算页号的宏定义 123#define PTE_COW (1L &lt;&lt; 8) // copy on write#define PA2PN(pa) (((uint64)pa) &gt;&gt; 12)","link":"/2024/02/03/MIT6.S081/lab/lab6/"},{"title":"MIT6.S081 lab7 Multithreading","text":"这个实验主要是熟悉多线程编程，比较容易。 第一个实验线程切换，这个只要理解xv6的线程调度就能解决，甚至代码都可以直接抄。 第二个实验哈希表加锁。关键代码量不到两行，甚至分桶加锁也是。 第三个实验同步屏障，这个还有意思一点。 Barriera point in an application at which all participating threads must wait until all other participating threads reach that point too. 同步屏障：它是一个点，任何参与线程都必须等到其他所有参与线程达到这个点之后，才能继续执行下去。 一个应用的例子就是Java的CountDownLatch。 怎么实现？我们在barrier的初始化时，肯定是想知道有多少个参与线程，需要一个字段nthread记录。我们还需要知道当前有多少个进程达到了point，需要一个cnt字段。 为了实现同步，我们利用了posix的互斥锁和条件变量。 123456789101112131415struct barrier { pthread_mutex_t barrier_mutex; pthread_cond_t barrier_cond; int cnt; int nthread; // Number of threads that have reached this round of the barrier int round; // Barrier round} bstate;static void barrier_init(void){ assert(pthread_mutex_init(&amp;bstate.barrier_mutex, NULL) == 0); assert(pthread_cond_init(&amp;bstate.barrier_cond, NULL) == 0); bstate.nthread = 0; bstate.cnt = nthread;} 显而易见，cnt由互斥锁保护。调用barrier函数就是增加cnt的过程，增加完cnt我们再比较cnt和nthread。 如果cnt==nthread，那么我们就唤醒所有睡眠的线程，并且重置cnt为0。 如果cnt&lt;nthread，那么就睡眠。 12345678910111213static void barrier(){ pthread_mutex_lock(&amp;bstate.barrier_mutex); //对当前round调用barrier的线程进行计数 bstate.nthread+=1; if(bstate.nthread&lt;nthread){ pthread_cond_wait(&amp;bstate.barrier_cond,&amp;bstate.barrier_mutex); }else{ bstate.round+=1;//进入下一个round bstate.nthread=0;//下一round的 bstate.nthread清零 pthread_cond_broadcast(&amp;bstate.barrier_cond); // wake up every thread sleeping on cond } pthread_mutex_unlock(&amp;bstate.barrier_mutex);} 噢，多么直观并且能通过测试。 细节Hint中有一句：Make sure that a thread that leaves the barrier and races around the loop doesn’t increase bstate.nthread while a previous round is still using it. 举例子来说，轮次1的N个线程都到达了屏障，其中有一个线程A离开了屏障，进入了下一轮2。那么此时要小心注意A在轮次2不能增加 bstate.nthread ，因为轮次1的其他线程还在使用bstate.nthread。 那么我们看代码，轮次1的其余线程其实都到达了pthread_cond_wait(&amp;bstate.barrier_cond,&amp;bstate.barrier_mutex);，被唤醒后不依赖bstate.nthread，线程被唤醒后的操作就是释放锁并返回。 即便到轮次2，A又获得了锁并成功增加了bstate.nthread，但此时bstate.nthread为1，A线程其实又会睡眠释放锁，这就给轮次1的其余线程拿锁的机会。 让我们来看错误的实现： 12345678910111213141516static void barrier(){ pthread_mutex_lock(&amp;bstate.barrier_mutex); bstate.nthread+=1; pthread_cond_broadcast(&amp;bstate.barrier_cond); while(bstate.nthread&lt;nthread) { pthread_cond_wait(&amp;bstate.barrier_cond, &amp;bstate.barrier_mutex); } if(bstate.nthread == nthread) { bstate.round+=1;//进入下一个round bstate.nthread=0;//下一round的 bstate.nthread清零 } pthread_mutex_unlock(&amp;bstate.barrier_mutex);} 使用条件变量的惯例是包裹在循环中，但在这里的反而适得其反。轮次1的线程wait返回后，还需要检查bstate.nthread变量，而这个变量是可能会被轮次2的线程A影响的（存在一种时序，A先获得了锁）。","link":"/2024/01/17/MIT6.S081/lab/lab7/"},{"title":"MIT6.S081 lab9 locks","text":"lab9以提高并行度的方式熟悉并行编程，第一个实验是多核并行，第二个实验是key级别的哈希表锁编程。 Memory allocator在内存的分配上，原先的xv6代码只有一条freelist，多核并行比较慢。现在要求实现一个cpu一条freelist，当一个CPU的freelist不够用时，需要向其他CPU借。 xv6多核并行理解xv6的并行的实现：多核并行到底是怎么样的？是所有CPU都执行同样的代码还是咋地？ 从代码结构上来看，我倾向于：只有一份代码，多个CPU有各自PC，按照PC取指令执行。这里并行的关键是多个核心而只有一份物理内存空间。代码保存在物理地址上，CPU按照PC读取指令执行。 12345678910111213141516171819struct cpu { struct proc *proc; // The process running on this cpu, or null. struct context context; // swtch() here to enter scheduler(). int noff; // Depth of push_off() nesting. int intena; // Were interrupts enabled before push_off()?};extern struct cpu cpus[NCPU];struct cpu* mycpu(void) { int id = cpuid(); struct cpu *c = &amp;cpus[id]; return c;}int cpuid(){ int id = r_tp(); return id;} 所以可以看到，以上声明了cpu数组cpus，这侧面映射了只有一份代码。如果每个CPU对应一份代码，那么就不应该是数组的形式，参考fork的含义。 构建多核freelist理解多核并行的机制后就不难构建多核freelist了，即然cpu是一个数组，那么freelist也构建一个数组。 123456789struct { struct spinlock lock; struct run *freelist;} kmem[NCPU];void kinit(){ for(int i=0; i&lt;NCPU; ++i) initlock(&amp;kmem[i].lock, &quot;kmem&quot;); freerange(end, (void*)PHYSTOP);} 不够再补的机制采用最简单的实现：将CPU看成环形队列，每个CPU的freelist不够时，都先向下家借。如果下家没有，就继续轮询。如果有，那么直接将一半的链表借出去。 这里一半链表的实现采取快慢指针。 123456789101112131415161718192021222324252627282930313233343536373839void * kalloc(void){ struct run *r; push_off(); // close interrupt int id = cpuid(); pop_off(); acquire(&amp;kmem[id].lock); r = kmem[id].freelist; if(!r){ for(int i=1; i&lt;NCPU; ++i){ int index = (id+i)%NCPU; acquire(&amp;kmem[index].lock); struct run *head = kmem[index].freelist; if(head){ // borrow some node struct run* slow = head; struct run* fast = head; while(fast &amp;&amp; fast-&gt;next!=NULL){ fast = fast-&gt;next-&gt;next; slow = slow-&gt;next; } kmem[index].freelist = slow-&gt;next; slow-&gt;next = NULL; r = head; // then return release(&amp;kmem[index].lock); break; } release(&amp;kmem[index].lock); } } if(r) kmem[id].freelist = r-&gt;next; release(&amp;kmem[id].lock); if(r) memset((char*)r, 5, PGSIZE); // fill with junk return (void*)r;} 归还的操作很简单，利用锁保护好链表就行。 12345678910111213141516171819void kfree(void *pa){ struct run *r; if(((uint64)pa % PGSIZE) != 0 || (char*)pa &lt; end || (uint64)pa &gt;= PHYSTOP) panic(&quot;kfree&quot;); // Fill with junk to catch dangling refs. memset(pa, 1, PGSIZE); r = (struct run*)pa; push_off(); // close interrupt int id = cpuid(); pop_off(); // open interrupt acquire(&amp;kmem[id].lock); r-&gt;next = kmem[id].freelist; kmem[id].freelist = r; release(&amp;kmem[id].lock);} Buffer cacheblock cache机制原先的block cache是只有一条LRU链表，一个大锁。现在改进机制是利用一个hash bucket级别的锁保护一个hash table，利用block no作为哈希索引。 网上看到的一种实现是： 1234struct { struct spinlock lock; struct buf buf[NBUF];//NBUF=30} bcache[NBUCKET]; 直接将bcache分为NBUCKET份，利用blockno作为索引，在相应的链表上进行查找cache和牺牲cache的操作。这样的实现粗暴简单，也不会有死锁的风险，但总觉得与实验指导的意思相悖。 我更倾向于这种实现： 12345678910111213#define NBUCKET 13#define HINDEX(x) ((x) % NBUCKET)struct bucket{ struct spinlock lock; struct buf head;};struct { struct spinlock lock; struct buf buf[NBUF]; struct bucket htable[NBUCKET];} bcache; 即将buf数组作为buf的池子，htable在buf不够用时再从buf中取buf。如果需要牺牲一个buf，是可能出现从一个bucket到另外一个bucket的情况。 实现思考1234567891011121314void binit(void) { struct buf *b; initlock(&amp;bcache.lock, &quot;bcache&quot;); for (b = bcache.buf; b &lt; bcache.buf + NBUF; b++) { initsleeplock(&amp;b-&gt;lock, &quot;buffer&quot;); } for(int i=0; i&lt;NBUCKET; ++i){ initlock(&amp;bcache.htable[i].lock, &quot;bcache.bucklock&quot;); bcache.htable[i].head.next = &amp;bcache.htable[i].head; bcache.htable[i].head.prev = &amp;bcache.htable[i].head; }} 在初始化时，我的hash table里的LRU链表肯定都是空的，只有一个伪头节点。 一种实现是：将所有buf（一共NBUF个）直接加载到htable[0]的链表中。后续其他bucket的链表不够用时，从其他bucket的链表找牺牲buf 另一种实现：当前bucket的链表找不到buf，那么就去buf数组找还有没有空闲的buf，如果没有空闲的buf，那么再进行全hash table的扫描，找出交换的buf 再对每个bucket的链表进行访问时，都需要获取当前bucket的锁。 有缺陷的实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283static struct buf* bget(uint dev, uint blockno) { struct buf *b; uint index = HINDEX(blockno); acquire(&amp;bcache.htable[index].lock); // Is the block already cached? for (b = bcache.htable[index].head.next; b != &amp;bcache.htable[index].head; b = b-&gt;next) { if (b-&gt;dev == dev &amp;&amp; b-&gt;blockno == blockno) { b-&gt;refcnt++; b-&gt;timestamp = ticks; release(&amp;bcache.htable[index].lock); acquiresleep(&amp;b-&gt;lock); return b; } } // Not cached. 从buf数组中找到一个refcnt为0，并且时间戳最小的buf struct buf* tmp = 0; acquire(&amp;bcache.lock); for (b = bcache.buf; b &lt; bcache.buf + NBUF; b++) { if (b-&gt;refcnt == 0) { if( !tmp || tmp-&gt;timestamp &gt; b-&gt;timestamp) { tmp = b; } } } if(!tmp) panic(&quot;bget: no buffers&quot;); // 现在我们要重建缓存 // tmp可能已经在哈希表中，需要先从哈希表中释放tmp节点，然后再插入（这个过程可能对同一个槽） // 1、判断tmp是否在哈希表中 if(tmp-&gt;timestamp == 0){ setBuf(tmp, dev, blockno, ticks); insertBuf(&amp;bcache.htable[index], tmp); }else{ //2、判断前后哈希槽是否相同 uint oldIndex = HINDEX(tmp-&gt;blockno); uint newIndex = index; setBuf(tmp, dev, blockno, ticks); if(oldIndex != newIndex){ //3、前后槽不同，需要先释放旧节点然后插入新节点 acquire(&amp;bcache.htable[oldIndex].lock); tmp-&gt;prev-&gt;next = tmp-&gt;next; tmp-&gt;next-&gt;prev = tmp-&gt;prev; release(&amp;bcache.htable[oldIndex].lock); insertBuf(&amp;bcache.htable[index], tmp); } } release(&amp;bcache.lock); release(&amp;bcache.htable[index].lock); acquiresleep(&amp;tmp-&gt;lock); return tmp;}void brelse(struct buf *b) { if (!holdingsleep(&amp;b-&gt;lock)) panic(&quot;brelse&quot;); releasesleep(&amp;b-&gt;lock); acquire(&amp;bcache.htable[HINDEX(b-&gt;blockno)].lock); b-&gt;refcnt--; if(b-&gt;refcnt==0) b-&gt;timestamp=ticks; release(&amp;bcache.htable[HINDEX(b-&gt;blockno)].lock);}void setBuf(struct buf* buf, uint dev, uint blockno, uint timestamp){ buf-&gt;dev = dev; buf-&gt;blockno = blockno; buf-&gt;timestamp = timestamp; buf-&gt;valid = 0; buf-&gt;refcnt = 1;}void insertBuf(struct bucket* bucket, struct buf* node){ // 尾插法 struct buf* head = &amp;bucket-&gt;head; head-&gt;prev-&gt;next = node; node-&gt;prev = head-&gt;prev; head-&gt;prev = node; node-&gt;next = head;} 可以通过bcachetest，但是无法通过usertests，挠头。 这里明显的缺陷就是死锁。当线程A获取bucket1的锁，线程B获取bucket2的锁，两个线程都要继续进行下去，然后A获得了bcache的锁，但是A选取的牺牲buf恰好是bucket2的buf，那么A还要获得bucket2的锁，那么就造成了死锁。 如果采用全哈希表扫描的方式获取一个牺牲buf，感觉也会有死锁的场景。","link":"/2024/01/18/MIT6.S081/lab/lab9/"},{"title":"MIT6.S081 调试xv6","text":"之前学了一些gdb的使用，但是总不能实际上手操作，不如终端IDE可视化调试。这次由于Docker配置环境，不想再折腾连接IDE调试，于是学习GDB。 开始在课程的lab guidance上有这么一段话： In many cases, print statements will be sufficient, but sometimes being able to single step through some assembly code or inspecting the variables on the stack is helpful. To use gdb with xv6, run make make qemu-gdb in one window, run gdb (or riscv64-linux-gnu-gdb) in another window, set a break point, followed by followed by ‘c’ (continue), and xv6 will run until it hits the breakpoint. (See Using the GNU Debugger for helpful GDB tips.) 大意是，在一个终端上执行 make qemu-gdb ，在另一个终端上执行 gdb。 出现的问题当我在第二个终端执行gdb时出现以下提示： 1234567891011warning: File &quot;/home/xv6-labs-2021/.gdbinit&quot; auto-loading has been declined by your `auto-load safe-path' set to &quot;$debugdir:$datadir/auto-load&quot;.To enable execution of this file add add-auto-load-safe-path /home/xv6-labs-2021/.gdbinitline to your configuration file &quot;/root/.gdbinit&quot;.To completely disable this security protection add set auto-load safe-path /line to your configuration file &quot;/root/.gdbinit&quot;.--Type &lt;RET&gt; for more, q to quit, c to continue without paging--For more information about this security protection see the&quot;Auto-loading safe path&quot; section in the GDB manual. E.g., run from the shell: info &quot;(gdb)Auto-loading safe path&quot; 直接按照提示，add-auto-load-safe-path /home/xv6-labs-2021/.gdbinit 关于gdbinit文件查看 gdbinit文件内容，猜测 1// 另开一个Terminal窗口，切到xv6-labs-2020目录下，切到util分支，执行 1riscv64-unknown-elf-gdb kernel/kernel 然后在(gdb)环境下执行 1(gdb) target remote localhost:26000 不过可以按如下操作简化：在~目录下新建.gdbinit文件，内容为： 1add-auto-load-safe-path ~/xv6-labs-2020/.gdbinit 其中~改为自己的xv6-labs-2020目录所在路径 调试在一个终端上执行 make qemu-gdb ，在另一个终端上执行 gdb。 https://zhuanlan.zhihu.com/p/466423677 直接使用gdb命令会提示体系结构不支持，因此改用其他命令。 如果想调试特定的文件例如xargs.c，则在一开始启动gdb后执行: 1(gdb) file user/_xargs 加载特定的符号文件，然后就可以打断点了 1(gdb) b main 然后调试 1(gdb) c 如果不加载符号文件，打断点时就会找不到函数位置。","link":"/2024/01/03/MIT6.S081/lab/%E8%B0%83%E8%AF%95xv6/"},{"title":"实验P0","text":"实验零要求实现一个数据结构：前缀树。适合复习CPP以及适应实验代码环境。 前言实现前缀树，实际上是实现一种特殊情况的kv存储，key为字符串，value为任意类型。 1234&lt;&quot;abcd&quot;, 1&gt;&lt;&quot;abc&quot;, 2&gt;&lt;&quot;abce&quot;, 3&gt;&lt;&quot;a&quot;, 1&gt; 有三个类： Trie 字典树 TrieNode 字典树节点类 TrieNodeWithValue 继承自TrieNode，表示一个key的结尾并存储value 可以很简单地想到每个节点类存储一个字符以及对应的子节点指针的集合。 注意：前缀树的叶子结点必然对应一个value存储，同时内部节点也可能对应一个value存储。 TrieNodeWith Value可以出现在树的任何地方，比如插入a，插入aa，插入aaa，此时树中三个结点均为TrieNodeWithValue类型。 查找思路： key与前缀树的遍历二者同时进行，key的每个位置上的char指导当前节点往下走。 当走到最后一个char时，需要检查是否是end node。 删除思路： 遍历到最后一个char，中间有任何问题（结点不存在）直接返回false 将最后一个char对应的结点的is_end设置为false 往上回溯遍历的结点，对每个回溯的节点进行判断 如果这个结点没有child并且不是end node，那么可以安全删除 踩坑本地测试，请去除DISABLED前缀。 网页测评前，代码格式检测： 123$ make format$ make check-lint$ make check-clang-tidy-p0 提交文件制作，需要包括完整路径： 1zip -r p0.zip src/include/primer/p0_trie.h TrieNode Insert测试提交时TrieNode Insert测试没有通过，只有70分。 123456789101112131415161718192021222324252627282930313233template &lt;typename T&gt;bool Insert(const std::string &amp;key, T value) { if (key.empty()) { return false; } latch_.WLock(); auto *node = &amp;root_; for (char key_char : key) { auto node_next = (*node)-&gt;GetChildNode(key_char); if (node_next == nullptr) { node_next = (*node)-&gt;InsertChildNode(key_char, std::make_unique&lt;TrieNode&gt;(key_char)); } node = node_next; } if ((*node)-&gt;IsEndNode()) { latch_.WUnlock(); return false; } // error implementation of convert TrieNode to TrieNodeWithValue // char ch = (*node)-&gt;GetKeyChar(); // node-&gt;reset(new TrieNodeWithValue&lt;T&gt;(ch, value)); auto *new_node = new TrieNodeWithValue(std::move(**node), value); node-&gt;reset(new_node); latch_.WUnlock(); LOG_DEBUG(&quot;insert into key %s, success&quot;, key.c_str()); return true;} 主要错误：将TrieNode转换为TrieNodeValues时，丢失了子孙信息。","link":"/2024/04/15/cmu15445/lab/%E5%AE%9E%E9%AA%8Cp0/"},{"title":"实验P1","text":"实验一要求实现一个缓冲池实例，包括动态扩张的哈希表、基于LRU-K的替换器。 动态哈希表的难点在于理清数据结构，数据插入与扩容过程，不要求缩容。 LRU-K的实现比较坑，如果没有理解替换器与缓冲池整体的关系，也就很难理解各个函数的实现。 建议看教材：Database System Concepts 里面讲得比较清晰。 Extendible hash table原理Extendible Hashing is a dynamic hashing method wherein directories, and buckets are used to hash data. It is an aggressively flexible method in which the hash function also experiences dynamic changes. Frequently used terms in Extendible Hashing: Directories: These containers store pointers to buckets. Each directory is given a unique id which may change each time when expansion takes place. The hash function returns this directory id which is used to navigate to the appropriate bucket. Number of Directories = 2^Global Depth. Buckets: They store the hashed keys. Directories point to buckets. A bucket may contain more than one pointers to it if its local depth is less than the global depth. Global Depth: It is associated with the Directories. They denote the number of bits which are used by the hash function to categorize the keys. Global Depth = Number of bits in directory id. Local Depth: It is the same as that of Global Depth except for the fact that Local Depth is associated with the buckets and not the directories. Local depth in accordance with the global depth is used to decide the action that to be performed in case an overflow occurs. Local Depth is always less than or equal to the Global Depth. Bucket Splitting: When the number of elements in a bucket exceeds a particular size, then the bucket is split into two parts. Directory Expansion: Directory Expansion Takes place when a bucket overflows. Directory Expansion is performed when the local depth of the overflowing bucket is equal to the global depth. Extendible Hash是动态扩容的哈希表，有两个重要概念：directory和bucket。bucket直译为桶，directory直译为目录。桶是一个固定数量的容器，目录就真的是目录（看作存储桶指针的线性表，表动态增长）。 （1）查找过程 首先，通过hash function找到Directory的Index，然后找到对应的Bucket，Bucket就是个链表，顺序查找。 （2）插入过程 extendible hash table的bucket是固定大小的，当Bucket满时只会创建新桶，而不是扩容桶大小。新桶会链接到目录（directory）上，当目录条目满时，触发目录的扩容。这就是extendible hash table的主要扩容逻辑。 当然，实现上有global depth和local depth来加速判断目录是否需要扩容。具体地，当前bucket有$2^{global-local}$个指针指向它，当 global==local时，只有一个指针，这时候桶满扩容的同时需要目录扩容。 有两种扩容情况： local depth &lt; global depth local depth == global depth 第一种情况只涉及bucket split，第二种情况涉及bucket split 和 directory expansion。 bucket split过程：增加local depth，然后创建两个新桶，根据新的local depth将原桶的数据分配（采取位运算）到新的两个桶中。最后调整directory的指针，即将指向原桶的指针分配（采取位运算）给新的两个桶。 directory expansion过程：将directory扩容至原先两倍，扩容采取复制的办法。这样指向每一个桶的指针就会变为原先的两倍。 （3）初始情况 global depth=0， local depth =0，directory大小为1，即只有一个桶。 注意点 实验要求的insert接口，对于相同的Key时，能够做到修改值而不是返回错误。这点如果没有确认，线上测试的InsertAndReplace测试项就会不通过。 即使桶分裂、目录扩张后，新的桶可能还是满的（数据的低N位为止都相同），需要递归插入。 递归时需要先释放锁，避免死锁（锁不可重入）。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152template &lt;typename K, typename V&gt;void ExtendibleHashTable&lt;K, V&gt;::Insert(const K &amp;key, const V &amp;value) { latch_.lock(); size_t index = IndexOf(key); std::shared_ptr&lt;Bucket&gt; p_bucket = dir_[index]; if (p_bucket-&gt;Insert(key, value)) { latch_.unlock(); return; } // 插入失败，桶已满，根据global depth和local depth决定是否进行目录扩张 // 目录扩张 if (GetGlobalDepthInternal() == p_bucket-&gt;GetDepth()) { // 1. 复制目录 auto copy_dir = dir_; // 2. 拼接 dir_.insert(dir_.end(), copy_dir.begin(), copy_dir.end()); // 3. 增加globalDepth IncrementGlobalDepth(); } // 桶分裂 // 1. 创建两个新桶（depth+1） p_bucket-&gt;IncrementDepth(); auto p_b_0 = std::make_shared&lt;Bucket&gt;(bucket_size_, p_bucket-&gt;GetDepth()); auto p_b_1 = std::make_shared&lt;Bucket&gt;(bucket_size_, p_bucket-&gt;GetDepth()); // 2. 重新分配桶内元素 // 2.1 获取第depth位掩码 size_t mask = 1 &lt;&lt; (p_bucket-&gt;GetDepth() - 1); for (const auto &amp;item : p_bucket-&gt;GetItems()) { // 2.2 根据第depth位分配给两个新桶 if ((IndexOf(item.first) &amp; mask) != 0) { p_b_1-&gt;Insert(item.first, item.second); } else { p_b_0-&gt;Insert(item.first, item.second); } } // 重新分配directory指针 size_t idx = 0; for (auto &amp;pb : dir_) { if (pb.get() == p_bucket.get()) { if ((idx &amp; mask) == 0) { pb = p_b_0; } else { pb = p_b_1; } } idx++; } num_buckets_++; latch_.unlock(); // 递归插入 Insert(key, value);} LRU-K Replacer原理核心概念：Backward K-distance ，Backward k-distance is computed as the difference in time between current timestamp and the timestamp of kth previous access。 我们有磁盘页的集合$N={1,2,3,..,n}$，然后给定磁盘页访问的时间序列 $r_1, r_2,…r_t$，其中$r_t = p$表示在t时刻访问页号为p的磁盘页，那么页号p的Backward K-distance 可以表示为 $b_t(p, K)$。 $b_t(p, K) = x$ ，如果 $r_{t-x}=p$，并且在时刻t-x到t中，p出现了K次。 $b_t(p, K) = +\\infin$ ， 如果在 1,2,3..t 时刻中，p出现不足K次。 LRU-K算法就是在驱逐页面时，选择具有最大Backward K-distance的页。如果有多个页的Backward K-distance都是正无穷，那么可采取其他页面替换算法，比如LRU算法，驱逐最近不常使用的页面。 xv6的缓存实现在我自己的想法中，Replacer用来记录每个page的访问情况，然后调用eviect决定哪个page应该牺牲。在xv6操作系统的文件块缓存中，它是这么设计的： 磁盘可以想象成块数组，每个块block有唯一的ID。bcache作为缓存，存储的是一个buf的链表。这个buf有两个属性，分别是refcnt引用计数和blockno对应的块ID。通过bcache拿块的过程就是顺序访问链表，查找有无对应ID的buf，如果没有，选择一个空白的buf，然后从磁盘上加载对应块的内容。如果没有空白的buf，就得牺牲一个refcnt为0的块。链表采用LRU算法组织，链表头部是经常使用的节点。引用计数refcnt维护了当前正在使用块的线程数量，线程get一个块会增加引用计数，release一个块会减少引用计数。当引用计数为零时，会将buf移动到链表头部，方便LRU算法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// Look through buffer cache for block on device dev.// If not found, allocate a buffer.// In either case, return locked buffer.static struct buf* bget(uint dev, uint blockno){ struct buf *b; acquire(&amp;bcache.lock); // Is the block already cached? for(b = bcache.head.next; b != &amp;bcache.head; b = b-&gt;next){ if(b-&gt;dev == dev &amp;&amp; b-&gt;blockno == blockno){ b-&gt;refcnt++; release(&amp;bcache.lock); acquiresleep(&amp;b-&gt;lock); return b; } } // Not cached. // Recycle the least recently used (LRU) unused buffer. for(b = bcache.head.prev; b != &amp;bcache.head; b = b-&gt;prev){ if(b-&gt;refcnt == 0) { b-&gt;dev = dev; b-&gt;blockno = blockno; b-&gt;valid = 0; b-&gt;refcnt = 1; release(&amp;bcache.lock); acquiresleep(&amp;b-&gt;lock); return b; } } panic(&quot;bget: no buffers&quot;);}// Release a locked buffer.// Move to the head of the most-recently-used list.void brelse(struct buf *b){ if(!holdingsleep(&amp;b-&gt;lock)) panic(&quot;brelse&quot;); releasesleep(&amp;b-&gt;lock); acquire(&amp;bcache.lock); b-&gt;refcnt--; if (b-&gt;refcnt == 0) { // no one is waiting for it. b-&gt;next-&gt;prev = b-&gt;prev; b-&gt;prev-&gt;next = b-&gt;next; b-&gt;next = bcache.head.next; b-&gt;prev = &amp;bcache.head; bcache.head.next-&gt;prev = b; bcache.head.next = b; } release(&amp;bcache.lock);} 实验中的缓冲池实现 实验中的replacer设计弯弯绕绕，一开始我还没明白为什么replacer管理的是frame而不是page。首先从buffer pool manager来看，它有一个pages_数组作为缓存，有一个哈希表page_table_记录page在哪个frame里。这个frame说白了就是slot，再看实现，其实就是0到$len(pages_)$的整数。 真的是好家伙，比方说数组大小为10，那么replacer就管理这10个整数的出现频次，所以才会有Remove方法出现。 remove：Remove an evictable frame from replacer, along with its access history. 为什么有remove方法？evit不就好了，而且为什么要清除一个page的access历史？ RecordAccess: If frame id is invalid (ie. larger than replacer_size_), throw an exception. 为什么一个大于size的frame id会违法？这在当时我是想不通的，frame id不是随机出现的page id吗？结果就是frame id只是个整数，数组的索引不能越界的限制。 这一切的一切，全都源自于buffer pool manager（bpm）和replaces的分离式设计！这使得引用计数的维护和牺牲页面两个功能分开了！由于replacer并不知道一个frame被用了多少次，所以不得不靠bpm来主动设置一个frame的evictable属性，避免页面被提前换出。 注意点（1）timestamp的实现 只需要在access的时候自增timestamp变量。 （2）pin frame的实现 利用一个数组记录相应frame是否固定或者将pin与frame组成一个新结构体。这是因为固定的frame解除固定后，还需要被正常追踪LRU-K。 （3）大小的追踪（replacer_size不是max_size） 可驱逐的帧数量 replacer_size_ 不可驱逐的帧数量 curr_size_ 减去 replacer_size_ 最大追踪的帧数量 max_size_ （curr_size_ 小于等于 max_size_) The size of LRUKReplacer is represented by the number of evictable frames. The LRUKReplacer is initialized to have no frames in it. Then, only when a frame is marked as evictable, replacer’s size will increase. 实验踩坑（1）线上测试，我用自己实现的根据backward K距离牺牲页面的算法不通过。网上查看，一些是依据前第k次的时间戳排序，一些人直接将访问次数达到K次的的frame用LRU算法实现（连一个帧的access history都不需要存储，只需要记录访问次数）。 我修改代码为后一种方式后通过了在线测试，真是魔幻！ （2）死锁问题 void LRUKReplacer::RecordAccess(frame_id_t frame_id) 中调用 auto LRUKReplacer::Evict(frame_id_t *frame_id) -&gt; bool 由于两个函数都是一个大锁保护，造成死锁。 解决方法：利用一个Internal函数，解除锁的依赖。 1234auto LRUKReplacer::Evict(frame_id_t *frame_id) -&gt; bool { std::lock_guard&lt;std::mutex&gt; lg(latch_); return EvictInternal(frame_id);} Buffer pool instance原理 首先，从Buffer pool的使用者上来看，Buffer pool最主要的功能就是查找页FetchPg(page_id_t page_id)和新建页NewPg(page_id_t *page_id)。上层使用者希望通过一个page id得到对应的页内容，或者希望插入一些新数据（需要得到一个空页）。 从Buffer pool里面来看，有一块连续的地址空间Page *pages_;用来存Page，但是Page在这块空间可能是分散存放的（写回一个脏页时，该位置上的Page不再使用，可以被覆盖。Buffer pool不作内存整理）。对应的，有一个ExtendibleHashTable&lt;page_id_t, frame_id_t&gt; *page_table的哈希表，维护着page id 与 page index（page 在数组中的位置）的映射。这个page index表现为frame id。怎么理解呢？帧（frame）相当于快递盒子，页（page）作为物品放置于快递盒子中。缓冲池管理固定个数的盒子，比如10个盒子。于是有一个空闲链表std::list&lt;frame_id_t&gt; free_list 追踪空盒子。 通过页找到帧 PageTable 通过帧找到页 pages_[frame_id] 当所有盒子都满了时，由LRUKReplacer *replacer_决定哪一个盒子应该置空，盒子本身是重复使用的。LRUK算法根据最近K次使用盒子时间来决定哪个盒子应该置空。 实现注意点（1）基本逻辑 FetchPg的逻辑 首先在缓冲池pages_里查找，如果找到了，更新访问记录并返回。如果未找到，那么我们需要一个帧来装这个页，优先从空帧中找，否则需要牺牲一个帧。然后通过DiskManager装载Page的内容，最后更新访问记录并返回。 NewPg的逻辑 首先需要找到一个帧来装载Pg。从空帧链表中找或者牺牲一个帧。然后通过AllocatePage()分配一个新页，将页装在帧上，更新访问记录并返回。 （2）牺牲帧时的操作 牺牲得到帧里面的页可能是Dirty的，需要写回到磁盘，同时解除页与帧的映射关系。 （3）Unpin时，页的diry设置 1pages_[frame_id].is_dirty_ = pages_[frame_id].is_dirty_ || is_dirty; 不可能从脏页变成干净页。只有刷新页的时候才会设置干净页。 （4）小心维护引用计数和Replacer的分离设计 引用计数和Replacer相互分离，需要额外通过设置evictable属性避免引用计数大于零的页面被驱逐。 12345678910111213141516171819auto BufferPoolManagerInstance::FetchPgImp(page_id_t page_id) -&gt; Page * { std::lock_guard&lt;std::mutex&gt; lg(latch_); frame_id_t frame_id; if (!page_table_-&gt;Find(page_id, frame_id)) { // 未找到页面，分配新帧 if (!GetFrame(&amp;frame_id)) { return nullptr; } ... replacer_-&gt;SetEvictable(frame_id, false); pages_[frame_id].pin_count_++; return page; } // 找到页面，更新访问次数 ... pages_[frame_id].pin_count_++; replacer_-&gt;SetEvictable(frame_id, false); return &amp;pages_[frame_id];} 这个后果就是：这两个语句需要绑定在一起。 12pages_[frame_id].pin_count_++;replacer_-&gt;SetEvictable(frame_id, false);","link":"/2024/04/15/cmu15445/lab/%E5%AE%9E%E9%AA%8Cp1/"},{"title":"实验P2","text":"实验二要求实现一个数据结构 ：B+树。 实验难点在于理清B+树存储结构、插入分裂、删除合并以及并发控制。 强烈建议阅读教材给出的B+树执行流程的伪代码。 B+树细节B+树的阶数m阶B+树，即内部结点最多m个子树。参考教材可以得到： 根结点最少2个孩子，最多m个孩子。根结点既可以是内部结点，也可以是叶子结点。 内部结点最少有$\\lceil m/2\\rceil$ 孩子，最多m个孩子。 叶子结点的键值对最少有$\\lceil (m-1) /2\\rceil$ ，最多m-1。 当根节点是叶子结点时（即当前B+树只有一个结点），根节点最多存储m-1个键值对；当根节点为内部结点时，根节点可以存储最多m个键值对。 从定义上我们可以窥见：B+树的结点总是不太满又不太少（大于一半），这就有很好的页利用率。 tips: 上取整数的实现技巧 ⌈x/2⌉ = ⌊(1+x)/2⌋ 阶数与实现关系（1）数组存储 在键值对的存储上，内部结点和叶子结点都采用一个键值对数组的方式。 1234#define MappingType std::pair&lt;KeyType, ValueType&gt;MappingType array_[1];// 可以理解为vector&lt;pair&lt;key, value&gt;&gt; array; 内部结点的key就是泛化的键（用于索引比较），value则是指向下一个页的指针（本次实验则是存储下一个页的页ID）。 叶子结点的key是泛化的键，value就是一个RecordID，RecordID包括PageID和SlotNum（表示一条记录在一个页内的偏移）。 Pm所在的子树上所有键都小于Km，大于等于Km-1 采取RecordID是间接存储行记录的方式，也有直接存储，即将整个行记录存在value中的方式。 在实现上为了维护内部结点指针比键多一的特性，内部结点的数组的第一个元素的key设置为空。 回到实验代码上，结点会有size和max_size属性表示当前数组的长度和最大长度。 size_ 4 Number of Key &amp; Value pairs in page max_size_ 4 Max number of Key &amp; Value pairs in page 12345#define LEAF_PAGE_HEADER_SIZE 28#define LEAF_PAGE_SIZE ((BUSTUB_PAGE_SIZE - LEAF_PAGE_HEADER_SIZE) / sizeof(MappingType))#define INTERNAL_PAGE_HEADER_SIZE 24#define INTERNAL_PAGE_SIZE ((BUSTUB_PAGE_SIZE - INTERNAL_PAGE_HEADER_SIZE) / (sizeof(MappingType))) 从宏定义上也能看出，默认的数组的最大长度由一个页减去头部字段大小然后除以kv对计算得到。 （2）阶数与数组最大长度关系 123456789INDEX_TEMPLATE_ARGUMENTSBPLUSTREE_TYPE::BPlusTree(std::string name, BufferPoolManager *buffer_pool_manager, const KeyComparator &amp;comparator, int leaf_max_size, int internal_max_size) : index_name_(std::move(name)), root_page_id_(INVALID_PAGE_ID), buffer_pool_manager_(buffer_pool_manager), comparator_(comparator), leaf_max_size_(leaf_max_size), internal_max_size_(internal_max_size) {} 在B+树的构造函数中，会传入叶子结点的最大长度和内部结点的最大长度。 1BPlusTree&lt;GenericKey&lt;8&gt;, RID, GenericComparator&lt;8&gt;&gt; tree(&quot;foo_pk&quot;, bpm, comparator, 2, 3); 并且在测试代码中，可以看到这两个最大长度并不是一致的。 问题：为什么这两个size为不一样？ 答：因为叶子结点和内部结点存的东西不一样，一张页的大小是固定的，自然计算出的size不一样。 问题2：阶数到底是哪一个？是leaf_max_size_还是internal_max_size_？ 答：这里我觉得无需介意，在固定页大小背景下， 这两个都是能真实存储的极限大小，实现上满足内部结点和叶子结点的语义即可。 内部结点的语义是：给定大小m，我的数组长度最小为$\\lceil m/2\\rceil$ ，最多m，即我可以占满整个页空间。 叶子结点的语义是：给定大小m，我的数组长度最小$\\lceil (m-1) /2\\rceil$ ，最多m-1，即我的数组最长时，在整个页空间上留下一个空位。 问题3：为什么要留下一个空位，而不是存满？ 答：想象一下，在数据库的存储中，假设一个页最多存M个数据，叶子页可以存满M个。我现在有一个满叶子页L，此时插入的新数据K正好索引到L上，页满需要页分裂。页分裂的过程：创建新页，然后将M+1个数据平分到两个页上。但是，你需要先将K插入到M个数据上的合适位置，这就要求申请存储M+1个数据大小的内存空间。而一个页最多存M个数据，这就很别扭。而留下空位的做法，使得最后一个位置的元素可以充当哨兵，可以做到先插入再分裂。插入数据结束后，检查叶子页大小是否已满，已满则进行分裂。 问题4：为什么内部页可以存满？ 答： 因为内部页的第一个元素的key是未使用的（牵强） 插入过程伪代码 插入过程需要注意的是： 叶子结点分裂时，中间键作为索引是复制一份插入到parent。而内部结点分裂时，中间键直接被拿走，插入parent中。 内部页分裂时必须及时更新孩子结点的父亲指向 删除过程伪代码 删除过程比较复杂，内部结点的删除和中间结点的删除需要单独处理。大致逻辑是从叶子结点删除完一个元素后，如果元素太少，那么就需要和周围结点合并为一个结点，或者重新分配元素（无法合并为一个结点的情况）。最后别忘记更改父亲的指针，整个过程从下往上进行。 重分配的过程是从邻居结点借一个元素的过程。 B+树节点页的交互 B+树的节点页是以嵌套的方式存储在页的data区域，通过buffer pool manager进行交互。 1auto* p = reinterpret_cast&lt;LeafPage*&gt;(buffer_pool_manager_-&gt;FetchPage(page_id)-&gt;GetData()); B+树并发基本思想主要思想为像螃蟹一样横着走路，意为先跨出去一步踩稳后，再收回一步。体现在B+树中就是从当前结点N开始获得锁，然后在获得N的儿子C的锁。如果C是安全的，那么就可以释放N的锁。（A thread can only release latch on a parent page if its child page considered “safe”. ） 根据操作的不同，结点安全也有不同的解释： 对于插入操作，只有当前size小于GetMaxSize() - 1才是安全的 对于删除操作，只有当前size大于GetMinSize()才是安全的 基本的螃蟹锁协议： 查找：从根结点开始，获得儿子结点的共享锁后释放父结点的共享锁。 插入/删除：从根结点开始，获得儿子结点的排它锁 。然后检查儿子的安全性，如果儿子节点是安全的，则释放儿子结点的所有祖先结点的锁。否则一直持有锁。 注意这里儿子结点安全后是释放所有祖先结点的锁。如果只释放父结点的锁的话，会出现锁得不到释放的现象。比如ABCD的遍历顺序，A是安全根结点，BC是不安全结点，D是安全结点，根据规则，我们将一直持有锁遍历到D，如果只释放父结点的锁，那么AB的锁就得不到释放。 优化思想The problem with the basic latch crabbing algorithm is that transac- tions always acquire an exclusive latch on the root for every insert/delete operation 基本的螃蟹锁思想缺点是插入与删除操作都要先获得根结点的排它锁，这导致并行度不高。 一种优化的思想是采用乐观锁的思想，插入与删除操作都先采用共享锁一路爬到叶子结点，然后校验叶子结点的安全性。如果叶子是安全的，采用排它锁完成更新。如果叶子节点不安全，则放弃所有共享锁，从根结点开始一路获取排它锁。 Search: Same algorithm as before. Insert/Delete: Set READ latches as if for search, go to leaf, and set WRITE latch on leaf. If the leaf is not safe, release all previous latches, and restart the transaction using previous Insert/Delete protocol. 书本18.10描述的螃蟹锁规则/协议： 1234567891011When searching for a key value, the crabbing protocol first locks the root node in shared mode. When traversing down the tree, it acquires a shared lock on the child node to be traversed further. After acquiring the lock on the child node, it releases the lock on the parent node. It repeats this process until it reaches a leaf node.When inserting or deleting a key value, the crabbing protocol takes these actions:° It follows the same protocol as for searching until it reaches the desired leaf node. Up to this point, it obtains (and releases) only shared locks.° It locks the leaf node in exclusive mode and inserts or deletes the key value.° If it needs to split a node or coalesce it with its siblings, or redistribute key values between siblings, the crabbing protocol locks the parent of the node in exclusive mode. After performing these actions, it releases the locks on the node and siblings.If the parent requires splitting, coalescing, or redistribution of key values, the protocol retains the lock on the parent, and splitting, coalescing, or redistri- bution propagates further in the same manner. Otherwise, it releases the lock on the parent. 搜索键值时，crabbing 协议首先将根节点锁定为共享模式。向下遍历树时，它会在子节点上获取共享锁，以便进一步遍历。获取子节点上的锁后，它会释放父节点上的锁。它会重复此过程，直到到达叶节点。 插入或删除键值时，Crabbing 协议会执行以下操作： 它遵循与搜索相同的协议，直到到达所需的叶节点。到目前为止，它只获取（和释放）共享锁。 将叶节点锁定为独占模式，并插入或删除键值。 如果它需要拆分节点或将其与其同级合并或在同级之间重新分配密钥值，则 crabbing 协议会以独占模式锁定节点的父节点。执行这些操作后，它会释放节点和同级上的锁。 如果父级需要拆分、合并或重新分发密钥值，则协议将保留对父级的锁定，并且拆分、合并或重新分配会以相同的方式进一步传播。否则，它将释放父项上的锁。 leaf node scan问题前述加锁方式都是top-down自顶向下式的，一个线程只能获得当前结点的儿子结点的锁，如果不能获得，就必须等待。 但如果一个线程从一个叶子移动到另外一个叶子，就会出现死锁的情况。此时，需要靠程序进行死锁预防/避免。no-wait原则要求一个线程获得锁失败时释放它所有拥有的锁，然后重新开始尝试。 前置知识点flexible array 柔性数组，可自适应空间大小，避免固定空间浪费。 具体特点： 柔性数组为结构体的最后一个成员； 该结构体至少包含一个非柔性数组成员； 编译器支持C99标准。 12345678 typedef struct { int32_t id; int32_t grade; int8_t name[]; }student_info_struct;// 使用方式int8_t *name = &quot;sdc&quot;;si = (student_info_struct *)malloc(sizeof(student_info_struct) + strlen(name) + 1); 数组名作为地址，可以自适应占据分配给结构体的空间，实现动态扩张。 好处：直接分配结构体和缓冲区大小，避免两次分配（一次结构体，一次缓冲区） 踩坑/经验Root page id的更新1void BPLUSTREE_TYPE::UpdateRootPageId(int insert_record); 当第一次创建根结点时，我们需要向header page插入一条root page id的记录，即使用UpdateRootPageId(1); 此后，更新根结点但树不变，采用UpdateRootPageId(0); InternalPage 和 leafPage 的更新（1）数组 这两个page的array的是不一样的，内部页第一个key为空，leaf则存满。 在实现插入/删除/构造新page的API时，这两个不一样的array常常使得我的下标计算错误，出现各种莫名bug。 （2）叶子是链表关系，内部页是树关系 在分裂过程中，叶子结点要额外维护链表指针关系；内部页则要维护树关系（及时更新child的parent pointer指向）。 页管理page的缓存管理是个大难题，因为我们要手动进行抓取和释放页面的管理（FetchPage和 UnpinPage）。 在实践中，我总结出了两种页管理的机制： 谁fetch，谁unpin； 谁最后一次用page，谁unpin。 首先我们需要知道释放一个页面的时机是什么。答案是：这个页面不用时。 （1）谁fetch，谁unpin 这个的思想在于让第一次fetch的函数作为页面负责人，由它进行释放页面。好比于小明向图书馆借了一本书，然后小明又将这本书借给同学A、同学B、同学C，最后小明还要负责从C手上拿回书，然后小明将书还给图书馆。 1234567891011121314INDEX_TEMPLATE_ARGUMENTSauto BPLUSTREE_TYPE::Insert(const KeyType &amp;key, const ValueType &amp;value, Transaction *transaction) -&gt; bool { .... auto leaf_page = FindLeafPage(key, Operation::INSERT, transaction); auto *leaf_node = reinterpret_cast&lt;LeafPage *&gt;(leaf_page); ... InsertInParent(risen_key, leaf_node, sibling_leaf_node, transaction); ... buffer_pool_manager_-&gt;UnpinPage(leaf_node-&gt;GetPageId(), true); buffer_pool_manager_-&gt;UnpinPage(sibling_leaf_node-&gt;GetPageId(), true); return true;} 在代码中，实际上是函数嵌套的情况，最后一次拿回书的过程其实不用实现。 （2）谁最后一次用page，谁unpin 这个思想应该很好懂了， 结合上面的代码，那么InsertInParent应该负责leaf_node和sibling_leaf_node的页面释放。 （3）意外情况 / 辅助函数设计 在实际实现中，我们会有一个findLeaf的函数，它需要找到叶子页面并交出去。显然这个findLeaf的函数并不能很好地适合第一种页管理的原则，因为它抓取了页面，却不能管理页面的释放。 但是我们这样想就简单多了：将findLeaf视作一个大fetch的函数，其他函数使用它就相当于抓取页面，最后由其他函数负责释放。 迭代器迭代器就是简单的单向链表遍历，只有查找的API，比较容易实现。实现过程犯的错： 在创建迭代器时忘记判断树是否为空，未及时返回END迭代器 辅助函数没有设置树空的判断，导致出现逻辑错误。 并发控制（1）锁存储 由于需要“释放之前持有的锁”这一操作，我们需要一个顺序容器来存储锁，这点请看transaction里的page_set_成员。 （2）锁管理与页管理 锁管理依然有两种方式： 谁加锁，谁负责释放锁 谁最后一次用锁，谁负责释放锁 但是实现螃蟹锁的过程中，我们管理的其实是page的队列，这要求我们一并管理页面：在队列里拿到page，释放这个page的锁，然后释放这个page。 （3）root page id锁 为了代码锁里的简洁，可以添加一个root page id锁，作为root结点的“前置锁”。相当于一个伪根结点，这样判断结点安全的逻辑就很顺畅了：默认我们持有前一个页面锁和现在的结点，再判断结点是否安全后，再释放前一个页面锁或将之添加到锁队列中。 开发经验实验中涉及多个代码文件，虽然实验指导上写着先实现B+树的page，但实际上此时根本不知道怎么设计API。而且这时臆想的接口与直接写B+树时大相径庭。实现中辅助函数是多变的。 12345678910src/include/storage/page/b_plus_tree_page.hsrc/storage/page/b_plus_tree_page.cppsrc/include/storage/page/b_plus_tree_internal_page.hsrc/storage/page/b_plus_tree_internal_page.cppsrc/include/storage/page/b_plus_tree_leaf_page.hsrc/storage/page/b_plus_tree_leaf_page.cppsrc/include/storage/index/b_plus_tree.hsrc/storage/index/b_plus_tree.cppsrc/include/storage/index/index_iterator.hsrc/storage/index/index_iterator.cpp 开发思路：自顶向下，先填充主干，再丰满细节。 b_plus_tree_page.h b_plus_tree_internal_page.h b_plus_tree_leaf_page.h 以上头文件写函数签名，暂时不要考虑实现。 然后在b+树的实现文件b_plus_tree.cpp里将整个函数流程实现，遇到辅助函数就在相应头文件定义。最后再去补充各个头文件的实现，最后再补齐b_plus_tree.h的函数签名。","link":"/2024/04/22/cmu15445/lab/%E5%AE%9E%E9%AA%8Cp2/"},{"title":"Redis学习篇","text":"Redis是一款用C编写的基于内存的非关系数据库，实际开发中，Redis用作缓存数据库，用来减轻后端数据库的压力。Redis全称为：Remote Dictionary Server（远程数据服务）。 Redis官网:：http://redis.io/ 在线尝试：https://try.redis.io/ 咱认为，学习Redis的最佳方式是从项目开始。先学一点数据结构Redis的终端命令，然后再接入SpringBoot快速上手项目使用。学完基本数据使用后，再探究其原理。 基本数据类型Reids的基本数据类型是value的类型，而不是键的类型。 string类型基本读写 12set key value [EX seconds|PX milliseconds] [NX|XX] get key EX|PX 设置过期时间，单位不同； NX （Not Exist），表示键不存在才进行操作，XX相反； 多字符串存取 12mset key value [key2 value2 ...]mget key [key2 ...] 值的加减 1234incr keydecr keyincrby key numberdecrby key number key对应的数据不是字符串类型吗？怎么能进行加减操作？这里埋个坑。 hash类型redis hash 是 字符 filed 和 value 之间的映射表，所以非常适合用于存储对象。比如说key作为对象名，Field作为对象的属性字段，value则是属性字段的值。 基本读写 123hset key field value [field value ...]hget key fieldhdel key field 查看哈希表的所有field： hkeys key 查看哈希表的所有value：hvals key 查看哈希表的所有field value对：hgetall key 判断一个Key是否存在：hexists key field 应用场景hash类型一般适合用来存对象，能够独立存储每个字段，如果需要修改某个字段的值，可针对性修改。适合对象字段频繁改变的情况。 string类型也能用来存储对象，首先将对象序列化为Json字符串，再存入Redis。这样的坏处是修改字段麻烦。适合对象字段不怎么改变的情况。 List类型redis的list相当于Java中的LinkedList，是一个双向链表，可以在头部或者尾部添加元素，当列表弹出最后一个元素后，该结构自动删除。 （1）基本读写 1234lpush key element [element2]lindex key indexrpush key element [element2]rindex key index lpush 可以将一个或多个值依次插入列表的头部，rpush则将一个或多个值依次插入列表的尾部。 lindex获取指定index的值（注意index从0开始） （2）删除元素 12lpop keyrpop key （3）获取区间元素，注意区间是左闭右闭。 1lrange start stop （4）插入元素 1linsert list BEFORE|AFTER target_element new element Set类型set就是集合，集合的元素不重复无序。Redise的Set底层由哈希表实现，查询复杂度为$O(1)$。 添加一个或多个元素 1SADD key element [element2 ...] 移除一个或多个元素 1SREM key element [element2 ..] 获取集合的所有元素 1SMEMBERS key 判断是否是成员 1SISMEMBER key member 集合应用场景（1）用户点赞 用户对某条评论点赞。偶数次点赞会取消赞。这就要求用户是否对某条评论点赞的判断。 利用set的是否是成员快速判断用户是否点赞。如果点赞，就将用户id添加到评论的点赞set里。 （2）共同关注 利用集合取交集的命令，就能实现共同关注的功能。 Zset类型Set是无序集合，ZSet则是有序集合。有序性是因为ZSet中的每个元素关联了一个Score分数，依据分数进行排序。 ZSet的终端命令与Set大体相同，前缀从S换成了Z，并且额外要求一个Score参数。 有序集合应用场景（1）点赞好友显示 朋友圈点赞头像显示。利用时间戳作为Zset的score，就能以时间排序。 （2）朋友圈滚动分页 用户查看朋友圈其实是查看它的收件箱。如果有新动态发布，那一定是在最顶上。以时间戳作为排序就能实现这种情况。 通用命令（1）exists 存在命令 1exists key 判断指定的key是否存在 （2）keys 查找命令 1keys pattern 查找指定模式的键，模式匹配（通配符、正则表达式） （3）rename 重命令 1rename key newKeyName （4）del 删除key 1del key （5）ttl 获取键的生存时间 1ttl key 值得注意：在多个键时，可以用冒号为键分隔，达到更好可视化效果 底层数据结构 简单动态字符串12345struct sdshdr{ int len; //当前保存字符串长度 int free; //当前未使用字符数量 char buf[]; } SDS类似Java的ArrayList、cpp的vector，动态扩容。虽然底层使用字符数组存储字符，但配合了两个整数变量控制存储空间，这两个变量就是实际所占空间大小和剩余空间大小。 SDS采取预先分配冗余空间策略减少内存的频繁分配。当字符串所占空间小于1M时，成倍扩容。超过1M时，每次只扩容1MB，最多512MB。 压缩链表 ZipList1234567struct ziplist&lt;T&gt; { int32 zlbytes; // 全部占用字节数 int32 zltail_offset; // 最后一个元素距离压缩列表起始位置的偏移量，用于快速定位到最后一个节点 int16 zllength; // 元素个数 T[] entries; // 元素内容列表 int8 zlend; // 标志压缩列表的结束，值恒为 0xFF} ZipList与SDS结构相差无几，由连续内存块组成的顺序型数据结构，它有多个entry节点，每个entry节点可以存放整数或者字符串。另外多了几个标志符，字节数、偏移量、长度、结尾标志符。 List 使用压缩链表的情况：List中元素的数量小于或等于16个时，Redis会使用压缩链表进行存储。 hash对象只有同时满足以下条件，才会采用ziplist编码： hash对象保存的键和值字符串长度都小于64字节 hash对象保存的键值对数量小于512 当Zset中元素的数量小于或等于256个时，Redis会使用压缩列表进行存储。 当ziplist作为zset的底层存储结构时候，每个集合元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员，第二个元素保存元素的分值。 哈希表 Redis的哈希表实现其实是字典，一个字典中包含了两个哈希表。一个哈希表里面可以有多个槽，而每个槽保存了一个键值对（或者多个，取决于是否有哈希冲突）。 采用开链法解决哈希冲突，当不同key映射到同一个哈希槽时，Redis会采用链表的方式，将后来的节点链接到上一节点。 双哈希表设计：这是一种以空间换时间的技术。特别是应对ReHash过程（哈希表扩容或收缩）。 当哈希表的负载因子超过一定阈值时，就会将0号哈希表上的键值对转移到1号哈希表上。具体过程为：为1号哈希表申请空间，然后重新计算哈希值和索引，并重新插入到 ht[1] 中，插入一个删除一个。当0号哈希表所有元素转移完成时，释放0的空间，然后将1号设为0号。 注意这个数据转移过程可以是一次性操作、也可以是分批次操作（渐进式rehash）。另外因为有两个哈希表，查询时如果0号哈希表查不到，还需要在1号哈希表再查一次，牺牲了一点查询性能。 整数集合12345typedef struct intset{ uint32_t encoding; //编码方式 uint32_t length; //集合包含的元素数量 int8_t contents[]; //保存元素的数组}intset; 当set存的都是整数，且个数小于512个时，底层使用整数集合。 跳跃链表 SkipList跳表 = 单链表+随机化的多级索引。 它的基本思想是在链表的基础上，增加多级索引，从而提高数据的查找效率。在一般情况下，它的查找、插入、删除等操作的时间复杂度都为O(log n)。 跳表的核心是索引，它通过维护多级有序链表来实现。每一级索引是原始链表的一部分节点组成，每一级索引的元素数量都比它下一级索引的元素数量少一半。最上面一级索引只有两个节点，第二级索引有四个节点，以此类推。通过这种方式，跳表在空间复杂度和时间复杂度之间做到了平衡。 跳表的查找过程与二分查找类似，先在最高级的索引中查找目标节点，然后通过下降到更低一级的索引再次查找，直到在最底层的索引中找到目标节点或者查找到整个跳表中都没有这个节点。由于跳表的结构不依赖于节点的分布情况，所以它可以用来代替平衡树，实现更高效的查找操作。 12345跳跃链表相比红黑树的一些主要好处：算法实现难度：跳跃链表的实现相对简单，而红黑树的实现则需要遵循颜色规则和其他约束条件，因此实现起来更为复杂。空间复杂度与内存占用：跳跃链表的空间复杂度更灵活，可以通过参数设置来调整每个节点包含的指针数量。相比之下，红黑树每个节点通常包含两个指针（指向左右子树）。在某些情况下，跳跃链表可以更节省内存。插入和删除的复杂情况：红黑树在插入或删除节点时，可能会引发子树的调整，且调整范围可能较大。而跳跃链表在插入或删除节点时，通常只需要修改相邻的指针，即进行局部调整，这使得操作更为简单和高效。范围查询：跳跃链表在进行范围查询时更为方便。由于跳跃链表中的元素是有序的，且上层的元素分布较稀疏，因此可以更快地定位到目标范围。相比之下，平衡二叉树（包括红黑树）在范围查询方面可能不如跳跃链表高效。","link":"/2023/12/06/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/Redis/Redis%E5%AD%A6%E4%B9%A0%E7%AF%87/"},{"title":"Redis 应用篇","text":"从应用角度介绍Redis常见应用面试题。 缓存缓存穿透（1）概念 客户端请求的数据在缓存和数据库中都不存在。如果持续发起这个请求，那么缓存会失效，好像不存在。 （2）解决方法 缓存空对象 布隆过滤器 缓存空对象是在数据库未命中时，缓存一个null并设置一个短有效时间。 布隆过滤器则是在缓存前的一道关卡，查询数据是否存在，具体实现未知。 缓存雪崩（1）概念 缓存雪崩就是同一时间大量key失效或者直接Redis宕机。那么这时候针对不同的key的大量请求都会要求重建缓存，数据库压力大。 （2）解决方法 为不同的key设置不同的过期时间（随机TTL） Redis集群 缓存击穿（1）概念 缓存击穿也称之为热点key问题，一旦热点key失效，那么大量的请求都会打到数据库（在缓存重建时间内）。 （2）解决方法 互斥锁：为缓存重建的过程加锁，只有一个线程能拿到锁进行缓存重建，没拿到锁的线程休眠一段时间，再次查缓存，直到缓存重建完成。 逻辑过期：不设置热点key的过期时间，由代码判断key的value中的expireTime字段是否过期。如果过期，由互斥锁保证开启一个新线程重建缓存，未获得锁的其他线程直接返回旧数据。 缓存与数据库的一致性读操作：缓存命中直接返回；缓存未命中，则查询数据库，然后更新缓存并设置有效时间。 写操作：写数据库，然后选择主动更新缓存抑或删除缓存。 四种同步策略（数据库更新时主动更新缓存） 先更新缓存再更新数据库：第二步失败缓存库是脏数据 先更新数据库再更新缓存：第二步失败缓存库是旧数据 先删除缓存再更新数据库：第二步失败缓存库是空数据 先更新数据库、再删除缓存（推荐）：第二步失败缓存库是旧数据 更新缓存or删除缓存更新缓存的优点是每次数据变化都能及时更新缓存，但缺点是操作消耗大，频繁更新缓存会影响服务器性能。 删除缓存优点是操作简单，惰性重建，将重建代价移动到下一次访问。 更新数据库与删除缓存的时序 先删缓存再更新数据库：线程1删除缓存后，线程2查询缓存不存在，然后重新写入缓存，此时缓存为旧数据。线程1再更新数据库为新数据。那么就出现了缓存旧数据、数据库新数据的不一致性。 先更新数据库在删除缓存：恰好缓存数据失效，线程1查缓存失效，查数据库旧数据；线程2更新数据库；线程1再更新缓存。这种不一致性出现概率低。 最优同步策略：先更新数据库、再删除缓存所以我们得到结论：先更新数据库、再删除缓存是影响更小的方案。如果第二步出现失败的情况，则可以采用重试机制解决问题。 同步删除方案： 先更新数据库、再删除缓存。适用于不强制要求数据一致性的情景 流程：先更新数据库、再删除缓存。 问题： 并发时脏数据：在查询数据库到写缓存期间其他线程执行了一次更新删除，导致缓存的数据是旧数据 缓存删除失败：删除失败导致缓存库还是旧数据 同步删除+可靠消息方案同步删除+可靠消息删除： 解决缓存删除失败问题，利用可靠消息多次重试删除缓存操作。 流程：先更新数据库、再删除缓存，如果删除失败就发可靠MQ不断重试删除缓存，直到删除成功或重试5次。 问题：消息队列中消息消费有时延，数据不一致时间较长（适用于不强制要求数据一致性的情景）；MQ多次重试失败，导致长期脏数据 延迟双删：更高一致性流程：先删除缓存再更新数据库，然后在从数据库库更新后再删一次缓存。 为什么要延时呢？为了分布式系统下主从同步。 数据工作的大致流程： 主节点删除 redis 库数据； 主节点修改 mysql 库数据； 当前业务处理 等待一段时间，等 redis 和 mysql 主从节点数据同步； 从节点 redis 主库删除数据； 其它服务节点读取 redis 从库数据，发现没有数据，从 mysql 从库读取数据，并写入 redis 主库。 问题：时间无法控制，不能保证在数据库从库更新后删除缓存。如果在从库更新前删除，用户再在更新前查从库又把脏数据写在缓存里了。 异步监听数据库+可靠消息删除流程： 更新数据库后不做操作； Canal等组件监听binlog发现有更新时就发可靠MQ删除缓存； 如果删除缓存失败，就基于手动ack、retry等机制，让消息在有限次数之内不断重试。 优点： 异步删除，性能更高； 可靠消息重试机制，多次删除保证删除成功。 问题：要求canal等binlog抓取组件高可用，如果canal故障，会导致长期脏数据。 限流常见限流算法： 计数器算法 滑动窗口算法 漏桶算法 令牌桶算法 计数器算法比如说我要维持1秒内最多200个请求访问，那么我就设置一个计数器表示1秒内请求访问的数量，每隔一秒固定清空计数器。可以自定义窗口时间。 12345678910boolean fixedWindowsTryAcquire() { long currentTime = System.currentTimeMillis(); //获取系统当前时间 if (currentTime - lastRequestTime &gt; windowUnit) { //检查是否在时间窗口内 counter = 0; // 计数器清0 lastRequestTime = currentTime; //开启新的时间窗口 } if (counter &gt;= threshold) return flase; counter++; //计数器加1 return true;} 坏处：临界请求问题。比如0.9s有200个请求，1.1s有200个请求，那么实际在0.5到1.5s之间处理了400个请求。 滑动窗口算法滑动窗口的思想是将一个窗口细分为若干个小窗口，每个小窗口独立负责一个时间段的请求限流，随着时间的前进，最旧的窗口丢弃，新的空窗口生成。 通过细化窗口的方式，能够将临界请求也一起细化。 1234567891011121314151617181920212223242526272829303132333435private int SUB_CYCLE = 10; // 单位时间划分的小周期（单位时间是1分钟，10s一个小格子窗口，一共6个格子）private int thresholdPerMin = 100; // 每分钟限流请求数private final TreeMap&lt;Long, Integer&gt; counters = new TreeMap&lt;&gt;(); // 计数器, key为当前窗口的开始时间值秒，value为当前窗口的计数boolean slidingWindowsTryAcquire() { //获取当前时间在哪个小周期窗口 long currentWindowTime = LocalDateTime.now().toEpochSecond(ZoneOffset.UTC) / SUB_CYCLE * SUB_CYCLE; //当前窗口总请求数 int currentWindowNum = countCurrentWindow(currentWindowTime); if (currentWindowNum &gt;= thresholdPerMin) return false; counters.get(currentWindowTime)++; return true;}/*** 统计当前窗口的请求数*/private int countCurrentWindow(long currentWindowTime) { //计算窗口开始位置 long startTime = currentWindowTime - SUB_CYCLE* (60/SUB_CYCLE-1); int count = 0; //遍历存储的计数器 Iterator&lt;Map.Entry&lt;Long, Integer&gt;&gt; iterator = counters.entrySet().iterator(); while (iterator.hasNext()) { Map.Entry&lt;Long, Integer&gt; entry = iterator.next(); // 删除无效过期的子窗口计数器 if (entry.getKey() &lt; startTime) { iterator.remove(); } else { count =count + entry.getValue(); } } return count;} 漏桶算法 漏桶算法采取一个容器存储到来的请求，以生产者消费者的思想处理请求。客户端是生产者，实际流量的产生者；服务端是消费者，负责消费容器中的请求。容器的大小是固定的，超出容器大小的请求将会被丢弃。 这样就能保证以不超过固定消费速率的方式处理请求。缺点是：消费速率固定，无法调整。如果大量请求到来，我们希望提高系统的处理效率。 1234567891011121314151617181920private long rate; // 每秒处理数（出水率）private long currentWater; //当前剩余水量private long refreshTime; // 最后刷新时间private long capacity; // 桶容量boolean leakybucketLimitTryAcquire() { long currentTime = System.currentTimeMillis(); //获取系统当前时间 long outWater = (currentTime - refreshTime) / 1000 * rate; //流出的水量 =(当前时间-上次刷新时间)* 出水率 long currentWater = Math.max(0, currentWater - outWater); // 当前水量 = 之前的桶内水量-流出的水量 refreshTime = currentTime; // 刷新时间 // 当前剩余水量还是小于桶的容量，则请求放行 if (currentWater &lt; capacity) { currentWater++; return true; } // 当前剩余水量大于等于桶的容量，限流 return false;} 令牌桶算法令牌桶算法改良了漏桶算法，使得消费的速率能够调整。具体实现为：漏桶不再存储请求，而是存储令牌。每个请求要先获得令牌才能被处理。 此时桶的生产者和消费者倒置：由服务端以可调整的速率生成令牌，由客户端请求消费令牌。如果请求拿不到令牌，就直接放弃处理。 12345678910111213141516171819private long putTokenRate; //每秒处理数（放入令牌数量）private long refreshTime; //最后刷新时间private long capacity; //令牌桶容量private long currentToken = 0L; // 令牌桶容量boolean tokenBucketTryAcquire() { long currentTime = System.currentTimeMillis(); //获取系统当前时间 long generateToken = (currentTime - refreshTime) / 1000 * putTokenRate; //生成的令牌 =(当前时间-上次刷新时间)* 放入令牌的速率 currentToken = Math.min(capacity, generateToken + currentToken); // 当前令牌数量 = 之前的桶内令牌数量+放入的令牌数量 refreshTime = currentTime; // 刷新时间 //桶里面还有令牌，请求正常处理 if (currentToken &gt; 0) { currentToken--; //令牌数量-1 return true; } return false;} Redis实现限流滑动窗口法主要是利用Redis的ZSet数据结构来实现，每个请求的value都要保持互不相同，score为当前时间戳。利用ZSet的range，查询当前时间窗口内的请求数量，进而达到限流作用。 12345678910111213public Response limitFlow(){ Long currentTime = new Date().getTime(); System.out.println(currentTime); if(redisTemplate.hasKey(&quot;limit&quot;)) { Integer count = redisTemplate.opsForZSet().rangeByScore(&quot;limit&quot;, currentTime - intervalTime, currentTime).size(); // intervalTime是限流的时间 System.out.println(count); if (count != null &amp;&amp; count &gt; 5) { return Response.ok(&quot;每分钟最多只能访问5次&quot;); } } redisTemplate.opsForZSet().add(&quot;limit&quot;,UUID.randomUUID().toString(),currentTime); return Response.ok(&quot;访问成功&quot;); } 通过上述代码可以做到滑动窗口的效果，并且能保证每N秒内至多M个请求，缺点就是zset的数据结构会越来越大。 令牌桶方法Redis实现令牌桶，实际就是让Redis充当桶的角色。类似消息队列的意味，利用Redis的list实现令牌的队列。 12345678910111213// 获得令牌 public Response limitFlow2(Long id){ Object result = redisTemplate.opsForList().leftPop(&quot;limit_list&quot;); if(result == null){ return Response.ok(&quot;当前令牌桶中无令牌&quot;); } return Response.ok(articleDescription2); }// 10S的速率往令牌桶中添加UUID，只为保证唯一性 @Scheduled(fixedDelay = 10_000,initialDelay = 0) public void setIntervalTimeTask(){ redisTemplate.opsForList().rightPush(&quot;limit_list&quot;,UUID.randomUUID().toString()); } 依靠Java的定时任务，定时往List中rightPush令牌，当然令牌也需要唯一性。 全局ID生成全局id生成器，是在分布式系统下用来生成全局唯一ID的工具， 设计思想：时间戳以秒为单位，留下1秒的时间让业务并发。这1秒的时间最多2的32次方个id。我不同的业务使用不同的key自增，业务再怎么大，一秒2的32次方个id也是够用的。 1234567891011121314151617181920212223242526272829303132333435363738@Componentpublic class RedisIdWorker { //开始时间戳 private static final long BEGIN_TIMESTAMP = 1674086400L; //序列号位数 private static final int COUNT_BITS = 32; private StringRedisTemplate stringRedisTemplate; public RedisIdWorker(StringRedisTemplate stringRedisTemplate) { this.stringRedisTemplate = stringRedisTemplate; } public long nextId(String keyPrefix){ //1.生成时间戳 LocalDateTime time = LocalDateTime.now(); long nowSecond = time.toEpochSecond(ZoneOffset.UTC); long timestamp = nowSecond - BEGIN_TIMESTAMP; //2.生成序列号,redis自增长,redis单个key自增长有上限，2的64次方 //2.1获取当前日期，精确到天 String date = time.format(DateTimeFormatter.ofPattern(&quot;yyyy:MM:dd&quot;)); long count = stringRedisTemplate.opsForValue().increment(&quot;icr:&quot; + keyPrefix + &quot;:&quot; + date); //3.拼接并返回,不能使用字符串方式拼接 return timestamp &lt;&lt; COUNT_BITS | count;//先向左移32位，那么低32位全为0，跟序列号进行或操作 } /** * 生成开始时间戳 * @param args */ public static void main(String[] args) { LocalDateTime time = LocalDateTime.of(2023, 1, 19, 0, 0, 0); long second = time.toEpochSecond(ZoneOffset.UTC); System.out.println(second); }} 分布式锁简单的分布式锁利用setnx实现简单的分布式锁，锁名称由业务决定，并完成锁的初始化（初始化需要传入锁名称）tryLock返回加锁是否成功的判断。锁需要设置超时过期时间，避免业务阻塞造成锁无法释放。 获取锁 1SET lock thread1 NX EX 10 释放锁 1DEL key 1234567891011121314151617181920212223public class SimpleRedisLock implements ILock{ private StringRedisTemplate stringRedisTemplate; private String lock_name; //业务名称 public SimpleRedisLock(StringRedisTemplate stringRedisTemplate, String name){ this.stringRedisTemplate = stringRedisTemplate; lock_name = name; } @Override public boolean tryLock(long timeoutSec) { // 1、确定key和value String key = &quot;lock:&quot; + lock_name; String value = Thread.currentThread().getId() + &quot;&quot;; // 2、执行setnx Boolean succ = stringRedisTemplate.opsForValue().setIfAbsent(key, value, timeoutSec, TimeUnit.SECONDS); return Boolean.TRUE.equals(succ); } @Override public void unlock() { String key = &quot;lock:&quot; + lock_name; stringRedisTemplate.delete(key); }} 加锁失败，由业务自己决定是否重试。 改进分布式锁锁二次删除问题考虑这么一个场景：线程获得锁后阻塞，超过过期时间，锁删除。第二个线程获得锁，但一个线程恢复后删除了第二个线程持有的锁。最后导致第三个线程又获得了锁。 改进方法：利用锁的value来判断当前持有锁的线程。每个机器上线程都要有一个全局ID。释放锁时需要判断锁是否是自己的。 加锁：指定锁的value 为线程的全局ID。 释放锁：释放锁一共有三个步骤，先获取锁的value，然后判断value是否为当前线程ID，如果是才能删除锁。 12345678910111213141516171819202122232425262728public class SimpleRedisLock implements ILock{ private StringRedisTemplate stringRedisTemplate; private String lock_name; //业务名称 public SimpleRedisLock(StringRedisTemplate stringRedisTemplate, String name){ this.stringRedisTemplate = stringRedisTemplate; lock_name = name; } private final String KEY_PREFIX = &quot;lock:&quot;; private final String VALUE_PREFIX = UUID.randomUUID().toString(true)+&quot;-&quot;; @Override public boolean tryLock(long timeoutSec) { // 1、确定key和value String key = KEY_PREFIX + lock_name; String value = VALUE_PREFIX + Thread.currentThread().getId(); // 2、执行setnx Boolean succ = stringRedisTemplate.opsForValue().setIfAbsent(key, value, timeoutSec, TimeUnit.SECONDS); return Boolean.TRUE.equals(succ); } @Override public void unlock() { String key = KEY_PREFIX + lock_name; String value = VALUE_PREFIX + Thread.currentThread().getId(); String lock_value = stringRedisTemplate.opsForValue().get(key); if(StrUtil.equals(value, lock_value)) // 线程只能释放自己持有的锁！ stringRedisTemplate.delete(key); }} 释放锁原子性问题释放锁的过程可能被阻塞（JVM的垃圾回收机制导致的短暂阻塞），因此要采用LUA脚本保证原子性。 （1）编写lua脚本 12345678910-- 获取key和valuelocal key = KEYS[1]local value = ARGV[1]-- 判断get（key）和value是否一致local lock_value = redis.call('GET', key)if lock_value == value then return redis.call('DEL', key)endreturn 0 （2）加载lua脚本并执行 1234567891011121314151617181920212223242526272829303132333435363738public class SimpleRedisLock implements ILock{ private StringRedisTemplate stringRedisTemplate; private String lock_name; //业务名称 public SimpleRedisLock(StringRedisTemplate stringRedisTemplate, String name){ this.stringRedisTemplate = stringRedisTemplate; lock_name = name; } /** * 加载Lua脚本 */ private static final DefaultRedisScript&lt;Long&gt; LOCK_SCRIPT; static { LOCK_SCRIPT = new DefaultRedisScript&lt;&gt;(); LOCK_SCRIPT.setLocation(new ClassPathResource(&quot;lock.lua&quot;)); LOCK_SCRIPT.setResultType(Long.class); } private final String KEY_PREFIX = &quot;lock:&quot;; private final String VALUE_PREFIX = UUID.randomUUID().toString(true)+&quot;-&quot;; @Override public boolean tryLock(long timeoutSec) { // 1、确定key和value String key = KEY_PREFIX + lock_name; String value = VALUE_PREFIX + Thread.currentThread().getId(); // 2、执行setnx Boolean succ = stringRedisTemplate.opsForValue().setIfAbsent(key, value, timeoutSec, TimeUnit.SECONDS); return Boolean.TRUE.equals(succ); } @Override public void unlock() { String key = KEY_PREFIX + lock_name; String value = VALUE_PREFIX + Thread.currentThread().getId(); // 调用LUA脚本释放锁,保证原子性 stringRedisTemplate.execute(LOCK_SCRIPT, Collections.singletonList(key), value); }} 至此，一个简单的不可重入的无重试机制的分布式锁就完成了。 后续改进： 可重入性（需要记录线程获锁的次数，当次数为0时释放锁） 重试机制 续约机制 主从一致性问题 可重入分布式锁实现可重入锁需要维护引用计数，简单的string类型无法满足需求，需要换用hash类型。 加锁：两次判断，第一次判断锁是否存在；如果不存在创建锁；如果存在，增加引用计数。 释放锁：两次判断，引用计数减1；如果引用计数为0，删除锁。 由于加锁和释放锁都是多步操作，因此均采用LUA脚本。 （1）获取锁的lua脚本 1234567891011121314151617181920local key = KEYS[1]local threadId = ARGV[1]local releaseTime = ARGV[2]-- 1、查询key是否存在-- 1.1 不存在直接获取锁，并设置过期时间if (redis.call('exists', key) == 0) then redis.call('hset', key, threadId, '1') redis.call('expire', key, releaseTime) return 1end-- 2、如果key存在，再比较field是否是当前线程(锁是否是自己的）-- 2.1 如果是当前线程，引用计数加1并重设有效期返回tureif (redis.call('hexists', key, threadId) == 1) then redis.call('hincrby', key, threadId, '1') redis.call('expire', key, releaseTime) return 1end-- return 1 获取锁成功，0失败return 0 （2）释放锁的lua脚本 123456789101112131415161718192021local key = KEYS[1]local threadId = ARGV[1]local releaseTime = ARGV[2]-- 1、判断要释放的锁是否存在if (redis.call('hexists', key, threadId) == 0) then return nilend-- 2、锁存在，引用计数减1local count = redis.call('HINCRBY', key, threadId, -1);-- 进一步判断是否需要释放锁if (count &gt; 0) then -- 重入次数大于0，说明不能释放锁，且刷新锁的有效期 redis.call('EXPIRE', key, releaseTime); return nil;else -- 重入次数等于0，说明可以释放锁 redis.call('DEL', key); return nil;end （3）可重入锁类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package com.hmdp.utils;import cn.hutool.core.lang.UUID;import cn.hutool.core.util.StrUtil;import org.springframework.core.io.ClassPathResource;import org.springframework.data.redis.core.StringRedisTemplate;import org.springframework.data.redis.core.script.DefaultRedisScript;import java.util.Collections;import java.util.concurrent.TimeUnit;public class SimpleRedisLock implements ILock{ private StringRedisTemplate stringRedisTemplate; private String lock_name; //业务名称 private long timeOutSec; public SimpleRedisLock(StringRedisTemplate stringRedisTemplate, String name){ this.stringRedisTemplate = stringRedisTemplate; lock_name = name; } /** * 加载Lua脚本 */ private static final DefaultRedisScript&lt;Long&gt; LOCK_SCRIPT; private static final DefaultRedisScript&lt;Long&gt; UNLOCK_SCRIPT; static { LOCK_SCRIPT = new DefaultRedisScript&lt;&gt;(); LOCK_SCRIPT.setLocation(new ClassPathResource(&quot;get_lock.lua&quot;)); LOCK_SCRIPT.setResultType(Long.class); UNLOCK_SCRIPT = new DefaultRedisScript&lt;&gt;(); UNLOCK_SCRIPT.setLocation(new ClassPathResource(&quot;release_lock.lua&quot;)); UNLOCK_SCRIPT.setResultType(Long.class); } private final String KEY_PREFIX = &quot;lock:&quot;; private final String VALUE_PREFIX = UUID.randomUUID().toString(true)+&quot;-&quot;; @Override public boolean tryLock(long timeoutSec) { this.timeOutSec = timeoutSec; // 1、确定key和value String key = KEY_PREFIX + lock_name; String value = VALUE_PREFIX + Thread.currentThread().getId(); // 2、执行setnx// Boolean succ = stringRedisTemplate.opsForValue().setIfAbsent(key, value, timeoutSec, TimeUnit.SECONDS); Long result = stringRedisTemplate.execute(LOCK_SCRIPT, Collections.singletonList(key), value, Long.toString(timeoutSec));// System.out.println(result); return result!=null &amp;&amp; result.equals(1L); } @Override public void unlock() { String key = KEY_PREFIX + lock_name; String value = VALUE_PREFIX + Thread.currentThread().getId();// String lock_value = stringRedisTemplate.opsForValue().get(key);// if(StrUtil.equals(value, lock_value)) // 线程只能释放自己持有的锁！// stringRedisTemplate.delete(key); // 调用LUA脚本释放锁,保证原子性 stringRedisTemplate.execute(UNLOCK_SCRIPT, Collections.singletonList(key), value, Long.toString(this.timeOutSec)); }} 滚动推送TimeLine推送模型最典型的就是朋友圈，按照内容产生的时间顺序推送给关注用户。 实现模式：推模式、拉模式、推拉结合 推模式就是当前用户发布一条内容后，马上将这条内容推送到每个粉丝的收件箱。适合粉丝数少的一般人。 拉模式则相反，用户发布的内容先暂存到发件箱，当粉丝用户查看内容时，再从发件箱拉取内容到收件箱消费。适合粉丝众多的大V。 推拉模式结合适合用于大V的活跃粉丝和不活跃粉丝。活跃粉丝用推模式，不活跃粉丝用拉模式。 Redis实现推模式推模式包括推送加收取。推送：将内容id推送的粉丝的收件箱；拉取：从个人收件箱拉取推文id。 可以利用set维护用户关注表，查找出所有粉丝ID。收件箱利用ZSet，每个推文加上时间戳。 1234567891011121314151617@Overridepublic Result saveBlog(Blog blog) { // 获取登录用户 UserDTO user = UserHolder.getUser(); blog.setUserId(user.getId()); // 保存探店博文 save(blog); // 1、查找当前用户的粉丝 List&lt;Follow&gt; follows = followService.query().eq(&quot;follow_user_id&quot;, user.getId()).list(); // 2、将blog的id推送到粉丝的收件箱 follows.forEach( follow -&gt; { stringRedisTemplate.opsForZSet().add(FEED_KEY+follow.getUserId(), blog.getId().toString(), System.currentTimeMillis()); } ); return Result.ok(blog.getId());} 滚动分页查询：回想起朋友圈，可以一直往下滚动，浏览旧时间的朋友圈内容。如果想消费最新内容，往上滑刷新，就得到了最新内容。 实现：对推文进行时间戳进行降序排序，记录每次读的最后一条推文的时间戳位置。下次读从上次记录到的位置开始。如果是刷新的情况，则从头开始读（新的推文一定在头部，因为时间戳较大）。 这在Redis的ZSet对应的命令如下： 1ZREVRANGEBYSCORE key Max Min LIMIT offset count ZSet+Reverse+RangeByScore，按照分数降序排序。Max则是要读取的最大分数，Min是要读取的最低分数。offset就是偏移量，count就是读取的数据条数。 12345678910111213141516171819202122232425262728293031323334353637383940@Overridepublic Result queryBlogOfFollow(Long lastId, Integer offset) { Long userId = UserHolder.getUser().getId(); //1、从Redis的收件箱中查询博客id // ZREVRANGEBYSCORE key Max Min LIMIT offset count Set&lt;ZSetOperations.TypedTuple&lt;String&gt;&gt; typedTuples = stringRedisTemplate.opsForZSet() .reverseRangeByScoreWithScores(FEED_KEY + userId, 0, lastId, offset, 2); if(typedTuples==null||typedTuples.isEmpty()){ return Result.ok(); } //2、解析获得的数据 List&lt;Long&gt; ids = new ArrayList&lt;&gt;(typedTuples.size()); long minTime = 0; int ofset = 1; for (ZSetOperations.TypedTuple&lt;String&gt; typedTuple : typedTuples) { String idStr = typedTuple.getValue(); ids.add(Long.valueOf(idStr)); long time = typedTuple.getScore().longValue(); if(time == minTime){ ofset+=1; }else{ minTime = time; ofset=1; } } //3、从数据库中查询博客的具体信息 String idStrs = StrUtil.join(&quot;,&quot;, ids); List&lt;Blog&gt; blogs = query().in(&quot;id&quot;, ids).last(&quot;ORDER BY FIELD(id,&quot; + idStrs + &quot;)&quot;) .list(); blogs.forEach(blog-&gt;{ queryUserByBlog(blog); isBlogLiked(blog); }); // 4、封装并返回 ScrollResult scrollResult = new ScrollResult(); scrollResult.setList(blogs); scrollResult.setOffset(ofset); scrollResult.setMinTime(minTime); return Result.ok(scrollResult);} 其中第一次查询时，lastId传当前时间戳；此后第二次查询，lastId为上次查询的最小时间戳， 偏移量是为了记住同一时间发布的推文数量，假如上次查询的最小时间戳一共有5条推文，那么下次查询必须从第6次推文读起。","link":"/2024/02/19/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/Redis/Redis%E5%BA%94%E7%94%A8%E7%AF%87/"},{"title":"Redis系统篇","text":"从系统维度介绍Redis的常见面试题。参考：https://zhuanlan.zhihu.com/p/427496556 基本数据类型与应用场景 缓存 排行榜 计数器应用 共享Session 分布式锁 消息队列 位操作 string类 应用场景：缓存（共享session）、分布式锁，计数器、限流。 哈希类 应用场景：缓存用户信息等。 列表 1234lpush+lpop=Stack（栈）lpush+rpop=Queue（队列）lpsh+ltrim=Capped Collection（有限集合）lpush+brpop=Message Queue（消息队列） 应用场景：消息队列 集合 应用场景：用户标签、共同好友 有序集合 应用场景：排行榜 Redis为什么快? 基于内存 redis是纯内存操作：数据存放在内存中，内存的响应时间大约是100纳秒，这是Redis每秒万亿级别访问的重要基础。 非阻塞I/O：Redis采用epoll作为I/O多路复用技术的实现，再加上Redis自身的事件处理模型将epoll中的连接，读写，关闭都转换为了时间，不在I/O上浪费过多的时间。 单线程机制Redis用单线程处理客户端请求，避免了线程切换和竞争态消耗。 Redis基于Reactor模式开发了自己的网络事件处理器，由以下这四部分组成。 套接字； I/O多路复用程序； 文件事件分派器（dispatcher）； 事件处理器 IO多路复用思想是：让内核遍历socker是否就绪，而不是线程sleep+遍历+非阻塞套接字。 底层数据结构Redis支持多种复杂数据结构，如字符串、列表、集合、有序集合和哈希表等。这些数据结构在某些场景下能够显著提高性能。 过期删除策略过期校验首先，Redis维护了一个过期字典，expires字典会保存所有设置了过期时间的key的过期时间数据，其中，key是指向键空间中的某个键的指针，value是该键的毫秒精度的UNIX时间戳表示的过期时间。 任何对key的查询都要先查过期字典，如果不在过期字典中，说明是持久数据（没有设置过期时间的数据）。 如果在字典中，就校验是否过期，没过期才继续查询。 过期删除Redis维护了两种过期删除策略，实际上这两种过期策略都有使用。 惰性删除（被动删除） 定期删除（主动删除） （1）惰性删除 一个key只有被访问时才去判断是否已经过期，如果过期了，就删除它。这是一种被动删除的策略。 优点：在执行查询时才检查key是否过期，CPU友好 缺点：存在未访问的过期key堆积现象，内存得不到有效清理（内存不友好） （2）定期删除 Redis每隔100ms就随机抽取一定数量的key进行过期检查和删除。如果过期的key占比全部抽样key超过25%，那么Redis就会继续进行抽样检测。同时为了避免抽样检测的无限进行，设置了一个最长任务时间。 优点：较为平衡的策略，cpu压力低同时也能执行删除策略。 缺点：定期任务的频率和时长难以控制。频率高则CPU压力大，时长低则删除不彻底。 内存淘汰策略当Redis的运行内存达到max_memory，就会触发内存淘汰机制。此时内存不足以容纳新数据的写入。 内存淘汰主要可分为三大类，共8种： 不进行内存淘汰，直接报错服务不可用； 针对设置过期时间的key的内存淘汰策略； 针对没有设置过期时间的key的内存淘汰策略。 后两者差不多，只不过针对的key不同。$4+3+1 = 8$ 1234567ttl：淘汰最早过期时间的keyrandom：随机淘汰lru：最少最近使用lfu：最少不常用 LRUleast Recently Used ，Recently Used 即最近使用的，least最少的。从时间的角度上淘汰key，即淘汰距离上一次使用时间最长的key。 LRU算法的思想是：如果一个数据在最近一段时间没有被访问到，那么可以认为在将来它被访问的可能性也很小。因此，当空间满时，最久没有访问的数据最先被置换（淘汰）。 实现：我们可以用双向链表（LinkedList）+哈希表（HashMap）实现（链表用来表示位置，哈希表用来存储和查找），在Java里有对应的数据结构LinkedHashMap。 1234LRU算法的描述： 设计一种缓存结构，该结构在构造时确定大小，假设大小为 K，并有两个功能：set(key,value)：将记录(key,value)插入该结构。当缓存满时，将最久未使用的数据置换掉。get(key)：返回key对应的value值。 LFULFU（Least Frequently Used ，最近最少使用算法），从使用次数的角度上淘汰key，即淘汰最少使用次数的数据。 LFU的每个数据块都有一个引用计数，所有数据块按照引用计数排序，具有相同引用计数的数据块则按照时间排序。 实现：考虑到 LFU 会淘汰访问使用次数最小的数据，即选出使用次数最小的元素，最终实现策略为小顶堆+哈希表。 123456LFU 算法的描述：设计一种缓存结构，该结构在构造时确定大小，假设大小为 K，并有两个功能：set(key,value)：将记录(key,value)插入该结构。当缓存满时，将访问频率最低的数据置换掉。get(key)：返回key对应的value值。 持久化机制redis是一个内存数据库，当Redis服务重启时，在内存中的数据就会丢失。所以需要定期将内存中的数据同步到硬盘文件来保证数据的持久化。当Redis重启时，通过加载硬盘文件到内存，就能达到恢复数据的目的。 redis主要有两种持久化的手段： AOF （append only file， 只追加文件） RDB （Redis DataBase， 基于Redis数据库） AOF（1）概念 AOF就是append only file， 只追加文件。通过日志的方式记录Redis的每个“写”命令。 在Redis服务重启时，重新加载执行日志文件中的命令，从而达到恢复数据的效果。 （2）应用场景 优点：稳定、数据完整性好； 适合场景：数据安全性要求高（订单、购物车） 缺点：AOF文件会越来越大，比较冗余 RDB（1）概念 RDB就是Redis Databse，基于Redis的数据库文件。这是指在一定的时间间隔内，将内存中的键值对数据以数据集快照的形式写入磁盘。也就是保存某个时间点的快照，这个快照文件就是RDB。 Redis定时执行一个子进程，这个子进程将数据写到RDB临时文件，等待临时文件写完，就将临时文件替换RDB文件。 （2）应用场景 优点：恢复大数据集速度比AOF快 适合场景：数据备份 缺点：基于数据备份的方式会丢失上次备份与服务宕机时间点之间的数据 实际 使用通常都是结合两者来。 Redis集群/高可用为什么要集群？因为单台服务器部署的Redis服务不能满足高并发压力，且服务稳定性也无法得到保障（单服务器挂之后，整个系统可能就会崩溃）。 主从模式主从模式，就是一台Redis服务器作为主服务器，同时有若干台服务器作为从服务器。主从服务器通常采取读写分离的策略，主服务器可以进行读写操作，从服务器只读。 也就是说：数据修改只在主服务器上，然后主服务器将最新数据同步给从服务器。从节点的数据来自主节点，实现原理就是主从复制机制。主从复制包括全量复制，增量复制两种。 （1）全量复制 一般当slave第一次启动连接master，或者认为是第一次连接，就采用全量复制。 123456781.slave发送sync命令到master。2.master接收到SYNC命令后，执行bgsave命令，生成RDB全量文件。3.master使用缓冲区，记录RDB快照生成期间的所有写命令。4.master执行完bgsave后，向所有slave发送RDB快照文件。5.slave收到RDB快照文件后，载入、解析收到的快照。6.master使用缓冲区，记录RDB同步期间生成的所有写的命令。7.master快照发送完毕后，开始向slave发送缓冲区中的写命令;8.salve接受命令请求，并执行来自master缓冲区的写命令 （2）增量复制 slave与master同步之后，master上的数据，如果再次发生更新，就会触发增量复制。 master节点会判断用户执行的命令是否有数据更新，如果有数据更新的话，并且slave节点不为空，就会执行此函数。这个函数作用就是：把用户执行的命令发送到所有的slave节点，让slave节点执行。 （3）主从模式存在的问题 数据不一致 客户端可能读到落后的副本，进而读到不一致的数据。 容错 主从模式中，一旦主节点由于故障不能提供服务，需要人工将从节点晋升为主节点，同时还要通知应用方更新主节点地址。Redis从2.8开始正式提供了Redis Sentinel（哨兵）架构来解决这个问题。 哨兵模式哨兵模式，由一个或多个Sentinel实例组成的Sentinel系统，它可以监视所有的Redis主节点和从节点，并在被监视的主节点进入下线状态时，自动将下线主服务器属下的某个从节点升级为新的主节点。 但是呢，一个哨兵进程对Redis节点进行监控，就可能会出现问题（单点问题），因此，可以使用多个哨兵来进行监控Redis节点，并且各个哨兵之间还会进行监控。 哨兵监测到主节点宕机，会自动将从节点切换成主节点，然后通过发布订阅模式通知其他的从节点，修改配置文件，让它们切换主机； 哨兵之间还会相互监控。 Cluster集群Cluster集群实现了Redis的分布式存储。对数据进行分片，也就是说每台Redis节点上存储不同的内容，来解决在线扩容的问题。并且，它也提供复制和故障转移的功能。 Hash Slot插槽算法使用的哈希映射也比较简单，用CRC16算法计算出一个16 位的值，再对16384（$2^{14}$)取模。 集群中的每个节点负责一部分的hash槽，比如当前集群有A、B、C个节点，每个节点上的哈希槽数 =16384/3，那么就有： 节点A负责0~5460号哈希槽 节点B负责5461~10922号哈希槽 节点C负责10923~16383号哈希槽 Redis 大Key通常以Key的大小和Key中成员的数量来综合判定大Key： Key本身的数据量过大：一个String类型的Key，它的值为5 MB。 Key中的成员数过多：一个ZSET类型的Key，它的成员数量为10,000个。 Key中成员的数据量过大：一个Hash类型的Key，它的成员数量虽然只有1,000个但这些成员的Value（值）总大小为100 MB。 大Key带来的常见问题 客户端执行命令的时长变慢。 Redis内存达到maxmemory参数定义的上限引发操作阻塞或重要的Key被逐出，甚至引发内存溢出（Out Of Memory）。 集群架构下，某个数据分片的内存使用率远超其他数据分片，无法使数据分片的内存资源达到均衡。 对大Key执行读请求，会使Redis实例的带宽使用率被占满，导致自身服务变慢，同时易波及相关的服务。 对大Key执行删除操作，易造成主库较长时间的阻塞，进而可能引发同步中断或主从切换。 大key的常见处理办法： string类型 压缩处理 进行序列化压缩，代价是反序列化读取； list/set类型 分片处理 进行分片、拆分； 对大Key进行清理（删除） 将不适用Redis能力的数据存至其它存储，并在Redis中删除此类数据。 说明 Redis 4.0及之后版本：您可以通过UNLINK命令安全地删除大Key甚至特大Key，该命令能够以非阻塞的方式，逐步地清理传入的Key。 Redis 4.0之前的版本：建议先通过SCAN命令读取部分数据，然后进行删除，避免一次性删除大量key导致Redis阻塞。 Redis 热点Key阿里云手册关于热点key问题的链接 什么是热Key呢？在Redis中，我们把访问频率高的key，称为热点key。 而热点Key是怎么产生的呢？主要原因有两个： 用户消费的数据远大于生产的数据：如秒杀、热点新闻等读多写少的场景。 请求分片集中，超过单Redi服务器的性能：比如固定名称key，Hash落入同一台服务器，瞬间访问量极大，超过机器瓶颈，产生热点Key问题。 怎么解决热点key问题？ 在Redis集群架构中对热Key进行复制，将热点数据分散存储在多个Redis节点上 例如将热Key foo复制出3个内容完全一样的Key并名为foo2、foo3、foo4，将这三个Key迁移到其他数据分片来解决单个数据分片的热Key压力。 该方案的缺点在于需要联动修改代码，同时带来了数据一致性的挑战（由原来更新一个Key演变为需要更新多个Key），仅建议该方案用来解决临时棘手的问题。 使用二级缓存（即JVM本地缓存+Redis缓存，减少Redis读请求） 限制流量 限流是通过控制请求的速率来防止系统过载。在应用层实现限流，可以有效减轻热点Key对Redis的压力。常见的限流算法有漏桶算法和令牌桶算法。","link":"/2023/12/13/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/Redis/Redis%E7%B3%BB%E7%BB%9F%E7%AF%87/"},{"title":"muduo网络库学习","text":"《Linux多线程服务端编程：使用muduo C++网络库》，muduo的核心我认为是EventLoop、Poller、Channel。EventLoop实现了one loop per thread 语义，poller管理众多channel、channel管理fd以及相关的事件回调。三者互相配合，实现了简洁高效的网络库。 注：为展示核心逻辑，贴出的代码有删减。 前置知识std::bind std::function eventfd 前置知识：eventfd相当于一个计数器，可以随时对它写，但只能在计数器有值时可读。写入为累加操作，读取可每次读1或者读全部，随后减去读取的值。 那么eventfd有什么作用？事件通知/事件驱动。 线程b监听一个eventfd，线程a如果想要通知线程b，只需要向eventfd中写值就行了。 引用eventfs的Manual中NOTE段落的第一句话： Applications can use an eventfd file descriptor instead of a pipe in all cases where a pipe is used simply to signal events. 在信号通知的场景下，相比pipe有非常大的资源和性能优势。其根本在于counter（计数器）和channel（数据信道）的区别。 第一，是打开文件数量的巨大差别。由于pipe是半双工的传统IPC方式，所以两个线程通信需要两个pipe文件，而用eventfd只要打开一个文件。众所周知，文件描述符可是系统中非常宝贵的资源，linux的默认值也只有1024而已。那开发者可能会说，1相比2也只节省了一半嘛。要知道pipe只能在两个进程/线程间使用，并且是面向连接（类似TCP socket）的，即需要之前准备好两个pipe；而eventfd是广播式的通知，可以多对多的。如上面的NxM的生产者-消费者例子，如果需要完成全双工的通信，需要NxMx2个的pipe，而且需要提前建立并保持打开，作为通知信号实在太奢侈了，但如果用eventfd，只需要在发通知的时候瞬时创建、触发并关闭一个即可。 第二，是内存使用的差别。eventfd是一个计数器，内核维护几乎成本忽略不计，大概是自旋锁+唤醒队列（后续详细介绍），8个字节的传输成本也微乎其微。但pipe可就完全不是了，一来一回数据在用户空间和内核空间有多达4次的复制，而且更糟糕的是，内核还要为每个pipe分配至少4K的虚拟内存页，哪怕传输的数据长度为0。 第三，对于timerfd，还有精准度和实现复杂度的巨大差异。由内核管理的timerfd底层是内核中的hrtimer（高精度时钟定时器），可以精确至纳秒（1e-9秒）级，完全胜任实时任务。而用户态要想实现一个传统的定时器，通常是基于优先队列/二叉堆，不仅实现复杂维护成本高，而且运行时效率低，通常只能到达毫秒级。 所以，第一个最佳实践法则：当pipe只用来发送通知（传输控制信息而不是实际数据），放弃pipe，放心地用eventfd/timerfd，”in all cases”。 另外一个重要优势就是eventfd/timerfd被设计成与epoll完美结合，比如支持非阻塞的读取等。事实上，二者就是为epoll而生的（但是pipe就不是，它在Unix的史前时代就有了，那时不仅没有epoll连Linux都还没诞生）。应用程序可以在用epoll监控其他文件描述符的状态的同时，可以“顺便“”一起监控实现了eventfd的内核通知机制，何乐而不为呢？ https://zhuanlan.zhihu.com/p/40572954 从echo服务器例子看起muduo库是怎么搭建echo服务器的？下面的例子展示了两个组件： EventLoop Server 调用Server的start以及EventLoop的loop后，整个服务器就开始运行了。 123456789101112int main(){ EventLoop loop;。 //InetAddress是对socket编程中的sockaddr_in进行封装，使其变为更友好简单的接口而已 InetAddress addr(4567); EchoServer server(&amp;loop, addr, &quot;EchoServer-01&quot;); server.start(); loop.loop(); return 0;} 下面再看看Server是如何编写的。我们的Server有两个成员变量： EventLoop TcpServer EventLoop是muduo库的核心，这里先按下不表。EchoServer的构造函数和Start方法其实都是调用TcpServer的方法，前者注册两种事件的回调，后者调用TcpServer的start方法。 这里注册了两种事件的回调：连接事件和可读事件。 12345678910111213141516171819202122232425262728293031323334353637383940414243class EchoServer{public: EchoServer(EventLoop *loop, const InetAddress &amp;addr, const std::string &amp;name) : server_(loop, addr, name), loop_(loop) { // 将用户定义的连接事件处理函数注册进TcpServer中，TcpServer发生连接事件时会执行onConnection函数。 server_.setConnectionCallback( std::bind(&amp;EchoServer::onConnection, this, std::placeholders::_1) ); // 将用户定义的可读事件处理函数注册进TcpServer中，TcpServer发生可读事件时会执行onMessage函数。 server_.setMessageCallback( std::bind(&amp;EchoServer::onMessage, this, std::placeholders::_1, std::placeholders::_2, std::placeholders::_3) ); // 设置线程数量 server_.setThreadNum(3); } void start(){server_.start();}private: void onConnection(const TcpConnectionPtr &amp;conn) { // 用户定义的连接事件处理函数：当服务端接收到新连接建立请求，则打印Connection UP，如果是关闭连接请求，则打印Connection Down if (conn-&gt;connected()) LOG_INFO(&quot;Connection UP : %s&quot;, conn-&gt;peerAddress().toIpPort().c_str()); else LOG_INFO(&quot;Connection DOWN : %s&quot;, conn-&gt;peerAddress().toIpPort().c_str()); } void onMessage(const TcpConnectionPtr &amp;conn, Buffer *buf, Timestamp time) { // 用户定义的可读事件处理函数：当一个Tcp连接发生了可读事件就把它这个接收到的消息原封不动的还回去 std::string msg = buf-&gt;retrieveAllAsString(); conn-&gt;send(msg); conn-&gt;shutdown(); }private: EventLoop *loop_; TcpServer server_;}; 回调注册的艺术可以看到，muduo库使用非常简单，只要和EventLoop和TcpServer两个交流即可： EventLoop调用Loop函数 TcpServer注册事件回调以及调用setThreadNum和start函数 如果要继续了解muduo，那么得深入了解TcpServer的实现： TcpServer注册了Acceptor的回调 TcpServer内含有一个线程池 Acceptor::listen函数在loop内运行runInLoop 1234567891011121314151617TcpServer::TcpServer(EventLoop* loop, const InetAddress&amp; listenAddr) : loop_(CHECK_NOTNULL(loop)), ipPort_(listenAddr.toIpPort()){ acceptor_-&gt;setNewConnectionCallback( std::bind(&amp;TcpServer::newConnection, this, _1, _2) );}void TcpServer::start(){ threadPool_-&gt;start(threadInitCallback_); loop_-&gt;runInLoop( std::bind(&amp;Acceptor::listen, get_pointer(acceptor_)) );} 这里不禁发问： Acceptor是什么东西，为什么又注册了回调？ runInLoop是什么含义？为什么要运行Acceptor的listen函数？ 从字面意思上可以猜测，Acceptor是连接接受类，管理连接事件。listen函数其实就是监听开始，runInLoop就是让loop所在的线程执行listen函数。 换个方向123456789101112131415161718192021222324252627282930void EventLoop::loop(){ while (!quit_){ activeChannels_.clear(); pollReturnTime_ = poller_-&gt;poll(kPollTimeMs, &amp;activeChannels_); for (Channel* channel : activeChannels_){ currentActiveChannel_ = channel; currentActiveChannel_-&gt;handleEvent(pollReturnTime_); } doPendingFunctors(); }}void EventLoop::doPendingFunctors(){ std::vector&lt;Functor&gt; functors; callingPendingFunctors_ = true; { MutexLockGuard lock(mutex_); functors.swap(pendingFunctors_); } for (const Functor&amp; functor : functors){ functor(); } callingPendingFunctors_ = false;} loop函数的实现回归了poll/epoll调用的范例： 先调用poller_-&gt;poll进行监听事件 再调用currentActiveChannel_-&gt;handleEvent进行活跃事件的处理 最后调用doPendingFunctors()处理其他不紧急的事件 这里先不管poller（大概率是epoll/poll的封装 ）和 Channel。 Wait，既然loop函数在busy-querying，那么loop对应的线程又是怎么runInLoop的？ One Loop Per Threadone loop per thread是muduo的核心：一个EventLoop绑定一个线程。你有任务交给这个eventloop，那么eventloop对应的线程就会干活，有两种让线程干活的方式： runInLoop 马上进行 queueInLoop 排队进行 那么，如何保证一个EventLoop对应一个线程？muduo采用的方案也很简单，eventLoop持有所在线程的线程号，当你有任务交给一个eventLoop做时，它先校验当前线程号是否与自己持有的线程号相同： 如果相同，说明在同一个线程中，唤醒线程干活 如果不同，那么将任务添加到eventLoop的等待队列pendingFuncotrs中 （1）t_loopInThisThread 线程局部变量 前述中eventLoop的线程号只保证了一个eventLoop对应一个线程，却并不能保证一个线程对应多个eventLoop。 t_loopInThisThread 变量就是为了解决一个线程对应一个eventLoop的问题，它是eventLoop的指针，并且是线程局部存储的（这意味着它不会在线程间共享，而是每个线程独自有一份）。在eventLoop的构造函数中会检查t_loopInThisThread的值是否设置，如果设置了，就打破了one loop per thread的语义。 另外，在许多函数中，都有 loop_-&gt;assertInLoopThread(); 来检查当前线程id是否与eventloop构造时存储的线程id一致 123456789101112131415161718192021222324/***** EventLoop.cc *****/__thread EventLoop* t_loopInThisThread = nullptr;EventLoop::EventLoop() : threadId_(CurrentThread::tid()), wakeupFd_(createEventfd()), wakeupChannel_(new Channel(this, wakeupFd_)){ //如果当前线程已经绑定了某个EventLoop对象了，那么该线程就无法创建新的EventLoop对象了 if(t_loopInThisThread) LOG_FATAL(&quot;Another EventLoop %p exits in this thread %d \\n&quot;, t_loopInThisThread, threadId_); else t_loopInThisThread = this; wakeupChannel_-&gt;setReadCallback(std::bind(&amp;EventLoop::handleRead, this)); wakeupChannel_-&gt;enableReading(); }void assertInLoopThread(){ if (!isInLoopThread()){ abortNotInLoopThread(); }}bool isInLoopThread() const { return threadId_ == CurrentThread::tid(); } （2）runInLoop &amp; queueInLoop 123456789101112131415161718192021222324void EventLoop::runInLoop(Functor cb){ if (isInLoopThread()){ cb(); }else { queueInLoop(std::move(cb)); }}void EventLoop::queueInLoop(Functor cb){ { MutexLockGuard lock(mutex_); pendingFunctors_.push_back(std::move(cb)); } if (!isInLoopThread() || callingPendingFunctors_){ wakeup(); }}void EventLoop::wakeup(){ uint64_t one = 1; ssize_t n = write(wakeupFd_, &amp;one, sizeof(one));} 这里需要将eventLoop与线程分开来看待。 先说明一个背景：每个线程其实是在执行eventLoop的loop函数，loop函数干什么？poll系统调用轮询感兴趣事件。那么在没有事件发生时，大部分线程其实都是在睡眠状态的。 为什么强调线程与eventLoop分开？因为我们的线程可能拿到其他线程的eventLoop，而那个eventLoop的线程t1可能在沉睡。queueInLoop于是先将cb添加到pendingFunctors_中，然后再进行唤醒（往eventfd写一个数据，t1监听到eventFd有数据后，就会唤醒工作）。eventLoop会在处理完所有activeChannel的事件后处理pendingFunctor队列里积累的任务。 Q：为什么wake的条件是!isInLoopThread() || callingPendingFunctors_？前者容易理解，不在当前线程，后者如何理解？ A：todo 刨根问底前述已经追问到TcpServer的Acceptor，并且已经大致理解了EventLoop的one loop per thread的语义。我们自顶向下地看，不免看到诸多注册回调的过程： 真是又重又长，但我们去伪存真后就会发现，muduo的核心就在这几类上： EventLoop Poller Channel 每个EventLoop都有一个Poller，Poller负责掌管众多Channel，而Channel则掌管着fd以及对应事件的回调。特别地，我们可以抛弃Acceptor和TcpConnection，只需要Channel（将各种回调都注册进Channe中）。 Channel12345678910111213141516171819202122232425262728293031323334353637EventLoop* loop_;const int fd_; //文件描述符int events_; //感兴趣事件int revents_; //实际发生事件ReadEventCallback readCallback_; //可读回调EventCallback writeCallback_; // 可写回调EventCallback closeCallback_;EventCallback errorCallback_;void enableReading() { events_ |= kReadEvent; update(); } void disableReading() { events_ &amp;= ~kReadEvent; update(); }void enableWriting() { events_ |= kWriteEvent; update(); }void disableWriting() { events_ &amp;= ~kWriteEvent; update(); }void handleEvent(Timestamp receiveTime);void setReadCallback(ReadEventCallback cb) { readCallback_ = std::move(cb); }void setWriteCallback(EventCallback cb) { writeCallback_ = std::move(cb); }void setCloseCallback(EventCallback cb) { closeCallback_ = std::move(cb); }void setErrorCallback(EventCallback cb) { errorCallback_ = std::move(cb); }void Channel::handleEventWithGuard(Timestamp receiveTime){ if ((revents_ &amp; POLLHUP) &amp;&amp; !(revents_ &amp; POLLIN)){ if (closeCallback_) closeCallback_(); } if (revents_ &amp; (POLLERR | POLLNVAL)){ if (errorCallback_) errorCallback_(); } if (revents_ &amp; (POLLIN | POLLPRI | POLLRDHUP)){ if (readCallback_) readCallback_(receiveTime); } if (revents_ &amp; POLLOUT){ if (writeCallback_) writeCallback_(); }} Channel类是事件机制的保姆，它封装fd上的感兴趣事件以及发生的事件，封装了注册修改事件以及发生对应事件的回调函数。在发生事件时，调用Channel的handleEvent进行事件处理。 Q：channel是什么时候被注册进poller中的呢？ A：enableReading、enableWriting等函数，该函数实现中的update Poller123456789101112131415161718192021222324252627282930313233343536373839class Poller : noncopyable{public: Poller(EventLoop *loop); virtual ~Poller(); virtual Timestamp poll(int timeoutMs, ChannelList *activeChannels) = 0; virtual void updateChannel(Channel *channel) = 0;protected: typedef std::map&lt;int, Channel *&gt; ChannelMap; ChannelMap channels_;private: EventLoop *ownerLoop_;};Timestamp EPollPoller::poll(int timeoutMs, ChannelList* activeChannels){ int numEvents = ::epoll_wait(epollfd_, &amp;*events_.begin(), static_cast&lt;int&gt;(events_.size()), timeoutMs); Timestamp now(Timestamp::now()); if (numEvents &gt; 0){ fillActiveChannels(numEvents, activeChannels); } return now;}void EPollPoller::fillActiveChannels(int numEvents, ChannelList* activeChannels) const{ for (int i = 0; i &lt; numEvents; ++i){ Channel* channel = static_cast&lt;Channel*&gt;(events_[i].data.ptr); channel-&gt;set_revents(events_[i].events); activeChannels-&gt;push_back(channel); }} Pooler是Poll或Epoll的封装，提供注册修改Channel的接口。所有的Channel都会保存在poller的map中。poll函数是IO复用的重要封装，它将返回的事件填充到activeChannels中。 理解muduo 连接建立 消息处理（读/写） 连接断开 首先就是要理解mainReactor和subReactor，它们都是对应有eventLoop，分别称为mainEventloop和subEventloop。mainEventloop主要处理连接事件，包含了acceptor这个重要组件。subReactor有自己的监听器，处理读写事件。 每个eventloop都有自己的Poller（也就是事件监听器），这样的好处是高效利用线程（不这么做的话，线程就是干等任务，而如此实现，线程其实阻塞在epoll调用，相当于减少任务分发过程，还能保持一个连接同一个线程服务）。 连接建立 上图中可能不太准确，5改为2，6改为3。 在muduo启动后，acceptor处理可读事件，调用TcpServer::newConnection。它获取一个subEventLoop，构造TcpConnection，然后在subEventLoop所在的线程中进行连接的建立（runInLoop、connectEstablished）。 connectEstablished会将fd注册到subEventloop中的Poller中 channel_-&gt;enableReading(); 1void enableReading() { events_ |= kReadEvent; update(); } // 同时调用update将channel添加或更新到poller的fds中。 这里获取一个eventLoop然后调用runInLoop就能在所在线程执行任务是一个很关键的设计点，后续会讲。 消息读取 消息读取的主要逻辑就在loop函数中，对于每个channel依次调用对应事件的处理函数。读取处理分为两步： 读取消息至inputbuffer中 调用用户的messageCallBack 12345for (Channel* channel : activeChannels_){ currentActiveChannel_ = channel; currentActiveChannel_-&gt;handleEvent(pollReturnTime_);} 1234567891011121314151617void TcpConnection::handleRead(TimeStamp receiveTime){ int savedErrno = 0; ssize_t n = inputBuffer_.readFd(channel_-&gt;fd(), &amp;savedErrno); if(n &gt; 0) //从fd读到了数据，并且放在了inputBuffer_上 { messageCallback_(shared_from_this(), &amp;inputBuffer_, receiveTime); } else if(n == 0) handleClose(); else { errno = savedErrno; LOG_ERROR(&quot;TcpConnection::handleRead&quot;); handleError(); }} 消息发送调用TcpConnetion::send(buf)函数，将buf内的数据发送给对应客户端。 这里对于写是多段处理的：如果TCP的缓冲区放不下buf的数据，那么剩余未发送的数据会存放到TcpConnection::outputBuffer_中。然后注册可写事件，在监听到可写时，由TcpConnection::handleWrite( )函数把TcpConnection::outputBuffer_中剩余的数据发送出去。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354void TcpConnection::sendInLoop(const void* data, size_t len){ loop_-&gt;assertInLoopThread(); ssize_t nwrote = 0; size_t remaining = len; bool faultError = false; if (state_ == kDisconnected) { LOG_WARN &lt;&lt; &quot;disconnected, give up writing&quot;; return; } // if no thing in output queue, try writing directly if (!channel_-&gt;isWriting() &amp;&amp; outputBuffer_.readableBytes() == 0) { nwrote = sockets::write(channel_-&gt;fd(), data, len); if (nwrote &gt;= 0) { remaining = len - nwrote; if (remaining == 0 &amp;&amp; writeCompleteCallback_) { loop_-&gt;queueInLoop(std::bind(writeCompleteCallback_, shared_from_this())); } } else // nwrote &lt; 0 { nwrote = 0; if (errno != EWOULDBLOCK) { LOG_SYSERR &lt;&lt; &quot;TcpConnection::sendInLoop&quot;; if (errno == EPIPE || errno == ECONNRESET) // FIXME: any others? { faultError = true; } } } } assert(remaining &lt;= len); if (!faultError &amp;&amp; remaining &gt; 0) { size_t oldLen = outputBuffer_.readableBytes(); if (oldLen + remaining &gt;= highWaterMark_ &amp;&amp; oldLen &lt; highWaterMark_ &amp;&amp; highWaterMarkCallback_) { loop_-&gt;queueInLoop(std::bind(highWaterMarkCallback_, shared_from_this(), oldLen + remaining)); } outputBuffer_.append(static_cast&lt;const char*&gt;(data)+nwrote, remaining); if (!channel_-&gt;isWriting()) { channel_-&gt;enableWriting(); } }} 连接关闭muduo处理连接关闭的方式只有一种——被动关闭。等待客户端关闭连接，服务端调用read返回0后被动关闭连接。 连接关闭既然从本地对应的subEventloop中删除fd，也要在mainEventLoop的TcpServer中删除该fd。 其余模块Acceptor TcpConnection 线程类：ThreadPool、ThreadData、Thread TimerQueue、Buffer TimerQueue定时器的实现比较有趣，时间轮：当连接有事件发生时，将连接注册到当前指针指向的格子中；指针每隔固定时间转动一格，当指向某格时，执行当前格里所有回调函数。 代码实现：不是真的把一个连接从一个格子移动到另一个格子中，而是利用引用计数方式。 格子以unordered_set的方式管理entry，一个entry就是一个连接的共享指针。 时间轮以环形队列管理 注册每秒的事件：往队尾添加一个空的Bucket。这样队头的Bucket就会弹出自动析构。 在接收到消息时，将Entry放到时间轮的队尾（如此，引用计数递增） 采用共享指针可以确保连接出现在格子中时，引用计数不为零。而当引用计数减为零时，说明连接没有在任何一个格子中出现，那么连接超时，Entry的析构函数会断开连接。 1234typedef std::shared_ptr&lt;Entry&gt; EntryPtr;typedef std::weak_ptr&lt;Entry&gt; WeakEntryPtr;typedef std::unordered_set&lt;EntryPtr&gt; Bucket;typedef boost::circular_buffer&lt;Bucket&gt; WeakConnectionList; 细节：在TCPconnection中保存一个Entry的弱引用WeakEntryPtr，在接收到消息时，将弱引用提升为强引用EntryPtr。如此实现正确的引用计数。 Buffer Buffer 封装了一段缓冲区，用于消息读取和写入。在muduo里，你不必自己去read或write某个socket，只会操作TcpConnection的input buffer和output buffer。 特性表现： 对外表现为连续内存，大小可以自动增长 表现为queue，从末尾写入数据，从头部读出数据 线程不安全 值的借鉴的设计有：缓冲区前增加一段8字节空间（prependable space），可以让程序以极低的代价在数据前面添加几个字节，比如说消息的长度。 代码设计： 两个游标readerIndex和writerIndex size指向实际使用的空间，capacity指向扩容的总空间 内部腾挪：当writable空间不足时，会将已有数据整体前挪，再根据判断是否触发扩容 参考长文梳理Muduo库核心代码及优秀编程细节剖析-CSDN博客","link":"/2024/11/15/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/muduo%E7%BD%91%E7%BB%9C%E5%BA%93/Muduo%20%E5%AD%A6%E4%B9%A0/"},{"title":"muduo高性能异步日志","text":"如何构建一个高性能的异步日志库？ 日志系统的要求日志库大致可分为前端和后端两部分，前端负责提供应用程序日志接口并生成日志消息，后端负责接收日志消息并将消息写往某处。 在多线程程序中，多个线程有前端，同时共用一个后端，这是一个典型的多生产者单消费者问题。对前端而言需要做到低延迟、低CPU开销、无阻塞；后端要做到大吞吐量、占用少量资源。 功能： 日志消息多级别 日志多目的地 日志格式可配置 运行时过滤：不同级别消息的日志分目的地 线程安全问题：多个线程并发写日志，日志消息不会交织出现。比如线程1写消息abc，线程2写消息123，不能出现a1b23c，只能是abc123或123abc。 muduo日志使用方式muduo采用流式日志，使用时非常简单，只需向LOG_INFO写数据即可LOG_INFO &lt;&lt; &quot;Hello 0123456789&quot;;，默认为终端输出。 123456#define LOG_TRACE if (muduo::Logger::logLevel() &lt;= muduo::Logger::TRACE) \\ muduo::Logger(__FILE__, __LINE__, muduo::Logger::TRACE, __func__).stream()#define LOG_DEBUG if (muduo::Logger::logLevel() &lt;= muduo::Logger::DEBUG) \\ muduo::Logger(__FILE__, __LINE__, muduo::Logger::DEBUG, __func__).stream()#define LOG_INFO if (muduo::Logger::logLevel() &lt;= muduo::Logger::INFO) \\ muduo::Logger(__FILE__, __LINE__).stream() 实际上LOG_INFO为一个宏，只有日志级别小于INFO才生效。这个宏构造了匿名对象Logger，并调用stream方法获取Stream流，然后重载运算符&lt;&lt;。 123456Logger::OutputFunc Logger::g_output = [](const char* msg, int len) { fwrite(msg, 1, len, stdout); // ok, thread safe};Logger::FlushFunc Logger::g_flush = []() { fflush(stdout);}; 异步日志使用 构造后端 AsyncLogging 设置前端的输出 123456789101112131415off_t kRollSize = 500*1000*1000;muduo::AsyncLogging* g_asyncLog = NULL;void asyncOutput(const char* msg, int len){ g_asyncLog-&gt;append(msg, len);}int main(){ muduo::AsyncLogging log(::basename(name), kRollSize); log.start(); g_asyncLog = &amp;log; muduo::Logger::setOutput(asyncOutput); LOG_INFO &lt;&lt; &quot;Hello 0123456789&quot;;} muduo异步日志原理 前述日志库分为前端和后端，前后端之间如何交互呢？如果只靠一个blockingQueue，那么每条日志都会通知后端一次，不太现实。 实际上muduo采用了双缓冲技术：前端写入缓冲区A，后端读取缓冲区B，当A满或者B空时，交换两个缓冲区。 这样做的好处是： 前端将多条消息合并为一个大buffer发给后端，相当于批处理； 前端写消息和后端读消息互不阻塞，分开进行。 在实现时，为了消息处理的及时性，即便前端缓冲区未满，每隔3秒也会执行一次缓冲区交换操作。 核心代码实现在实现时采用了四个缓冲区，前端两个，后端两个。这样做是为了当一个缓冲区耗尽时，能够及时启用下一个缓冲区，进一步减少前端的等待。 前端： currentBufer_ nextBuffer_ buffer_ 缓冲区的队列 后端： newBuffer1 newBuffer2 buffersToWrite 缓冲区的队列 前端日志写入实际上，前端调用（g_output）的还是asyncLogging的接口void AsyncLogging::append(const char* logline, int len) 1234567891011121314151617181920class AsyncLogging : noncopyable{ private: void threadFunc(); typedef muduo::detail::FixedBuffer&lt;muduo::detail::kLargeBuffer&gt; Buffer; typedef std::vector&lt;std::unique_ptr&lt;Buffer&gt;&gt; BufferVector; typedef BufferVector::value_type BufferPtr; const int flushInterval_; std::atomic&lt;bool&gt; running_; const string basename_; const off_t rollSize_; muduo::Thread thread_; muduo::CountDownLatch latch_; muduo::MutexLock mutex_; muduo::Condition cond_ GUARDED_BY(mutex_); BufferPtr currentBuffer_ GUARDED_BY(mutex_); BufferPtr nextBuffer_ GUARDED_BY(mutex_); BufferVector buffers_ GUARDED_BY(mutex_);}; 这里的buffers_是bufferPtr的队列，已满的缓冲区会先收集到这个队列中。append函数主要逻辑就是： 判断curentBuffer_是否已经满 未满则写入一条日志，结束 已满，则将cureentBuffer_放入buffers_，并启用nextBuffer_ 123456789101112131415161718void AsyncLogging::append(const char *logLine, int len) { std::lock_guard&lt;std::mutex&gt; lockGuard(mutex_); // 当前缓冲区空间足够 if (currentBuffer_-&gt;avail() &gt; len) { currentBuffer_-&gt;append(logLine, len); } else { buffers_.emplace_back(currentBuffer_.release()); if (nextBuffer_) { // 使用另一个缓冲区 currentBuffer_ = std::move(nextBuffer_); // now nextBuffer_ == nullptr } else { // 两个缓冲区都满了，重新分配一个缓冲区，很少发生 currentBuffer_ = std::make_unique&lt;Buffer&gt;(); } currentBuffer_-&gt;append(logLine, len); cond_.notify_one(); }} 后端日志落盘AsyncLogging::threadFunc()：后端日志落盘线程的执行函数。 这里准备了三块缓冲区newBuffer1和newBuffer2前面介绍过，用于和前端的缓冲区交换，buffersToWrite 关键看临界区内的代码，并没有采用while循环，而是采用了带时间间隔的条件变量的唤醒。 异常处理：当已满缓冲队列中的数据堆积（&gt; 默认缓冲数25），就会丢弃多余缓冲，只保留最开始2个。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960void AsyncLogging::theadFunc() { assert(running_ == true); LogFile output(basename_, rollSize_); BufferPtr newBuffer1 = std::make_unique&lt;Buffer&gt;(); BufferPtr newBuffer2 = std::make_unique&lt;Buffer&gt;(); newBuffer1-&gt;bzero(); newBuffer2-&gt;bzero(); BufferVector buffersToWrite; buffersToWrite.reserve(16); while (running_) { assert(newBuffer1 &amp;&amp; newBuffer1-&gt;length() == 0); assert(newBuffer2 &amp;&amp; newBuffer2-&gt;length() == 0); assert(buffersToWrite.empty()); { std::unique_lock&lt;std::mutex&gt; uniqueLock(mutex_); if (buffers_.empty()) { cond_.wait_for(uniqueLock, std::chrono::seconds(flushInterval_)); } buffers_.emplace_back(currentBuffer_.release()); currentBuffer_ = std::move(newBuffer1); buffersToWrite.swap(buffers_); if (!nextBuffer_) { nextBuffer_ = std::move(newBuffer2); } } // 丢弃过多的日志 if (buffersToWrite.size() &gt; 25) { char buf[256]; snprintf(buf, sizeof buf, &quot;Dropped log messages at %s, %zd larger buffers\\n&quot;, Timestamp::now().toFormattedString().c_str(), buffersToWrite.size()-2); fputs(buf, stderr); output.append(buf, static_cast&lt;int&gt;(strlen(buf))); buffersToWrite.erase(buffersToWrite.begin()+2, buffersToWrite.end()); } // 日志落盘，写入文件中 for (const auto&amp; b : buffersToWrite) { output.append(b-&gt;data(), b-&gt;length()); } if (buffersToWrite.size() &gt; 2) { buffersToWrite.resize(2); } if (!newBuffer1) { newBuffer1 = std::move(buffersToWrite.back()); buffersToWrite.pop_back(); newBuffer1-&gt;reset(); } if (!newBuffer2) { newBuffer2 = std::move(buffersToWrite.back()); buffersToWrite.pop_back(); newBuffer2-&gt;reset(); } buffersToWrite.clear(); output.flush(); } output.flush();} 前端前述前端是调用g_output将消息发送过去，那么整个过程是什么样的呢？ Logger -&gt; Impl -&gt; LogStream -&gt; operator&lt;&lt; -&gt; LogStream的FixBuffer内 -&gt; ~Logger -&gt; g_output 1234567891011Logger::~Logger(){ impl_.finish(); // 往Small Buffer添加后缀 文件名:行数 换行符 const LogStream::Buffer&amp; buf(stream().buffer()); g_output(buf.data(), buf.length()); // 回调保存的g_output, 输出Small Buffer到指定文件流 if (impl_.level_ == FATAL) // 发生致命错误, 输出log并终止程序 { g_flush(); // 回调冲刷 abort(); }} Logger 提供用户接口，一个pointer to implement实现，提供日志等级、文件行数代码详细信息 Impl Logger的详细实现 LogStream 重载operator&lt;&lt;，将用户输入保存在类中的small buffer中 FixedBuffer 固定大小的缓冲区 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364class Logger {public: enum LogLevel { TRACE, DEBUG, INFO, WARN, ERROR, FATAL, NUM_LOG_LEVELS, }; Logger(const char* file, int line); Logger(const char* file, int line, LogLevel level); ~Logger(); LogStream&amp; stream();public: static LogLevel logLevel() { return g_logLevel; } static void setLogLevel(LogLevel level) { g_logLevel = level; } typedef void (*OutputFunc)(const char* msg, int len); typedef void (*FlushFunc)(); static void setOutput(OutputFunc o) { g_output = o; } static void setFlush(FlushFunc f) { g_flush = f; }private: static LogLevel g_logLevel; static OutputFunc g_output; static FlushFunc g_flush; class Impl; std::unique_ptr&lt;Impl&gt; impl;};class Logger::Impl {public: typedef Logger::LogLevel LogLevel; Impl(LogLevel level, int old_errno, const char* file, int line) : time_(Timestamp::now()), stream_(), level_(level), line_(line), basename_(file) { formatTime(); CurrentThread::tid(); stream_.append(CurrentThread::tidString(), CurrentThread::t_tidLen); stream_.append(LogLevelName[level], 8); if (old_errno != 0) { stream_ &lt;&lt; strerror_tl(old_errno) &lt;&lt; &quot; (errno=&quot; &lt;&lt; old_errno &lt;&lt; &quot;) &quot;; } stream_.append(basename_.data(), basename_.size()); stream_ &lt;&lt; ':' &lt;&lt; line_ &lt;&lt; &quot; - &quot;; } void formatTime(); Timestamp time_; LogStream stream_; LogLevel level_; int line_; SourceFile basename_;}; 参考https://xiaodongfan.com/Muduo网络库实现-一-异步日志.html https://www.cnblogs.com/fortunely/p/15973948.html","link":"/2024/11/15/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/muduo%E7%BD%91%E7%BB%9C%E5%BA%93/Muduo%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"title":"单例模式","text":"如何正确实现一个单例模式？ 单例模式单例类的特点 构造函数和析构函数为私有类型，目的是禁止外部构造和析构。 拷贝构造函数和赋值构造函数是私有类型，目的是禁止外部拷贝和赋值，确保实例的唯一性。 类中有一个获取实例的静态方法，可以全局访问。 Meyer‘s Singleton要点： static获取实例对象的引用 静态函数局部变量作为单一实例 懒汉式 懒汉式：系统运行中，实例并不存在，只有当需要使用该实例时，才会去创建并使用实例。这种方式要考虑线程安全。 特点：静态局部变量方式天然线程安全。 1234567891011121314151617181920212223242526272829303132333435class S{public: // Guaranteed to be destroyed. // Instantiated on first use. static S &amp;getInstance(){ static S instance; return instance; }private: S() {} // C++ 03 // ======== // Don't forget to declare these two. You want to make sure they // are inaccessible(especially from outside), otherwise, you may accidentally get copies of // your singleton appearing. S(S const &amp;); // Don't Implement void operator=(S const &amp;); // Don't implement // C++ 11 // ======= // We can use the better technique of deleting the methods // we don't want.public: S(S const &amp;) = delete; void operator=(S const &amp;) = delete; // Note: Scott Meyers mentions in his Effective Modern // C++ book, that deleted functions should generally // be public as it results in better error messages // due to the compilers behavior to check accessibility // before deleted status}; 加锁懒汉式实现要点： 静态获取实例指针的函数 静态指针作为单一实例 多线程适用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/// 加锁的懒汉式实现 //class SingleInstance{public: static SingleInstance *GetInstance(); static void deleteInstance();private: // 将其构造和析构成为私有的, 禁止外部构造和析构 SingleInstance(); ~SingleInstance(); // 将其拷贝构造和赋值构造成为私有函数, 禁止外部拷贝和赋值 SingleInstance(const SingleInstance &amp;signal); const SingleInstance &amp;operator=(const SingleInstance &amp;signal);private: static SingleInstance* m_SingleInstance; static std::mutex m_Mutex;};// 初始化静态成员变量SingleInstance *SingleInstance::m_SingleInstance = nullptr;std::mutex SingleInstance::m_Mutex;// 注意：不能返回指针的引用，否则存在外部被修改的风险！SingleInstance *SingleInstance::GetInstance(){ // 这里使用了两个 if 判断语句的技术称为双检锁； // 好处是：只有判断指针为空的时候才加锁， // 避免每次调用 GetInstance的方法都加锁。 if (m_SingleInstance == nullptr){ std::unique_lock&lt;std::mutex&gt; lock(m_Mutex); if (m_SingleInstance == nullptr){ volatile auto temp = new (std::nothrow) SingleInstance(); m_SingleInstance = temp; } } return m_SingleInstance;}void SingleInstance::deleteInstance(){ std::unique_lock&lt;std::mutex&gt; lock(m_Mutex); // 加锁 if (m_SingleInstance){ delete m_SingleInstance; m_SingleInstance = nullptr; }} cpp11实现要点： call_once 123456789101112131415161718192021222324252627#include &lt;iostream&gt;#include &lt;memory&gt;#include &lt;mutex&gt;class Singleton {public: static std::shared_ptr&lt;Singleton&gt; getSingleton(); ~Singleton() { std::cout &lt;&lt; __PRETTY_FUNCTION__ &lt;&lt; std::endl; }private: Singleton() { std::cout &lt;&lt; __PRETTY_FUNCTION__ &lt;&lt; std::endl; }};static std::shared_ptr&lt;Singleton&gt; singleton = nullptr;static std::once_flag singletonFlag;std::shared_ptr&lt;Singleton&gt; Singleton::getSingleton() { std::call_once(singletonFlag, [&amp;] { singleton = std::shared_ptr&lt;Singleton&gt;(new Singleton()); }); return singleton;} 饿汉式实现系统一运行，就初始化创建实例，当需要时，直接调用即可。这种方式本身就线程安全。 123456789101112131415161718192021222324252627282930313233// 饿汉实现 /class Singleton{public: static Singleton* GetInstance(); static void deleteInstance();private: // 将其构造和析构成为私有的, 禁止外部构造和析构 Singleton(); ~Singleton(); // 将其拷贝构造和赋值构造成为私有函数, 禁止外部拷贝和赋值 Singleton(const Singleton &amp;signal); const Singleton &amp;operator=(const Singleton &amp;signal);private: static Singleton *g_pSingleton;};// 代码一运行就初始化创建实例 ，本身就线程安全Singleton* Singleton::g_pSingleton = new (std::nothrow) Singleton();Singleton* Singleton::GetInstance(){ return g_pSingleton;}void Singleton::deleteInstance(){ if (g_pSingleton){ delete g_pSingleton; g_pSingleton = nullptr; }} referencehttps://blog.csdn.net/unonoi/article/details/121138176 https://stackoverflow.com/questions/1008019/how-do-you-implement-the-singleton-design-pattern","link":"/2025/05/04/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"},{"title":"设计模式学习","text":"设计模式大致分为三类。 创建者模式：提供一种创建对象的方式，同时隐藏了创建对象的逻辑。而不是直接使用new创建对象。 结构型模式：结构型模式更加关注对象与对象之间的关系与组合，旨在构建灵活可复用的类和对象结构。 行为型模式：关注类或对象之间的通信、协作、职责分配。旨在对象间的责任分配和算法封装。 记住所有的设计模式是愚蠢的，关注自己所在领域常用设计模式，语言框架中默认使用的设计模式。 创建型模式创建者模式封装了创建对象的逻辑，将复杂对象的构建过程与其表示（使用）分离。代替手动用new操作符调用构造函数繁琐的过程。 优点：对象构造与表示分离，隐藏对象的内部结构。 工厂模式工厂模式提供了一种将对象的实例化过程封装在工厂类中的方式。 分类： 简单工厂模式 工厂方法模式 抽象工厂模式 缺点： 增加了系统中的类和对象的个数，复杂度增加。 需要额外工作量创建和维护工厂类和产品类，增加开发成本。 应用场景： 日志配置器：日志记录层次、记录格式、记录的存放路径 123456789101112131415public class ShapeFactory { public Shape getShape(String shapeType){ //使用 getShape 方法获取形状类型的对象 if(shapeType == null){ return null; } if(shapeType.equalsIgnoreCase(&quot;CIRCLE&quot;)){ return new Circle(); } else if(shapeType.equalsIgnoreCase(&quot;RECTANGLE&quot;)){ return new Rectangle(); } else if(shapeType.equalsIgnoreCase(&quot;SQUARE&quot;)){ return new Square(); } return null; }} 自己的应用： 深度学习中，经常需要对比不同学习模型的在相同任务上的效果。而不同的模型的创建逻辑大体相同，但部分细节不同。我自己写了一个模型工厂，根据传入的模型名称、模型层数、模块机制来自动构建模型。这样，每当我要改变一个模型训练，我就修改相应参数。 其实，这么说，整个深度学习任务的过程都可以看成工厂模式，只不过我没有做整个大任务的抽象封装。在Python代码中，我调用了一个argparse这么一个模块，它的作用就是解析命令行的参数。我训练一个任务，大体有数据集、模型、学习率、迭代次数这些个参数，每一次任务可以用参数组合表示。那么就是说我用参数组合来定义任务，这与工厂模式的思想是不谋而合的，我把要改变的地方全部提取出来，放到一起。 单例模式单例模式也就说保证一个类只有一个实例存在，整个系统中只有一个全局对象。 应用场景：当系统只需要一个实例来协调整个系统的行为时 日志记录器 配置管理器 windos中的任务管理器 单线程下实现方式： 私有化构造函数，使得构造函数无法通过外部调用； 创建一个持有字段hold，类型为对象的引用； 创建一个静态方法get，用于获得对象实例的引用。首先检查hold是否为空，为空才创建对象，否则返回引用。 多线程下实现注意点： 线程安全性，get方法得加锁 双重检查：在单例模式中，通常需要进行双重检查锁定，即先检查单例对象是否已经被创建，然后再加锁并再次检查。 饿汉式和懒汉式的选择：饿汉式在类加载时就完成了初始化，而懒汉式则在第一次调用getInstance方法时才进行初始化。 懒汉模式 12345678910111213141516public class Singleton { private static volatile Singleton instance; private Singleton() {} public static Singleton getInstance() { if (instance == null) { // 进入前检测 synchronized (Singleton.class) { // synchronized加锁 if (instance == null) { //进入后检测 instance = new Singleton(); } } } return instance; } } 饿汉模式 123456789public class Singleton { private static Singleton instance = new Singleton(); private Singleton() {} public static Singleton getInstance() { return instance; } } 建造者模式建造者模式将一个复杂对象分解成多个简单部分，对复杂对象分模块构建，一步步构建最终对象。 一般适合创建实例有多个步骤的复杂对象，比如说汽车有各个零件，每种零件的厂商是不固定的，但汽车的组装步骤是一定的。再提炼来说：一个复杂对象由各个部分的子对象组成，子对象可能会经常变化，而各个子对象的组合逻辑却不怎么变化。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class Computer { private final String cpu;//必须 private final String ram;//必须 private final int usbCount;//可选 private final String keyboard;//可选 private final String display;//可选 private Computer(Builder builder){ this.cpu=builder.cpu; this.ram=builder.ram; this.usbCount=builder.usbCount; this.keyboard=builder.keyboard; this.display=builder.display; } public static class Builder{ private String cpu;//必须 private String ram;//必须 private int usbCount;//可选 private String keyboard;//可选 private String display;//可选 public Builder(String cup,String ram){ this.cpu=cup; this.ram=ram; } public Builder setUsbCount(int usbCount) { this.usbCount = usbCount; return this; } public Builder setKeyboard(String keyboard) { this.keyboard = keyboard; return this; } public Builder setDisplay(String display) { this.display = display; return this; } public Computer build(){ return new Computer(this); } } //省略getter方法}---// 使用方式Computer computer=new Computer.Builder(&quot;因特尔&quot;,&quot;三星&quot;) .setDisplay(&quot;三星24寸&quot;) .setKeyboard(&quot;罗技&quot;) .setUsbCount(2) .build(); 结构型模式类与类之间的关系与组合，关注的是类间的布局。 装饰器模式装饰器模式允许向一个对象添加新的功能，同时却不改变其原有代码。 应用： Java中的注解 python里装饰器 Spring框架的注解AOP Java中可以自定义注解，然后通过反射的方式获取注解（注解拦截），然后进行功能增强。 适配器模式适配器模式允许你将不兼容的对象包装成一个适配器类，使它们能够与其他对象一起工作。适配器模式通常用于处理与现有类库或框架不兼容的类或接口。 在STL里，栈和队列都是适配器，它们底层使用Deque作为容器存储，对外却表现为栈或队列的特性。 代理模式unix系统调用中，错误包装函数。 我们需要从概念上了解代理和装饰的区别： 代理是全权代理，目标根本不对外，全部由代理类来完成。 装饰是增强，是辅助，目标仍然可以自行对外提供服务，装饰器只起增强作用。 行为型模式行为型模式关注的是对象间的通信、写作、职责分配等。 责任链模式将处理对象连成一条链，请求沿着链传递，直到有一个对象处理为止。 状态模式对象的行为跟随着状态而改变。【状态机】 迭代器模式提供一个方法顺序访问对象的各个元素，但不暴露对象的内部表示。 CPP的STL库里的迭代器就很好体现这一点。原生指针不足以支持元素的顺序访问，譬如链表节点、树的节点。迭代器的出现使得容器和算法分离，算法通过迭代器访问容器元素却不用知晓其实现，换句话说，算法更加通用。","link":"/2023/12/01/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"title":"GDB调试信号","text":"GDB可以发送信号，拦截信号，方便地对信号进行调试。 捕获信号GDB调试时，如果有信号产生，会切换到处理到信号的进程上去，十分影响调试。 在GDB中handle指令用于设置GDB对于信号的处理，可以输入help handle来查看。 123456789101112131415161718192021222324(gdb) help handleSpecify how to handle signals.Usage: handle SIGNAL [ACTIONS]Args are signals and actions to apply to those signals.If no actions are specified, the current settings for the specified signalswill be displayed instead.Symbolic signals (e.g. SIGSEGV) are recommended but numeric signalsfrom 1-15 are allowed for compatibility with old versions of GDB.Numeric ranges may be specified with the form LOW-HIGH (e.g. 1-5).The special arg &quot;all&quot; is recognized to mean all signals except thoseused by the debugger, typically SIGTRAP and SIGINT.Recognized actions include &quot;stop&quot;, &quot;nostop&quot;, &quot;print&quot;, &quot;noprint&quot;,&quot;pass&quot;, &quot;nopass&quot;, &quot;ignore&quot;, or &quot;noignore&quot;.Stop means reenter debugger if this signal happens (implies print).Print means print a message if this signal happens.Pass means let program see this signal; otherwise program doesn't know.Ignore is a synonym for nopass and noignore is a synonym for pass.Pass and Stop may be combined.Multiple signals may be specified. Signal numbers and signal namesmay be interspersed with actions, with the actions being performed forall signals cumulatively specified. 可以看到用法为：handle SIGNAL [ACTIONS] signal 参数表示要设定的目标信号，它通常为某个信号的全名（SIGINT）或者简称（去除‘SIG’后的部分，如 INT）；如果要指定所有信号，可以用 all 表示。 ACTION 参数用于明确 GDB 处理该目标信息的方式，其值可以是如下几个： nostop：当信号发生时，GDB 不会暂停程序，其可以继续执行，但会打印出一条提示信息，告诉我们信号已经发生； stop：当信号发生时，GDB 会暂停程序执行。 noprint：当信号发生时，GDB 不会打印出任何提示信息； print：当信号发生时，GDB 会打印出必要的提示信息； nopass（或者 ignore）：GDB 捕获目标信号的同时，不允许程序自行处理该信号； pass（或者 noignore）：GDB 调试在捕获目标信号的同时，也允许程序自动处理该信号。 上面的6项配置可划分成3组，具备相互叠加的状态集合 ，即： stop/nostop print/noprint pass/nopass 查看信号的处理方式GDB 调试器提供了info signals指令，用于查看 GDB 可以处理的信号种类，以及各个信号的具体处理方式。 12345678910111213(gdb) info signalsSignal Stop Print Pass to program DescriptionSIGHUP Yes Yes Yes HangupSIGINT Yes Yes No InterruptSIGQUIT Yes Yes Yes QuitSIGILL Yes Yes Yes Illegal instructionSIGTRAP Yes Yes No Trace/breakpoint trapSIGABRT Yes Yes Yes AbortedSIGEMT Yes Yes Yes Emulation trapSIGFPE Yes Yes Yes Arithmetic exceptionSIGKILL Yes Yes Yes Killed...... 第一项（Signal）：标示每个信号。第二项（Stop）：表示被调试的程序有对应的信号发生时，gdb是否会暂停程序。第三项（Print）：表示被调试的程序有对应的信号发生时，gdb是否会打印相关信息。第四项（Pass to program）：gdb是否会把这个信号发给被调试的程序。第五项（Description）：信号的描述信息。 发送信号在GDB调试状态中，可以在命令号输入signal 信号来向程序发送信号。","link":"/2024/08/25/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/GDB/GDB%E8%B0%83%E8%AF%95%E4%BF%A1%E5%8F%B7/"},{"title":"GDB调试学习","text":"GDB是命令行下调试C++程序的好工具，在Linux上跑程序就不可避免地与它打交道。 GDB调试的一般流程程序编译时带上-g选项1g++ test.cpp -o test -g 启动gdb对可执行程序进行调试启动gdb来调试程序有两种思路： 利用gdb启动程序 利用gdb调试运行中的程序 方式一：利用gdb启动程序 1gdb ./file_name 或者先运行gdb命令，进入gdb调试程序内，然后利用file命令启动程序 1file ./file_name 方式二：利用gdb调试运行中的程序 1gdb -p 进程号 或者先运行gdb命令，进入gdb调试程序内，然后利用attach命令依附到进程 1attach 进程号 设置断点等单步调试 start 程序运行至主函数main入口处暂停（相当于在main函数打了一个断点） run 程序开始运行直到遇到一个断点，如果没有断点则一直运行至结束 break/b + 文件路:行数 在文件的第x行打断点 next/n 执行单行代码 n 10 # 执行10行代码 [enter] 回车键执行上次运行的命令 continue/c 运行到下一个断点 list /l 显示当前附近的代码 list file:line 查看指定文件行数附近的代码 print/p 变量 打印变量的值 backtrace/bt 查看当前的调用栈以及当前的文件和行 finish 执行完当前的函数 until 执行完当前的循环 好用的进阶知识点gdb启动程序时传参数很多时候，我们的程序启动需要带上命令行参数，此时可利用–args选项带上参数 1gdb --args ./program arg1 arg2 打印相关（1）格式控制 print可以指定显示的格式，支持的变量显示格式有： x 按十六进制格式显示变量。 d 按十进制格式显示变量。 u 按十六进制格式显示无符号整型。 o 按八进制格式显示变量。 t 按二进制格式显示变量。 a 按十六进制格式显示变量。 c 按字符格式显示变量。 f 按浮点数格式显示变量。 比如：用16进制显示(var)值： (gdb) print /x var （2）地址/解引用 打印变量的地址 (print &amp;var) 打印地址的数据值 (print *address) 打印数组 print *a@10 显示10个元素，无论a是double或者是int的都会正确地显示10个元素。 （3）GDB打印要点 在对地址做强制转换时，括号全都加：（类型）（地址） 后续想要对转换后的变量操作时，再加一层大括号 ，以视为整体操作：（（类型）（地址））-&gt; 成员 宏相关 info macro+宏名 查看宏的定义 macro expand+宏 可以展开宏的表达情况 其他 watchpoint 监听一个变量，改变时通知 info line *&lt;地址&gt; 获取某个地址对应的源代码行号 调试崩溃的程序程序崩溃时会由操作系统生成core dump文件，里面包含了程序崩溃时的内存内容、寄存器状态和其他相关信息，借此我们可以调试分析程序崩溃的原因。 core文件设置（1）默认情况下，core文件的大小可能被设置为0，这意味着系统不会为崩溃的进程生成core文件。 12ulimit -a # 查看core文件的大小设置ulimit -c unlimited #设置core大小无限 以上针对的是当前shell会话，如果要永久开启core文件的生成，需要编辑/etc/security/limits.conf文件（针对使用PAM的Linux系统）。在该文件中，为需要生成core文件的用户添加或修改一行配置，如* soft core unlimited，这里的*代表所有用户，也可以指定具体用户名。 （2）设置core文件的路径和名称 12# 将core文件保存到/corefile目录下，并以core-命令名-进程号-时间戳的格式命名。echo &quot;/corefile/core-%e-%p-%t&quot; &gt; /proc/sys/kernel/core_pattern ore文件的生成路径和名称可以通过修改/proc/sys/kernel/core_pattern文件来设置。这个文件包含了一个字符串，用于指定core文件的命名格式和存储位置。 直接修改/proc/sys/kernel/core_pattern文件的效果是临时的，重启后会失效。为了永久更改，可以在系统启动时通过sysctl配置或使用其他系统管理工具进行设置。 core加载调试使用命令 gdb [exec file] [core file] 加载core 文件进行调试。 使用bt（backtrace）命令查看当前的调用栈。这将列出从程序入口到崩溃点的所有函数调用序列。 1234(gdb) bt#0 function1 (arg1=1, arg2=2) at file.c:10#1 function2 (arg=3) at file.c:20#2 0x00000000004006b4 in main () at main.c:5 使用frame命令加上栈帧编号来切换到该栈帧。 12(gdb) frame 1#1 0x000055555555465a in function2 (arg=3) at file.c:20 在切换到特定栈帧后，你可以使用info locals命令来查看该栈帧中的所有局部变量。此外，info args命令可以查看当前函数的参数。 12345(gdb) info localsarg = 3local_var = 13(gdb) info argsarg = 3 多线程调试gdb还可以调试多线程的程序 查看可切换调试的线程：info threads 切换调试的线程：thread 线程id 只运行当前线程：set scheduler-locking on 指定某线程执行某gdb命令：thread apply 线程id gdb_cmd 运行全部的线程：set scheduler-locking off 全部的线程执行某gdb命令：thread apply all gdb_cmd 调试死锁的程序有些时候我们的程序会死锁，这时候该怎么调试程序呢？答案是保存现场，然后慢慢进行调试。 gdb attach pid # 依附到hang的进程上 set logging on # 将gdb的会话输出保存 thread apply all bt # 打印所有线程的堆栈 generate-core-file # 输出core文件 或者 gcore 进程号 保存程序产生的日志","link":"/2024/08/08/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/GDB/GDB%E8%B0%83%E8%AF%95%E5%AD%A6%E4%B9%A0/"},{"title":"Git快速入门","text":"Git是一个版本控制工具，通常配合远程代码仓库多人协作开发。上手Git并不难，用过之后就会觉得真香。我入门的方式就是给一个项目提Pull Request。 git学习思路：单链 -&gt; 树 -&gt; 多棵树 本地版本控制（利用状态机的思想学习Git） 分支版本控制（利用树的思想） 远程仓库控制（两颗树之间的对应！） 最后学习学习git相关的配置文件，git就算简单入门了。 推荐阅读：https://www.progit.cn/#_pro_git 在线Git闯关-图形化学GIt：https://learngitbranching.js.org/?locale=zh_CN 一、git基础工作目录下的每一个文件都不外乎这两种状态：已跟踪或未跟踪 已跟踪的文件是指那些被纳入了版本控制的文件，在上一次快照中有它们的记录。 未跟踪文件是工作目录中除已跟踪文件以外的所有其它文件，它们既不存在于上次快照的记录中，也没有放入暂存区。 经过Git追踪的文件，在工作一段时间后，它们可能处于其中之一的状态： committed 已经提交，数据在本地仓库中 modified 已经修改，没有保存在数据库中 staged 已经暂存，包含在下次提交的快照中 引入Git项目三个工作区域的概念：Git仓库、工作目录、暂存区域 基本的 Git 工作流程如下： 在工作目录中修改文件。 暂存文件，将文件的快照放入暂存区域。 提交更新，找到暂存区域的文件，将快照永久性存储到 Git 仓库目录。 如果 Git 目录中保存着的特定版本文件，就属于已提交状态。 如果作了修改并已放入暂存区域，就属于已暂存状态。 如果自上次取出后，作了修改但还没有放到暂存区域，就是已修改状态。 二、本地版本控制2.1 获取仓库获取仓库的方法： 现有目录初始化仓库 克隆仓库 （1）现有目录初始化仓库 1234git init git add your_filegit add LISCENSEgit commit -m 'initial project version' （2）克隆仓库 1git clone [url] 比如 1git clone https://github.com/libgit2/libgit2 这会在当前目录下创建一个名为 “libgit2” 的目录，并在这个目录下初始化一个 .git 文件夹。 如果你想在克隆远程仓库的时候自定义本地仓库的名字， 在上条命令后面跟着你自定义的名字： 1git clone https://github.com/libgit2/libgit2 your_local_name 2.2 git状态工作目录下的每一个文件都不外乎这两种状态：已跟踪或未跟踪 已跟踪的文件是指那些被纳入了版本控制的文件，在上一次快照中有它们的记录，在工作一段时间后，它们的状态可能处于未修改，已修改或已放入暂存区。 未跟踪文件是工作目录中除已跟踪文件以外的所有其它文件，它们既不存在于上次快照的记录中，也没有放入暂存区。 初次克隆某个仓库的时候，工作目录中的所有文件都属于已跟踪文件，并处于未修改状态。 编辑过某些文件之后，由于自上次提交后你对它们做了修改，Git 将它们标记为已修改文件。 我们逐步将这些修改过的文件放入暂存区，然后提交所有暂存了的修改，如此反复。这就是Git本地工作的思想。 2.3 git操作（1）查看文件状态1$ git status （2）跟踪新文件（untracked -&gt; staged)1$ git add yourfile 这是个多功能命令：可以用它开始跟踪新文件，或者把已跟踪的文件放到暂存区，还能用于合并时把有冲突的文件标记为已解决状态等。 （3）暂存已修改文件 (modified -&gt; staged)1$ git add yourfile （4）忽略文件在这种情况下，我们可以创建一个名为 .gitignore 的文件，列出要忽略的文件模式。这些文件不会被提交。 （5）提交更新12$ git commit//另外，你也可以在 commit 命令后添加 -m 选项，将提交信息与命令放在同一行 可以看到，提交后它会告诉你，当前是在哪个分支（master）提交的，本次提交的完整 SHA-1 校验和是什么（463dc4f），以及在本次提交中，有多少文件修订过，多少行添加和删改过。 在提交前，请一定要确认还有什么修改过的或新建的文件还没有 git add 过，否则提交的时候不会记录这些还没暂存起来的变化。 这些修改过的文件只保留在本地磁盘。 每次准备提交前用 git status 看下，是不是都已暂存起来了。 （6）跳过暂存1git commit -a 跳过暂存步骤，将已跟踪的文件（若已经修改）提交。 （7）移除文件xx （8）版本回滚首先查看提交的各个版本提交的 SHA-1 标识符。两个命令都行，不过第二个显示的信息更加简洁。 12$ git log --pretty=oneline$ git log --oneline 使用 git revert 命令可以创建一个新的提交，它撤销了指定的提交内容，但是保留了原来的提交记录。 1git revert SHA-1 使用 git reset 命令可以回滚提交，但这种方式是破坏性的，因为它会更改 Git 历史记录，从而删除要回滚的提交以及回滚之后的提交。 1git reset --hard SHA-1 使用reset后就不能恢复了！ （9）放弃暂存区的修改，回到上次提交要放弃本次代码修改并将工作区回到上次提交的状态，可以使用命令： 1git checkout -- . 该命令会将工作区中所有文件的修改全部还原到上次提交的状态，注意命令中的点号”.”表示当前目录，也可以替换成具体的文件或目录名。 此外，如果你只是想还原某个特定文件的修改，可以使用： 1git checkout -- 文件名 注意，这个命令并不会从版本库中删除已经提交的修改记录，只是还原到上次提交。 如果需要完全撤销某个提交，使用 git reset 命令。 三、分支版本控制3.0 查看分支1git branch 这个命令可以查看当前的所有分支。 1234$ git branch iss53* master testing 注意 master 分支前的 * 字符：它代表现在位于的分支（当前 HEAD 指针所指向的分支）。 3.1 查看分支指向的对象分支指向的对象指commit的文件对象。 123git log --oneline --decorategit log --decorate git log --oneline --decorate 输出效果： 123位于分支 master2348425 (HEAD -&gt; master, testing) v265cd212 initial commit!# 当前 HEAD 指针所指向的分支是master，代表当前所在分支。 3.2 创建分支1git branch your_name 这会在当前提交对象上创建your_name的一个指针，代表创建了一个分支。 3.3 切换分支1git checkout branch_name 切换到branch_name这条分支。实际上会将head指针指向branch_name上。输出效果： 122348425 (HEAD -&gt; testing, master) v265cd212 initial commit!# （1）当你在testing分支提交时，会像现在这样： 123dcd85fe (HEAD -&gt; testing) add file a.c2348425 (master) v265cd212 initial commit!# （2）当你切换回mater分支时,head指针会指向master。 注意：你的工作目录恢复成 master 分支所指向的快照内容。 也就是说，你现在做修改的话，项目将始于一个较旧的版本。 本质上来讲，这就是忽略 testing 分支所做的修改，以便于向另一个方向进行开发。 （3）当你在master分支上再次提交修改时，你的项目就会产生分叉！ 1git log --oneline --decorate --graph --all 它会输出你的提交历史、各个分支的指向以及项目的分支分叉情况。 12345* c8f77ad (HEAD -&gt; master) somethign fixed| * dcd85fe (testing) add file a.c|/* 2348425 v2* 65cd212 initial commit!# Git 的分支实质上仅是包含所指对象校验和（长度为 40 的 SHA-1 值字符串）的文件，所以它的创建和销毁都异常高效。 3.3 分支工作流（1）创建并切换到新分支 1git checkout -b issue54 （2）删除分支 1git branch -d hostfix （3）合并分支 12345678//先切换到master分支$ git checkout masterSwitched to branch 'master'//然后将iss53分支合并到master分支$ git merge iss53Merge made by the 'recursive' strategy.index.html | 1 +1 file changed, 1 insertion(+) 和之前将分支指针向前推进所不同的是，Git 将此次三方合并的结果做了一个新的快照并且自动创建一个新的提交指向它。 这个被称作一次合并提交，它的特别之处在于他有不止一个父提交。 3.4 遇到冲突时的合并如果两次合并都涉及同一个文件的同一处修改，在合并它们的时候就会产生冲突。 此时需要手动排除冲突。步骤： git status 查看冲突的文件 逐一打开冲突文件修改 git add将修改完的文件放入暂存区 git commit提交修改 3.5 放弃合并1git merge --abort 有时候冲突太多了，直接放弃合并吧。 3.6 分支开发工作流比如只在 master 分支上保留完全稳定的代码——有可能仅仅是已经发布或即将发布的代码。 他们还有一些名为 develop 或者 next 的平行分支，被用来做后续开发或者测试稳定性——这些分支不必保持绝对稳定，但是一旦达到稳定状态，它们就可以被合并入 master 分支。 稳定分支的指针总是在提交历史中落后一大截，而前沿分支的指针往往比较靠前。 四、远程仓库控制4.1 查看远程仓库12$ git remoteorigin 它会列出你指定的每一个远程服务器的简写。默认情况下就只有一个origin。 使用选项 -v，会显示远程仓库使用的 Git 保存的简写与其对应的 URL。 123$ git remote -vorigin https://github.com/schacon/ticgit (fetch)origin https://github.com/schacon/ticgit (push) 4.2 添加远程仓库1git remote add &lt;shortname&gt; &lt;url&gt; 添加一个新的远程 Git 仓库，同时指定一个你可以引用的简写。 比如： 12345678$ git remoteorigin$ git remote add pb https://github.com/paulboone/ticgit$ git remote -vorigin https://github.com/schacon/ticgit (fetch)origin https://github.com/schacon/ticgit (push)pb https://github.com/paulboone/ticgit (fetch)pb https://github.com/paulboone/ticgit (push) 先查看现在有远程仓库，只有一个origin。然后添加一个简写为pb的远程仓库。再此查看对应的远程仓库，发现pb已经添加上了。 4.3 从远程仓库抓取fetch1$ git fetch [remote-name] 这个命令会访问远程仓库，拉取所有你还没有的数据（包括新的分支）。 git fetch 命令会将数据拉取到你的本地仓库 - 它并不会自动合并或修改你当前的工作。 如果你使用 clone 命令克隆了一个仓库，命令会自动将其添加为远程仓库并默认以 “origin” 为简写。 所以，git fetch origin 会抓取克隆（或上一次抓取）后新推送的所有工作。 4.4 推送到远程仓库push1git push &lt;远程仓库名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt; 将你本地的某个分支推送到远程的某个分支。两个分支名可以不相同。 如果一个本地分支和远程分支建立了联系（下节会讲，所谓联系就是一一对应），直接 git push就能推送到对应的远程分支。 4.5 跟踪分支track跟踪实际上意味着将本地分支与远程分支建立联系。 查看本地分支与远程分支之间的关系1git branch -vv 样例输出： 123 develop 3e7f1c3 [origin/develop: ahead 2] Fix bug #123 feature-abc 12a8ee2 [origin/feature-abc] New feature implementation* main 4d59b46 [origin/main: ahead 1, behind 2] Merge pull request #456 这个输出列出了本地仓库中的三个分支：develop、feature-abc和main。其中，星号(*)表示当前所在的分支是main。 对于每个分支，输出显示了以下信息： 分支名称 分支所依据的提交哈希值 与之对应的远程分支名称及其状态信息 在这个示例中，develop分支有两个本地提交尚未推送到远程，而feature-abc分支只有与远程分支同步的提交。同时，main分支有一个本地提交，需要将其推送给远程，并且还需要从远程拉取两个提交。 1、当克隆一个仓库时，git通常会自动地创建一个跟踪 origin/master 的 master 分支。 2、需要重点注意的是这个命令并没有连接服务器，它只会告诉你关于本地缓存的服务器数据。 如果想要统计最新的领先与落后数字，需要在运行此命令前抓取所有的远程仓库。 git fetch --all 跟踪一个远程分支（重要）1git checkout -b [local_branch] [remote_name]/[remote_branch] 这个命令会自动创建一个本地分支并跟踪远程分支。 这是一个十分常用的操作，所以 Git 提供了 --track 快捷方式： 1$ git checkout --track origin/[remote_branch] 直接创建本地的同名分支，跟踪远程分支。比如： 1git checkout --track origin/bugfix-update-v1.1 这会建立一个本地分支origin/bugfix-update-v1.1，它会自动与远程同名分支建立联系。 修改本地分支跟踪的远程分支1$ git branch -u [remotename]/[remote_branch] 这条命令将设置当前分支跟踪的远程分支。 或者这条命令也有同样效果。 1$ git branch --set-upstream-to=[remotename]/[branch] 4.6 拉取分支pull1git pull git pull是指将远程仓库的代码更新到本地仓库，并合并到本地分支上。 具体来说，git pull命令相当于执行了两个命令： git fetch：从远程仓库拉取最新的代码，并将其存放在本地的“FETCH_HEAD”引用中，但不会修改本地分支。 git merge：将“FETCH_HEAD”引用合并到当前分支上，从而将最新的代码更新到本地仓库。 当执行git pull命令时，会自动执行以上两个步骤，从远程仓库拉取最新的代码，并合并到本地分支上，以使本地代码与远程仓库保持同步。 4.6 查看远程仓库查看某一个远程仓库的更多信息 1git remote show [remote-name] 重命名引用的名字 1git remote rename [old_name] [new_name] 比如将pb远程引用的仓库名称改为paul 1234$ git remote rename pb paul$ git remoteoriginpaul 五、标签Git 可以给历史中的某一个提交打上标签，标签可以看作是提交的一个快照，但它通常用于标记重要的里程碑，如发布新版本。与分支（branch）不同，标签是静态的，指向特定提交，不会随着新的提交而移动。 （1）A tag is immutable！ Tag是不可变的，在合入主分支与发布的期间，不必担心任何非预期的改变。 （2）便于管理 标签可比提交带有更多的信息。 5.1 标签使用（1）创建标签 1git tag v1.0 这会为当前HEAD指向的提交打上v1.0的标签。 （2）查看标签 1$ git tag -l 如果你没有查看到想要的标签信息，不妨 1git fetch --tags 这个命令会从远程仓库获取所有最新的tags。 （3）检出特定标签 1git checkout -b &lt;new_branch_name&gt; tags/&lt;tag_name&gt; 基于标签名称，创建新分支。 你不能直接“拉取”一个tag，但你可以通过检出tag或基于tag创建一个新分支来查看和使用特定版本的代码。","link":"/2023/12/01/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/Git/Git-fast-learning/"},{"title":"Learn Vim Efficiently 2","text":"这里将介绍vim的语法和光标浏览，这几乎是vim最重要的部分。 一、语法强烈推荐阅读： https://github.com/iggredible/Learn-Vim/blob/master/ch04_vim_grammar.md 不同于其他文本编辑器的快捷键（需要同时按下两个键或者三个键），vim的命令更像是编程，有一套特定的语法。 在vim中只有一个语法规则： 1动词+名词 1.1 动词所谓动词就是Operator，操作符。 用:h operator可以查看16种操作符，这里列举三种最常用的操作符。 123y Yank text (copy)d Delete text and save to registerc Delete text, save to register, and start insert mode 1.2 名词所谓名词就是motions，你用来在vim中移动的符号。这里是一些motions。 1234567h Leftj Downk Upl Rightw 移动到下一个单词b 反向移动到下一个单词$ 移动到本行末尾 1.3 动词+名词的语法体现假设你有如下文本： 1cosnt string learn = “vim”; 在正常模式下，你的光标在字母c上。 复制一整行:y$ y是复制，$是移动到一行末尾 删除const：dw d删除w一个单词 向左拷贝3个字母：y3h 删除2个单词：d2w 所以vim的命令不需要刻意记忆，就像自然语言。 以行为单位的操作很频繁，所以vim将准备了一些行操作的快捷方式：yy,dd和cc 1.4 更加快捷的操作假设你有如下文本： 1234int print(){ console.log(&quot;hello vim&quot;); int a[15];} 快速删除括号内的内容di( 快速删除双引号里的内容di&quot; 快速删除中括号内的内容di[ 这将是vim的必杀技。di代表着delete inner。对于结构化的文本，特别是代码。 12i + object Inner text objecta + object Outer text object da(将会连括号一起删除。 1234567891011w A wordp A paragraphs A sentence( or ) A pair of ( ){ or } A pair of { }[ or ] A pair of [ ]&lt; or &gt; A pair of &lt; &gt;t XML tags&quot; A pair of &quot; &quot;' A Pair of ' '` A pair of ` ` 二、光标移动强烈推荐阅读： https://github.com/iggredible/Learn-Vim/blob/master/ch05_moving_in_file.md 光标移动是很基础且重要的内容，一般我们退出编辑模式就是进行光标的移动。 2.1 字符移动12345hjklN + Motion 比如说5H向左移动5个字符。 2.2 单词间移动顾名思义，在单词间移动。 12345w Move forward to the beginning of the next worde Move forward one word to the end of the next wordb Move backward to beginning of the previous word 一般命令都会有大写和小写两个版本，或者代表着两个方向，或者代表着两个不同的意思。 123456W Move forward to the beginning of the next WORDE Move forward one word to the end of the next WORDB Move backward to beginning of the previous WORDge Move backward to end of the previous wordgE Move backward to end of the previous WORD 那么大写的单词和小写的单词有什么区别呢？单词都是被空白字符分隔的字符串。 小写单词只包括字母和数字 大写单词包括任何字符除了空格、制表符和 EOL 2.3 行间移动或者叫行内水平移动更佳。 1230 Go to the first character in the current line$ Go to the last char in the current linen| Go the column n in the current line 值得说是n|，在代码的报警信息中经常能看到第几行第几列报错，使用这个命令能快速定位到出错列。n代表任意数字。 快捷的操作：行内搜索。我认为这是vim的第二个必杀技。 12f Search forward for a match in the same linet Search forward for a match in the same line, stopping before match 利用f可以快速到达你想要的字符面前。比如说fa，快速将光标定位到第一个a的位置。 快速记住f和t的区别：f代表find，找到。t代表till，直到。 同样大小写两个版本代表着两个方向。 12345F Search backward for a match in the same lineT Search backward for a match in the same line, stopping before match; Repeat the last search in the same line using the same direction, Repeat the last search in the same line using the opposite direction 使用;和.能避免重复劳动。记住上次的 行内查找操作。 2.4 行号移动这才是名副其实的行间移动。比如说你想到第7行，命令7G 1234gg Go to the first lineG Go to the last linenG Go to line nn% Go to n% in file 2.5 搜索与替换终于来了，全文搜索与替换。 1234/ Search forward for a match? Search backward for a matchn Repeat last search in same direction of previous searchN Repeat last search in opposite direction of previous search 比如说，现在我们有这样一段文本： 123const int a = 1;const int b = 2;int c = 3; 现在我们想要将所有的int都替换为float： \\int&lt;Enter&gt; 这时你将定位到第一个int cwfloat&lt;Esc&gt; change word改变一个单词，然后输入float n. 继续下一个搜索，然后用点命令重复改变 这时你就能发现vim的快捷了。 还有一些快捷命令： 1234* Search for whole word under cursor forward# Search for whole word under cursor backwardg* Search for word under cursor forwardg# Search for word under cursor backward g*和*的作用，客观自行搜索。 2.6 窗口与浏览To scroll, you have 3 speed increments: full-screen (Ctrl-F/Ctrl-B), half-screen (Ctrl-D/Ctrl-U), and line (Ctrl-E/Ctrl-Y). 123456* Ctrl-E Scroll down a lineCtrl-D Scroll down half screenCtrl-F Scroll down whole screen* Ctrl-Y Scroll up a lineCtrl-U Scroll up half screenCtrl-B Scroll up whole screen You can also scroll relatively to the current line (zoom screen sight): 123zt Bring the current line near the top of your screen* zz Bring the current line to the middle of your screenzb Bring the current line near the bottom of your screen 这里留下作者的话： Finally, realize that you do not need to know every single Vim command to be productive. Most Vim users don’t. I don’t. Learn the commands that will help you accomplish your task at that moment. Take your time. Navigation skill is a very important skill in Vim. Learn one small thing every day and learn it well. 三、Vimrc3.1 是什么？vimrc是vim的配置文件。 3.2 有什么用？它能将某些设置永久保存。什么意思呢？比如说，你现在打开vim设置了行号:set number，当你下一次打开vim时，这个设置就失效了。通过vimrc就能永久保存设置。 一般vimrc在用户目录下， ~/.vimrc. 3.3 它有哪些内容？一般来说，vimrc主要配置以下内容： Plugins Settings Custom Funcitons Custom Commands Mappings 我们只挑常用的讲，设置settings和映射mappings。 当你改变vimrc时，记得source it。 Save it (:w), then source it (:source %). 3.4 设置你可以准备一些常用的设置： 12set numberset nocompatible Since we are learning about Vim and not Vi, a setting that you must have is the nocompatible option. Add set nocompatible in your vimrc. Many Vim-specific features are disabled when it is running on compatible option. 3.5 映射你可以将一些键位映射成一系列命令的组合。这是个非常有用的功能。比方说，你如果不习惯vim的hjkl你可以映射为类似方向键布局的jkli。 语法为： 1nnoremap &lt;key&gt; &lt;key&gt; n意味着normal模式 nore意味着non-recursive，不递归的 map就是映射 如何理解non-recursive呢？让我们来看一个例子： 你现在想要实现这样一个功能：按B就能在每一行的末尾加一个分号，然后退回到上一个单词。你写出这样： 1nmap B A;&lt;esc&gt;B 注意，A行末尾插入，分号，esc退回到normal模式，B回退一个单词。 这看起来很美好，但实际上这个命令会加无限多的分号。除非你按Ctrl-C停止。 为什么？因为没有设置不递归，最后一个B也被解释为映射后的B，而不是映射前的B（回退单词）。 所以，最好在平常中都使用不递归的映射。 好了，现在你可以实现一些快捷的功能了。 1inoremap jk &lt;esc&gt; 这个命令在插入模式下，同时按住jk就能退出插入模式。 map命令的首字母对应不同的模式，这里留给大家探索。 四、后序多用，多折腾。 这里留下作者的话： Vimrc is an important component of Vim customization. A good way to start building your vimrc is by reading other people’s vimrcs and gradually build it over time. The best vimrc is not the one that developer X uses, but the one that is tailored exactly to fit your thinking framework and editing style.","link":"/2023/11/22/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/Vim/VIm-2/"},{"title":"Learn Vim Efficiently 1","text":"前言：学linux时接触了vim这个编辑器，当时只知道三种模式转换，并不觉得vim有多好用。看南大蒋炎岩操作系统课程时，jyy在shell上键指如飞，我就思考为什么他能够编辑得这么快。我想到的一个点就是光标的移动。在没有接触vim之前，我都是通过键盘右下角的上下左右键进行光标的移动，这意味着右手需要移动一段距离。而接触vim之后，hjkl的移动映射只能说真香。现在我恨不得接触到的每个文本编辑器都有vim工作模式。 推荐阅读： https://github.com/iggredible/Learn-Vim https://missing.csail.mit.edu/2020/editors/ 快速体验：力扣刷题设置绑定vim键位，快速体验vim。 三种工作模式知道vim的三种工作模式 ：编辑模式（insert mode）、命令行模式（command line mode）、正常模式（normal mode） 编辑模式：最一般的文本编辑 按i进入，&lt;Esc&gt;退出 命令行模式：保存文件，离开，读入文件，显示行号等 按:显示，&lt;Esc&gt;退出 正常模式：光标移动、删除、复制粘贴、查找替换 初始模式，&lt;Esc&gt;总能返回normal mode 推荐将&lt;Esc&gt;键位映射至&lt;Caps&gt;键位。 hjkl光标移动与插入模式在normal mode下，可以通过hjkl键进行光标的移动，练会以后很香。 光标移动： 123456h Leftj Downk Upl Rightw 移动到下一个单词（挖坑、w和W区别）b 反向移动到下一个单词 插入模式： i 光标之前 I 本行开头 a 光标之后 A 本行结尾 o 本行之后新增一行插入 O 本行之前新增一行插入 s 删除当前字符插入 S 删除当前行插入 复制粘贴撤销删除在normal mode下可以进行以下操作： yy 复制当前行 （y代表 yank） dd 剪切当前行 p 粘贴 paste u 撤销 undo （挖坑，u撤销的到底是什么？） &lt;ctrl-r&gt; 重做 redo 可视化编辑 v 文本块编辑 V 行块编辑 Ctrl-v 块编辑 123y Yank text (copy)d Delete text and save to registerc Delete text, save to register, and start insert mode 后序： 本文以学windows文本编辑器的逻辑介绍了vim。学vim重要的是提高效率，如何快速入门vim？我想是掌握最常用的操作，抛弃那些看起来效率很高但是使用频率低的操作（比如e、E、ge、gE），这些只会徒增记忆的烦恼。待到使用这些命令成为肌肉记忆时，再学习也不迟。 好了，学会以上这些就算简单入门了，实际上vim还有更多命令，能带来效率质的提高。看不如动手，去力扣刷题吧，感受vim的魅力。 更多材料： vim-commands-cheat-sheet vim-cheet-sheet","link":"/2023/11/22/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/Vim/Vim-1/"},{"title":"Learn Vim Efficiently 4","text":"这里介绍将Vim当作开发工具的几个特性：文件浏览、分屏、查找。 文件浏览文件浏览能力利用的是Vim的原生插件：NetRW。 之前的Vim操作都是直接 Vim+文件名，现在你可以 Vim+目录 快速进入文件浏览界面。利用hjkl进行方向移动，利用Enter键进入目录内并选择一个具体文件打开。 如果已经提前打开文件了，如何再一次进入文件浏览界面呢？ 123:edit . #edit可以简化为e:edit src/client/:edit app/controllers/ 也可以在其他窗口打开netrw界面。 123:Explore 从当前文件启动netrw。:Sexplore Sex_Plore?不是开玩笑:)，在顶部水平分割的窗口打开netrw。:Vexplore 在左侧垂直分割的窗口打开netrw。 分屏显示输入以下命令，上下分屏和左右分屏。 12:split:vsplit 如果想要在窗口间切换，利用ctrl-w前缀符+hjkl进行切换。 1234Ctrl-W H Moves the cursor to the left windowCtrl-W J Moves the cursor to the window belowCtrl-W K Moves the cursor to the window upperCtrl-W L Moves the cursor to the right window 然后是一些更好用的组合键 1234Ctrl-W V Opens a new vertical splitCtrl-W S Opens a new horizontal splitCtrl-W C Closes a windowCtrl-W O Makes the current window the only one on screen and closes other windows Vim查找利用 / 完成正则模式匹配，我感觉比较鸡肋。 n: 下一个列出的关键字 N: 上一个列出的关键字 Vim配置 配色方案：gruvbox 框架：vimPlus","link":"/2024/07/05/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/Vim/Vim-4/"},{"title":"Learn Vim Efficiently 3","text":"这里介绍点命令、寄存器和宏。点命令比较有用，寄存器和宏比较鸡肋。 一、 点命令点命令 . 可以重复你在vim中的改变。 1.1 change in vim在vim中，究竟什么被视为一个改变？ 简单的来说，从进入插入模式到退出之间的所有操作！ 1.2 一个点命令的快捷使用方式比如说，现在我们有这样一段文本： 123const int a = 1;const int b = 2;int c = 3; 现在我们想要将所有的int都替换为float： \\int&lt;Enter&gt; 这时你将定位到第一个int cwfloat&lt;Esc&gt; change word改变一个单词，然后输入float n. 继续下一个搜索，然后用点命令重复改变 点命令的最佳使用场景就是变量更名，当你修改完一个变量的名字，移动光标到下一个变量，然后应用点命令。 二、寄存器在vim中有10种类型的寄存器，不过我并不打算全部介绍它们。 关于寄存器，我们要知道： 有哪些？ 怎么往寄存器里存值？ 怎么从寄存器里取值？ 2.1 start by 4 types register 匿名寄存器：&quot;&quot; 拷贝寄存器：&quot;0 数字寄存器：&quot;1-9 和字母寄存器：&quot;a-z small delete register：&quot;- 寄存器总是以双引号开头，后面跟着一个符号。 匿名寄存器，是我们最常用的寄存器。这里的常用，是它被vim使用，而不是我们主动显式地调用。之前讲的dd,yy,p快捷方式都是往匿名寄存器里存值或取值。 拷贝寄存器，是我们使用y操作符时关联的寄存器。注意yy命令会同时拷贝匿名寄存器和拷贝寄存器，利用这点我们就能得到一个缓存。比如说先用yy再用dd，此时匿名寄存器被更新，如果想用第一次复制的内容，需要从拷贝寄存器拉值&quot;0p。 数字寄存器和字母寄存器都是常规寄存器，主要是往里面存值和取值。 samll ddelete register主要用于小单词的存取。当你diw一个单词的时候，这个单词就会存在这个寄存器中。 2.2 寄存器存取值对寄存器的操作都很简单，用双引号来调用一个寄存器，后面跟上你的命令。 比如，现在你有以下文本： 1const int a = 1; &quot;ad3l&lt;esc&gt; 向左删除3个字符，存在寄存器a中 j 移动到下一行 &quot;ap 从寄存器a中取值 三、宏3.1 是什么？宏可以看作一系列操作的录制，它能帮助你避免许多的重复劳动，在你需要的时候自动执行预先录制好的操作。 3.2 录制宏如果要录制宏，当然需要一个能存储的宏的容器，在vim中，自然就是寄存器了。 录制宏 1q&lt;寄存器名&gt; 结束录制 1q 比如说，录制宏到寄存器4 1q4 之后，寄存器4会记录下你的每一个按键操作。 记得结束录制。 3.3 使用宏使用宏也很简单，用@调用存在寄存器里的宏。 1@&lt;寄存器名&gt; 或者 1@@ Execute the last executed macros 这个命令直接执行上一次录制的宏。 举一个例子：我们想要大写每一个单词 12345hellovimmacrosareawesome With your cursor at the start of the line “hello”, run: 1qa0gU$jq The breakdown: qa starts recording a macro in the a register. 0 goes to beginning of the line. gU$ uppercases the text from your current location to the end of the line. j goes down one line. q stops recording. To replay it, run @a. Just like many other Vim commands, you can pass a count argument to macros. For example, running 3@a executes the macro three times.","link":"/2023/11/22/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/Vim/vim-3/"},{"title":"Linux命令","text":"学习思路： 大类相关：系统资源查看、文件操作 命令基本知识，比如选项参数、输出情况 应用场景：针对特定需求写命令 你应该知道的linux技巧 https://coolshell.cn/articles/8883.html 杂项sudo !! # 执行上条权限不够的命令 查看操作系统版本（1）lsb_release 1lsb_release -a 这个命令通过读取/etc/lsb-release文件（如果存在的话），来显示Linux Standard Base (LSB) 信息，包括发行版的ID、版本号等。不是所有的Linux发行版都支持LSB，但许多常见的发行版（如Ubuntu、Debian、Fedora等）都支持。 12345LSB Version: n/aDistributor ID: Ubuntu Description: Ubuntu 20.04.2 LTS Release: 20.04 Codename: focal （2）cat 1cat /etc/*release 这个命令通过查看/etc/目录下以release结尾的文件，来获取操作系统的版本信息。这种方法更加通用，因为几乎所有Linux发行版都会在/etc/目录下放置一个或多个包含版本信息的文件。 查看内核版本1uname -a 详细的内核信息（包括内核名称、主机名、内核版本、处理器类型等） 1Linux myhostname 5.4.0-65-generic #73-Ubuntu SMP Mon Jan 18 17:25:17 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux 利用-r选项可只显示版本信息 123uname -r5.4.0-65-generic 文件管理查看 ls head、tail less、more、cat ls只能查看文件的大小（当有目录时，显示的是目录的大小，而不是目录含有的文件大小）；正确方法为使用du递归统计一个目录大小 管理 chmod、chown 文件解压缩压缩命令：tar -zcvf 压缩文件名.tar.gz 被压缩文件名 解压命令：tar -zxvf 压缩文件名.tar.gz -C /指定路径 1lz4 -d file.lz4 -o output_file 系统资源管理进程情况PS（1）查询指定名称的进程pid，cpu 占用率和 memory 使用率 1ps aux | grep example （2）杀死指定pid进程 1kill process_pid （3）查看进程号为1172的相关线程 1ps -T -p 1172 注： a: 显示终端上的所有进程，包括其他用户的进程。 u: 以用户为中心的格式显示进程信息，通常包含用户ID、CPU和内存使用情况等信息。 x: 显示没有控制终端的进程。 p: 显示进程的PID（进程ID） -T 选项告诉ps命令显示与指定进程相关的线程。 cpu使用情况top（1）top与ps区别 top命令可以实时地展示系统当前的进程状态，它会不断更新，提供系统进程的动态信息。而ps命令则是系统在过去执行的进程的静态快照，它不能实时更新。 此外，top命令还具有交互性，允许用户输入控制命令，比如在top命令的模式下输入n5，就显示此时的5个最活跃的进程，top会持续运行直到用户按下“q”，退出top。 （2）top显示特定进程的线程情况 1top -Hp 16735 -H：显示线程（而非仅显示进程）。这意味着 top 会显示每个进程的线程信息，而不仅仅是进程本身。 -p：后面跟随一个或多个 PID（进程ID），用来指定 top 命令只显示这些特定 PID 的信息。 内存使用情况1free -h 查看内存使用情况，例如 1234 total used free shared buffers cachedMem: 2016 1973 42 0 163 1497-/+ buffers/cache: 312 1703Swap: 4094 0 4094 磁盘使用情况（1）统计各个磁盘 1df -h 查看磁盘设备的使用情况，例如 123456[root@LinServ-1 ~]# df -h文件系统 容量 已用 可用 已用% 挂载点/dev/sda2 140G 27G 106G 21% //dev/sda1 996M 61M 884M 7% /boottmpfs 1009M 0 1009M 0% /dev/shm/dev/sdb1 2.7T 209G 2.4T 8% /data1 （2）统计当前目录下，每个目录占用的大小 1du -sh ./* 网络管理查看端口占用1lsof -i:8080 文本操作grep查找，sed编辑，awk对数据分析并生成报告。 grep更适合单纯的查找或匹配文本，sed更适合编辑匹配到的文本，awk更适合格式化文本。 grepGrep能使用正则表达式搜索文本，并把匹配的行打印出来，全称是 Global Regular Expression Print，全局正则表达式打印。grep通过返回一个状态值来说明搜索的状态，如果模板搜索成功，则返回0，如果搜索不成功，则返回1，如果搜索的文件不存在，则返回2。 命令的基本格式： 1grep [option] pattern file 常见参数： -C（context） -B（before） -A（after）选项 实例： 1、系统报警显示了时间，但是日志文件太大无法直接 cat 查看。(查询含有特定文本的文件，并拿到这些文本所在的行) 1grep -n '2019-10-24 00:01:11' *.log 2、在文件夹 dir 中递归查找所有文件中匹配正则表达式 “pattern” 的行，并打印匹配行所在的文件名和行号： 1grep -r -n pattern dir/ awkAWK是文本处理命令( pattern-directed scanning and processing language)，名称取自三位创始人首字符。awk的大致逻辑是逐行读入文件，以空格为默认分隔符将每行切片，再对切开的部分再进行各种分析处理。 基本用法： 1awk '[pattern] {action}' {filenames} # 行匹配语句 awk '' 只能用单引号 pattern 是要匹配的模式，通常是基于正则表达式； action 是当模式匹配时要执行的动作； filename 是您要处理的文件名。 过滤(1) 例子 提取第1列与第4列 1$ awk '{print $1, $4}' netstat.txt 亦可格式化输出，格式化语义与C语言的printf语义一致 1$ awk '{printf &quot;%-8s %-8s %-8s %-18s %-22s %-15s\\n&quot;,$1,$2,$3,$4,$5,$6}' netstat.tx 提取第3列为0且第6列为LISTEN的行的第1列信息 1$ awk '$3==0 &amp;&amp; $6==&quot;LISTEN&quot;{print $1} ' netstat.txt 取出文件中的第一万至两万行 1awk 'NR&gt;=10000 &amp;&amp; NR&lt;=20000' &lt;filename&gt; （2）基本知识 比较运算符：!=, &gt;, &lt;, &gt;=, &lt;=, == 内建变量 名称 作用 $0 当前记录（这个变量中存放着整个行的内容） $1~$n 当前记录的第n个字段，字段间由FS分隔 FS 输入字段分隔符 默认是空格或Tab NF 当前记录中的字段个数，就是有多少列 NR 已经读出的记录数，就是行号，从1开始，如果有多个文件话，这个值也是不断累加中。 FNR 当前记录数，与NR不同的是，这个值会是各个文件自己的行号 RS 输入的记录分隔符， 默认为换行符 OFS 输出字段分隔符， 默认也是空格 ORS 输出的记录分隔符，默认为换行符 FILENAME 当前输入文件的名字 123456789- FS(Field Separator)：输入字段分隔符， 默认为空白字符- OFS(Out of Field Separator)：输出字段分隔符， 默认为空白字符- RS(Record Separator)：输入记录分隔符(输入换行符)， 指定输入时的换行符- ORS(Output Record Separate)：输出记录分隔符（输出换行符），输出时用指定符号代替换行符- NF(Number for Field)：当前行的字段的个数(即当前行被分割成了几列)- NR(Number of Record)：行号，当前处理的文本行的行号。- FNR：各文件分别计数的行号- ARGC：命令行参数的个数- ARGV：数组，保存的是命令行所给定的各参数 使用：打印首行 1$ awk '$3==0 &amp;&amp; $6==&quot;ESTABLISHED&quot; || NR==1 {printf &quot;%s %s\\n&quot;,NR,$4}' netstat.txt 指定分割符，利用短选项-F 1$ awk -F: '{print $1,$3,$6}' /etc/passwd 统计脚本awk其实是一门脚本语言，有自己的语法结构，变量定义、条件循环等流程控制。 参考：https://www.bookstack.cn/books/junmajinlong-awk （1）BEGIN 与 END BEGIN：当awk开始处理任何输入行之前，BEGIN模式下的代码块会执行一次。 END：当awk处理完所有输入行后，END模式被触发。 BEGIN 和 END都放在要执行的代码块之前。 （2）自定义变量与流程控制 自定义变量，统计文件中含有字符串 abc 的总行数 1awk '/abc/ {count++} END {print count}' filename.txt 自定义变量，统计目录下所有的C文件，CPP文件和H文件的文件大小总和。 1$ ls -l *.cpp *.c *.h | awk '{sum+=$5} END {print sum}' 自定义数组，统计各个connection状态的个数 1awk 'NR!=1 {a[$6]++;} END { for (i in a) print i &quot;, &quot; a[i]; }' netstat.txt 自定义数组，统计每个用户的进程的占了多少内存 1ps aux | awk 'NR!=1{a[$1]+=$6;} END { for(i in a) print i &quot;, &quot; a[i]&quot;KB&quot;;}' 自定义数组，统计一个文件(IP TIME) 的每个IP出现次数，并按次数排序 1awk '{ip[$1]++} END {for (i in ip) print ip[i], i}' access.log | sort -k2 sedsed全称（stream editor）流式编辑器，主要逻辑也是逐行匹配，编辑。玩sed主要还得熟练正则表达式。 sed最主要的场景就是匹配并替换。 more命令 回车 向下一行 空格 向下一页 b 向上一页（back） tail命令1tail -f #实时查看文件尾部内容","link":"/2023/12/22/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/%E5%91%BD%E4%BB%A4%E8%A1%8C/Linux%E5%91%BD%E4%BB%A4/"},{"title":"Missing Semmster Learning 学习笔记","text":"计算机教学中缺失的一课 ：https://missing.csail.mit.edu/。 这里的笔记主要关于：命令行、shell编程、shell环境。 一、Course overview + the shell认识shell。shell直译为壳，比喻为操作系统内核外面的一层，是我们同内核对话的一个界面。 推荐阅读：https://wangdoc.com/bash/intro bash是最常用的shell，可以把它当作一种编程语言，命令解释器。以下学习的就是bash的相关命令。 1.1 shell命令入门123echo &quot;hello world&quot;echo 'hello world'echo hello\\ world echo的字符用双引号或单引号包含。也可以不用它们，但遇到空格时要用反斜杠转译空格。（因为空格默认为分隔符） 1.2 how system can find echo?123echo $PATHwhich echo/bin/echo &quot;hello world&quot; echo其实是一段小程序，它也有自己的代码。通过$PATH这个系统变量，就能知道操作系统在哪里寻找echo的可执行文件。 也可以通过指定可执行文件的路径的方式来执行特定的可执行文件。 1.3 navigting in the shell1234cdpwdls和ls -l绝对路径和相对路径 理解linux的路径是一颗树，根路径从/开始。绝对路径从根开始，相对路径是相对于当前目录。 1.4 connecting programsprograms always associated with tow stream: input stream and output streamredirection &lt; file and &gt; filewhen cat is not given any arguments, it prints contents from its input stream to its output stream 12cat &lt; hello.txt| pipe command unix系统设计的哲学： 程序默认从键盘接受输入，输出到屏幕。（即每个程序关联标准输入流，标准输出流） 通过左右箭头符号可以重定向输入输出 管道可以将上一个程序的输出导入到下一个程序的输入 二、Shell Tools and Scriptingshell scripting, about learning a new language: basic data type Control flow If case while for syntax shell编程就是学新的编程语言，你需要知道： 数据类型 程序控制流 具体语法 2.1 variable如何定义变量？直接写出变量名，紧跟着等于号，最后是值。注意中间不能有空格。 1foo=bar # foo = bar is wrong 双引号和单引号在shell程序中的区别在于里面的变量是否会被解释。单引号不会解释变量。 12echo &quot;$foo&quot; # this print barecho '$foo' # this print $foo 2.2 function1234mcd () { mkdir -p &quot;$1&quot; cd &quot;$1&quot;} $0 name of program $1-9 arguments to the script $# number of arguments $$ pid $@ all the arguments $? the last command’s exit status 定义函数也非常简单，xxx。 2.3 Logical command123|| &amp;&amp;; # simplely seperate current command and the next command 或逻辑、与逻辑、单纯的分隔符。在命令行环境中也能使用。 2.4 command substitution1echo &quot;start program at $(date)&quot; 这就是先前讲的，双引号内的命令会被解释执行。前提是用$()包围。 2.5 Process substitution1234&lt;(cmd) # this will execute cmd and place the output in a temporary file and substitute the# &lt;() with that file's name 在Bash中，”&lt;(cmd)”是一种称为”Process Substitution”的特殊语法，它允许将命令的输出作为文件传递给另一个命令。 具体来说，”&lt;(cmd)”会将命令cmd的输出作为一个临时文件，并将该文件的路径作为参数传递给当前命令。 这个临时文件只存在于命令执行期间，并在命令执行完毕后自动删除。 2.6 wildcards and curly braces Wildcards - Whenever you want to perform some sort of wildcard matching, you can use ? and * to match one or any amount of characters respectively. For instance, given files foo, foo1, foo2, foo10 and bar, the command rm foo? will delete foo1 and foo2 whereas rm foo* will delete all but bar. Curly braces {} - Whenever you have a common substring in a series of commands, you can use curly braces for bash to expand this automatically. This comes in very handy when moving or converting files. 1234567891011121314151617181920212223convert image.{png,jpg}# Will expand toconvert image.png image.jpgcp /path/to/project/{foo,bar,baz}.sh /newpath# Will expand tocp /path/to/project/foo.sh /path/to/project/bar.sh /path/to/project/baz.sh /newpath# Globbing techniques can also be combinedmv *{.py,.sh} folder# Will move all *.py and *.sh filesmkdir foo bar# This creates files foo/a, foo/b, ... foo/h, bar/a, bar/b, ... bar/htouch {foo,bar}/{a..h}touch foo/x bar/y# Show differences between files in foo and bardiff &lt;(ls foo) &lt;(ls bar)# Outputs# &lt; x# ---# &gt; y 通配符的概念无需多言。？表示任意一个字符，*表示任意多个字符。 大括号的作用比较微妙。有点像for循环遍历列表，然后自动展开。 这三个符号能极大的拓展匹配，实现自动化操作。 2.7 shebang line1#!/bin/bash Shebang line是指在脚本文件的第一行中使用特定格式的注释来指定解释器的路径。Shebang（也称为 Hashbang ）是一个由井号和叹号构成的字符串行 *#!*。 Shebang line的作用是告诉系统应该使用哪个解释器来执行脚本，从而使脚本能够正确地运行。 Some differences between shell functions and scripts that you should keep in mind are: Functions have to be in the same language as the shell, while scripts can be written in any language. This is why including a shebang for scripts is important. Functions are loaded once when their definition is read. Scripts are loaded every time they are executed. This makes functions slightly faster to load, but whenever you change them you will have to reload their definition. Functions are executed in the current shell environment whereas scripts execute in their own process. Thus, functions can modify environment variables, e.g. change your current directory, whereas scripts can’t. Scripts will be passed by value environment variables that have been exported using export As with any programming language, functions are a powerful construct to achieve modularity, code reuse, and clarity of shell code. Often shell scripts will include their own function definitions. differences between shell functions and scripts functions are executed in the current shell environment scripts execute in their own process 执行shell脚本其实是另外开了一个进程执行，所以当前环境不受影响。 1source xx.sh 而source一个shell脚本其实是加载脚本内的变量，这会影响当前环境变量。 2.8 shell tools123456find grepuniqsortwcawk 一些好用的小工具： TLDR pages Tree fasd autojump nnn 五、Command-line Environment提升你的shell工作流。 5.1 job control你的shell使用一种叫做信号的机制在进程间沟通。信号是一种软中断机制。 123ctrl-c 传递SIGINT信号ctrl-\\ 传递SIGQUIT信号ctrl-z 传递SIGTSTP信号，short for Terminal Stop SIGTERM signal ask a process to exit. Using kill command to send it. kill jobs fg bg nohup 5.2 terminal multiplexerstmux教学 leading key &lt;C-b&gt; x means you press ctrl and b, then release them together, and then press x panes 123竖直分裂一个窗口 &lt;C-b&gt; %水平分裂一个窗口 &lt;C-b&gt; &quot;关闭当前窗口 exit or ctrl-d windows - equivalent to tabs in browsers(threads in process) 123&lt;C-b&gt; c 创建一个虚拟桌面&lt;C-b&gt; p 切换上一个&lt;C-b&gt; n 切换下一个 sessions - a session is an independent workspace with one or more windows 12345tmux # start a new sessiontmux new -s NAME # start a new session with nametmux ls #ls current sessionsdetach a session with &lt;C-b&gt; dattach a session `tmux a` , with -t to specify which 5.3 Aliases1alias name=&quot;command arg1 arg2&quot; 为你的常用命令设置别名，减少重复劳动。 使用alias可以查看设置的别名。 常见的别名设置： 1todo 5.4 Dotfiles隐藏文件，通常是各种程序的配置文件。 bash ~/.bashrc or~/.bash_profile git ~/.gitconfig vim ~/.vimrc tmux ~/.tmux.conf ssh~/.ssh/config 关于隐藏文件，我们需要知道三件事： 内容 位置 管理 5.5 Remote Machines（1）ssh远程登录 1ssh user@remote_server_name ssh远程登录十分重要。 1ssh user@remote_server_name command 如果只执行一条命令，不想登录远程主机。 1ls | ssh user@remote_server_name grep PATTERN 这条命令会先将本地ls的输出通过管道传送到远程机器的grep上。是不是很神奇。这就是Unix的设计哲学。 （2）如果你不想每次都输入密码，利用非对称加密算法中的公钥和私钥，就能免去麻烦。 Key generationTo generate a pair you can run ssh-keygen. 1ssh-keygen -o -a 100 -t ed25519 -f ~/.ssh/id_ed25519 You should choose a passphrase, to avoid someone who gets hold of your private key to access authorized servers. Use ssh-agent or gpg-agent so you do not have to type your passphrase every time. If you have ever configured pushing to GitHub using SSH keys, then you have probably done the steps outlined here and have a valid key pair already. To check if you have a passphrase and validate it you can run ssh-keygen -y -f /path/to/key. Key based authenticationssh will look into .ssh/authorized_keys to determine which clients it should let in. To copy a public key over you can use: 1cat .ssh/id_ed25519.pub | ssh foobar@remote 'cat &gt;&gt; ~/.ssh/authorized_keys' A simpler solution can be achieved with ssh-copy-id where available: 1ssh-copy-id -i .ssh/id_ed25519 foobar@remote （3）文件传输 ssh+tee 1cat localfile | ssh remote_server tee serverfile tee命令读标准输入到一个文件中。 scp 1scp path/local_file remote_host:path/remote_file scp可以像cp一样，将本地文件cp到远程路径 rsync 增强的scp，不过多深入。 （4）端口转发 本地端口转发：发送给本地端口的请求发送到远程机器上 远程端口转发：远程机器监听请求，将请求转发给本地机器 1ssh -L local_ip:local_port:remote_ip:remote_port user@remote_seerver 这是本地端口转发的语法，L表示本地端口转发。本地网卡端口是可以省略的，这时表示local port绑定了本地主机所有的网卡。 比如： 1$ ssh -L 9999:localhost:8888 user@remote_server 通过访问本地localhost:9999就能访问远程服务器的localhost:8888服务。 了解跳板机的概念：https://developer.aliyun.com/article/1035160 5.6 Shells &amp; FrameworksOn-my-zsh Syntax-highlighting History-substring-search 框架是件美好的事情。","link":"/2023/12/01/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/%E5%91%BD%E4%BB%A4%E8%A1%8C/missing-semester-note/"},{"title":"LINUX&#x2F;MAC 打造次世代终端","text":"效果图： 对于终端的基本要求：语法高亮+命令补全+配色美化 涉及工具： zsh on-my-zsh powerlevel10k iterm2 网上有很多教程，做得也很好，贴一下链接： Mac 终端美化指南 - 知乎 https://segmentfault.com/a/1190000022813972 安装字体 Nerd Fonts 是一个使用大量字体图标来解决程序员在开发过程中缺少合适字体的问题的项目。它可以从流行的字体图标库中将大量外部字体引入待开发的项目中，它支持的字体图标库包括 Font Awesome , Devicons , Octicons , and others。 Nerd fonts 就是把各种常见的 ‘iconic fonts’，打包到你常用的字体里，这样在命令行里就支持显示这些图标了。 reference：https://blog.csdn.net/SmallTeddy/article/details/124850597 安装 nerd font123&gt;&gt;&gt; git clone https://github.com/ryanoasis/nerd-fonts.git --depth 1&gt;&gt;&gt; cd nerd-fonts&gt;&gt;&gt; ./install.sh 安装zsh zsh是一款强大的交互式shell，也可以作为脚本解释器来使用。它融合了bash、ksh、tcsh等其他shell中的许多优秀功能，并具备诸多自身特色。zsh最初由保罗·弗斯塔德（Paul Falstad）于1990年在普林斯顿大学求学时编写，其名称来源于普林斯顿大学助教的邵中（Zhong Shao）的用户名“zsh”。zsh以其开箱即用的命令行补全功能、可编程性、强大的变量与数组处理能力、多兼容模式以及完全可定制化的特性而著称。自macOS Catalina版本起，zsh成为macOS的默认shell。 zsh与bash的比较 特性 zsh bash 起源与发展 最初由保罗·弗斯塔德编写，后由彼得·斯蒂芬森等人继续开发。 由布莱恩·福克斯为GNU计划编写，是Bourne shell的后继兼容版本。 默认shell地位 macOS Catalina及以后版本的默认shell。 曾是许多Linux发行版和旧版macOS的默认shell。 交互性 提供更强大的交互性特性，如更好的自动补全、拼写纠正等。 也具备自动补全等功能，但相对zsh来说可能稍逊一筹。 配置 拥有一个交互式配置器，便于定制shell环境。 配置过程通常需要编辑.bashrc或.bash_profile文件，相对较为繁琐。 兼容性 在大多数系统上都能运行，但并非所有系统的默认shell环境。 几乎在所有的Unix系统中都是默认的shell环境，脚本兼容性好。 社区支持 社区用户群体和支持相对较小，但社区正在不断壮大。 拥有大量的用户和社区支持，教程和资源丰富。 插件和主题 拥有Oh-My-Zsh等社区驱动的框架，提供丰富的插件和主题。 插件和主题相对较少，需要手动配置和安装。 性能 通常比bash更快，且功能更加强大。 性能稳定，但相对于zsh来说可能在某些方面稍逊。 如果你的系统是mac，它自带zsh，不需要安装。 on-my-zsh Oh My Zsh 是一个开源的、社区驱动的命令行工具，它基于 zsh（Z Shell）命令行，为 zsh 提供了丰富的主题配置、插件机制以及内置的便捷操作。Oh My Zsh 的出现极大地改善了 zsh 的使用体验，为用户带来了一种全新的命令行交互方式。 Oh My Zsh 的主要特点包括： 主题配置：Oh My Zsh 提供了大量的主题供用户选择，这些主题可以自定义命令行的外观，包括颜色、字体、提示符样式等，使得命令行界面更加美观和个性化。 插件机制：Oh My Zsh 支持安装各种插件，这些插件可以扩展 zsh 的功能，比如提供自动补全、语法高亮、命令历史记录等功能，从而提高用户的工作效率。 便捷的命令操作：Oh My Zsh 内置了许多便捷的命令操作，比如快速跳转到指定目录、快速查看文件内容等，这些操作可以极大地简化用户的命令行操作过程。 on-my-zsh 安装以下四个命令选一个，会自动下载执行install脚本。 1234sh -c &quot;$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot;sh -c &quot;$(curl -fsSL https://gitee.com/mirrors/oh-my-zsh/raw/master/tools/install.sh)&quot;sh -c &quot;$(wget https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)&quot;sh -c &quot;$(wget -O- https://gitee.com/pocmon/mirrors/raw/master/tools/install.sh)&quot; curl是一个用于从服务器传输数据的命令行工具，支持多种协议，包括HTTP、HTTPS等。 $(...) 这是命令替换的语法。它会执行括号内的命令，并将输出替换到当前位置。 sh -c 选项后面跟着的字符串是要由sh执行的命令。 插件安装方法首先将插件下载到 ${ZSH_CUSTOM:-/.oh-my-zsh/custom 目录下，然后在 `/.zshrc` 中设置开启的插件。 （1）语法高亮 zsh-syntax-highlighting 1git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting （2）自动提示 zsh-autosuggestions 1git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions （3）配置 .zshrc 在 ~/.zshrc 中设置 plugins=(git zsh-autosuggestions zsh-syntax-highlighting) 然后再生效一下 source ~/.zshrc iterm2 iTerm2 是一款专为 macOS 用户设计的强大终端模拟器，旨在提供比 macOS 默认的 Terminal.app 更丰富、更高效的终端体验。 iterm2安装从官网上点击下载安装包：https://iterm2.com/downloads.html 像安装正常软件一样安装Iterm2即可，或者利用homebrew下载： 1brew install iTerm2 iterm2其他设置设置字体iTerm2 -&gt; Preferences -&gt; Profiles -&gt; Text -&gt; Font 修改字体为 Hack Nerd Font 为了测试是否成功，可以到这个网址：www.nerdfonts.com/cheat-sheet 点击 Show All Icons 按钮，选择一个图标，点击右上角的 Copy Icon，然后粘贴到我们的 Terminal 命令行里。 设置状态栏可以为每个打开的终端都设置一个状态栏，显示一些系统信息（比如 CPU、RAM、当前目录等）。 Profiles -&gt; session-&gt; 勾选 Status bar enable-&gt; configure Status bar，选择自己想要的展示内容即可。 统一标签页配色打开iTerm2，打开Preferences配置界面，Appearence -&gt; General，将 Theme 改为 Minimal 设置终端历史行数打开iTerm2，打开Preferences配置界面，Profiles -&gt; Terminal，根须需求进行修改，如果想不限制行数可以勾选Unlimited scrollback powerlevel10k Powerlevel10k 是一个高度可定制化的 Zsh（Z Shell）主题，旨在提升终端用户的体验，使其既美观又实用。 Powerlevel10k 是 Powerlevel9k 的改进版本，具有更快的渲染速度和更好的兼容性。它基于 Zsh 这一功能强大的 Unix shell，利用了 Zsh 的自动完成、语法高亮和命令历史搜索等高级特性，并进一步优化了终端的界面显示。 powerlevel10k安装以下两个命令二选一 12git clone --depth=1 https://github.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10kgit clone --depth=1 https://gitee.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k 设置主题打开zshrc文件然后修改ZSH_THEME 12open ~/.zshrcZSH_THEME=&quot;powerlevel10k/powerlevel10k&quot; 然后进行手动完成配置，执行下面的命令为逐步引导你完成主题配置 1p10k configure 执行完命令之后，就会初始化 p10k，在根目录下生成 ~/.p10k.zsh，并且在 ~/.zshrc 底部写入： 12# To customize prompt, run p1ok configure’or edit ~/ .p10k.zsh.[[ ! -f ~/.p10k.zsh ]] | | source ~/.p10k.zsh 如果想废除 p10k 的配置，只需要删除 ~/.p10k.zsh，并且删除上面这条命令即可。 踩坑zsh-autosuggestion的配色问题自动提示的颜色有时会淹没在背景色中，需要修改它的颜色。 在zshrc中追加一行： 1ZSH_AUTOSUGGEST_HIGHLIGHT_STYLE='fg=blue' 当前仅支持有限种颜色： black, red, green, yellow, blue, magenta, cyan and white","link":"/2023/12/01/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/%E5%91%BD%E4%BB%A4%E8%A1%8C/%E6%89%93%E9%80%A0%E6%AC%A1%E4%B8%96%E4%BB%A3%E7%BB%88%E7%AB%AF/"},{"title":"终端基础知识","text":"命令行、终端、Shell、Promt的基础认知。 操作系统自带的终端都很丑且难用，好用的终端需要一番折腾配置（特别是国内环境网络问题），新手往往望而生畏。 【在学校没有人教你的终端基础知识】 https://www.bilibili.com/video/BV1rk4y1W7dZ 一、CLICLI is the abbreviation of Command Line Interface. It’s a text-based way of interacting with a computer. 相比于图像界面提供的按钮，你可以使用一行命令来实现你想要的功能，比如说打开、关闭文件，从而实现与计算机的交互。 那么，你在哪里输入这种文本命令？ 二、TerminalTerminal直译为终端，什么是终端？你可以理解为计算机与人们之间沟通的桥梁。通常它是一个全黑的窗口，可以输入命令并提供反馈。 终端是一款软件，许多系统都有自带的终端。也可以使用其他的终端软件。 三、ShellShell直译为壳，这里不必纠结翻译问题。 Shell运行在终端中，解释你的输入并执行它们。可以简单理解为一个命令解释器，不同的shell有不同的语法。 你输入的文本就好比日常生活中人与人沟通的话，计算机有自己的二进制语言，你有自己的一套语言，比如汉语、英语、法语、日语，Shell就在其中充当翻译官的角色。 四、Prompt命令提示符。在终端中，命令提示符用来提示你输入。比如说提示你当前所在的路径等等","link":"/2023/12/01/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/%E5%91%BD%E4%BB%A4%E8%A1%8C/%E7%BB%88%E7%AB%AF%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"title":"PG中的临界区","text":"critical section 关键区的作用 引子gtm.h文件 123456#define START_CRIT_SECTION() (CritSectionCount++)#define END_CRIT_SECTION() do { \\ Assert(CritSectionCount &gt; 0); \\ CritSectionCount--; \\} while (0) 在代码中我们可以看到这样一些调用： 123START_CRIT_SECTION() ...END_CRIT_SECTION() 这两行代码不过是对一个CritSectionCount进行加减，怎么起到对关键区的保护？ 解释在errstart中，如果发生问题，有一个判断： 1234567891011/* * Check some cases in which we want to promote an error into a more * severe error. None of this logic applies for non-error messages. */if (elevel &gt;= ERROR &amp;&amp; u_sess != NULL) { /* * If we are inside a critical section, all errors become PANIC * errors. See miscadmin.h. */ if (t_thrd.int_cxt.CritSectionCount &gt; 0) elevel = PANIC; 如果 CritSectionCount 没有清0，说明错误发生在临界区内，于是把错误级别置为 PANIC 严重错误。 PANIC错误不会返回false，因此会进行整个错误处理过程。","link":"/2024/08/11/%E6%95%B0%E6%8D%AE%E5%BA%93/PostgreSQL/PG%E4%B8%AD%E7%9A%84%E4%B8%B4%E7%95%8C%E5%8C%BA/"},{"title":"PG中的Latch分析","text":"PG中的latch很奇怪，不是lock的语义，而是一种等待唤醒机制，其背后还有着更深层的含义。 引子考虑这样一个场景：使用IO复用函数比如select时，进程收到一个信号，会怎么处理？ 答案是：select返回-1，并设置errno为EINTR=4（Interrupted system call）。可见select被信号打断了，在代码中应该考虑这种状况。 为什么会这样？ 信号的自定义处理函数在用户层，IO复用函数调用时在内核层 内核态转到用户态，之前的系统调用被打断 不只是select，比如sleep系统调用，如果收到信号也是提前返回，以下是一个实现不被SIGINT信号打扰的sleep例子： 1234567891011121314151617181920212223#include&lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;signal.h&gt;#include &lt;unistd.h&gt; void sig_handler(int num){ printf(&quot;\\nrecvive the signal is %d\\n&quot;, num);} int main(){ int time = 20; signal(SIGINT, sig_handler); printf(&quot;enter to the sleep.\\n&quot;); do{ time = sleep(time); }while(time &gt; 0); printf(&quot;sleep is over, main over.\\n&quot;); exit(0);} 那么，有什么方法能够将信号处理与IO事件处理互相统一（比如在select中监听信号事件）呢？有，那就是self-pipe技巧。 self-pipe trick自管道技巧，与网络编程中的一个概念统一事件源很相似，操作手法为： 定义一个匿名管道（进出全部非阻塞）只给当前进程自己使用，所以叫self-pipe。 用select监听业务IO事件 并 监听self-pipe[0]读端。 当信号到来时，信号处理函数在self-pipe[1]中写入1个字节就退出。 select被self-pipe[0]唤醒，检查FD_ISSET(self-pipe[0]…)是否就绪，走信号处理流程。 大概就是这样的流程： 有什么好处？ 私以为：信号处理和IO复用处理明显同步了，先IO复用再信号处理，可以避免潜在的竞争。管道上传来的字节能够可靠地中断IO调用，即使信号在IO复用函数调用开始之前到达。 reference:https://cloud.tencent.com/developer/article/2001066?from_column=20421&amp;from=20421 Latch好了，讲了那么多，self-pipe和Latch有什么关系？ 答案是：Latch其实就是self-pipe技巧的封装。 数据结构大概有以下几个Latch相关的函数 1234567InitLatch()，初始化一个非共享型 LatchInitSharedLatch()，初始化一个共享型 LatchWaitLatch()，等待 LatchResetLatch()，重置 LatchSetLatch()，设置 Latch 标记，唤醒等待 Latch 的进程OwnLatch()，设置 Latch 的拥有者为当前进程DisownLatch()，当前进程不再拥有该 Latch Latch的结构体： 12345typedef struct { sig_atomic_t is_set; //是否设置 bool is_shared; //是否共享 ThreadId owner_pid; // 拥有者的线程ID} Latch; InitializeLatchSupportInitializeLatchSupport函数初始化process-local latch设施。该函数必须在任何进程启动过程中InitLactch或OwnLatch函数调用之前调用。 主要完成：创建管道，设置管道读端和写端全局变量。 12345678910111213141516171819202122void InitializeLatchSupport(void){ int pipefd[2]; Assert(selfpipe_readfd == -1); /* * Set up the self-pipe that allows a signal handler to wake up the * select() in WaitLatch. Make the write-end non-blocking, so that * SetLatch won't block if the event has already been set many times * filling the kernel buffer. Make the read-end non-blocking too, so that * we can easily clear the pipe by reading until EAGAIN or EWOULDBLOCK. */ if (pipe(pipefd) &lt; 0) ereport(FATAL, (errmsg(&quot;pipe() failed: %m&quot;))); if (fcntl(pipefd[0], F_SETFL, O_NONBLOCK) &lt; 0) ereport(FATAL, (errmsg(&quot;fcntl() failed on read-end of self-pipe: %m&quot;))); if (fcntl(pipefd[1], F_SETFL, O_NONBLOCK) &lt; 0) ereport(FATAL, (errmsg(&quot;fcntl() failed on write-end of self-pipe: %m&quot;))); selfpipe_readfd = pipefd[0]; selfpipe_writefd = pipefd[1];} InitLatchInitLatch函数初始化进程本地的latch（自己初始化自己的latch，设置latch的为当前进程的Pid）。 12345678void InitLatch(volatile Latch* latch){ /* Assert InitializeLatchSupport has been called in this process */ Assert(selfpipe_readfd &gt;= 0); latch-&gt;is_set = false; latch-&gt;owner_pid = t_thrd.proc_cxt.MyProcPid; // 设置latch的为当前进程的Pid latch-&gt;is_shared = false;} 在Latch上等待WaitLatch就是调用WaitLatchOrSocket函数，WaitLatchOrSocket比WaitLatch多了一个PGINVALID_SOCKET。 123int WaitLatch(Latch *latch, int wakeEvents, long timeout, uint32 wait_event_info) { return WaitLatchOrSocket(latch, wakeEvents, PGINVALID_SOCKET, timeout, wait_event_info);} 几个关键的数据结构： WaitEventSet 等待事件的集合 WaitEvent 等待事件 1234567891011121314151617181920212223242526272829303132/* typedef in latch.h */struct WaitEventSet{ int nevents; /* number of registered events */ int nevents_space; /* maximum number of events in this set */ /* * Array, of nevents_space length, storing the definition of events this * set is waiting for. */ WaitEvent *events; /* * If WL_LATCH_SET is specified in any wait event, latch is a pointer to * said latch, and latch_pos the offset in the -&gt;events array. This is * useful because we check the state of the latch before performing doing * syscalls related to waiting. */ Latch *latch; // 数组记录该set下所有的latch = event int latch_pos; int epoll_fd; /* epoll_wait returns events in a user provided arrays, allocate once */ struct epoll_event *epoll_ret_events;};// 每个epoll事件对应一个，也对应一个latchtypedef struct WaitEvent{ int pos; /* position in the event data structure */ uint32 events; /* triggered events */ pgsocket fd; /* socket fd associated with event */ void *user_data; /* pointer provided in AddWaitEventToSet */} WaitEvent; 怎么实现在latch上等待呢？实际上还是利用IO复用等待socket的事件。 WaitLatch调用时使用PGINVALID_SOCKET，随后使用Poll或者Select监听PGINVALID_SOCKET和管道读端。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105intWaitLatchOrSocket(volatile Latch *latch, int wakeEvents, pgsocket sock, long timeout, uint32 wait_event_info){ int ret = 0; int rc; WaitEvent event; WaitEventSet *set = CreateWaitEventSet(CurrentMemoryContext, 3);/******************************************************************CreateWaitEventSet展开：构造WaitEventSetWaitEventSet *set // 内存结构：set-&gt; sz += MAXALIGN(sizeof(WaitEventSet)) // 整体分配一个WaitEventSetset-&gt;events-&gt; sz += MAXALIGN(sizeof(WaitEvent) * nevents) // 每个事件有一个WaitEventset-&gt;epoll_ret_events-&gt; sz += MAXALIGN(sizeof(struct epoll_event) * nevents) // 要监听的3个事件set-&gt;latch = NULLset-&gt;nevents_space = neventsset-&gt;epoll_fd = epoll_create1(EPOLL_CLOEXEC) // 200w个******************************************************************/ if (wakeEvents &amp; WL_TIMEOUT) Assert(timeout &gt;= 0); else timeout = -1; if (wakeEvents &amp; WL_LATCH_SET) AddWaitEventToSet(set, WL_LATCH_SET, PGINVALID_SOCKET, (Latch *) latch, NULL);/******************************************************************WL_LATCH_SET会进入这个分支：AddWaitEventToSet(WaitEventSet *set, uint32 events, pgsocket fd, Latch *latch, void *user_data)1、现在的latch={is_set = 0, is_shared = 1 '\\001', owner_pid = 30877}， 30877是startup的pid2、开始拼WaitEvent *event; event = &amp;set-&gt;events[set-&gt;nevents] ... event-&gt;fd = selfpipe_readfd ***********注意这里监控的是管道的读端 ... //set: {nevents = 1, nevents_space = 3, events = 0xf81dd8, latch = 0x2aaaaac0d254, latch_pos = 0, epoll_fd = 7, epoll_ret_events = 0xf81e20} //event: {pos = 0, events = 1, fd = 13, user_data = 0x0} WaitEventAdjustEpoll(set, event, EPOLL_CTL_ADD) epoll_event epoll_ev： EPOLLERR：表示对应的文件描述符发生错误； EPOLLHUP：表示对应的文件描述符被挂断； EPOLLIN：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）； epoll_ctl(set-&gt;epoll_fd, action, event-&gt;fd, &amp;epoll_ev)******************************************************************/ if (wakeEvents &amp; WL_POSTMASTER_DEATH &amp;&amp; IsUnderPostmaster) AddWaitEventToSet(set, WL_POSTMASTER_DEATH, PGINVALID_SOCKET, NULL, NULL); /****************************************************************** WL_POSTMASTER_DEATH进入这个分支 和上流程相同，不同的是event-&gt;fd = postmaster_alive_fds[POSTMASTER_FD_WATCH] ******************************************************************/ if (wakeEvents &amp; WL_SOCKET_MASK) { int ev; ev = wakeEvents &amp; WL_SOCKET_MASK; AddWaitEventToSet(set, ev, sock, NULL, NULL); } rc = WaitEventSetWait(set, timeout, &amp;event, 1, wait_event_info);/******************************************************************开始等待：类似epoll的函数构造，传入上面构造好的set，可能记录多个event。 传出event唤醒的事件。进入rc = WaitEventSetWaitBlock(set, cur_timeout,occurred_events, nevents); epoll_wait(set-&gt;epoll_fd, set-&gt;epoll_ret_events, nevents, cur_timeout) 等5秒唤醒 rc == 0 return -1; ******************************************************************/ if (rc == 0) ret |= WL_TIMEOUT; else { ret |= event.events &amp; (WL_LATCH_SET | WL_POSTMASTER_DEATH | WL_SOCKET_MASK); } FreeWaitEventSet(set);/******************************************************************释放刚刚epoll_create1创建的epoll_fdclose(set-&gt;epoll_fd)释放整体pfree(set)******************************************************************/ return ret;} 主要就是三个函数： AddWaitEventToSet WaitEventSetWait FreeWaitEventSet 唤醒Latch唤醒Latch调用SetLatch，其主要作用为设置一个latch，然后唤醒等待的进程。 如果是当前进程在等待该latch，说明我们是在信号处理函数中设置的Latch，我们使用self-pipe唤醒poll或epoll_wait。 如果是其他进程在等待该latch，则发送一个SIGUSR1信号。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/* * Sets a latch and wakes up anyone waiting on it. * * This is cheap if the latch is already set, otherwise not so much. * * NB: when calling this in a signal handler, be sure to save and restore * errno around it. (That's standard practice in most signal handlers, of * course, but we used to omit it in handlers that only set a flag.) */void SetLatch(volatile Latch* latch){ ThreadId owner_pid; /* * The memory barrier has be to be placed here to ensure that any flag * variables possibly changed by this process have been flushed to main * memory, before we check/set is_set. */ pg_memory_barrier(); /* Quick exit if already set */ if (latch-&gt;is_set) return; latch-&gt;is_set = true; /* * See if anyone's waiting for the latch. It can be the current process if * we're in a signal handler. We use the self-pipe to wake up the select() * in that case. If it's another process, send a signal. * * Fetch owner_pid only once, in case the latch is concurrently getting * owned or disowned. XXX: This assumes that pid_t is atomic, which isn't * guaranteed to be true! In practice, the effective range of pid_t fits * in a 32 bit integer, and so should be atomic. In the worst case, we * might end up signaling the wrong process. Even then, you're very * unlucky if a process with that bogus pid exists and belongs to * openGauss; and PG database processes should handle excess SIGUSR1 * interrupts without a problem anyhow. * * Another sort of race condition that's possible here is for a new * process to own the latch immediately after we look, so we don't signal * it. This is okay so long as all callers of ResetLatch/WaitLatch follow * the standard coding convention of waiting at the bottom of their loops, * not the top, so that they'll correctly process latch-setting events * that happen before they enter the loop. */ owner_pid = latch-&gt;owner_pid; if (owner_pid == 0) return; else if (owner_pid == t_thrd.proc_cxt.MyProcPid) { if (waiting) sendSelfPipeByte(); } else gs_signal_send(owner_pid, SIGUSR1);} sendSelfPipeByte就是往管道写一个数据。 1234567891011121314static void sendSelfPipeByte(void){ int rc; char dummy = 0;retry: rc = write(selfpipe_writefd, &amp;dummy, 1); if (rc &lt; 0) { /* If interrupted by signal, just retry */ if (errno == EINTR) goto retry; if (errno == EAGAIN || errno == EWOULDBLOCK) return; return; }} 而SIGUSR1信号的处理函数行为是：如果自己在等待，那么往管道写一个数据。 123void latch_sigusr1_handler(void) { if (waiting) sendSelfPipeByte();} 综合上来看，唤醒Latch的行为是往管道写一个字节的数据，任何监听管道读端的进程都会被唤醒。 总结常用的等待唤醒机制就是条件变量机制，但是条件变量要搭配互斥锁一起使用。在没有特别地需要锁保护临界区的场景，利用条件变量实现等待唤醒闲的有些过于刻意。 利用Latch机制可以实现无锁睡眠等待，避免锁的开销，也避免许多引入锁带来的问题。 reference: https://cloud.tencent.com/developer/article/2000758 https://blog.csdn.net/asmartkiller/article/details/121924748","link":"/2024/08/04/%E6%95%B0%E6%8D%AE%E5%BA%93/PostgreSQL/PG%E4%B9%8BLatch/"},{"title":"PG内存管理篇一","text":"网上关于PG的内存管理博客讲得迷迷糊糊，上来给一大堆数据结构或者有图也是没有突出重点，本着学习的态度，我自己总结了一下。 基本思想 上下文PG内存管理以上下文方式进行，何为上下文？就是一个内存管理器既有上文，又有下文，在逻辑组织上就是一颗树（有parent也有children）。 内存上下文机制本质上就是对内存进行分类和分层。 比如说我们需要为用户发来的命令，例如 &quot;select * from t&quot;，开辟一个内存空间并存储它，同时在对命令进行语法解析后生成的语法解析树也需要内存保存，因此 PostgreSQL 使用 MessageContext 来存储。 对于不经常改变的 Catalog Relation 可以放入缓存中，不必每次都从磁盘中读取，那么 Cache 所需的内存就可以由 CacheMemoryContext 进行管理。 当执行一个事务时，一定会伴随着内存分配，比如元组的扫描、索引的扫描或者元组的排序等等，这些内存可能需要在事务结束后才释放，因此可由 CurTransactionContext、ExecutorState、PortalHeapMemory 等内存上下文来管理。 可以看到，在数据库运行过程中，会不断地申请各种各样的内存，PostgreSQL 将其分门别类整理好，在内存释放时就将更加从容和方便。即系统中的内存分配操作在各种语义的内存上下文中进行，所有在内存上下文中分配的内存空间都通过内存上下文进行记录。因此可以很轻松地通过释放内存上下文来释放其中所有的内存，而不用费心地去释放其中的每一块内存。 也就是说，在相同上下文上的内存有着相似的语义（作用），那么可以共同管理，而不是每一块内存都去管理。 链式内存有了上下文之后，那么具体的内存是怎么管理的呢？基本思想是数据库自己向操作系统OS（malloc）要一块大内存，然后分为若干大小的块状链条（freelist）数组管理。当数据库需要内存时，优先从freelist里找到匹配大小的块状内存使用，如果没有适合大小的链条结点，那么再向OS申请新的内存。 虽然思想简单，但在实现上有几个更加细致的点： 新申请的内存存储在一个块blocks中，而不是直接分配给freelist freelist管理的是chunk链表，而chunk则存在于blocks中 用完的blocks以链表的方式串在一起，头部则是新申请的blocks Region-Based Memory Management reference: https://smartkeyerror.com/PostgreSQL-MemoryContext 下图为 VC6 编译器在进行 malloc 调用时返回的结果的内存布局，其中 Debug Header 只有在 Debug 模式下才会出现，但是所分配内存区域的首、尾两端的 Cookie 却必不可少，因为它记录了一次 malloc 所分配的总内存，总计占用 8 Bytes。 也就是说，我们每次使用 malloc() 申请 24 Bytes 的内存，系统最少消耗 32 Bytes 的内存，那么对于应用程序来说，内存的实际使用率为 24/32 = 0.75。如果我们有 100 万个 malloc 调用，那么将会有非常多的内存用于 Cookie 中，如此一来内存使用效率将会非常之低。 PostgreSQL 使用了一种名为 Region-Based Memory Management 的内存管理方式，原理其实非常简单: 使用 malloc 申请较大的内存块，然后将该内存块切割成一个一个的小的内存片，将内存片返回给调用方。当调用方使用完毕返还时，并不会直接返回给操作系统，而是添加至 Free List 这一空闲链表的指定区域内，以用于下一次的内存分配。 也就是说，我们向操作系统申请24B的内存，会有8B附加信息。同样，由PG实现的内存管理中，我们申请的24B内存，也会有一些附加信息。 实际上，调用palloc返回的地址的前面，还有一片Header信息，用来记录这片内存大小等信息。 数据结构OK，有了以上核心思想的铺垫以后，再看数据结构就很清楚明白了。 MemoryContextData负责记录和管理内存树的信息，AllocSetContext负责真正的分配和管理内存，PG向操作系统申请的内存以AllocBlock为单位。应用向PG要内存则从Block中切割出Chunk分配。应用使用内存完毕后，优先将Chunk归还到freelist（Chunk地址未变，freelist多了一个指向）。 MemoryContextData1234567891011typedef struct MemoryContextData{ NodeTag type; /* identifies exact kind of context */ MemoryContextMethods *methods; /* virtual function table */ MemoryContext parent; /* NULL if no parent (toplevel context) */ MemoryContext firstchild; /* head of linked list of children */ MemoryContext nextchild; /* next child of same parent */ char *name; /* context name (just for debugging) */ bool isReset; /* T = no space alloced since last reset */} MemoryContextData;typedef struct MemoryContextData* MemoryContext; parent、firstchild和nextchild字段用于标识树，这其实构成的是一颗多叉树，树的每一层都是一个链表。 methods字段是一个函数表，这是C实现面向对象多态的一种手段，不懂的查询相关资料，这里不再赘述。实际上进行内存管理时，调用的是methods里的函数。methods里的函数其实是一个声明，可以有不同的具体实现，后续会绑定函数地址。 123456789101112typedef struct MemoryContextMethods{ void *(*alloc) (MemoryContext context, Size size); // 内存分配 void (*free_p) (MemoryContext context, void *pointer); // 内存释放 void *(*realloc) (MemoryContext context, void *pointer, Size size); // 内存重分配 void (*reset) (MemoryContext context); // 内存重置 void (*delete_context) (MemoryContext context); // 删除某个内存上下文 Size (*get_chunk_space) (MemoryContext context, void *pointer); // 获取内存片大小 bool (*is_empty) (MemoryContext context); // 判断内存上下文是否为空 void (*stats) (MemoryContext context, MemoryStatsPrintFunc printfunc, void *passthru, MemoryContextCounters *totals, bool print_to_stderr);} MemoryContextMethods; 以上两个数据结构只是定义了树的关系，真正的内存在哪里？答案是另外一个大结构体AllocSetContext。 AllocSetContext 1234567891011121314typedef struct AllocSetContext{ MemoryContextData header; /* Standard memory-context fields */ /* Info about storage allocated in this context: */ AllocBlock blocks; /* head of list of blocks in this set */ AllocChunk freelist[ALLOCSET_NUM_FREELISTS]; /* free chunk lists */ /* Allocation parameters for this context: */ Size initBlockSize; /* initial block size */ Size maxBlockSize; /* maximum block size */ Size nextBlockSize; /* next block size to allocate */ Size allocChunkLimit; /* effective chunk size limit */ AllocBlock keeper; /* if not NULL, keep this block over resets */} AllocSetContext;typedef AllocSetContext* AllocSet; AllocSetContext将MemoryContextData作为结构体的第一个数据成员，当我们拿到MemoryContex时（也就是拿到了AllocSet），那么可以通过类型的强制转换拿到AllocSetContext（后续在blocks也可看到这个技巧的使用）。 1234typedef AllocSetContext* AllocSet;typedef struct MemoryContextData* MemoryContext;AllocSet set = (AllocSet) context; // MemoryContext context； AllocBlockDataAllocBlockData 是PG管理内存的基本单位，每次向OS申请都是Block的单位。 12345678typedef struct AllocBlockData* AllocBlock;typedef struct AllocBlockData{ AllocSet aset; /* aset that owns this block */ AllocBlock prev; /* prev block in aset's blocks list, if any */ AllocBlock next; /* next block in aset's blocks list, if any */ char *freeptr; /* start of free space in this block */ char *endptr; /* end of space in this block */}AllocBlockData; 等等，不是说好内存会存在blocks中，怎么没看到一点内存的影子？实际上，这里也运用了申请的内存以AllocBlockData开头这一技巧，AllocBlockData的大小是固定的，而freeptr和endptr指向了可用空间的起始和结束地址。 123456#define ALLOC_CHUNKHDRSZ MAXALIGN(sizeof(AllocChunkData))#define ALLOC_BLOCKHDRSZ MAXALIGN(sizeof(AllocBlockData))// 除开申请的内存片以外，还需要为 AllocBlockData 和 AllocChunkData 预留空间blksize = chunk_size + ALLOC_BLOCKHDRSZ + ALLOC_CHUNKHDRSZ;// 向 OS 申请内存，这里使用的是 mallocblock = (AllocBlock) malloc(blksize); AllocChunkData前面我们已经知道了一个内存块（Block）中会被切割成一个或者多个内存片（Chunk），这个chunk的结构如下所示，同样，它也没有带有内存空间，只不过作为内存空间的头部（元信息）存在，标识着内存空间的大小。 123456#define ALLOC_CHUNKHDRSZ MAXALIGN(sizeof(AllocChunkData))typedef struct AllocChunkData{ void *aset; // 该指针有两个作用，使用时指向 AllocSet，空闲时作为 next 指针链接其空闲链表 Size size; // 内存片的实际大小，以 2 的幂为大小进行向上取整 Size requested_size; // debug 使用} AllocChunkData; freelistfreelist管理了零碎的内存片，数组的大小默认为 11，能够保存 11 种不同大小的空闲内存片，对于数组的第 K 个元素，其保存的内存片大小为 2^(K+2) 字节。K 从 1 开始取值，也就是说，freelist 数组中最小的内存片大小为 8 Bytes，最大的内存片为 8192 bytes（默认情况下），相同大小的内存片由链表链接。 当我们使用完内存空间后，chunk块不会马上调用free返回给操作系统，而是挂载到freelist上，方便下次查找合适的内存块使用。 内存分配在 PostgreSQL 中，所有内存的申请、释放和重置都是在内存上下文中进行的，因此不会直接使用 malloc()、realloc() 和 free() 系统调用函数，而是使用 palloc()、repalloc() 和 pfree() 来实现内存的分配、重分配和释放。 palloc12345678910111213void * palloc(Size size){ void *ret; // 在当前内存上下文中进行内存分配 MemoryContext context = CurrentMemoryContext; // 将 isReset 标志位设置为 false，那么在释放内存上下文时就需要清理其内存 context-&gt;isReset = false; // 此处为多态实现，目前只有 AllocSetAlloc() 这一个实现 ret = context-&gt;methods-&gt;alloc(context, size); if (unlikely(ret == NULL)){ // 此处将打印 OOM 错误信息 } return ret;} 在 palloc() 方法中，内存分配实际上会调用 AllocSetAlloc() 方法，根据申请的size有不同的处理方法： size大于allocChunkLimit，说明size太大了，超过现在freelist和chunk的最大大小，需要重新申请block freelist中查找合适大小的空间，如果没有，进入到第3步 申请新的block，从block中切割chunk 1// 补充代码 上述的逻辑还比较粗糙，实际上还有一些有意思的小点： 当申请的内存大于allocChunkLimit时，会申请新内存块，该块只存放一个内存片，并且这个内存片释放后不会被freelist管理，直接释放free 当freelist空间不够，block空间也不够时，旧的block会被切割成chunk扔到freelist中（物尽其用） pfree1234567891011121314151617181920/* * pfree * Release an allocated chunk. */void pfree(void* pointer){ MemoryContext context = NULL; /* * Try to detect bogus pointers handed to us, poorly though we can. * Presumably, a pointer that isn't MAXALIGNED isn't pointing at an * allocated chunk. */ Assert(pointer != NULL); Assert(pointer == (void*)MAXALIGN(pointer)); context = ((StandardChunkHeader*)((char*)pointer - STANDARDCHUNKHEADERSIZE))-&gt;context; AssertArg(MemoryContextIsValid(context)); (*context-&gt;methods-&gt;free_p)(context, pointer);} 首先，从注释中我们可以get到很重要一点就是：内存分配是以chunk为单位的，那么我们归还的时候也要检查它是否是一个chunk。 context = ((StandardChunkHeader*)((char*)pointer - STANDARDCHUNKHEADERSIZE))-&gt;context; 这句话计算真正的chunk 头地址，然后通chunk头知道当前属于哪个内存上下文，从而正确释放内存。 1234567891011typedef struct StandardChunkHeader { MemoryContext context; /* owning context */ Size size; /* size of data space allocated in chunk */ Size requested_size;} StandardChunkHeader;typedef struct AllocChunkData{ void *aset; // 该指针有两个作用，使用时指向 AllocSet，空闲时作为 next 指针链接其空闲链表 Size size; // 内存片的实际大小，以 2 的幂为大小进行向上取整 Size requested_size; // debug 使用} AllocChunkData; 在看内存上下文的free_p函数： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109template &lt;bool enable_memoryprotect, bool is_shared, bool is_tracked&gt;void GenericMemoryAllocator::AllocSetFree(MemoryContext context, void* pointer){ AllocSet set = (AllocSet)context; AllocChunk chunk = AllocPointerGetChunk(pointer); Size tempSize = 0; MemoryProtectFuncDef* func = NULL; AssertArg(AllocSetIsValid(set)); /* * If this is a shared context, make it thread safe by acquiring * appropriate lock */ if (is_shared) { MemoryContextLock(context); func = &amp;SharedFunctions; } else { CHECK_CONTEXT_OWNER(context); if (context-&gt;session_id &gt; 0) func = &amp;SessionFunctions; else func = &amp;GenericFunctions; } AllocFreeInfo(set, chunk);#ifdef MEMORY_CONTEXT_CHECKING /* Test for someone scribbling on unused space in chunk */ if (chunk-&gt;requested_size != (Size)MAXALIGN(chunk-&gt;requested_size) &amp;&amp; chunk-&gt;requested_size &lt; chunk-&gt;size) if (!sentinel_ok(pointer, chunk-&gt;requested_size - ALLOC_MAGICHDRSZ)) { if (is_shared) { MemoryContextUnlock(context); } ereport(PANIC, (errmsg(&quot;detected write past chunk end in %s&quot;, set-&gt;header.name))); } AllocMagicData* magic = (AllocMagicData*)(((char*)chunk) + ALLOC_CHUNKHDRSZ + MAXALIGN(chunk-&gt;requested_size) - ALLOC_MAGICHDRSZ); Assert(magic-&gt;aset == set &amp;&amp; magic-&gt;size == chunk-&gt;size &amp;&amp; magic-&gt;posnum == PosmagicNum);#endif#ifndef ENABLE_MEMORY_CHECK if (chunk-&gt;size &gt; set-&gt;allocChunkLimit) {#endif /* * Big chunks are certain to have been allocated as single-chunk * blocks. Find the containing block and return it to malloc(). */ AllocBlock block = (AllocBlock)(((char*)chunk) - ALLOC_BLOCKHDRSZ); check_pointer_valid(block, is_shared, context, chunk); /* OK, remove block from aset's list and free it */ if (block-&gt;prev) block-&gt;prev-&gt;next = block-&gt;next; else set-&gt;blocks = block-&gt;next; if (block-&gt;next) block-&gt;next-&gt;prev = block-&gt;prev; tempSize = block-&gt;allocSize; set-&gt;totalSpace -= block-&gt;allocSize; /* clean the structure of block */ block-&gt;aset = NULL; block-&gt;prev = NULL; block-&gt;next = NULL; block-&gt;freeptr = NULL; block-&gt;endptr = NULL; block-&gt;allocSize = 0; if (is_tracked) MemoryTrackingFreeInfo(context, tempSize); if (GS_MP_INITED) (*func-&gt;free)(block, tempSize); else gs_free(block, tempSize);#ifndef ENABLE_MEMORY_CHECK } else { /* Normal case, put the chunk into appropriate freelist */ int fidx = AllocSetFreeIndex(chunk-&gt;size); chunk-&gt;aset = (void*)set-&gt;freelist[fidx]; set-&gt;freeSpace += chunk-&gt;size + ALLOC_CHUNKHDRSZ;#ifdef MEMORY_CONTEXT_TRACK chunk-&gt;file = NULL; chunk-&gt;line = 0;#endif#ifdef MEMORY_CONTEXT_CHECKING /* Reset requested_size to 0 in chunks that are on freelist */ chunk-&gt;requested_size = 0; chunk-&gt;prenum = 0; AllocMagicData* magic = (AllocMagicData*)(((char*)chunk) + ALLOC_CHUNKHDRSZ + MAXALIGN(chunk-&gt;requested_size) - ALLOC_MAGICHDRSZ); magic-&gt;aset = NULL; magic-&gt;size = 0; magic-&gt;posnum = 0;#endif set-&gt;freelist[fidx] = chunk; Assert(chunk-&gt;aset != set); }#endif if (is_shared) MemoryContextUnlock(context);} 其中主要逻辑就是： 归还的内存大于allocChunkLimit时，直接释放。 归还的内存小于allocChunkLimit时，挂到freelist上。 *func-&gt;free 目前可以直接理解为调用操作系统的free函数，实际上结合is_shared和context-&gt;session_id参数引出了openGauss的内存保护机制，这里避开不谈。 最后是一张内存关系图，展示了经过一段时间后的内存情况： 总结 内存上下文以block单位向OS拿内存，以chunk的单位分配内存。 palloc和pfree的语义是从上下文拿内存和归还内存，内存申请和释放的单位都是chunk。 最后，非常感谢这两篇文章，里面的图很好用直接拿来用了，希望大家也去看一看这两篇文章： https://www.jianshu.com/p/d22bdfe5a6e8 https://smartkeyerror.com/PostgreSQL-MemoryContext","link":"/2024/08/03/%E6%95%B0%E6%8D%AE%E5%BA%93/PostgreSQL/PG%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E7%AF%87%E4%B8%80/"},{"title":"PG内存管理篇二","text":"更详细地讲述PG的内存管理，演示代码为OpenGauss。省流的话直接看总结。 引言上一篇我们谈论了内存上下文的接呢结构，内存申请的函数palloc和释放函数pfree。现在我们讨论一下内存自动管理的原理。 PG给了我们内存申请的接口palloc，难道还要我们自己手动调用pfree吗？答案是当然不用。有了内存上下文之后，我们只需要切换到对应的内存上下文，直接调用palloc，申请的内存将在对应内存上下文MemContext删除时一并释放。 创建内存上下文123456789MemoryContext AllocSetContextCreate( _in_ MemoryContext parent, _in_ const char* name, _in_ Size minContextSize, _in_ Size initBlockSize, _in_ Size maxBlockSize, _in_ MemoryContextType contextType, _in_ Size maxSize, _in_ bool isSession); 创建内存上下有一个公用的接口，该接口会根据内存上下文的类型选择合适的创建函数，这里以标准内存上下文的创建为说明。 注意这三个参数的作用： 123* minContextSize: minimum context size* initBlockSize: initial allocation block size* maxBlockSize: maximum allocation block size 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141MemoryContext GenericMemoryAllocator::AllocSetContextCreate(MemoryContext parent, const char* name, Size minContextSize, Size initBlockSize, Size maxBlockSize, Size maxSize, bool isShared, bool isSession){ AllocSet context; NodeTag type = isShared ? T_SharedAllocSetContext : T_AllocSetContext; bool isTracked = false; unsigned long value = isShared ? IS_SHARED : 0; MemoryProtectFuncDef* func = NULL; if (isShared) func = &amp;SharedFunctions; else if (!isSession &amp;&amp; (parent == NULL || parent-&gt;session_id == 0)) func = &amp;GenericFunctions; else func = &amp;SessionFunctions; /* we want to be sure ErrorContext still has some memory even if we've run out elsewhere! * Don't limit the memory allocation for ErrorContext. And skip memory tracking memory allocation. */ if ((0 != strcmp(name, &quot;ErrorContext&quot;)) &amp;&amp; (0 != strcmp(name, &quot;MemoryTrackMemoryContext&quot;)) &amp;&amp; (strcmp(name, &quot;Track MemoryInfo hash&quot;) != 0) &amp;&amp; (0 != strcmp(name, &quot;DolphinErrorData&quot;))) value |= IS_PROTECT; /* only track the unshared context after t_thrd.mem_cxt.mem_track_mem_cxt is created */ if (func == &amp;GenericFunctions &amp;&amp; parent &amp;&amp; (MEMORY_TRACKING_MODE &gt; MEMORY_TRACKING_PEAKMEMORY) &amp;&amp; t_thrd.mem_cxt.mem_track_mem_cxt &amp;&amp; (t_thrd.utils_cxt.ExecutorMemoryTrack == NULL || ((AllocSet)parent)-&gt;track)) { isTracked = true; value |= IS_TRACKED; } /* Do the type-independent part of context creation */ context = (AllocSet)MemoryContextCreate(type, sizeof(AllocSetContext), parent, name, __FILE__, __LINE__); if (isShared &amp;&amp; maxSize == DEFAULT_MEMORY_CONTEXT_MAX_SIZE) { // default maxSize of shared memory context. context-&gt;maxSpaceSize = SHARED_MEMORY_CONTEXT_MAX_SIZE; } else { // set by user (shared or generic),default generic max size(eg. 10M), // these three types run following scope: context-&gt;maxSpaceSize = maxSize + SELF_GENRIC_MEMCTX_LIMITATION; } /* * If MemoryContext's name is in white list(GUC parameter,see @memory_context_limited_white_list), * then set maxSize as infinite,that is unlimited. */#ifdef MEMORY_CONTEXT_CHECKING MemoryContextControlSet(context, name);#endif /* assign the method function with specified templated to the context */ AllocSetContextSetMethods(value, ((MemoryContext)context)-&gt;methods); /* * Make sure alloc parameters are reasonable, and save them. * * We somewhat arbitrarily enforce a minimum 1K block size. */ initBlockSize = MAXALIGN(initBlockSize); if (initBlockSize &lt; 1024) initBlockSize = 1024; maxBlockSize = MAXALIGN(maxBlockSize); if (maxBlockSize &lt; initBlockSize) maxBlockSize = initBlockSize; context-&gt;initBlockSize = initBlockSize; context-&gt;maxBlockSize = maxBlockSize; context-&gt;nextBlockSize = initBlockSize; /* initialize statistic */ context-&gt;totalSpace = 0; context-&gt;freeSpace = 0; /* create the memory track structure */ if (isTracked) MemoryTrackingCreate((MemoryContext)context, parent); /* * Compute the allocation chunk size limit for this context. It can't be * more than ALLOC_CHUNK_LIMIT because of the fixed number of freelists. * If maxBlockSize is small then requests exceeding the maxBlockSize, or * even a significant fraction of it, should be treated as large chunks * too. For the typical case of maxBlockSize a power of 2, the chunk size * limit will be at most 1/8th maxBlockSize, so that given a stream of * requests that are all the maximum chunk size we will waste at most * 1/8th of the allocated space. * * We have to have allocChunkLimit a power of two, because the requested * and actually-allocated sizes of any chunk must be on the same side of * the limit, else we get confused about whether the chunk is &quot;big&quot;. */ context-&gt;allocChunkLimit = ALLOC_CHUNK_LIMIT; while ((Size)(context-&gt;allocChunkLimit + ALLOC_CHUNKHDRSZ) &gt; (Size)((maxBlockSize - ALLOC_BLOCKHDRSZ) / ALLOC_CHUNK_FRACTION)) context-&gt;allocChunkLimit &gt;&gt;= 1; /* * Grab always-allocated space, if requested */ if (minContextSize &gt; ALLOC_BLOCKHDRSZ + ALLOC_CHUNKHDRSZ) { Size blksize = MAXALIGN(minContextSize); AllocBlock block; if (GS_MP_INITED) block = (AllocBlock)(*func-&gt;malloc)(blksize, (value &amp; IS_PROTECT) == 1 ? true : false); else gs_malloc(blksize, block, AllocBlock); if (block == NULL) { ereport(ERROR, (errcode(ERRCODE_OUT_OF_LOGICAL_MEMORY), errmsg(&quot;memory is temporarily unavailable&quot;), errdetail(&quot;Failed while creating memory context \\&quot;%s\\&quot;.&quot;, name))); } block-&gt;aset = context; block-&gt;freeptr = ((char*)block) + ALLOC_BLOCKHDRSZ; block-&gt;endptr = ((char*)block) + blksize; block-&gt;allocSize = blksize;#ifdef MEMORY_CONTEXT_CHECKING block-&gt;magicNum = BlkMagicNum;#endif context-&gt;totalSpace += blksize; context-&gt;freeSpace += block-&gt;endptr - block-&gt;freeptr; /* update the memory tracking information when allocating memory */ if (isTracked) MemoryTrackingAllocInfo((MemoryContext)context, blksize); block-&gt;prev = NULL; block-&gt;next = NULL; /* Remember block as part of block list */ context-&gt;blocks = block; /* Mark block as not to be released at reset time */ context-&gt;keeper = block; } context-&gt;header.is_shared = isShared; if (isShared) (void)pthread_rwlock_init(&amp;(context-&gt;header.lock), NULL); return (MemoryContext)context;} 这个函数分为几个部分： 选择合适的内存申请函数 func 设置value（用于methods字段，选取合适虚表） 创建context 设置context的methods字段 设置context的allocChunkLimit 若合适，申请context的第一个block 其中func、value、methods关联度比较大，涉及内存保护机制。 cllockChunkLimit适合仔细揣摩：maxBlockSize - ALLOC_BLOCKHDRSZ就是实际能够分配给chunk的空间，ALLOC_CHUNK_FRACTION为4，也就是说至少要能平均分配4个大小的chunk。context-&gt;allocChunkLimit + ALLOC_CHUNKHDRSZ就是申请一个段内存要加上header的大小。 1234context-&gt;allocChunkLimit = ALLOC_CHUNK_LIMIT;while ((Size)(context-&gt;allocChunkLimit + ALLOC_CHUNKHDRSZ) &gt; (Size)((maxBlockSize - ALLOC_BLOCKHDRSZ) / ALLOC_CHUNK_FRACTION)) context-&gt;allocChunkLimit &gt;&gt;= 1; 合适时会申请aset的第一个block，这个时机依据的是minSize。 1if (minContextSize &gt; ALLOC_BLOCKHDRSZ + ALLOC_CHUNKHDRSZ) 下面看context的创建函数： 12345678910111213141516171819202122232425MemoryContext MemoryContextCreate( NodeTag tag, Size size, MemoryContext parent, const char* name, const char* file, int line){ MemoryContext node; Size needed = size + sizeof(MemoryContextMethods) + strlen(name) + 1; MemoryContext root = ChooseRootContext(tag, parent); errno_t rc = EOK; /* Get space for node and name */ if (root != NULL) { /* Normal case: allocate the node in Root MemoryContext */ node = (MemoryContext)MemoryAllocFromContext(root, needed, file, line); } else { /* Special case for startup: use good ol' malloc */ node = (MemoryContext)malloc(needed); if (node == NULL) ereport(ERROR, (errcode(ERRCODE_OUT_OF_MEMORY), errmsg(&quot;out of memory&quot;), errdetail(&quot;Failed on request of size %lu in %s:%d.&quot;, (unsigned long)needed, file, line))); } ... return node;} 其中最主要的就是：选取root，然后从root上下文创建。 12MemoryContext root = ChooseRootContext(tag, parent);node = (MemoryContext)MemoryAllocFromContext(root, needed, file, line); 这个tag是 NodeTag type = isShared ? T_SharedAllocSetContext : T_AllocSetContext; 选取root的函数，可以看到就三种值： g_instance.instance_context; u_sess-&gt;top_mem_cxt; t_thrd.top_mem_cxt; 123456789101112131415161718192021static MemoryContext ChooseRootContext(NodeTag tag, MemoryContext parent){ MemoryContext root = NULL; if (tag == T_SharedAllocSetContext || tag == T_MemalignSharedAllocSetContext) { root = g_instance.instance_context; } else if (parent) { if (parent-&gt;type == T_SharedAllocSetContext || parent-&gt;type == T_MemalignSharedAllocSetContext) { root = g_instance.instance_context; } else if (parent-&gt;session_id &gt; 0) { Assert(u_sess-&gt;session_id == parent-&gt;session_id); root = u_sess-&gt;top_mem_cxt; } else { root = t_thrd.top_mem_cxt; } } else { root = t_thrd.top_mem_cxt; } return root;} 因此我们可以得出这样一个结论：不管传入公共接口AllocSetContextCreate的parent上下文是什么，最终总是会选取对应的根上下文进行内存分配。 但是context的树形关系并未被破坏，node的parent会被正确设置。 12345678910if (parent) { node-&gt;parent = parent; node-&gt;nextchild = parent-&gt;firstchild; if (parent-&gt;firstchild != NULL) parent-&gt;firstchild-&gt;prevchild = node; parent-&gt;firstchild = node; node-&gt;level = parent-&gt;level + 1;} else node-&gt;level = 0; 总结在内存上下文创建的公共接口中，parent只是用来正确设置树形关系，MemoryContext的创建内存实际由对应的根上下文分配。minContextSize决定了是否给创建的上下文申请第一个Block，initContextSize和maxContextSize没有多大用处。 删除内存上下文在进程退出时gs_thread_exit(code); 看看进行了什么，标准的内存上下文删除函数，调用的是mcxt_methods-&gt;mcxt_destroy。 1234MemoryContextDestroyAtThreadExit(t_thrd.top_mem_cxt); t_thrd.top_mem_cxt = NULL; TopMemoryContext = NULL; u_sess = NULL; 12#define MemoryContextDestroyAtThreadExit(context) \\ (((MemoryContext)context)-&gt;mcxt_methods-&gt;mcxt_destroy(context)) 123456789101112131415161718192021222324static McxtOperationMethods StdMcxtOpMtd = { std_MemoryContextReset, std_MemoryContextDelete, std_MemoryContextDeleteChildren, std_MemoryContextDestroyAtThreadExit, std_MemoryContextResetAndDeleteChildren, std_MemoryContextSetParent#ifdef MEMORY_CONTEXT_CHECKING , std_MemoryContextCheck#endif};typedef struct McxtOperationMethods { void (*mcxt_reset)(MemoryContext context); void (*mcxt_delete)(MemoryContext context); void (*mcxt_delete_children)(MemoryContext context, List* context_list); void (*mcxt_destroy)(MemoryContext context); void (*mcxt_reset_and_delete_children)(MemoryContext context); void (*mcxt_set_parent)(MemoryContext context, MemoryContext new_parent);#ifdef MEMORY_CONTEXT_CHECKING void (*mcxt_check)(MemoryContext context, bool own_by_session);#endif} McxtOperationMethods; std_MemoryContextDestroyAtThreadExitstd_MemoryContextDestroyAtThreadExit主要做两件事情： MemoryContextDeleteChildren(pContext, NULL); 删除分配个子上下文的内存 (*pContext-&gt;methods-&gt;delete_context)(pContext); 删除分配给上下文本身的内存 ​ free(pContext); 释放上下文本身 12345678910111213141516171819202122232425262728293031323334353637383940414243void std_MemoryContextDestroyAtThreadExit(MemoryContext context){ MemoryContext pContext = context; if (!IsTopMemCxt(context)) { PreventActionOnSealedContext(context); } else {#ifdef MEMORY_CONTEXT_CHECKING /* before delete top memcxt, you should close lsc */ if (EnableGlobalSysCache() &amp;&amp; context == t_thrd.top_mem_cxt &amp;&amp; t_thrd.lsc_cxt.lsc != NULL) { Assert(t_thrd.lsc_cxt.lsc-&gt;is_closed); }#endif } if (pContext != NULL) { /* To avoid delete current context */ MemoryContextSwitchTo(pContext); /* Delete all its decendents */ Assert(!pContext-&gt;parent); MemoryContextDeleteChildren(pContext, NULL); // 第一件事 /* Delete the top context itself */ RemoveMemoryContextInfo(pContext); (*pContext-&gt;methods-&gt;delete_context)(pContext); //第二件事 if (pContext != t_thrd.top_mem_cxt) return; /* * Lock this thread's delete MemoryContext. * Because pv_session_memory_detail view will recursive MemoryContext tree. * Relate to pgstatfuncs.c:pvSessionMemoryDetail(). */ if (t_thrd.proc != NULL &amp;&amp; t_thrd.proc-&gt;topmcxt != NULL) { (void)syscalllockAcquire(&amp;t_thrd.proc-&gt;deleMemContextMutex); free(pContext); (void)syscalllockRelease(&amp;t_thrd.proc-&gt;deleMemContextMutex); } else { free(pContext); } }} MemoryContextDeleteChildrenstd_MemoryContextDeleteChildren 会调用 MemoryContextDeleteInternal，而 MemoryContextDeleteInternal还会调用std_MemoryContextDeleteChildren。 总之就是递归遍历context-&gt;firstchild，在依次调用methods-&gt;delete_context来收回分配给它的内存，注意context本身没有被释放。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100/* * std_MemoryContextDeleteChildren * Delete all the descendants of the named context and release all * space allocated therein. The named context itself is not touched. */void std_MemoryContextDeleteChildren(MemoryContext context, List* context_list){ AssertArg(MemoryContextIsValid(context)); List res_list = {T_List, 0, NULL, NULL}; if (context_list == NULL) { context_list = &amp;res_list; } if (MemoryContextIsShared(context)) MemoryContextLock(context); /* * MemoryContextDelete will delink the child from me, so just iterate as * long as there is a child. */ while (context-&gt;firstchild != NULL) MemoryContextDeleteInternal(context-&gt;firstchild, true, context_list); if (MemoryContextIsShared(context)) MemoryContextUnlock(context); if (context_list == &amp;res_list) { FreeMemoryContextList(&amp;res_list); }}static void MemoryContextDeleteInternal(MemoryContext context, bool parent_locked, List* context_list){ AssertArg(MemoryContextIsValid(context)); /* We had better not be deleting t_thrd.top_mem_cxt ... */ Assert(context != t_thrd.top_mem_cxt); /* And not CurrentMemoryContext, either */ Assert(context != CurrentMemoryContext); MemoryContextDeleteChildren(context, context_list);#ifdef MEMORY_CONTEXT_CHECKING /* Memory Context Checking */ MemoryContextCheck(context, context-&gt;session_id &gt; 0);#endif MemoryContext parent = context-&gt;parent; PG_TRY(); { HOLD_INTERRUPTS(); if (context-&gt;session_id &gt; 0) { (void)syscalllockAcquire(&amp;u_sess-&gt;utils_cxt.deleMemContextMutex); } else if (t_thrd.proc != NULL &amp;&amp; t_thrd.proc-&gt;topmcxt != NULL) { (void)syscalllockAcquire(&amp;t_thrd.proc-&gt;deleMemContextMutex); } /* * If the parent context is shared and is already locked by the caller, * no need to relock again. In fact, that's not the right thing to do * since it will lead to a self-deadlock */ if (parent &amp;&amp; MemoryContextIsShared(parent) &amp;&amp; (!parent_locked)) MemoryContextLock(parent); /* * We delink the context from its parent before deleting it, so that if * there's an error we won't have deleted/busted contexts still attached * to the context tree. Better a leak than a crash. */ TopMemCxtUnSeal(); MemoryContextSetParent(context, NULL); if (parent != NULL &amp;&amp; MemoryContextIsShared(parent) &amp;&amp; (parent_locked == false)) MemoryContextUnlock(parent); RemoveMemoryContextInfo(context); (*context-&gt;methods-&gt;delete_context)(context); (void)lappend2(context_list, &amp;context-&gt;cell); if (context-&gt;session_id &gt; 0) { (void)syscalllockRelease(&amp;u_sess-&gt;utils_cxt.deleMemContextMutex); } else if (t_thrd.proc != NULL &amp;&amp; t_thrd.proc-&gt;topmcxt != NULL) { (void)syscalllockRelease(&amp;t_thrd.proc-&gt;deleMemContextMutex); } TopMemCxtSeal(); RESUME_INTERRUPTS(); } PG_CATCH(); { if (context-&gt;session_id &gt; 0) { (void)syscalllockRelease(&amp;u_sess-&gt;utils_cxt.deleMemContextMutex); } else if (t_thrd.proc != NULL &amp;&amp; t_thrd.proc-&gt;topmcxt != NULL) { (void)syscalllockRelease(&amp;t_thrd.proc-&gt;deleMemContextMutex); } TopMemCxtSeal(); PG_RE_THROW(); } PG_END_TRY();} AllocSetDelete我们看AllocSetDelete这个函数，它的主要作用就是清空分配给context的blocks，从而达到释放context的内存目的，但是context本身并没有被释放。因此，在std_MemoryContextDestroyAtThreadExit中还需再次调用free来释放本身。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364/* * AllocSetDelete * Frees all memory which is allocated in the given set, * in preparation for deletion of the set. * * Unlike AllocSetReset, this *must* free all resources of the set. * But note we are not responsible for deleting the context node itself. */template &lt;bool enable_memoryprotect, bool is_shared, bool is_tracked&gt;void GenericMemoryAllocator::AllocSetDelete(MemoryContext context){ AllocSet set = (AllocSet)context; AssertArg(AllocSetIsValid(set)); AllocBlock block = set-&gt;blocks; MemoryProtectFuncDef* func = NULL; if (set-&gt;blocks == NULL) { return; } if (is_shared) { MemoryContextLock(context); func = &amp;SharedFunctions; } else { CHECK_CONTEXT_OWNER(context); if (context-&gt;session_id &gt; 0) func = &amp;SessionFunctions; else func = &amp;GenericFunctions; }#ifdef MEMORY_CONTEXT_CHECKING /* Check for corruption and leaks before freeing */ AllocSetCheck(context);#endif /* Make it look empty, just in case... */ MemSetAligned(set-&gt;freelist, 0, sizeof(set-&gt;freelist)); set-&gt;blocks = NULL; set-&gt;keeper = NULL; while (block != NULL) { AllocBlock next = block-&gt;next; Size tempSize = block-&gt;allocSize; if (is_tracked) MemoryTrackingFreeInfo(context, tempSize); if (GS_MP_INITED) (*func-&gt;free)(block, tempSize); else gs_free(block, tempSize); block = next; } /* reset to 0 after deletion. */ set-&gt;freeSpace = 0; set-&gt;totalSpace = 0; if (is_shared) { MemoryContextUnlock(context); }} 总结std_MemoryContextDestroyAtThreadExit 通过两步走的方式释放一个根内存上下文。 第一步递归释放孩子结点的内存，但是孩子结点并没有释放。 第二步释放根结点的内存（注意孩子结点是从根结点的内存申请的，因此孩子结点被释放了），然后在进一步释放根结点本身。 内存保护机制OG还拓展了内存保护机制，在创建上下文确定methods时，调用了这么一个函数： 12/* assign the method function with specified templated to the context */AllocSetContextSetMethods(value, ((MemoryContext)context)-&gt;methods); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960void GenericMemoryAllocator::AllocSetContextSetMethods(unsigned long value, MemoryContextMethods* method){ bool isProt = (value &amp; IS_PROTECT) ? true : false; bool isShared = (value &amp; IS_SHARED) ? true : false; bool isTracked = (value &amp; IS_TRACKED) ? true : false; if (isProt) { if (isShared) AllocSetMethodDefinition&lt;true, true, false&gt;(method); else { if (isTracked) AllocSetMethodDefinition&lt;true, false, true&gt;(method); else AllocSetMethodDefinition&lt;true, false, false&gt;(method); } } else { if (isShared) AllocSetMethodDefinition&lt;false, true, false&gt;(method); else { if (isTracked) AllocSetMethodDefinition&lt;false, false, true&gt;(method); else AllocSetMethodDefinition&lt;false, false, false&gt;(method); } }}template &lt;bool enable_memoryprotect, bool is_shared, bool is_tracked&gt;void GenericMemoryAllocator::AllocSetMethodDefinition(MemoryContextMethods* method){ method-&gt;alloc = &amp;GenericMemoryAllocator::AllocSetAlloc&lt;enable_memoryprotect, is_shared, is_tracked&gt;; method-&gt;free_p = &amp;GenericMemoryAllocator::AllocSetFree&lt;enable_memoryprotect, is_shared, is_tracked&gt;; method-&gt;realloc = &amp;GenericMemoryAllocator::AllocSetRealloc&lt;enable_memoryprotect, is_shared, is_tracked&gt;; method-&gt;init = &amp;GenericMemoryAllocator::AllocSetInit; method-&gt;reset = &amp;GenericMemoryAllocator::AllocSetReset&lt;enable_memoryprotect, is_shared, is_tracked&gt;; method-&gt;delete_context = &amp;GenericMemoryAllocator::AllocSetDelete&lt;enable_memoryprotect, is_shared, is_tracked&gt;; method-&gt;get_chunk_space = &amp;GenericMemoryAllocator::AllocSetGetChunkSpace; method-&gt;is_empty = &amp;GenericMemoryAllocator::AllocSetIsEmpty; method-&gt;stats = &amp;GenericMemoryAllocator::AllocSetStats;#ifdef MEMORY_CONTEXT_CHECKING method-&gt;check = &amp;GenericMemoryAllocator::AllocSetCheck;#endif} * This is the virtual function table for Memory Functions */MemoryProtectFuncDef GenericFunctions = {MemoryProtectFunctions::gs_memprot_malloc&lt;MEM_THRD&gt;, MemoryProtectFunctions::gs_memprot_free&lt;MEM_THRD&gt;, MemoryProtectFunctions::gs_memprot_realloc&lt;MEM_THRD&gt;, MemoryProtectFunctions::gs_posix_memalign&lt;MEM_THRD&gt;};MemoryProtectFuncDef SessionFunctions = {MemoryProtectFunctions::gs_memprot_malloc&lt;MEM_SESS&gt;, MemoryProtectFunctions::gs_memprot_free&lt;MEM_SESS&gt;, MemoryProtectFunctions::gs_memprot_realloc&lt;MEM_SESS&gt;, MemoryProtectFunctions::gs_posix_memalign&lt;MEM_SESS&gt;};MemoryProtectFuncDef SharedFunctions = {MemoryProtectFunctions::gs_memprot_malloc&lt;MEM_SHRD&gt;, MemoryProtectFunctions::gs_memprot_free&lt;MEM_SHRD&gt;, MemoryProtectFunctions::gs_memprot_realloc&lt;MEM_SHRD&gt;, MemoryProtectFunctions::gs_posix_memalign&lt;MEM_SHRD&gt;}; 最核心的片段就是根据value决定模版函数的is_shared和 is_tracked，而这些参数也会影响到palloc时对应的alloc函数的选择。 12345678910if (is_shared) { MemoryContextLock(context); func = &amp;SharedFunctions;} else { if (context-&gt;session_id &gt; 0) func = &amp;SessionFunctions; else func = &amp;GenericFunctions;}/* gs_memprot_malloc逻辑比较复杂，涉及到内存追踪、内存预留等，这里不展开讲。内存保护的基本思想是： 设定系统最大内存，追踪每次分配的内存字节 调用malloc前先进行内存充足检查（已经分配的字节小于系统最大内存） 1234567891011121314151617181920212223242526272829/* * Memory allocation for sz bytes. If memory quota is enabled, it uses gs_malloc_internal to * reserve the chunk and allocate memory. */template &lt;MemType mem_type&gt;void* MemoryProtectFunctions::gs_memprot_malloc(Size sz, bool needProtect){ if (!t_thrd.utils_cxt.gs_mp_inited) return malloc(sz); void* ptr = NULL; bool status = memTracker_ReserveMem&lt;mem_type&gt;(sz, needProtect); if (status == true) { ptr = malloc(sz); //这里分配内存 if (ptr == NULL) { memTracker_ReleaseMem&lt;mem_type&gt;(sz); gs_memprot_failed&lt;false&gt;(sz, mem_type); return NULL; } return ptr; } gs_memprot_failed&lt;true&gt;(sz, mem_type); return NULL;}","link":"/2024/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/PostgreSQL/PG%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E7%AF%87%E4%BA%8C/"},{"title":"PG可见性判断","text":"PG可见性判断是怎么进行的？ 前言前备知识：MVCC &amp;&amp; 事务隔离级别 场景：heapgetpage函数中，为了获取一个块内的所有可见tuple，遍历tuple时都要对它的可见性进行判断，该函数为HeapTupleSatisfiesMVCC。 事务具有xid，PG还有clog记录事务是否提交，PG还维护全局活跃的事务数组。 xmin：当前活跃事务最小的xid xmax：当前活跃事务最大的xid+1 回到事务读元组的场景，如果元组的xid&lt;xmin，那么这条元组可见；如果元组的xid&gt;xmax，那么这条元组不可见。但是PG的元组头中有t_xmin、t_max等字段，这些字段怎么一起控制元组可见性呢？ CLogPostgreSQL在提交日志（Commit Log, clog）中保存事务的状态。提交日志（通常称为clog）分配于共享内存中，并用于事务处理过程的全过程。 1234#define TRANSACTION_STATUS_IN_PROGRESS 0x00#define TRANSACTION_STATUS_COMMITTED 0x01#define TRANSACTION_STATUS_ABORTED 0x02#define TRANSACTION_STATUS_SUB_COMMITTED 0x03 四种事务状态，其中sub_committed与子事务相关，暂时略过。 提交日志（下称clog）在逻辑上是一个数组，由共享内存中一系列8KB页面组成，以页为单位。数组下标是事务ID，参考TransactionIdGetStatus函数；数组内容是事务状态，每个事务状态占用2bit。一个页面8K，可以存储8K*8/2=32K个事务状态。 Clog buffer大小为Min(128, Max(4, NBuffers / 512))，初始化函数为CLOGShmemInit。启动时会从pg_xact读取事务状态加载到内存。 Hint Bits为了避免多次访问clog造成的性能瓶颈，PG在元组头部设立了提示字段。具体而言，在元组的t_informask字段中设立如下的标记： 123456#define HEAP_XMIN_COMMITTED 0x0100 /* t_xmin committed */#define HEAP_XMIN_INVALID 0x0200 /* t_xmin invalid/aborted */#define HEAP_XMIN_FROZEN (HEAP_XMIN_COMMITTED|HEAP_XMIN_INVALID)#define HEAP_XMAX_COMMITTED 0x0400 /* t_xmax committed */#define HEAP_XMAX_INVALID 0x0800 /* t_xmax invalid/aborted */#define HEAP_XMAX_IS_MULTI 0x1000 /* t_xmax is a MultiXactId */ 访问元组头部就可以知道元组对应的t_xmin、t_max事务状态，不需要再次访问clog。 HeapTupleSatisfiesMVCC 可见情况： 在创建快照时所有已提交的事务 本事务之前执行的命令 不可见情况： 在创建快照时尚活跃的事务 在创建快照后启动的事务 当前命令造成的变化（changes made by the current command） 这个函数比较复杂，参考博客了解详情。下面是归纳的一份逻辑流程：大体是先判断xmin再判断xmax，根据xmin的状态分三条线走。 123456789101112131415161718192021222324252627282930313233343536/* t_xmin status = ABORTED */Rule 1: IF t_xmin status is 'ABORTED' THEN RETURN 'Invisible' END IF/* t_xmin status = IN_PROGRESS */ IF t_xmin status is 'IN_PROGRESS' THEN IF t_xmin = current_txid THENRule 2: IF t_xmax = INVALID THEN RETURN 'Visible'Rule 3: ELSE /* this tuple has been deleted or updated by the current transaction itself. */ RETURN 'Invisible' END IFRule 4: ELSE /* t_xmin ≠ current_txid */ RETURN 'Invisible' END IF END IF/* t_xmin status = COMMITTED */ IF t_xmin status is 'COMMITTED' THENRule 5: IF t_xmin is active in the obtained transaction snapshot THEN RETURN 'Invisible'Rule 6: ELSE IF t_xmax = INVALID OR status of t_xmax is 'ABORTED' THEN RETURN 'Visible' ELSE IF t_xmax status is 'IN_PROGRESS' THENRule 7: IF t_xmax = current_txid THEN RETURN 'Invisible'Rule 8: ELSE /* t_xmax ≠ current_txid */ RETURN 'Visible' END IF ELSE IF t_xmax status is 'COMMITTED' THENRule 9: IF t_xmax is active in the obtained transaction snapshot THEN RETURN 'Visible'Rule 10: ELSE RETURN 'Invisible' END IF END IF END IF SnapShot快照是如何产生的呢？主要看GetTransactionSnapshot这个函数，它的主要逻辑是： 根据FirstsnapshotSet判断是否是第一次生成快照 根据隔离级别决定要生成的快照 通过GetSnapshotData这个函数生成具体的快照 FirstsnapshotSet并不是强依赖于事务的变量，只是snapmgr.c的一个全局变量。根据不同隔离级别，这个变量设置也会有不同的时机。 初始值为false，生成snapshot后设置为true。如果隔离级别是read-commit，则当sql执行完成后会将FirstSnapshotSet设为false，如果是repeatable-read只有在事务结束后才会将FirstSnapshotSet设为false。通过监视FirstSnapshotSet变量的变化（添加数据断点&amp;FirstSnapshotSet）可以观察语句结束和事务提交的情况。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768Snapshot GetTransactionSnapshot(void){ /* * Return historic snapshot if doing logical decoding. We'll never need a * non-historic transaction snapshot in this (sub-)transaction, so there's * no need to be careful to set one up for later calls to * GetTransactionSnapshot(). */ if (HistoricSnapshotActive()) { Assert(!FirstSnapshotSet); return HistoricSnapshot; } /* First call in transaction? */ if (!FirstSnapshotSet) { /* * Don't allow catalog snapshot to be older than xact snapshot. Must * do this first to allow the empty-heap Assert to succeed. */ InvalidateCatalogSnapshot(); Assert(pairingheap_is_empty(&amp;RegisteredSnapshots)); Assert(FirstXactSnapshot == NULL); if (IsInParallelMode()) elog(ERROR, &quot;cannot take query snapshot during a parallel operation&quot;); /* * In transaction-snapshot mode, the first snapshot must live until * end of xact regardless of what the caller does with it, so we must * make a copy of it rather than returning CurrentSnapshotData * directly. Furthermore, if we're running in serializable mode, * predicate.c needs to wrap the snapshot fetch in its own processing. */ if (IsolationUsesXactSnapshot()) { /* First, create the snapshot in CurrentSnapshotData */ if (IsolationIsSerializable()) CurrentSnapshot = GetSerializableTransactionSnapshot(&amp;CurrentSnapshotData); else CurrentSnapshot = GetSnapshotData(&amp;CurrentSnapshotData); /* Make a saved copy */ CurrentSnapshot = CopySnapshot(CurrentSnapshot); FirstXactSnapshot = CurrentSnapshot; /* Mark it as &quot;registered&quot; in FirstXactSnapshot */ FirstXactSnapshot-&gt;regd_count++; pairingheap_add(&amp;RegisteredSnapshots, &amp;FirstXactSnapshot-&gt;ph_node); } else CurrentSnapshot = GetSnapshotData(&amp;CurrentSnapshotData); FirstSnapshotSet = true; return CurrentSnapshot; } if (IsolationUsesXactSnapshot()) return CurrentSnapshot; /* Don't allow catalog snapshot to be older than xact snapshot. */ InvalidateCatalogSnapshot(); CurrentSnapshot = GetSnapshotData(&amp;CurrentSnapshotData); return CurrentSnapshot;} 参考https://blog.csdn.net/Hehuyi_In/article/details/127344822 https://blog.csdn.net/obvious__/article/details/120710977 https://pg-internal.vonng.com/","link":"/2024/10/04/%E6%95%B0%E6%8D%AE%E5%BA%93/PostgreSQL/PG%E5%8F%AF%E8%A7%81%E6%80%A7%E5%88%A4%E6%96%AD/"},{"title":"PG存储Vacuum","text":"简单叙述vacuum的基本原理。 前言PG的astore的delete操作只是标记删除，元组本身空间并没有释放，造成空间浪费。这时候需要vacuum进程来进行不可见元组的清理。 有两种vacuum： lazy vacuum：将无效元组标记为可用（碎片空间）。 full vacuum：对表进行完全清理，释放无效元组空间，并整理元组。 版本链与HOT机制PG Update的实现是先删除旧元组，再插入一条新元组。原始元组使用t_ctid指向新元组，于是通过t_ctid，新旧多个版本的元组就组成了一条版本链。 如果表上创建了索引，由于元组的每次更新都会插入一条新元组，所以不论索引列是否更新都会向索引插入一条索引元组，这样会极大的降低插入性能。 可以用一个简单的思路来优化这个问题：如果更新操作不涉及索引列，那么就无需向索引插入索引元组。但是这个方法会造成版本链分散在多个块中，而磁盘IO是致命的慢。于是，PG就采用了HOT（Heap-Only Tuples）机制，使得满足以下两个条件的更新不向索引中插入元组，避免版本链分散在多个块中。 更新操作不涉及索引列 更新后，插入的新元组和老元组在同一个块 上图中，从ver1到ver3的红色链就是一条HOT链。HOT机制作用就是确保版本链不会跨块存储。另外，HOT还为vauccm带来一点优化，后文再述。 HOT链判断 元组的头部字段t_infomask2，新元组标记为HEAP_HOT_UPDATED，新元组会标记为HEAP_ONLY_TUPLE。图中ver2作为被更新的元组，既有only也有updated。 FSMFree Space Map，FSM，空闲空间映射图。当数据块中进行insert、update、delete这些操作时，都会产生一个旧版本的数据。vacuum时便会清理掉这些旧版本数据，数据块便存在许多空闲的空间，如果能够将这些空间再次利用起来当然是很好的，不然新插入数据时继续分配一个新的数据块，那数据文件的膨胀速度就会非常快，因此便通过FSM来实现这一功能。 将一个page的空闲空间分为256档（一个字节，8位，2^ 8=256），那么8k/256=32，32个字节就能表示一个页面的空闲程度。 回收流程 回收基于HOT链，当HOT链上的版本部分过期时，过期元组的Linp会被设置为LP_UNUSED，同时还需要修改第一个元组的Linp指向版本链的最后一个元组，这个过程称之为重定位： 将ver1的ItemIdData的状态修改为LP_REDIRECT。 将ver1的ItemIdData的lp_off指向ver3的ItemIdData的位置。 Linp复用：heap-insert时查找有无空闲的Linp 12345678910111213141516171819if (PageHasFreeLinePointers(phdr)){ /* * Look for &quot;recyclable&quot; (unused) ItemId. We check for no storage * as well, just to be paranoid --- unused items should never have * storage. */ for (offsetNumber = 1; offsetNumber &lt; limit; offsetNumber++) { itemId = PageGetItemId(phdr, offsetNumber); if (!ItemIdIsUsed(itemId) &amp;&amp; !ItemIdHasStorage(itemId)) break; } if (offsetNumber &gt;= limit) { /* the hint is wrong, so reset it */ PageClearHasFreeLinePointers(phdr); }} 当HOT链上的版本全部过期时，并不是简单地将所有链上的元组Linp设置为LP_UNUSED并删除索引元组idx1。PG为了优化批量删除idx，在删除了ver1的元组实体后，不会将ItemIdData标记为LP_UNUSED，而是标记为LP_DEAD。后面批量的删除索引后，再来将标记为LP_DEAD的元组修改为LP_UNUSED。 代码下面介绍heap_page_prune，该函数主要用于清理单个文件块的HOT链，并进行块内碎片的整理（由PageRepairFragmentation完成）。 heap_page_prune该函数的逻辑步骤就两步： 针对块内的每个元组，调用heap_prune_chain进行HOT链清理 调用heap_page_prune_execute完成块内碎片清理 12345678910111213141516171819202122232425262728293031323334353637383940414243//pruneheap.c line 182int heap_page_prune(Relation relation, Buffer buffer, TransactionId OldestXmin, bool report_stats, TransactionId *latestRemovedXid){ //省略... /* Scan the page */ maxoff = PageGetMaxOffsetNumber(page); for (offnum = FirstOffsetNumber; offnum &lt;= maxoff; offnum = OffsetNumberNext(offnum)) { ItemId itemid; /* Ignore items already processed as part of an earlier chain */ if (prstate.marked[offnum]) continue; /* Nothing to do if slot is empty or already dead */ itemid = PageGetItemId(page, offnum); if (!ItemIdIsUsed(itemid) || ItemIdIsDead(itemid)) continue; /* Process this item or chain of items */ ndeleted += heap_prune_chain(relation, buffer, offnum, OldestXmin, &amp;prstate); } ... /* Have we found any prunable items? */ if (prstate.nredirected &gt; 0 || prstate.ndead &gt; 0 || prstate.nunused &gt; 0) { /* * Apply the planned item changes, then repair page fragmentation, and * update the page's hint bit about whether it has free line pointers. */ heap_page_prune_execute(buffer, prstate.redirected, prstate.nredirected, prstate.nowdead, prstate.ndead, prstate.nowunused, prstate.nunused); //省略... } return ndeleted;} heap_prune_chain遍历HOT链，判断元组是否过期，记录需要设置为LP_UNUSED、LP_DEAD、LP_REDIRECT的元组。 heap_prune_chain包含三个步骤： 步骤1：遍历元组的HOT链 步骤2：判断元组是否过期 需要注意的是，HOT链上的元组是按照版本的先后顺序排列，所以只需要找到最后一条过期的原数，它之前的所有元组都过期了。 步骤3：记录需要设置为LP_UNUSED、LP_DEAD、LP_REDIRECT的元组 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214//pruneheap.c line 354static intheap_prune_chain(Relation relation, Buffer buffer, OffsetNumber rootoffnum, TransactionId OldestXmin, PruneState *prstate){ int ndeleted = 0; Page dp = (Page) BufferGetPage(buffer); TransactionId priorXmax = InvalidTransactionId; ItemId rootlp; HeapTupleHeader htup; OffsetNumber latestdead = InvalidOffsetNumber, maxoff = PageGetMaxOffsetNumber(dp), offnum; OffsetNumber chainitems[MaxHeapTuplesPerPage]; int nchain = 0, i; HeapTupleData tup; tup.t_tableOid = RelationGetRelid(relation); rootlp = PageGetItemId(dp, rootoffnum); //省略 /* Start from the root tuple */ offnum = rootoffnum; /* while not end of the chain * 步骤1：遍历元组的HOT链 */ for (;;) { ItemId lp; bool tupdead, recent_dead; /* Some sanity checks */ if (offnum &lt; FirstOffsetNumber || offnum &gt; maxoff) break; /* If item is already processed, stop --- it must not be same chain */ if (prstate-&gt;marked[offnum]) break; lp = PageGetItemId(dp, offnum); /* Unused item obviously isn't part of the chain */ if (!ItemIdIsUsed(lp)) break; /* * If we are looking at the redirected root line pointer, jump to the * first normal tuple in the chain. If we find a redirect somewhere * else, stop --- it must not be same chain. */ if (ItemIdIsRedirected(lp)) { if (nchain &gt; 0) break; /* not at start of chain */ chainitems[nchain++] = offnum; offnum = ItemIdGetRedirect(rootlp); continue; } /* * Likewise, a dead item pointer can't be part of the chain. (We * already eliminated the case of dead root tuple outside this * function.) */ if (ItemIdIsDead(lp)) break; Assert(ItemIdIsNormal(lp)); htup = (HeapTupleHeader) PageGetItem(dp, lp); tup.t_data = htup; tup.t_len = ItemIdGetLength(lp); ItemPointerSet(&amp;(tup.t_self), BufferGetBlockNumber(buffer), offnum); /* * Check the tuple XMIN against prior XMAX, if any */ if (TransactionIdIsValid(priorXmax) &amp;&amp; !TransactionIdEquals(HeapTupleHeaderGetXmin(htup), priorXmax)) break; /* * OK, this tuple is indeed a member of the chain. */ chainitems[nchain++] = offnum; /* * Check tuple's visibility status. */ tupdead = recent_dead = false; //步骤2：判断元组是否过期 switch (HeapTupleSatisfiesVacuum(&amp;tup, OldestXmin, buffer)) { case HEAPTUPLE_DEAD: //元组过期 tupdead = true; break; case HEAPTUPLE_RECENTLY_DEAD: //省略 break; case HEAPTUPLE_DELETE_IN_PROGRESS: //省略 break; case HEAPTUPLE_LIVE: case HEAPTUPLE_INSERT_IN_PROGRESS: //元组未过期 break; default: elog(ERROR, &quot;unexpected HeapTupleSatisfiesVacuum result&quot;); break; } /* * Remember the last DEAD tuple seen. We will advance past * RECENTLY_DEAD tuples just in case there's a DEAD one after them; * but we can't advance past anything else. (XXX is it really worth * continuing to scan beyond RECENTLY_DEAD? The case where we will * find another DEAD tuple is a fairly unusual corner case.) */ if (tupdead) { latestdead = offnum; HeapTupleHeaderAdvanceLatestRemovedXid(htup, &amp;prstate-&gt;latestRemovedXid); } else if (!recent_dead) break; /* * If the tuple is not HOT-updated, then we are at the end of this * HOT-update chain. * 判断是否到达链尾，链尾不含HEAP_HOT_UPDATED标志。 */ if (!HeapTupleHeaderIsHotUpdated(htup)) break; /* * Advance to next chain member. */ Assert(ItemPointerGetBlockNumber(&amp;htup-&gt;t_ctid) == BufferGetBlockNumber(buffer)); offnum = ItemPointerGetOffsetNumber(&amp;htup-&gt;t_ctid); priorXmax = HeapTupleHeaderGetUpdateXid(htup); } /* * If we found a DEAD tuple in the chain, adjust the HOT chain so that all * the DEAD tuples at the start of the chain are removed and the root line * pointer is appropriately redirected. * 步骤3：记录需要设置为LP_UNUSED、LP_DEAD、LP_REDIRECT的元组 */ if (OffsetNumberIsValid(latestdead)) { /* * Mark as unused each intermediate item that we are able to remove * from the chain. * * When the previous item is the last dead tuple seen, we are at the * right candidate for redirection. */ for (i = 1; (i &lt; nchain) &amp;&amp; (chainitems[i - 1] != latestdead); i++) { //记录需要设置为LP_UNUSED的元组 heap_prune_record_unused(prstate, chainitems[i]); ndeleted++; } /* * If the root entry had been a normal tuple, we are deleting it, so * count it in the result. But changing a redirect (even to DEAD * state) doesn't count. */ if (ItemIdIsNormal(rootlp)) ndeleted++; /* * If the DEAD tuple is at the end of the chain, the entire chain is * dead and the root line pointer can be marked dead. Otherwise just * redirect the root to the correct chain member. */ if (i &gt;= nchain) /*记录需要设置为LP_DEAD的元组i &gt;= nchain说明HOT链上的所有元组都过期了， *这时需要将链头设置为LP_DEAD */ heap_prune_record_dead(prstate, rootoffnum); else /*HOT链上还有元组没有过期，所以需要将链头重定位到该元组*/ heap_prune_record_redirect(prstate, rootoffnum, chainitems[i]); } else if (nchain &lt; 2 &amp;&amp; ItemIdIsRedirected(rootlp)) { /* * We found a redirect item that doesn't point to a valid follow-on * item. This can happen if the loop in heap_page_prune caused us to * visit the dead successor of a redirect item before visiting the * redirect item. We can clean up by setting the redirect item to * DEAD state. */ heap_prune_record_dead(prstate, rootoffnum); } return ndeleted;} heap_page_prune_executeheap_page_prune_execute主要包含两个步骤： 步骤1：依据heap_prune_chain的处理结果，将相关元组设置为LP_UNUSED、LP_DEAD、LP_REDIRECT。 这三种类型的元组，他们的元组实体部分都没有意义了，所以需要将他们ItemIdData中的lp_len设置为0，以此表示他们已经没有元组实体了。对于LP_REDIRECT元组，需要将其lp_off设置为重定位的ItemIdData位置，对于LP_UNUSED、LP_DEAD直接将其lp_off设置为0。具体代码实现参见：ItemIdSetUnused、ItemIdSetRedirect、ItemIdSetDead。 步骤2：调用PageRepairFragmentation对页面内进行空间整理，即删除过期元组的元组实体部分。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849voidheap_page_prune_execute(Buffer buffer, OffsetNumber *redirected, int nredirected, OffsetNumber *nowdead, int ndead, OffsetNumber *nowunused, int nunused){ Page page = (Page) BufferGetPage(buffer); OffsetNumber *offnum; int i; //步骤1：依据heap_prune_chain的处理结果，将相关元组设置为LP_UNUSED、LP_DEAD、LP_REDIRECT。 /* Update all redirected line pointers */ offnum = redirected; for (i = 0; i &lt; nredirected; i++) { OffsetNumber fromoff = *offnum++; OffsetNumber tooff = *offnum++; ItemId fromlp = PageGetItemId(page, fromoff); ItemIdSetRedirect(fromlp, tooff); } /* Update all now-dead line pointers */ offnum = nowdead; for (i = 0; i &lt; ndead; i++) { OffsetNumber off = *offnum++; ItemId lp = PageGetItemId(page, off); ItemIdSetDead(lp); } /* Update all now-unused line pointers */ offnum = nowunused; for (i = 0; i &lt; nunused; i++) { OffsetNumber off = *offnum++; ItemId lp = PageGetItemId(page, off); ItemIdSetUnused(lp); } /* * Finally, repair any fragmentation, and update the page's hint bit about * whether it has free pointers. * 步骤2：调用PageRepairFragmentation对页面内进行空间整理，即删除过期元组的元组实体部分。 */ PageRepairFragmentation(page);} PageRepairFragmentation 红色表示需要删除的元组，绿色表示需要保留的元组，那么回收的最便捷方式就是将TUPLE3-TUPLE1依次移动到块末尾. PageRepairFragmentation主要包含三个步骤： 步骤1：统计块内需要保留的元组数量。 如果块内没有元组需要保留，则直接修改块的pd_upper指针让其指向块末尾。 步骤2：记录块内需要保留的元组。 步骤3：调用compactify_tuples实现实际的元组删除。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899voidPageRepairFragmentation(Page page){ Offset pd_lower = ((PageHeader) page)-&gt;pd_lower; Offset pd_upper = ((PageHeader) page)-&gt;pd_upper; Offset pd_special = ((PageHeader) page)-&gt;pd_special; ItemId lp; int nline, nstorage, nunused; int i; Size totallen; /* * It's worth the trouble to be more paranoid here than in most places, * because we are about to reshuffle data in (what is usually) a shared * disk buffer. If we aren't careful then corrupted pointers, lengths, * etc could cause us to clobber adjacent disk buffers, spreading the data * loss further. So, check everything. */ if (pd_lower &lt; SizeOfPageHeaderData || pd_lower &gt; pd_upper || pd_upper &gt; pd_special || pd_special &gt; BLCKSZ || pd_special != MAXALIGN(pd_special)) ereport(ERROR, (errcode(ERRCODE_DATA_CORRUPTED), errmsg(&quot;corrupted page pointers: lower = %u, upper = %u, special = %u&quot;, pd_lower, pd_upper, pd_special))); nline = PageGetMaxOffsetNumber(page); nunused = nstorage = 0; //步骤1：统计块内需要保留的元组数量。 for (i = FirstOffsetNumber; i &lt;= nline; i++) { lp = PageGetItemId(page, i); if (ItemIdIsUsed(lp)) { if (ItemIdHasStorage(lp)) nstorage++; } else { /* Unused entries should have lp_len = 0, but make sure */ ItemIdSetUnused(lp); nunused++; } } if (nstorage == 0) { /* Page is completely empty, so just reset it quickly * 如果块内没有元组需要保留，则直接修改块的pd_upper指针让其指向块末尾。 */ ((PageHeader) page)-&gt;pd_upper = pd_special; } else { /* Need to compact the page the hard way */ itemIdSortData itemidbase[MaxHeapTuplesPerPage]; itemIdSort itemidptr = itemidbase; //步骤2：记录块内需要保留的元组。 totallen = 0; for (i = 0; i &lt; nline; i++) { lp = PageGetItemId(page, i + 1); if (ItemIdHasStorage(lp)) { itemidptr-&gt;offsetindex = i; itemidptr-&gt;itemoff = ItemIdGetOffset(lp); if (itemidptr-&gt;itemoff &lt; (int) pd_upper || itemidptr-&gt;itemoff &gt;= (int) pd_special) ereport(ERROR, (errcode(ERRCODE_DATA_CORRUPTED), errmsg(&quot;corrupted item pointer: %u&quot;, itemidptr-&gt;itemoff))); itemidptr-&gt;alignedlen = MAXALIGN(ItemIdGetLength(lp)); totallen += itemidptr-&gt;alignedlen; itemidptr++; } } if (totallen &gt; (Size) (pd_special - pd_lower)) ereport(ERROR, (errcode(ERRCODE_DATA_CORRUPTED), errmsg(&quot;corrupted item lengths: total %u, available space %u&quot;, (unsigned int) totallen, pd_special - pd_lower))); //步骤3：调用compactify_tuples实现实际的元组删除。 compactify_tuples(itemidbase, nstorage, page); } /* Set hint bit for PageAddItem */ if (nunused &gt; 0) PageSetHasFreeLinePointers(page); else PageClearHasFreeLinePointers(page);} compactify_tuplescompactify_tuples包含两个步骤： 步骤1：排序 通过图5和图6，不难发现，元组移动的先后顺序要和元组偏移的大小顺序保持一致，所以在整理之前，需要先将元组按照偏移的大小顺序降序排列。 步骤2：整理 123456789101112131415161718192021222324252627282930static voidcompactify_tuples(itemIdSort itemidbase, int nitems, Page page){ PageHeader phdr = (PageHeader) page; Offset upper; int i; /* sort itemIdSortData array into decreasing itemoff order * 步骤1：排序 */ qsort((char *) itemidbase, nitems, sizeof(itemIdSortData), itemoffcompare); //步骤2：整理 upper = phdr-&gt;pd_special; for (i = 0; i &lt; nitems; i++) { itemIdSort itemidptr = &amp;itemidbase[i]; ItemId lp; lp = PageGetItemId(page, itemidptr-&gt;offsetindex + 1); upper -= itemidptr-&gt;alignedlen; memmove((char *) page + upper, (char *) page + itemidptr-&gt;itemoff, itemidptr-&gt;alignedlen); lp-&gt;lp_off = upper; } phdr-&gt;pd_upper = upper;} 小思考：向一个新分配的块中插入元组，元组ItemData的顺序和元组实体offset之前应该是逆序关系。但是，随着元组的删除，元组ItemData的重用，会导致元组ItemData和元组实体offset之间完全乱序，这就是为什么在compactify_tuples中必须对元组排序的原因。 参考整篇文章大部分基于下方的博客，写得很好。 https://blog.csdn.net/obvious__/article/details/121318928","link":"/2024/10/04/%E6%95%B0%E6%8D%AE%E5%BA%93/PostgreSQL/PG%E5%AD%98%E5%82%A8Vacuum/"},{"title":"PG存储astore解析一","text":"PG存储结构astore表操作简单解析插入、删除、更新，并结合代码深度解析单表查询流程。 概述 表PG的表被称为堆，其中的元组以互不关联的形式一条一条堆在一起。每个页面的存储结构如下： 页头PageHeaderData 元组指针数组Linp 空闲空间 freespace 元组数组tuple 特别空间special space 1234567891011121314* +----------------+---------------------------------+* | PageHeaderData | linp1 linp2 linp3 ... |* +-----------+----+---------------------------------+* | ... linpN | |* +-----------+--------------------------------------+* | ^ pd_lower |* | |* | v pd_upper |* +-------------+------------------------------------+* | | tupleN ... |* +-------------+------------------+-----------------+* | ... tuple3 tuple2 tuple1 | &quot;special space&quot; |* +--------------------------------+-----------------+* ^ pd_special 页头记录了pd_lower、pd_upper，分别表示空闲空间的起始偏移和结束偏移，pd_upper - pd_lower即可获得空闲空间的大小。pd_linp为ItemIdData数组，通过pd_linp可以定位到一条记录。 123456789101112131415161718192021222324252627282930typedef struct { /* XXX LSN is member of *any* block, not only page-organized ones */ PageXLogRecPtr pd_lsn; /* LSN: next byte after last byte of xlog * record for last change to this page */ uint16 pd_checksum; /* checksum */ uint16 pd_flags; /* flag bits, see below */ LocationIndex pd_lower; /* offset to start of free space */ LocationIndex pd_upper; /* offset to end of free space */ LocationIndex pd_special; /* offset to start of special space */ uint16 pd_pagesize_version; ShortTransactionId pd_prune_xid; /* oldest prunable XID, or zero if none */ ItemIdData pd_linp[FLEXIBLE_ARRAY_MEMBER]; /* beginning of line pointer array */} PageHeaderData;typedef struct { /* XXX LSN is member of *any* block, not only page-organized ones */ PageXLogRecPtr pd_lsn; /* LSN: next byte after last byte of xlog * record for last change to this page */ uint16 pd_checksum; /* checksum */ uint16 pd_flags; /* flag bits, see below */ LocationIndex pd_lower; /* offset to start of free space */ LocationIndex pd_upper; /* offset to end of free space */ LocationIndex pd_special; /* offset to start of special space */ uint16 pd_pagesize_version; ShortTransactionId pd_prune_xid; /* oldest prunable XID, or zero if none */ TransactionId pd_xid_base; /* base value for transaction IDs on page */ TransactionId pd_multi_base; /* base value for multixact IDs on page */ ItemIdData pd_linp[FLEXIBLE_ARRAY_MEMBER]; /* beginning of line pointer array */} HeapPageHeaderData; 元组元组包括元组头和数据。 t_xmin：代表插入此元组的事务xid； t_xmax：代表更新或者删除此元组的事务xid，如果该元组插入后未进行更新或者删除，t_xmax=0； t_cid：command id，代表在当前事务中，已经执行过多少条sql，例如执行第一条sql时cid=0，执行第二条sql时cid=1； t_ctid：保存着指向自身或者新元组的元组标识（tid），由两个数字组成，第一个数字代表物理块号，或者叫页面号，第二个数字代表元组号。（如果是旧版本数据，则此字段指向新版本的数据）。 t_infomask2：使用其低11位表示当前元组的属性个数，其他位用于包含用于HOT技术及元组可见性的标志位。 t_infomask：标识元组的当前状态，比如：是否具有OID、是否有空属性等，t_infomask的每一位对应不同的状态，共16种状态。 t_hoff：表示元组头的大小。 t_bits：用于标识该元组哪些字段为空。 123456789101112131415161718192021222324252627typedef struct HeapTupleFields{ TransactionId t_xmin; /* inserting xact ID */ TransactionId t_xmax; /* deleting or locking xact ID */ union { CommandId t_cid; /* inserting or deleting command ID, or both */ TransactionId t_xvac; /* old-style VACUUM FULL xact ID */ } t_field3;} HeapTupleFields;typedef struct HeapTupleHeaderData { union { HeapTupleFields t_heap; DatumTupleFields t_datum; } t_choice; ItemPointerData t_ctid; /* current TID of this or newer tuple */ /* Fields below here must match MinimalTupleData! */ uint16 t_infomask2; /* number of attributes + various flags */ uint16 t_infomask; /* various flag bits, see below */ uint8 t_hoff; /* sizeof header incl. bitmap, padding */ /* ^ - 23 bytes - ^ */ bits8 t_bits[FLEXIBLE_ARRAY_MEMBER]; /* bitmap of NULLs -- VARIABLE LENGTH */ /* MORE DATA FOLLOWS AT END OF STRUCT */} HeapTupleHeaderData; 仔细看ItemPointerData的结构： ip_blkid：表示文件块编号。 ip_posid：表示该元组对应的ItemIdData数组的下标（ItemIdData数组见PageHeaderData）。 12345typedef struct ItemPointerData{ BlockIdData ip_blkid; OffsetNumber ip_posid;} 123456789101112131415161718typedef struct HeapTupleData { uint32 t_len; /* length of *t_data */ uint1 tupTableType = HEAP_TUPLE; uint1 tupInfo; int2 t_bucketId; ItemPointerData t_self; /* SelfItemPointer */ Oid t_tableOid; /* table the tuple came from */ TransactionId t_xid_base; TransactionId t_multi_base;#ifdef PGXC uint32 t_xc_node_id; /* Data node the tuple came from */#endif Page page = nullptr; Relation rel = nullptr; HeapTupleHeader t_data; /* -&gt; tuple header and data */} HeapTupleData;typedef void* Tuple; 表操作基本原理插入插入的过程很简单，修改对应Linp和tuple数组。值得注意的是Tuple头部各个字段的设置： t_xmin会被设置为执行当前命令的事务id t_xmax设置为0，t_cid则是根据事务内的命令数设置 t_ctid设置为块号和位置 上图中的tuple1的ctid应该是（0，1）。 1SELECT lp as tuple, t_xmin, t_xmax, t_field3 as t_cid, t_ctid FROM heap_page_items(get_raw_page(tbl, 0)); 删除astore的删除逻辑为标记删除，不删除元组本身，而是作标记。元组的回收由vacuum进程进行。删除时，元组头部设置： t_xmax设置为事务id 更新astore存储格式为追加写优化设计，当一个更新操作将v0版本元组更新为v1版本元组之后，如果v0版本元组所在页面仍然有空闲空间，则直接在该页面内插入更新后的v1版本元组，并将v0版本的元组指针指向v1版本的元组指针。 在这个过程中，新版本元组以追加写的方式和被更新的老版本元组混合存放，可减少更新操作的I/O开销。然而混合存放使得清理老版本元组开销较大。 更新操作执行的是先删除后插入，缺点显然易见：会造成数据表膨胀。在有索引的情况下，即便没有修改索引列的值，也会往索引中插入一条数据，PG为改善这种情况，采用了一种HOT技术。 关于HOT技术，在索引相关文章中再详细阐述。 下图中两次更新同一行，可以看到，更新的操作为： 针对旧元组，设置它的t_xmax为事务id，t_ctid指向新元组。 针对新元组，正常执行插入操作。 单表查询关于查询涉及很多方面：SQL解析、成本评估、索引选择等等，这里只讨论最简单的不涉及索引的单表顺序查询的过程。 下面是执行查询时的调用链： 123456789101112131415main PostmasterMain ServerLoop BackendStartup BackendRun PostgresMain exec_simple_query # 词法解析/语法解析/优化器 PortalRun # 已经生产执行计划，开始执行 PortalRunSelect # 执行计划是 查询，这里和 insert的执行计划是不一样的 standard_ExecutorRun ExecutePlan ExecProcNode ExecScan ExecScanFetch SeqNext 主要看调用顺序： 1234ExecutePlanExecProcNodeExecSeqScanExecScan 从ExecutePlan上可以看到该函数执行查询计划，直到达到指定数量numberTuples的元组。 该函数也是相当易懂：主体为一个循环，一次通过ExecProcNode获取一条tuple存储在slot中，如果sendTuple就发送到终端，增加current_tuple_count计数，直到numberTuples。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123/* ---------------------------------------------------------------- * ExecutePlan * * Processes the query plan until we have retrieved 'numberTuples' tuples, * moving in the specified direction. * * Runs to completion if numberTuples is 0 * * Note: the ctid attribute is a 'junk' attribute that is removed before the * user can see it * ---------------------------------------------------------------- */static void ExecutePlan(EState *estate, PlanState *planstate, bool use_parallel_mode, CmdType operation, bool sendTuples, uint64 numberTuples, ScanDirection direction, DestReceiver *dest, bool execute_once){ TupleTableSlot *slot; uint64 current_tuple_count; /* * initialize local variables */ current_tuple_count = 0; /* * Set the direction. */ estate-&gt;es_direction = direction; /* * If the plan might potentially be executed multiple times, we must force * it to run without parallelism, because we might exit early. Also * disable parallelism when writing into a relation, because no database * changes are allowed in parallel mode. */ if (!execute_once || dest-&gt;mydest == DestIntoRel) use_parallel_mode = false; estate-&gt;es_use_parallel_mode = use_parallel_mode; if (use_parallel_mode) EnterParallelMode(); /* * Loop until we've processed the proper number of tuples from the plan. */ for (;;) { /* Reset the per-output-tuple exprcontext */ ResetPerTupleExprContext(estate); /* * Execute the plan and obtain a tuple */ slot = ExecProcNode(planstate); /* * if the tuple is null, then we assume there is nothing more to * process so we just end the loop... */ if (TupIsNull(slot)) { /* Allow nodes to release or shut down resources. */ (void) ExecShutdownNode(planstate); break; } /* * If we have a junk filter, then project a new tuple with the junk * removed. * * Store this new &quot;clean&quot; tuple in the junkfilter's resultSlot. * (Formerly, we stored it back over the &quot;dirty&quot; tuple, which is WRONG * because that tuple slot has the wrong descriptor.) */ if (estate-&gt;es_junkFilter != NULL) slot = ExecFilterJunk(estate-&gt;es_junkFilter, slot); /* * If we are supposed to send the tuple somewhere, do so. (In * practice, this is probably always the case at this point.) */ if (sendTuples) { /* * If we are not able to send the tuple, we assume the destination * has closed and no more tuples can be sent. If that's the case, * end the loop. */ if (!((*dest-&gt;receiveSlot) (slot, dest))) break; } /* * Count tuples processed, if this is a SELECT. (For other operation * types, the ModifyTable plan node must count the appropriate * events.) */ if (operation == CMD_SELECT) (estate-&gt;es_processed)++; /* * check our tuple count.. if we've processed the proper number then * quit, else loop again and process more tuples. Zero numberTuples * means no limit. */ current_tuple_count++; if (numberTuples &amp;&amp; numberTuples == current_tuple_count) { /* Allow nodes to release or shut down resources. */ (void) ExecShutdownNode(planstate); break; } } if (use_parallel_mode) ExitParallelMode();} ExecProcNode会调用ExecSeqScan，ExecSeqScan又是对ExecScan的包装，下面重点看ExecScan，ExecScan会根据传入的扫描方式进行扫描，这样的好处是抽象。索引扫描也是执行ExecScan，只不过传入索引扫描的方法。 12345TupleTableSlot * ExecSeqScan(SeqScanState *node){ return ExecScan((ScanState *) node, (ExecScanAccessMtd) SeqNext, (ExecScanRecheckMtd) SeqRecheck);} ExecScan的主体仍然为一个循环，通过传入ExecScanAccessMtd（也就是SeqNext）获取一条Tuple，通过ExecQuel校验元组是否满足条件。这里的校验以后再谈。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163TupleTableSlot *ExecScan(ScanState *node, ExecScanAccessMtd accessMtd, /* function returning a tuple */ ExecScanRecheckMtd recheckMtd){ ExprContext *econtext; ExprState *qual; ProjectionInfo *projInfo; /* * Fetch data from node */ qual = node-&gt;ps.qual; projInfo = node-&gt;ps.ps_ProjInfo; econtext = node-&gt;ps.ps_ExprContext; /* interrupt checks are in ExecScanFetch */ /* * If we have neither a qual to check nor a projection to do, just skip * all the overhead and return the raw scan tuple. */ if (!qual &amp;&amp; !projInfo) { ResetExprContext(econtext); return ExecScanFetch(node, accessMtd, recheckMtd); } /* * Reset per-tuple memory context to free any expression evaluation * storage allocated in the previous tuple cycle. */ ResetExprContext(econtext); /* * get a tuple from the access method. Loop until we obtain a tuple that * passes the qualification. */ for (;;) { TupleTableSlot *slot; slot = ExecScanFetch(node, accessMtd, recheckMtd); /* * if the slot returned by the accessMtd contains NULL, then it means * there is nothing more to scan so we just return an empty slot, * being careful to use the projection result slot so it has correct * tupleDesc. */ if (TupIsNull(slot)) { if (projInfo) return ExecClearTuple(projInfo-&gt;pi_state.resultslot); else return slot; } /* * place the current tuple into the expr context */ econtext-&gt;ecxt_scantuple = slot; /* * check that the current tuple satisfies the qual-clause * * check for non-null qual here to avoid a function call to ExecQual() * when the qual is null ... saves only a few cycles, but they add up * ... */ if (qual == NULL || ExecQual(qual, econtext)) { /* * Found a satisfactory scan tuple. */ if (projInfo) { /* * Form a projection tuple, store it in the result tuple slot * and return it. */ return ExecProject(projInfo); } else { /* * Here, we aren't projecting, so just return scan tuple. */ return slot; } } else InstrCountFiltered1(node, 1); /* * Tuple fails qual, so free per-tuple memory and try again. */ ResetExprContext(econtext); }}static inline TupleTableSlot * ExecScanFetch(ScanState *node, ExecScanAccessMtd accessMtd, ExecScanRecheckMtd recheckMtd){ EState *estate = node-&gt;ps.state; CHECK_FOR_INTERRUPTS(); if (estate-&gt;es_epqTuple != NULL) { /* * We are inside an EvalPlanQual recheck. Return the test tuple if * one is available, after rechecking any access-method-specific * conditions. */ Index scanrelid = ((Scan *) node-&gt;ps.plan)-&gt;scanrelid; if (scanrelid == 0) { TupleTableSlot *slot = node-&gt;ss_ScanTupleSlot; /* * This is a ForeignScan or CustomScan which has pushed down a * join to the remote side. The recheck method is responsible not * only for rechecking the scan/join quals but also for storing * the correct tuple in the slot. */ if (!(*recheckMtd) (node, slot)) ExecClearTuple(slot); /* would not be returned by scan */ return slot; } else if (estate-&gt;es_epqTupleSet[scanrelid - 1]) { TupleTableSlot *slot = node-&gt;ss_ScanTupleSlot; /* Return empty slot if we already returned a tuple */ if (estate-&gt;es_epqScanDone[scanrelid - 1]) return ExecClearTuple(slot); /* Else mark to remember that we shouldn't return more */ estate-&gt;es_epqScanDone[scanrelid - 1] = true; /* Return empty slot if we haven't got a test tuple */ if (estate-&gt;es_epqTuple[scanrelid - 1] == NULL) return ExecClearTuple(slot); /* Store test tuple in the plan node's scan slot */ ExecStoreTuple(estate-&gt;es_epqTuple[scanrelid - 1], slot, InvalidBuffer, false); /* Check if it meets the access-method conditions */ if (!(*recheckMtd) (node, slot)) ExecClearTuple(slot); /* would not be returned by scan */ return slot; } } /* * Run the node-type-specific access method function to get the next tuple */ return (*accessMtd) (node);} SeqNext参数解释SeqNext的一个重要参数是SeqScanState顺序扫描状态，其中重要的是HeapScanDesc堆扫描描述符。 1234567891011121314151617typedef struct ScanState{ PlanState ps; /* its first field is NodeTag */ Relation ss_currentRelation; HeapScanDesc ss_currentScanDesc; TupleTableSlot *ss_ScanTupleSlot;} ScanState;/* ---------------- * SeqScanState information * ---------------- */typedef struct SeqScanState{ ScanState ss; /* its first field is NodeTag */ Size pscan_len; /* size of parallel heap scan descriptor */} SeqScanState; HeapScanDescData分为四个部分，第一部分是扫描参数；第二部分是初始化结构体相关；第三部分是扫描状态；第四部分与page-at-a-time扫描模式相关。 重点看第二部分和第三部分，它们保存了扫描了扫描的状态，比如当前扫描的块，元组，缓冲页等。由于一次只返回一条元组，所以需要它来记录当前遍历到哪个缓冲页的哪一条元组。 12345678910111213141516171819202122232425262728293031323334353637typedef struct HeapScanDescData{ /* scan parameters */ Relation rs_rd; /* 堆表描述符;heap relation descriptor */ Snapshot rs_snapshot; /* 快照;snapshot to see */ int rs_nkeys; /* 扫描键数;number of scan keys */ ScanKey rs_key; /* 扫描键数组;array of scan key descriptors */ bool rs_bitmapscan; /* bitmap scan=&gt;T;true if this is really a bitmap scan */ bool rs_samplescan; /* sample scan=&gt;T;true if this is really a sample scan */ bool rs_pageatatime; /* 是否验证可见性(MVCC机制);verify visibility page-at-a-time? */ bool rs_allow_strat; /* 是否允许访问策略的使用;allow or disallow use of access strategy */ bool rs_allow_sync; /* 是否允许syncscan的使用;allow or disallow use of syncscan */ bool rs_temp_snap; /* 是否在扫描结束后取消快照&quot;登记&quot;;unregister snapshot at scan end? */ /* state set up at initscan time */ BlockNumber rs_nblocks; /* rel中的blocks总数;total number of blocks in rel */ BlockNumber rs_startblock; /* 开始的block编号;block # to start at */ BlockNumber rs_numblocks; /* 最大的block编号;max number of blocks to scan */ /* rs_numblocks is usually InvalidBlockNumber, meaning &quot;scan whole rel&quot; */ BufferAccessStrategy rs_strategy; /* 读取时的访问场景;access strategy for reads */ bool rs_syncscan; /* 在syncscan逻辑处理时是否报告位置;report location to syncscan logic? */ /* scan current state */ bool rs_inited; /* 如为F,则扫描尚未初始化;false = scan not init'd yet */ HeapTupleData rs_ctup; /* 当前扫描的tuple;current tuple in scan, if any */ BlockNumber rs_cblock; /* 当前扫描的block;current block # in scan, if any */ Buffer rs_cbuf; /* 当前扫描的buffer;current buffer in scan, if any */ /* NB: if rs_cbuf is not InvalidBuffer, we hold a pin on that buffer */ ParallelHeapScanDesc rs_parallel; /* 并行扫描信息;parallel scan information */ /* these fields only used in page-at-a-time mode and for bitmap scans */ int rs_cindex; /* 在vistuples中的当前元组索引;current tuple's index in vistuples */ int rs_ntuples; /* page中的可见元组计数;number of visible tuples on page */ OffsetNumber rs_vistuples[MaxHeapTuplesPerPage]; /* 元组的偏移;their offsets */} HeapScanDescData; /* struct definitions appear in relscan.h */typedef struct HeapScanDescData *HeapScanDesc; SeqNext过程SeqNext逻辑也比较简单： 调用heap_beginscan初始化scandesc扫描 调用heap_getnext获取一条元组 调用ExecStoreTuple或ExecClearTuple执行一些清理操作 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354static TupleTableSlot * SeqNext(SeqScanState *node){ HeapTuple tuple; HeapScanDesc scandesc; EState *estate; ScanDirection direction; TupleTableSlot *slot; /* * get information from the estate and scan state */ scandesc = node-&gt;ss.ss_currentScanDesc; estate = node-&gt;ss.ps.state; direction = estate-&gt;es_direction; slot = node-&gt;ss.ss_ScanTupleSlot; /* 如果不存在scandesc，就创建一个scandesc */ if (scandesc == NULL) { /* * We reach here if the scan is not parallel, or if we're serially * executing a scan that was planned to be parallel. */ scandesc = heap_beginscan(node-&gt;ss.ss_currentRelation, estate-&gt;es_snapshot, 0, NULL); node-&gt;ss.ss_currentScanDesc = scandesc; } /* * get the next tuple from the table * 获取一条可见元组 */ tuple = heap_getnext(scandesc, direction); /* * save the tuple and the buffer returned to us by the access methods in * our scan tuple slot and return the slot. Note: we pass 'false' because * tuples returned by heap_getnext() are pointers onto disk pages and were * not created with palloc() and so should not be pfree()'d. Note also * that ExecStoreTuple will increment the refcount of the buffer; the * refcount will not be dropped until the tuple table slot is cleared. * 一些清理工作，比如对buffer page执行unpin操作。 */ if (tuple) ExecStoreTuple(tuple, /* tuple to store */ slot, /* slot to store in */ scandesc-&gt;rs_cbuf, /* buffer associated with this * tuple */ false); /* don't pfree this pointer */ else ExecClearTuple(slot); return slot;} heap_beginscanheap_beginscan调用heap_beginscan_internal设置扫描结构体HeapScanDesc。 heap_beginscan_internal 函数的处理流程如下: 首先根据传递给函数的参数对HeapScanDesoData 的相关扫描参数进行设置，包括扫描的关系表、快照、扫描键、rS_allow_strat 、rs_allow- syne 等信息。 调用函数initscan 对该结构体第二部分字段进行初始化。 heap_getnext这里注意到根据rs_pageatatime有两种不同的扫描模式，page-at-a-time是一种轻量级的扫描模式，它不对buffer进行加锁。 123456789101112131415161718192021222324252627HeapTuple heap_getnext(HeapScanDesc scan, ScanDirection direction){ /* Note: no locking manipulations needed */ HEAPDEBUG_1; /* heap_getnext( info ) */ if (scan-&gt;rs_pageatatime) heapgettup_pagemode(scan, direction, scan-&gt;rs_nkeys, scan-&gt;rs_key); else heapgettup(scan, direction, scan-&gt;rs_nkeys, scan-&gt;rs_key); if (scan-&gt;rs_ctup.t_data == NULL) { HEAPDEBUG_2; /* heap_getnext returning EOS */ return NULL; } /* * if we get here it means we have a new current scan tuple, so point to * the proper return buffer and return the tuple. */ HEAPDEBUG_3; /* heap_getnext returning tuple */ pgstat_count_heap_getnext(scan-&gt;rs_rd); return &amp;(scan-&gt;rs_ctup);} 这里要注意HeapScanDesc几个成员： rs_rd字段表示当前表 rs_snapshot表示扫描快照 rs_startblock表示了扫描的开始块 rs_nblocks是表中的tuple总数 rs_numblocks是可供扫描的块个数 rs_startblock是开始的块号 rs_cblock是当前缓存块 rs_cindex当前遍历的tuple下标 heapgettup或者heapgettup_pagemode的逻辑差不多，都是首先判断scandesc是否初始化，未初始则调用heapgetpage获取一页的tuple。然后遍历这一页的tuple，将其放到rs_ctup中。 heapgetpage将获取所有可见元组的ItemId放在rs_vsisituples中，注意，heapgetpage还会调用heap_page_prune_opt来清理HOT链。 heapgetpage的流程如下： 将物理块加载到缓存页中。 为缓存页加轻量级共享锁。 轻量级锁，即light wight lock，是PostgreSQL自己实现的一种锁，本质上是latch，用于共享资源的多进程同步，具备等待队列，不具备死锁检测。 遍历页面中的所有元组，判断元组的可见性，将可见元组的ItemId存入rs_vistuples中。 释放轻量级共享锁。 123456789101112131415heapgettup if (!scan-&gt;rs_base.rs_inited) { heapgetpage((TableScanDesc)scan, page); } else { /* continue from previously returned page/tuple */ page = scan-&gt;rs_base.rs_cblock; /* current page */ line_off = OffsetNumberNext(ItemPointerGetOffsetNumber(&amp;(tuple-&gt;t_self))); } lpp = HeapPageGetItemId(dp, line_off); for (;;) { while (lines_left &gt; 0) { ... } } 堆表访存管理 以astore堆表顺序扫描为例，执行流程如下。 （1）调用heap_open接口打开待扫描的堆表，获取表的相关元信息，如表的行存储子格式为astore格式等。该步通常要获取AccessShare一级表锁，防止并发的DDL操作。 （2）调用tableam_scan_begin接口，从g_tableam_routines数组中找到astore的初始化扫描接口，即heap_beginscan接口，完成初始化顺序扫描操作相关的结构体。 （3）循环调用tableam_scan_getnexttuple接口，从g_tableam_routines数组中找到astore的扫描元组接口，即heap_getnext接口，顺序获取一条astore元组，直到完成全部扫描。顺序扫描时，每次先获取下一个页面，然后依次返回该页面上的每一条元组。这里提供了两种元组可见性的判断时机： heapgettup_pagemode。在第一次加载下一个页面时，加上页面共享锁，完成对页面上所有元组的可见性判断，然后将可见的元组位置保存起来，释放页面共享锁。后面每次直接从保存的可见性元组列表中返回下一条可见的元组，无须再对页面加共享，使用快照的查询，默认都使用该批量模式，因为元组的可见性在同一个快照中不会再发生变化。 heapgetpage。除了第一次加载下一个页面时需要批量校验元组可见性之外，在后面每一次返回该页面下一条元组时，都要重新对页面加共享锁，判断下一条元组的可见性。该模式的查询性能较批量模式要稍低，适用于对系统表的顺序扫描（系统表的可见性不参照查询快照，而是以实时的事务提交状态为准）。 （4）调用tableam_scan_end接口，从g_tableam_routines数组中找到astore的扫描结束接口，即heap_endscan接口，结束顺序扫描操作，释放对应的扫描结构体。 （5）调用heap_close接口，释放对表加的锁或引用计数。 参考： https://blog.csdn.net/obvious__/article/details/120706222 https://pg-internal.vonng.com/#/","link":"/2024/10/03/%E6%95%B0%E6%8D%AE%E5%BA%93/PostgreSQL/PG%E5%AD%98%E5%82%A8astore%E8%A7%A3%E6%9E%90%E4%B8%80/"},{"title":"PG存储astore解析二","text":"结合代码流程解析插入、删除流程。 插入流程调用链123456789101112131415161718main PostmasterMain ServerLoop BackendStartup BackendRun PostgresMain exec_simple_query # 词法解析/语法解析/优化器 PortalRun PortalRunMulti ProcessQuery standard_ExecutorRun ExecutePlan ExecProcNode ExecModifyTable ExecInsert table_tuple_insert # 通过 default_table_access_method选择执行函数 heapam_tuple_insert # 选择了 heap access method. heap_insert # 插入元组 insert into t1 values(4,4); 其中exec_simple_query的逻辑如下： 1234567891011121314151617181920212223242526272829303132333435exec_simple_query--&gt; pg_parse_query //语法解析 --&gt; raw_parser --&gt; base_yyparse--&gt; pg_analyze_and_rewrite //语义分析 --&gt; parse_analyze --&gt; transformStmt --&gt; transformInsertStmt --&gt; pg_plan_queries //查询优化，生成执行计划 --&gt; pg_plan_query --&gt; standard_planner --&gt; subquery_planner --&gt; grouping_planner --&gt; query_planner --&gt; build_simple_rel --&gt; make_one_rel --&gt; create_modifytable_path --&gt; create_plan--&gt; PortalStart--&gt; PortalRun --&gt; ProcessQuery --&gt; ExecutorStart --&gt; InitPlan --&gt; ExecInitModifyTable --&gt; ExecutorRun --&gt; ExecutePlan --&gt; ExecModifyTable --&gt; planSlot = ExecProcNode(subplanstate); // 执行子执行计划Result，获取要插入的tuple值， 对应values(4,4) --&gt; ExecInitInsertProjection --&gt; ExecGetInsertNewTuple --&gt; ExecInsert // -----执行插入------ --&gt; table_tuple_insert --&gt; ExecutorEnd--&gt; PortalDrop ExecInsertheap_insert主要是四个步骤： 从values形成要插入的tuple heap_prepare_insert 从Buffer中获取一个页 RelationGetBufferForTuple 向缓冲页插入tuple，标记脏页 RelationPutHeapTuple 写WAL日志 1234567891011121314151617181920212223242526272829ExecInsert // 执行插入--&gt; table_tuple_insert --&gt; heap_insert /******** Buffer中向Page插入一条tuple ***********/ --&gt; GetCurrentTransactionId() --&gt; heap_prepare_insert // 1.准备tuple --&gt; RelationGetBufferForTuple // 2. Buffer中获取足够插入tuple大小的页， --&gt; GetPageWithFreeSpace --&gt; fsm_search // 结合fsm，查找含有足够空闲size的页 --&gt; CheckForSerializableConflictIn --&gt; RelationPutHeapTuple // 3. 向页中插入tuple --&gt; BufferGetPage(buffer); --&gt; PageAddItemExtended --&gt; MarkBufferDirty /******** 4.写WAL日志 ***********/ --&gt; XLogBeginInsert --&gt; XLogRegisterData --&gt; XLogRegisterBuffer --&gt; XLogRegisterBufData --&gt; XLogSetRecordFlags --&gt; XLogInsert --&gt; XLogRecordAssemble // 由前面的信息生成日志记录 --&gt; XLogInsertRecord // 插入WAL日志中 --&gt; CopyXLogRecordToWAL(rechdr-&gt;xl_tot_len, isLogSwitch, rdata,StartPos, EndPos); --&gt; GetXLogBuffer(CurrPos) --&gt; XLogFlush(EndPos) --&gt; XLogWrite // 写入WAL日志文件 --&gt; PageSetLSN(page, recptr); heap_prepare_insert的主要作用是设置Tuple元组头部信息，包括oid、xmin、xmax、cid等等，如果Tuple可以Toast则执行toast_insert_or_update。 RelationGetBufferForTuple： 计算元组需要预留的大小，加上元组大小不能超过元组最大大小 要插入的页尽可能是刚插入过的页，没有的话就从fsm上获取一页，如果没有fsm信息或fsm不够大，就获取关系表的最后一页 为获取的页加锁 检查是否pin和lock成功了这些页，并保证成功（pin操作是在vm里） 检查空间是否足够，如果空间够了，就返回这个buffer，如果空间不够，就重新获取 如果fsm中都不够用，就扩展表 对于扩展后的表，要将页初始化，再返回这个buffer RelationPutHeapTuple： 根据 buffer获取Page 执行 pageAddItemExtend 更新 元组指针 itemid 的 ctid PageAddItemExtended 主要是四步： 如果指定offsetNumber，则在指定偏移处覆盖数据，返回 否则找到空闲的Linp（或slot） 如果没有空闲的Linp则在其后找一个位置 设置item指向upper、拷贝数据到upper、更新lower和upper 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151OffsetNumberPageAddItemExtended(Page page, Item item, Size size, OffsetNumber offsetNumber, int flags){ PageHeader phdr = (PageHeader) page; Size alignedSize; int lower; int upper; ItemId itemId; OffsetNumber limit; bool needshuffle = false; /* * Be wary about corrupted page pointers */ if (phdr-&gt;pd_lower &lt; SizeOfPageHeaderData || phdr-&gt;pd_lower &gt; phdr-&gt;pd_upper || phdr-&gt;pd_upper &gt; phdr-&gt;pd_special || phdr-&gt;pd_special &gt; BLCKSZ) ereport(PANIC, (errcode(ERRCODE_DATA_CORRUPTED), errmsg(&quot;corrupted page pointers: lower = %u, upper = %u, special = %u&quot;, phdr-&gt;pd_lower, phdr-&gt;pd_upper, phdr-&gt;pd_special))); /* * Select offsetNumber to place the new item at */ limit = OffsetNumberNext(PageGetMaxOffsetNumber(page)); /* was offsetNumber passed in? */ if (OffsetNumberIsValid(offsetNumber)) { /* yes, check it */ if ((flags &amp; PAI_OVERWRITE) != 0) { if (offsetNumber &lt; limit) { itemId = PageGetItemId(phdr, offsetNumber); if (ItemIdIsUsed(itemId) || ItemIdHasStorage(itemId)) { elog(WARNING, &quot;will not overwrite a used ItemId&quot;); return InvalidOffsetNumber; } } } else { if (offsetNumber &lt; limit) needshuffle = true; /* need to move existing linp's */ } } else { /* offsetNumber was not passed in, so find a free slot */ /* if no free slot, we'll put it at limit (1st open slot) */ if (PageHasFreeLinePointers(phdr)) { /* * Look for &quot;recyclable&quot; (unused) ItemId. We check for no storage * as well, just to be paranoid --- unused items should never have * storage. */ for (offsetNumber = 1; offsetNumber &lt; limit; offsetNumber++) { itemId = PageGetItemId(phdr, offsetNumber); if (!ItemIdIsUsed(itemId) &amp;&amp; !ItemIdHasStorage(itemId)) break; } if (offsetNumber &gt;= limit) { /* the hint is wrong, so reset it */ PageClearHasFreeLinePointers(phdr); } } else { /* don't bother searching if hint says there's no free slot */ offsetNumber = limit; } } /* Reject placing items beyond the first unused line pointer */ if (offsetNumber &gt; limit) { elog(WARNING, &quot;specified item offset is too large&quot;); return InvalidOffsetNumber; } /* Reject placing items beyond heap boundary, if heap */ if ((flags &amp; PAI_IS_HEAP) != 0 &amp;&amp; offsetNumber &gt; MaxHeapTuplesPerPage) { elog(WARNING, &quot;can't put more than MaxHeapTuplesPerPage items in a heap page&quot;); return InvalidOffsetNumber; } /* * Compute new lower and upper pointers for page, see if it'll fit. * * Note: do arithmetic as signed ints, to avoid mistakes if, say, * alignedSize &gt; pd_upper. */ if (offsetNumber == limit || needshuffle) lower = phdr-&gt;pd_lower + sizeof(ItemIdData); else lower = phdr-&gt;pd_lower; alignedSize = MAXALIGN(size); upper = (int) phdr-&gt;pd_upper - (int) alignedSize; if (lower &gt; upper) return InvalidOffsetNumber; /* * OK to insert the item. First, shuffle the existing pointers if needed. */ itemId = PageGetItemId(phdr, offsetNumber); if (needshuffle) memmove(itemId + 1, itemId, (limit - offsetNumber) * sizeof(ItemIdData)); /* set the item pointer */ ItemIdSetNormal(itemId, upper, size); /* * Items normally contain no uninitialized bytes. Core bufpage consumers * conform, but this is not a necessary coding rule; a new index AM could * opt to depart from it. However, data type input functions and other * C-language functions that synthesize datums should initialize all * bytes; datumIsEqual() relies on this. Testing here, along with the * similar check in printtup(), helps to catch such mistakes. * * Values of the &quot;name&quot; type retrieved via index-only scans may contain * uninitialized bytes; see comment in btrescan(). Valgrind will report * this as an error, but it is safe to ignore. */ VALGRIND_CHECK_MEM_IS_DEFINED(item, size); /* copy the item's data onto the page */ memcpy((char *) page + upper, item, size); /* adjust page header */ phdr-&gt;pd_lower = (LocationIndex) lower; phdr-&gt;pd_upper = (LocationIndex) upper; return offsetNumber;} 删除流程这里贴上博客的内容，写得很好，不重新造轮子。 1234heap_delete buffer = ReadBuffer(relation, block); // 并发更新判断元组的状态 result = HeapTupleSatisfiesUpdate(&amp;tp, cid, buffer, allow_delete_self); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436/* * heap_delete - delete a tuple * * See table_tuple_delete() for an explanation of the parameters, except that * this routine directly takes a tuple rather than a slot. * * In the failure cases, the routine fills *tmfd with the tuple's t_ctid, * t_xmax (resolving a possible MultiXact, if necessary), and t_cmax (the last * only for TM_SelfModified, since we cannot obtain cmax from a combo CID * generated by another transaction). */TM_Result heap_delete(Relation relation, ItemPointer tid, CommandId cid, Snapshot crosscheck, bool wait, TM_FailureData *tmfd, bool changingPart){ TM_Result result; TransactionId xid = GetCurrentTransactionId(); // 写操作事务均需要获取事务号 ItemId lp; HeapTupleData tp; Page page; BlockNumber block; Buffer buffer; Buffer vmbuffer = InvalidBuffer; TransactionId new_xmax; uint16 new_infomask, new_infomask2; bool have_tuple_lock = false; bool iscombo; bool all_visible_cleared = false; HeapTuple old_key_tuple = NULL; /* replica identity of the tuple */ bool old_key_copied = false; Assert(ItemPointerIsValid(tid)); // 删除元组的 tid上层函数传入 /* * Forbid this during a parallel operation, lest it allocate a combo CID. * Other workers might need that combo CID for visibility checks, and we * have no provision for broadcasting it to them. */ // 删除一条元组禁止开并行模式 if (IsInParallelMode()) ereport(ERROR, (errcode(ERRCODE_INVALID_TRANSACTION_STATE), errmsg(&quot;cannot delete tuples during a parallel operation&quot;))); // 根据元组的 tid确定块号，并根据块号和 relation 描述符将数据块加载时共享缓冲区中buffer，获取页地址 block = ItemPointerGetBlockNumber(tid); buffer = ReadBuffer(relation, block); page = BufferGetPage(buffer); /* * Before locking the buffer, pin the visibility map page if it appears to * be necessary. Since we haven't got the lock yet, someone else might be * in the middle of changing this, so we'll need to recheck after we have * the lock. */ // 由于删除元组，势必会修改VM对应标识位，如果数据页含有 allvisible标记，则需要将数据页对应的VM页加载至 // vmbuffer(pin住) if (PageIsAllVisible(page)) visibilitymap_pin(relation, block, &amp;vmbuffer); // 对 buffer施加排他锁 LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE); /* * If we didn't pin the visibility map page and the page has become all * visible while we were busy locking the buffer, we'll have to unlock and * re-lock, to avoid holding the buffer lock across an I/O. That's a bit * unfortunate, but hopefully shouldn't happen often. */ // 在获取上述缓冲块排他锁期间，可能有其他进程将对应的VM 数据页标记信息更新为 allvisible,那么此时 // 需要释放buffer 排他锁，pin住 vmbuffer,后在此获取buffer排他锁。，其目的是为了防止在持有buffer // 排他锁行执行 io (加载vm page 至 vmbuffer) if (vmbuffer == InvalidBuffer &amp;&amp; PageIsAllVisible(page)) { LockBuffer(buffer, BUFFER_LOCK_UNLOCK); visibilitymap_pin(relation, block, &amp;vmbuffer); LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE); } // 获取偏移量为tid的元组相关信息 lp = PageGetItemId(page, ItemPointerGetOffsetNumber(tid)); Assert(ItemIdIsNormal(lp)); tp.t_tableOid = RelationGetRelid(relation); tp.t_data = (HeapTupleHeader) PageGetItem(page, lp); tp.t_len = ItemIdGetLength(lp); tp.t_self = *tid;l1: // 可见性判断：根据其结果判断元组是否满足被更新/删除 result = HeapTupleSatisfiesUpdate(&amp;tp, cid, buffer); // 元组不可见，报错 if (result == TM_Invisible) { UnlockReleaseBuffer(buffer); ereport(ERROR, (errcode(ERRCODE_OBJECT_NOT_IN_PREREQUISITE_STATE), errmsg(&quot;attempted to delete invisible tuple&quot;))); } // 该元组正在被更新，且等待 else if (result == TM_BeingModified &amp;&amp; wait) { TransactionId xwait; uint16 infomask; /* must copy state data before unlocking buffer */ // 获取 元组的xmax和 infomask，此时并不知道 xmax是单纯的事务号还是 MultiXactId xwait = HeapTupleHeaderGetRawXmax(tp.t_data); infomask = tp.t_data-&gt;t_infomask; /* * Sleep until concurrent transaction ends -- except when there's a * single locker and it's our own transaction. Note we don't care * which lock mode the locker has, because we need the strongest one. * * Before sleeping, we need to acquire tuple lock to establish our * priority for the tuple (see heap_lock_tuple). LockTuple will * release us when we are next-in-line for the tuple. * * If we are forced to &quot;start over&quot; below, we keep the tuple lock; * this arranges that we stay at the head of the line while rechecking * tuple state. */ // 如果是 MultiXactId if (infomask &amp; HEAP_XMAX_IS_MULTI) { bool current_is_member = false; // 判断 MultiXactId中保存的锁模式是否与 LockTupleExclusive冲突，冲突则 if (DoesMultiXactIdConflict((MultiXactId) xwait, infomask, LockTupleExclusive, &amp;current_is_member)) { LockBuffer(buffer, BUFFER_LOCK_UNLOCK); /* * Acquire the lock, if necessary (but skip it when we're * requesting a lock and already have one; avoids deadlock). */ // 如果当前事务不属于MultiXactId成员，则需获取元组级常规锁，反之无需获取， // 其目的是避免死锁 if (!current_is_member) heap_acquire_tuplock(relation, &amp;(tp.t_self), LockTupleExclusive, LockWaitBlock, &amp;have_tuple_lock); /* wait for multixact */ // 等待冲突的事务完成 MultiXactIdWait((MultiXactId) xwait, MultiXactStatusUpdate, infomask, relation, &amp;(tp.t_self), XLTW_Delete, NULL); LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE); /* * If xwait had just locked the tuple then some other xact * could update this tuple before we get to this point. Check * for xmax change, and start over if so. */ // 如果元组的 infomask被其他事务更新，则需重新进行上述操作 if (xmax_infomask_changed(tp.t_data-&gt;t_infomask, infomask) || !TransactionIdEquals(HeapTupleHeaderGetRawXmax(tp.t_data), xwait)) goto l1; } /* * You might think the multixact is necessarily done here, but not * so: it could have surviving members, namely our own xact or * other subxacts of this backend. It is legal for us to delete * the tuple in either case, however (the latter case is * essentially a situation of upgrading our former shared lock to * exclusive). We don't bother changing the on-disk hint bits * since we are about to overwrite the xmax altogether. */ } // xwait 是单一事务号，且不是当前事务号 else if (!TransactionIdIsCurrentTransactionId(xwait)) { /* * Wait for regular transaction to end; but first, acquire tuple * lock. */ // 获取元组级常规锁，等待其他事务的更新操作 LockBuffer(buffer, BUFFER_LOCK_UNLOCK); heap_acquire_tuplock(relation, &amp;(tp.t_self), LockTupleExclusive, LockWaitBlock, &amp;have_tuple_lock); XactLockTableWait(xwait, relation, &amp;(tp.t_self), XLTW_Delete); LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE); /* * xwait is done, but if xwait had just locked the tuple then some * other xact could update this tuple before we get to this point. * Check for xmax change, and start over if so. */ // 如果其他事务更新元组，则需回到 l1程序点进行相关操作 if (xmax_infomask_changed(tp.t_data-&gt;t_infomask, infomask) || !TransactionIdEquals(HeapTupleHeaderGetRawXmax(tp.t_data), xwait)) goto l1; /* Otherwise check if it committed or aborted */ // 更新元组的 HintBit标识位信息 UpdateXmaxHintBits(tp.t_data, buffer, xwait); } /* * We may overwrite if previous xmax aborted, or if it committed but * only locked the tuple without updating it. */ // 如果 xmax意外终止或者提交但是被他人锁住（未更新） if ((tp.t_data-&gt;t_infomask &amp; HEAP_XMAX_INVALID) || HEAP_XMAX_IS_LOCKED_ONLY(tp.t_data-&gt;t_infomask) || HeapTupleHeaderIsOnlyLocked(tp.t_data)) result = TM_Ok; else if (!ItemPointerEquals(&amp;tp.t_self, &amp;tp.t_data-&gt;t_ctid)) result = TM_Updated; else result = TM_Deleted; } if (crosscheck != InvalidSnapshot &amp;&amp; result == TM_Ok) { /* Perform additional check for transaction-snapshot mode RI updates */ if (!HeapTupleSatisfiesVisibility(&amp;tp, crosscheck, buffer)) result = TM_Updated; } if (result != TM_Ok) { Assert(result == TM_SelfModified || result == TM_Updated || result == TM_Deleted || result == TM_BeingModified); Assert(!(tp.t_data-&gt;t_infomask &amp; HEAP_XMAX_INVALID)); Assert(result != TM_Updated || !ItemPointerEquals(&amp;tp.t_self, &amp;tp.t_data-&gt;t_ctid)); tmfd-&gt;ctid = tp.t_data-&gt;t_ctid; tmfd-&gt;xmax = HeapTupleHeaderGetUpdateXid(tp.t_data); if (result == TM_SelfModified) tmfd-&gt;cmax = HeapTupleHeaderGetCmax(tp.t_data); else tmfd-&gt;cmax = InvalidCommandId; UnlockReleaseBuffer(buffer); if (have_tuple_lock) UnlockTupleTuplock(relation, &amp;(tp.t_self), LockTupleExclusive); if (vmbuffer != InvalidBuffer) ReleaseBuffer(vmbuffer); return result; } /* * We're about to do the actual delete -- check for conflict first, to * avoid possibly having to roll back work we've just done. * * This is safe without a recheck as long as there is no possibility of * another process scanning the page between this check and the delete * being visible to the scan (i.e., an exclusive buffer content lock is * continuously held from this point until the tuple delete is visible). */ // 序列化冲突检查 CheckForSerializableConflictIn(relation, tid, BufferGetBlockNumber(buffer)); /* replace cid with a combo CID if necessary */ HeapTupleHeaderAdjustCmax(tp.t_data, &amp;cid, &amp;iscombo); /* * Compute replica identity tuple before entering the critical section so * we don't PANIC upon a memory allocation failure. */ old_key_tuple = ExtractReplicaIdentity(relation, &amp;tp, true, &amp;old_key_copied); /* * If this is the first possibly-multixact-able operation in the current * transaction, set my per-backend OldestMemberMXactId setting. We can be * certain that the transaction will never become a member of any older * MultiXactIds than that. (We have to do this even if we end up just * using our own TransactionId below, since some other backend could * incorporate our XID into a MultiXact immediately afterwards.) */ MultiXactIdSetOldestMember(); // 计算新的xmax + infomask + infomask2 compute_new_xmax_infomask(HeapTupleHeaderGetRawXmax(tp.t_data), tp.t_data-&gt;t_infomask, tp.t_data-&gt;t_infomask2, xid, LockTupleExclusive, true, &amp;new_xmax, &amp;new_infomask, &amp;new_infomask2); START_CRIT_SECTION(); // 临界区 /* * If this transaction commits, the tuple will become DEAD sooner or * later. Set flag that this page is a candidate for pruning once our xid * falls below the OldestXmin horizon. If the transaction finally aborts, * the subsequent page pruning will be a no-op and the hint will be * cleared. */ PageSetPrunable(page, xid); // 首先清除元组对应数据页 和 vm 页的all visible标识位 if (PageIsAllVisible(page)) { all_visible_cleared = true; PageClearAllVisible(page); visibilitymap_clear(relation, BufferGetBlockNumber(buffer), vmbuffer, VISIBILITYMAP_VALID_BITS); } // 更新元组头等相关信息 /* store transaction information of xact deleting the tuple */ tp.t_data-&gt;t_infomask &amp;= ~(HEAP_XMAX_BITS | HEAP_MOVED); tp.t_data-&gt;t_infomask2 &amp;= ~HEAP_KEYS_UPDATED; tp.t_data-&gt;t_infomask |= new_infomask; tp.t_data-&gt;t_infomask2 |= new_infomask2; HeapTupleHeaderClearHotUpdated(tp.t_data); HeapTupleHeaderSetXmax(tp.t_data, new_xmax); HeapTupleHeaderSetCmax(tp.t_data, cid, iscombo); /* Make sure there is no forward chain link in t_ctid */ tp.t_data-&gt;t_ctid = tp.t_self; /* Signal that this is actually a move into another partition */ if (changingPart) HeapTupleHeaderSetMovedPartitions(tp.t_data); MarkBufferDirty(buffer); /* * XLOG stuff * * NB: heap_abort_speculative() uses the same xlog record and replay * routines. */ // 写XLOG日志，奔溃恢复 if (RelationNeedsWAL(relation)) { xl_heap_delete xlrec; xl_heap_header xlhdr; XLogRecPtr recptr; /* * For logical decode we need combo CIDs to properly decode the * catalog */ if (RelationIsAccessibleInLogicalDecoding(relation)) log_heap_new_cid(relation, &amp;tp); xlrec.flags = 0; if (all_visible_cleared) xlrec.flags |= XLH_DELETE_ALL_VISIBLE_CLEARED; if (changingPart) xlrec.flags |= XLH_DELETE_IS_PARTITION_MOVE; xlrec.infobits_set = compute_infobits(tp.t_data-&gt;t_infomask, tp.t_data-&gt;t_infomask2); xlrec.offnum = ItemPointerGetOffsetNumber(&amp;tp.t_self); xlrec.xmax = new_xmax; if (old_key_tuple != NULL) { if (relation-&gt;rd_rel-&gt;relreplident == REPLICA_IDENTITY_FULL) xlrec.flags |= XLH_DELETE_CONTAINS_OLD_TUPLE; else xlrec.flags |= XLH_DELETE_CONTAINS_OLD_KEY; } XLogBeginInsert(); XLogRegisterData((char *) &amp;xlrec, SizeOfHeapDelete); XLogRegisterBuffer(0, buffer, REGBUF_STANDARD); /* * Log replica identity of the deleted tuple if there is one */ if (old_key_tuple != NULL) { xlhdr.t_infomask2 = old_key_tuple-&gt;t_data-&gt;t_infomask2; xlhdr.t_infomask = old_key_tuple-&gt;t_data-&gt;t_infomask; xlhdr.t_hoff = old_key_tuple-&gt;t_data-&gt;t_hoff; XLogRegisterData((char *) &amp;xlhdr, SizeOfHeapHeader); XLogRegisterData((char *) old_key_tuple-&gt;t_data + SizeofHeapTupleHeader, old_key_tuple-&gt;t_len - SizeofHeapTupleHeader); } /* filtering by origin on a row level is much more efficient */ XLogSetRecordFlags(XLOG_INCLUDE_ORIGIN); recptr = XLogInsert(RM_HEAP_ID, XLOG_HEAP_DELETE); PageSetLSN(page, recptr); } END_CRIT_SECTION(); // 退出临界区 + 释放锁+内存资源 LockBuffer(buffer, BUFFER_LOCK_UNLOCK); if (vmbuffer != InvalidBuffer) ReleaseBuffer(vmbuffer); /* * If the tuple has toasted out-of-line attributes, we need to delete * those items too. We have to do this before releasing the buffer * because we need to look at the contents of the tuple, but it's OK to * release the content lock on the buffer first. */ if (relation-&gt;rd_rel-&gt;relkind != RELKIND_RELATION &amp;&amp; relation-&gt;rd_rel-&gt;relkind != RELKIND_MATVIEW) { /* toast table entries should never be recursively toasted */ Assert(!HeapTupleHasExternal(&amp;tp)); } else if (HeapTupleHasExternal(&amp;tp)) heap_toast_delete(relation, &amp;tp, false); /* * Mark tuple for invalidation from system caches at next command * boundary. We have to do this before releasing the buffer because we * need to look at the contents of the tuple. */ // 将删除元组在内存中对应的 cache 标记为无效 ==&gt; 普通表元组不执行，系统表元组会标记 CacheInvalidateHeapTuple(relation, &amp;tp, NULL); /* Now we can release the buffer */ ReleaseBuffer(buffer); /* * Release the lmgr tuple lock, if we had it. */ if (have_tuple_lock) UnlockTupleTuplock(relation, &amp;(tp.t_self), LockTupleExclusive); pgstat_count_heap_delete(relation); if (old_key_tuple != NULL &amp;&amp; old_key_copied) heap_freetuple(old_key_tuple); return TM_Ok;} 更新流程写-写冲突采取的是两阶段锁协议。 整个事务分为两个阶段，前一个阶段为加锁，后一个阶段为解锁。在加锁阶段，事务只能加锁，也可以操作数据，但不能解锁，直到事务释放第一个锁，就进入解锁阶段，此过程中事务只能解锁，也可以操作数据，不能再加锁。两阶段锁协议使得事务具有较高的并发度，因为解锁不必发生在事务结尾。 它的不足是没有解决死锁的问题，因为它在加锁阶段没有顺序要求。如两个事务分别申请了A, B锁，接着又申请对方的锁，此时进入死锁状态。 pg应对死锁：查询执行中的sql、查询等待锁的事务、手动取消和回滚事务、 1234567891011heap_update block = ItemPointerGetBlockNumber(otid); LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE); oldtup.t_data = (HeapTupleHeader)PageGetItem(page, lp); HeapSatisfiesHOTUpdate(relation, hot_attrs, key_attrs, id_attrs, &amp;satisfies_hot, &amp;satisfies_key, &amp;satisfies_id, &amp;oldtup, newtup, page); result = HeapTupleSatisfiesUpdate(&amp;oldtup, cid, buffer, allow_update_self); CheckForSerializableConflictIn(relation, &amp;oldtup, buffer); HeapTupleSetOid(newtup, HeapTupleGetOid(&amp;oldtup)); heap_page_prepare_for_xid(relation, buffer, xid, false); 参考https://blog.csdn.net/s_lisheng/article/details/139782641 https://blog.csdn.net/qq_37517281/article/details/104399535 https://blog.csdn.net/qq_52668274/article/details/128575448","link":"/2024/10/03/%E6%95%B0%E6%8D%AE%E5%BA%93/PostgreSQL/PG%E5%AD%98%E5%82%A8astore%E8%A7%A3%E6%9E%90%E4%BA%8C/"},{"title":"PG异常处理","text":"在PG中经常可以看到ereport错误日志，本以为是直接打印日志输出，实际更加复杂。另外PG用C实现了TRY-CATCH语义，这点也十分神奇。 setjmp宏要探究PG中的异常跳转，首先得熟悉setjmp宏，这里推荐菜鸟教程的一篇短文： https://www.runoob.com/cprogramming/c-macro-setjmp.html https://www.runoob.com/cprogramming/c-function-longjmp.html 1234#include &lt;setjmp.h&gt;int setjmp(jmp_buf env);void longjmp(jmp_buf env, int val); 主要思想为：通过jmp_buf类型的全局变量保存程序切换的上下文，setjmp将jmp_buf初始化同时创建保存点，第一次调用返回0。然后再通过longjmp返回第一次调用setjmp处，setjmp的返回值为longjmp的第二个整型参数。 ereport 日志输出在PG中，我们经常可以看到以下的错误处理代码： 123if (!OidIsValid(get_role_oid(user_name_reset, false))) { ereport(ERROR, (errcode(ERRCODE_UNDEFINED_OBJECT), errmsg(&quot;role \\&quot;%s\\&quot; does not exist&quot;, user_name_reset)));} ereport接口定义如下： 12345678910111213141516171819202122232425/* ---------- * New-style error reporting API: to be used in this way: * ereport(ERROR, * (errcode(ERRCODE_UNDEFINED_CURSOR), * errmsg(&quot;portal \\&quot;%s\\&quot; not found&quot;, stmt-&gt;portalname), * ... other errxxx() fields as needed ...)); * * The error level is required, and so is a primary error message (errmsg * or errmsg_internal). All else is optional. errcode() defaults to * ERRCODE_INTERNAL_ERROR if elevel is ERROR or more, ERRCODE_WARNING * if elevel is WARNING, or ERRCODE_SUCCESSFUL_COMPLETION if elevel is * NOTICE or below. * * ereport_domain() allows a message domain to be specified, for modules that * wish to use a different message catalog from the backend's. To avoid having * one copy of the default text domain per .o file, we define it as NULL here * and have errstart insert the default text domain. Modules can either use * ereport_domain() directly, or preferably they can override the TEXTDOMAIN * macro. * ---------- */#define ereport_domain(elevel, domain, rest) \\ (errstart(elevel, __FILE__, __LINE__, PG_FUNCNAME_MACRO, domain) ? (errfinish rest) : (void)0)#define ereport(elevel, rest) ereport_domain(elevel, TEXTDOMAIN, rest) ereport其实就是调用errstart，然后根据errstar的返回值决定调用errfinish还是什么都不做。 errstart介绍errstart之前先介绍一个数据结构，用于错误数据信息 12#define ERRORDATA_STACK_SIZE 5static ErrorData errordata[ERRORDATA_STACK_SIZE]; elog.c会有一个错误处理的栈，这是因为我们在错误处理的时候还可能会发生错误。 errstart主要完成： 初始化errdata信息 将errdata压入errodata栈 errfinish在关注errfinish之前，我们先关注errfinish的参数。在宏定义中，errfinish用于接收rest参数，而在实际使用中，rest这个参数实际上是由括号包裹的一串调用，分别是errcode和errmsg。 1ereport(ERROR, (errcode(ERRCODE_UNDEFINED_OBJECT), errmsg(&quot;role \\&quot;%s\\&quot; does not exist&quot;, user_name_reset))); 12345678910111213141516171819202122232425262728293031323334353637383940/* * errcode --- add SQLSTATE error code to the current error * * The code is expected to be represented as per MAKE_SQLSTATE(). */int errcode(int sqlerrcode){ ErrorData* edata = &amp;t_thrd.log_cxt.errordata[t_thrd.log_cxt.errordata_stack_depth]; /* we don't bother incrementing t_thrd.log_cxt.recursion_depth */ CHECK_STACK_DEPTH(); edata-&gt;sqlerrcode = sqlerrcode; return 0; /* return value does not matter */}/* * errmsg --- add a primary error message text to the current error * * In addition to the usual %-escapes recognized by printf, &quot;%m&quot; in * fmt is replaced by the error message for the caller's value of errno. * * Note: no newline is needed at the end of the fmt string, since * ereport will provide one for the output methods that need it. */int errmsg(const char* fmt, ...){ ErrorData* edata = &amp;t_thrd.log_cxt.errordata[t_thrd.log_cxt.errordata_stack_depth]; MemoryContext oldcontext; t_thrd.log_cxt.recursion_depth++; CHECK_STACK_DEPTH(); oldcontext = MemoryContextSwitchTo(ErrorContext); EVALUATE_MESSAGE(message, false, true); MemoryContextSwitchTo(oldcontext); t_thrd.log_cxt.recursion_depth--; return 0; /* return value does not matter */} errmsg通过EVALUATE_MESSAGE宏格式化字符串，将错误信息字符串计入到edata中的message中？ （1）error以下等级 然后再看errfinish的函数本体： 完成error_context_stack的回调功能，为errfinish增加报错信息 完成EmitErrorReport，为errfinish发送错误信息 123for (econtext = t_thrd.log_cxt.error_context_stack; econtext != NULL; econtext = econtext-&gt;previous) (*econtext-&gt;callback)(econtext-&gt;arg);EmitErrorReport(); 至此，一个简单的日志输出完成，返回调用ereport的代码处继续执行。 （2）error以上等级 error以上等级不再返回，调用 PG_RE_THROW(); 完成长跳转，根据PG _exception_stack记录的保存点进行跳转。PG _exception_stack是一个全局变量，在postgresMain中你会看到sigsetjmp的设置 1if (sigsetjmp(local_sigjmp_buf, 1) != 0) { TRY-CATCAH语义实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/* ---------- * API for catching ereport(ERROR) exits. Use these macros like so: * * PG_TRY(); * { * ... code that might throw ereport(ERROR) ... * } * PG_CATCH(); * { * ... error recovery code ... * } * PG_END_TRY(); * * (The braces are not actually necessary, but are recommended so that * pg_indent will indent the construct nicely.) The error recovery code * can optionally do PG_RE_THROW() to propagate the same error outwards. * * Note: while the system will correctly propagate any new ereport(ERROR) * occurring in the recovery section, there is a small limit on the number * of levels this will work for. It's best to keep the error recovery * section simple enough that it can't generate any new errors, at least * not before popping the error stack. * * Note: an ereport(FATAL) will not be caught by this construct; control will * exit straight through proc_exit(). Therefore, do NOT put any cleanup * of non-process-local resources into the error recovery section, at least * not without taking thought for what will happen during ereport(FATAL). * The PG_ENSURE_ERROR_CLEANUP macros provided by storage/ipc.h may be * helpful in such cases. * * Note: Don't execute statements such as break, continue, goto, or return in * PG_TRY. If you need to use these statements, you must recovery * PG_exception_stack first. * ---------- */#define PG_TRY() \\ do { \\ sigjmp_buf* save_exception_stack = t_thrd.log_cxt.PG_exception_stack; \\ ErrorContextCallback* save_context_stack = t_thrd.log_cxt.error_context_stack; \\ sigjmp_buf local_sigjmp_buf; \\ int tryCounter, *oldTryCounter = NULL; \\ if (sigsetjmp(local_sigjmp_buf, 0) == 0) { \\ t_thrd.log_cxt.PG_exception_stack = &amp;local_sigjmp_buf; \\ oldTryCounter = gstrace_tryblock_entry(&amp;tryCounter)#define PG_CATCH() \\ } \\ else \\ { \\ t_thrd.log_cxt.PG_exception_stack = save_exception_stack; \\ t_thrd.log_cxt.error_context_stack = save_context_stack; \\ gstrace_tryblock_exit(true, oldTryCounter)#define PG_END_TRY() \\ } \\ t_thrd.log_cxt.PG_exception_stack = save_exception_stack; \\ t_thrd.log_cxt.error_context_stack = save_context_stack; \\ gstrace_tryblock_exit(false, oldTryCounter); \\ }while (0) 在PG_TRY() 中主要设置了一个本地跳转保存点local_sigjmp_buf ，并将全局变量PG_exception_stack 设置为它，那么在发生错误时大于error等级的ereport调用就会返回此处，进而执行else分支（也就是PG_CATCH() 所在部分的代码）。 注意在CATCH中加载保存的状态点。 reference：https://blog.csdn.net/jackgo73/article/details/135130840","link":"/2024/08/04/%E6%95%B0%E6%8D%AE%E5%BA%93/PostgreSQL/PG%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/"},{"title":"openGauss内存保护机制","text":"openGauss内存统计、内存保护机制。 内存保护申请内存palloc时，GenericMemoryAllocator::AllocSetAlloc根据shard和session id 来选择合适的内存申请函数malloc。 最终是调用func-&gt;malloc来申请内存。 1234567891011121314151617181920212223242526272829303132// 选择函数if (is_shared) { MemoryContextLock(context); func = &amp;SharedFunctions;} else { if (context-&gt;session_id &gt; 0) func = &amp;SessionFunctions; else func = &amp;GenericFunctions;}// 不同类型的函数MemoryProtectFuncDef GenericFunctions = {MemoryProtectFunctions::gs_memprot_malloc&lt;MEM_THRD&gt;, MemoryProtectFunctions::gs_memprot_free&lt;MEM_THRD&gt;, MemoryProtectFunctions::gs_memprot_realloc&lt;MEM_THRD&gt;, MemoryProtectFunctions::gs_posix_memalign&lt;MEM_THRD&gt;};MemoryProtectFuncDef SessionFunctions = {MemoryProtectFunctions::gs_memprot_malloc&lt;MEM_SESS&gt;, MemoryProtectFunctions::gs_memprot_free&lt;MEM_SESS&gt;, MemoryProtectFunctions::gs_memprot_realloc&lt;MEM_SESS&gt;, MemoryProtectFunctions::gs_posix_memalign&lt;MEM_SESS&gt;};MemoryProtectFuncDef SharedFunctions = {MemoryProtectFunctions::gs_memprot_malloc&lt;MEM_SHRD&gt;, MemoryProtectFunctions::gs_memprot_free&lt;MEM_SHRD&gt;, MemoryProtectFunctions::gs_memprot_realloc&lt;MEM_SHRD&gt;, MemoryProtectFunctions::gs_posix_memalign&lt;MEM_SHRD&gt;};// 内存申请if (GS_MP_INITED) block = (AllocBlock)(*func-&gt;malloc)(blksize, (value &amp; IS_PROTECT) == 1 ? true : false);else gs_malloc(blksize, block, AllocBlock); 可以看到调用的malloc其实是gs_memprot_malloc（ src/common/backend/utils/mmgr/memprot.cpp），其中有一个内存类型的模版参数。内存类型用于调整统计指标和预留内存指标。只有通过内存充足检查后，才能调用malloc进行内存的分配。 1234567891011121314151617181920212223242526272829303132template &lt;MemType mem_type&gt;void* MemoryProtectFunctions::gs_memprot_malloc(Size sz, bool needProtect)template &lt;MemType type&gt;bool memTracker_ReserveMem(int64 requestedBytes, bool needProtect)template &lt;MemType type&gt;static bool memTracker_ReserveMemChunks(int32 numChunksToReserve, bool needProtect)// 内存统计if (type == MEM_SHRD) { tc = (uint64)shareTrackedBytes &gt;&gt; chunkSizeInBits; tb = gs_atomic_add_64(&amp;shareTrackedBytes, requestedBytes); gs_lock_test_and_set(&amp;shareTrackedMemChunks, tc); /* reset the value */} else if (type == MEM_THRD) { tc = t_thrd.utils_cxt.trackedMemChunks; t_thrd.utils_cxt.trackedBytes += requestedBytes; tb = t_thrd.utils_cxt.trackedBytes;} else { tc = u_sess-&gt;stat_cxt.trackedMemChunks; u_sess-&gt;stat_cxt.trackedBytes += requestedBytes; tb = u_sess-&gt;stat_cxt.trackedBytes;}// 内存预留&amp;&amp;保护（限额）if (t_thrd.utils_cxt.backend_reserved) { currSize = &amp;backendUsedMemInChunk; maxSize = &amp;backendReservedMemInChunk;} else { currSize = &amp;processMemInChunks; maxSize = &amp;maxChunksPerProcess;} 其中根据 t_thrd.utils_cxt.backend_reserved 来选择 backendReservedMemInChunk 为最大允许的内存。这些变量定义在memprot.cpp文件中，为全局变量。因此进程限额是全局级别的。 1234567int32 maxChunksPerProcess = 0; // be set by GUC variable --max_dynamic_memoryvolatile int32 processMemInChunks = 200; // track the memory used by process --dynamic_used_memoryint32 peakChunksPerProcess = 0; // the peak memory of process --dynamic_peak_memoryint32 comm_original_memory = 0; // original comm memoryint32 maxSharedMemory = 0; // original shared memoryint32 backendReservedMemInChunk = 0; // reserved memory for backend threadsvolatile int32 backendUsedMemInChunk = 0; // the memory usage for backend threads 再看这个t_thrd.utils_cxt.backend_reserved 是何时设置的，何时更改的。 t_thrd.utils_cxt.backend_reserved总结：在线程启动时，进行了是否启用预留内存的设置。并开启内存保护的审查机制，然后在上下文初始化函数中，初始化thrd的内存统计。 123456789template &lt;knl_thread_role thread_role&gt;int GaussDbThreadMain(knl_thread_arg* arg){ ... /* Check this thread will use reserved memory or not */ is_memory_backend_reserved(arg); /* Initialize the Memory Protection at the thread level */ gs_memprot_thread_init(); MemoryContextInit(); 其中的： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849static void is_memory_backend_reserved(const knl_thread_arg* arg){ if (arg-&gt;role == WORKER) { Port port = ((BackendParameters*)(arg-&gt;save_para))-&gt;port; if (processMemInChunks &gt;= maxChunksPerProcess * 0.8 &amp;&amp; IsHAPort(&amp;port)) { t_thrd.utils_cxt.backend_reserved = true; } else { t_thrd.utils_cxt.backend_reserved = false; } return; } switch (arg-&gt;role) { case WALWRITER: case WALRECEIVER: case WALRECWRITE: case DATARECIVER: case DATARECWRITER: t_thrd.utils_cxt.backend_reserved = true; break; default: t_thrd.utils_cxt.backend_reserved = false; break; }}/* thread level initialization */void gs_memprot_thread_init(void){ /* The Process level protection has been triggered */ if (maxChunksPerProcess) { t_thrd.utils_cxt.gs_mp_inited = true; }}void MemoryContextInit(void){ CStoreMemAlloc::Init(); if (TopMemoryContext != NULL) { return; } /* init the thread memory track object */ t_thrd.utils_cxt.trackedMemChunks = 0; t_thrd.utils_cxt.trackedBytes = 0; t_thrd.utils_cxt.peakedBytesInQueryLifeCycle = 0; t_thrd.utils_cxt.basedBytesInQueryLifeCycle = 0;} backendReservedMemInChunk总结：在gs_memprot_init中计算可用的总内存avail_mem。 然后以chunk为单位，将总内存分为backendReservedMemInChunk和maxChunksPerProcess两部分。 123456/* process level initialization only called in postmaster main thread */void gs_memprot_init(Size size)void gs_memprot_reserved_backend(int avail_mem) backendReservedMemInChunk = reserved_mem; maxChunksPerProcess = ((unsigned int)avail_mem &gt;&gt; BITS_IN_KB) - reserved_mem; 内存追踪有哈希表 12345678910void RemoveTrackMemoryInfo(const void* pointer){ uint64 key = (uint64)pointer; if (g_instance.stat_cxt.track_memory_inited == false) { return; } (void)hash_search(g_instance.stat_cxt.track_memory_info_hash, &amp;key, HASH_REMOVE, NULL);} 暂不清楚这个哈希表的作用。 内存视图1234567Datum pv_session_memory_detail(PG_FUNCTION_ARGS) g_threadPoolControler-&gt;GetSessionCtrl()-&gt;getSessionMemoryDetail(rsinfo-&gt;setResult, rsinfo-&gt;setDesc, &amp;sess);Datum pv_thread_memory_detail(PG_FUNCTION_ARGS) getThreadMemoryDetail(rsinfo-&gt;setResult, rsinfo-&gt;setDesc, &amp;procIdx); Datum pv_total_memory_detail(PG_FUNCTION_ARGS)","link":"/2024/11/04/%E6%95%B0%E6%8D%AE%E5%BA%93/openGauss/openGauss%E5%86%85%E5%AD%98%E4%BF%9D%E6%8A%A4%E6%9C%BA%E5%88%B6/"},{"title":"openGauss整体架构","text":"openGauss整体架构 客户端/服务端通信#/src/gausskernel/process/postmaster openGauss查询响应是使用简单的“单一用户对应一个服务器线程”的客户端/服务器模型实现。 openGauss数据库中处理客户端连接请求的模块叫做postmaster。主进程（GaussMaster）主进程在指定的TCP/IP端口上侦听传入的连接，只要检测到连接请求，主进程就会生成一个新的服务器线程。 服务器线程之间使用信号量和共享内存相互通信，以确保整个并发数据访问期间的数据完整性。 建立连接后，客户端进程可以将查询发送到后端服务器。服务器解析查询语句、创建执行计划、执行并通过在已建立的连接上传输检索到的结果集，将其返回给客户端。 公共组件系统表 数据库初始化 多线程架构｜线程池 内存管理 模拟信号机制 多维监控 SQL引擎#/src/common/backend/parser SQL引擎负责解析SQL字符串语句，然后输出执行计划（查询计划？计划树方式传递给执行器）。 查询解析—parserSQL解析对输入的SQL语句进行词法分析、语法分析、语义分析，获得查询解析树或者逻辑计划。 查询分流—traffic cop#src/gausskernel/process/tcop traffic cop模块负责查询的分流，它负责区分简单和复杂的查询指令。事务控制命令（例如BEGIN和ROLLBACK）非常简单，因此不需要其它处理，而其它命令（例如SELECT和JOIN）则传递给重写器。 简单和复杂查询指令也对应如下2类解析： （1）软解析（简单，旧查询）：当openGauss共享缓冲区中存在已提交SQL语句的已解析表示形式时，可以重复利用缓存内容执行语法和语义检查，避免查询优化的相对昂贵的操作。 （2）硬解析（复杂，新查询）：如果无缓存语句可重用，或者第一次将SQL语句加载到openGauss共享缓冲区中，则会导致硬解析。同样，当一条语句在共享缓冲区中老化时，再次重新加载该语句时，还会导致另一次硬解析。因此，共享Buffer的大小也会影响解析调用的数量。‘ 也就是说openGauss区别了简单和复杂的Sql语句，并为已解析的sql建立了缓存。 查询重写—rewriter#src/gausskernel/optimizer/rewrite 查询重写利用已有语句特征和关系代数运算来生成更高效的等价语句，在数据库优化器中扮演关键角色 几个查询重写： 常量表达式化简 嵌套子查询化为半连接semi join 谓词下推 查询优化—optimizer在某些情况下，检查执行查询的每种可能方式都会占用大量时间和内存空间,特别是在执行涉及大量连接操作（Join）的查询时。 为了在合理的时间内确定合理的（不一定是最佳的）查询计划，当查询连接数超过阈值时，openGauss使用遗传查询优化器(genetic query optimizer)，通过遗传算法来做执行计划的枚举。 优化器的查询计划（plan）确定代价最低的路径后，将构建完整的计划树以传递给执行器。 存储引擎 总体上，根据存储介质和并发控制机制，存储引擎分为磁盘引擎和内存引擎两大类。 磁盘引擎主要面向通用的、大容量的业务场景 astore（append-store，追加写优化格式） usotre（In-place Update，原地更新优化格式） cstore（column store，列存储格式） 可拓展的数据元组和数据页面组织格式 内存引擎主要面向容量可控的、追求极致性能的业务场景 mstore（memory-store，内存优化格式） openGauss存储引擎是可插拔、自组装的，支持多个存储引擎来满足不同场景的业务诉求，目前支持 行存储引擎 列存储引擎 内存引擎 行存储引擎磁盘引擎存储可以分为行存储格式和列存储格式。这两种数据格式共用相同的事务并发控制、日志系统、持久化和故障恢复、主备系统。 在此基础之上，行存储格式内部设计为可以支持多种不同子格式的可扩展架构。不同行存储子格式之间共用相同的行存储统一访存接口（table access method）、共享缓冲区、索引机制等。 行存储引擎： astore（追加写优化） ustore（写优化） 在openGauss行存储格式中，对同一行数据的写-写查询冲突通过两阶段锁协议来实现并发控制；对同一行数据的读-写查询冲突通过行级多版本技术来实现互不阻塞的、高效的并发控制。 事务机制事务架构 并发控制 事务ID与CLGO/CSNLOG MVCC机制 锁机制 参考https://www.modb.pro/topic/397775 https://www.cnblogs.com/openGauss-bot/category/2388509.html","link":"/2024/11/01/%E6%95%B0%E6%8D%AE%E5%BA%93/openGauss/openGauss%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84/"},{"title":"openGauss的中断与信号","text":"OG的“中断”并不是真正的OS级别的中断，它只是用来处理取消查询Cancel Querying的相关逻辑。 引子从代码可以看到，在整个语句的执行过程中，经常出现CHECK_FOR_INTERRUPTS();以及保持中断和开中断的操作。下面来探讨一下这个的作用。 1234567891011121314151617#define CHECK_FOR_INTERRUPTS() \\do { \\ if (InterruptPending) \\ ProcessInterrupts(); \\} while(0)#define HOLD_INTERRUPTS() (t_thrd.int_cxt.InterruptHoldoffCount++)#define RESUME_INTERRUPTS() \\ do { \\ if (t_thrd.int_cxt.InterruptCountResetFlag &amp;&amp; t_thrd.int_cxt.InterruptHoldoffCount== 0){ \\ t_thrd.int_cxt.InterruptCountResetFlag = false; \\ } else { \\ Assert(t_thrd.int_cxt.InterruptHoldoffCount &gt; 0); \\ t_thrd.int_cxt.InterruptHoldoffCount--; \\ } \\ } while (0) CHECK_FOR_INTERRUPTS12345678910111213141516171819202122232425262728293031323334353637383940/* * ProcessInterrupts: out-of-line portion of CHECK_FOR_INTERRUPTS() macro * * If an interrupt condition is pending, and it's safe to service it, * then clear the flag and accept the interrupt. Called only when * InterruptPending is true. */void ProcessInterrupts(void){ /* OK to accept interrupt now? */ if (t_thrd.int_cxt.InterruptHoldoffCount != 0 || t_thrd.int_cxt.CritSectionCount != 0) return; if (t_thrd.bn &amp;&amp; ((unsigned int)(t_thrd.bn-&gt;flag) &amp; THRD_SIGTERM)) { t_thrd.int_cxt.ProcDiePending = true; t_thrd.bn-&gt;flag = ((unsigned int)(t_thrd.bn-&gt;flag)) &amp; ~THRD_SIGTERM; } // The 'u_sess-&gt;stream_cxt.in_waiting_quit' flag is set to true to enable signal handling when waiting sub stream // threads quit. At the same time, if we get a SIGTERM signal, this signal should be held and the 'InterruptPending' // flag should not be set to false immediately. After all sub thread quit and the top consumer goes back to // ReadCommand again, the pending interrupt can be safely handled in function prepare_for_client_read. // if (t_thrd.int_cxt.ProcDiePending &amp;&amp; u_sess-&gt;stream_cxt.in_waiting_quit) { // It's more efficient to notify all stream threads to cancel the query first // and then top consumer can quit quickly. // StreamNodeGroup::cancelStreamThread(); return; } if (StreamThreadAmI() &amp;&amp; u_sess-&gt;debug_query_id == 0) { Assert(0); } InterruptPending = false; if (t_thrd.wlm_cxt.wlmalarm_pending) {...} if (t_thrd.int_cxt.ProcDiePending &amp;&amp; !u_sess-&gt;stream_cxt.in_waiting_quit) {...} if (t_thrd.int_cxt.ClientConnectionLost &amp;&amp; !u_sess-&gt;stream_cxt.in_waiting_quit) {...} if (t_thrd.int_cxt.QueryCancelPending) {...} 这里列出部分代码，从注释中可以看到，Called only when InterruptPending is true.。那么我们要去看这个InterruptPending是怎么一回事。 InterruptPending1THR_LOCAL volatile bool InterruptPending = false; InterruptPending 是一个布尔类型的线程局部变量，它是在什么时候变为True的呢？我们在postgres服务进程中全局搜索InterruptPending = true。可以看到，这些都是信号处理函数。 123void die(SIGNAL_ARGS)void StatementCancelHandler(SIGNAL_ARGS)void PoolValidateCancelHandler(SIGNAL_ARGS) 粗略阅读这些函数的代码，仅仅只是将InterruptPending设置为true，并没有ProcessInterrupts之类的主动调用，那么ProcessInterrupts调用时机究竟是怎么一回事呢？ ProcessInterruptsProcessInterrupts 函数对一系列中断上下文的中断标志位进行处理。看来并没有特别处理逻辑。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/* * ProcessInterrupts: out-of-line portion of CHECK_FOR_INTERRUPTS() macro * * If an interrupt condition is pending, and it's safe to service it, * then clear the flag and accept the interrupt. Called only when * InterruptPending is true. */void ProcessInterrupts(void){ /* OK to accept interrupt now? */ if (t_thrd.int_cxt.InterruptHoldoffCount != 0 || t_thrd.int_cxt.CritSectionCount != 0) return; if (t_thrd.bn &amp;&amp; ((unsigned int)(t_thrd.bn-&gt;flag) &amp; THRD_SIGTERM)) { t_thrd.int_cxt.ProcDiePending = true; t_thrd.bn-&gt;flag = ((unsigned int)(t_thrd.bn-&gt;flag)) &amp; ~THRD_SIGTERM; } // The 'u_sess-&gt;stream_cxt.in_waiting_quit' flag is set to true to enable signal handling when waiting sub stream // threads quit. At the same time, if we get a SIGTERM signal, this signal should be held and the 'InterruptPending' // flag should not be set to false immediately. After all sub thread quit and the top consumer goes back to // ReadCommand again, the pending interrupt can be safely handled in function prepare_for_client_read. // if (t_thrd.int_cxt.ProcDiePending &amp;&amp; u_sess-&gt;stream_cxt.in_waiting_quit) { // It's more efficient to notify all stream threads to cancel the query first // and then top consumer can quit quickly. // StreamNodeGroup::cancelStreamThread(); return; } if (StreamThreadAmI() &amp;&amp; u_sess-&gt;debug_query_id == 0) { Assert(0); } InterruptPending = false; if (t_thrd.wlm_cxt.wlmalarm_pending) { t_thrd.wlm_cxt.wlmalarm_pending = false; (void)WLMProcessWorkloadManager(); } if (t_thrd.int_cxt.ProcDiePending &amp;&amp; !u_sess-&gt;stream_cxt.in_waiting_quit) { ... } if (t_thrd.int_cxt.ClientConnectionLost &amp;&amp; !u_sess-&gt;stream_cxt.in_waiting_quit) { ... } if (t_thrd.int_cxt.QueryCancelPending) { ... } /* If we get here, do nothing (probably, t_thrd.int_cxt.QueryCancelPending was reset) */} HOLD_INTERRUPTS&amp;&amp;RESUME_INTERRUPTS1#define HOLD_INTERRUPTS() (t_thrd.int_cxt.InterruptHoldoffCount++) HOLD_INTERRUPTS() 有什么用呢？只不过增加了一个计数。仔细看processIntrerrupts处理中断的代码：只有当中断计数为零的时候，才能处理中断。这就是关中断的意思：我调用HOLD_INTERRUPTS之后，保证不会进行ProcessInterrupts，处理完关键代码后，我再开中断。 12345void ProcessInterrupts(void){ /* OK to accept interrupt now? */ if (t_thrd.int_cxt.InterruptHoldoffCount != 0 || t_thrd.int_cxt.CritSectionCount != 0) return; 结论123456789101112131415161718192021222324252627282930313233343536373839/***************************************************************************** * System interrupt and critical section handling * * There are two types of interrupts that a running backend needs to accept * without messing up its state: QueryCancel (SIGINT) and ProcDie (SIGTERM). * In both cases, we need to be able to clean up the current transaction * gracefully, so we can't respond to the interrupt instantaneously --- * there's no guarantee that internal data structures would be self-consistent * if the code is interrupted at an arbitrary instant. Instead, the signal * handlers set flags that are checked periodically during execution. * * The CHECK_FOR_INTERRUPTS() macro is called at strategically located spots * where it is normally safe to accept a cancel or die interrupt. In some * cases, we invoke CHECK_FOR_INTERRUPTS() inside low-level subroutines that * might sometimes be called in contexts that do *not* want to allow a cancel * or die interrupt. The HOLD_INTERRUPTS() and RESUME_INTERRUPTS() macros * allow code to ensure that no cancel or die interrupt will be accepted, * even if CHECK_FOR_INTERRUPTS() gets called in a subroutine. The interrupt * will be held off until CHECK_FOR_INTERRUPTS() is done outside any * HOLD_INTERRUPTS() ... RESUME_INTERRUPTS() section. * * Special mechanisms are used to let an interrupt be accepted when we are * waiting for a lock or when we are waiting for command input (but, of * course, only if the interrupt holdoff counter is zero). See the * related code for details. * * A lost connection is handled similarly, although the loss of connection * does not raise a signal, but is detected when we fail to write to the * socket. If there was a signal for a broken connection, we could make use of * it by setting t_thrd.int_cxt.ClientConnectionLost in the signal handler. * * A related, but conceptually distinct, mechanism is the &quot;critical section&quot; * mechanism. A critical section not only holds off cancel/die interrupts, * but causes any ereport(ERROR) or ereport(FATAL) to become ereport(PANIC) * --- that is, a system-wide reset is forced. Needless to say, only really * *critical* code should be marked as a critical section! Currently, this * mechanism is only used for XLOG-related code. * *****************************************************************************/ 仔细查看knl_t_interrupt_context的定义才发现有一大段注释，阅读完之后这个中断机制了解。 所谓“中断”其实是命令执行的中断，更具体的是事务执行过程中的中断（包括主动中断SIGINT和被动中断SIGTERM）。OG无法保证在事务执行的任何过程中都能执行中断逻辑，因此只能在一些相对“安全”的地方，主动调用CHECK_FOR_INTERRUPTS来检查中断是否发生。关中断和开中断能够保证代码执行过程中不受cancel或die的中断影响。 与之相似的还有一个“关键区”，任何发生在关键区的异常等级都会升级到PANIC。","link":"/2024/09/16/%E6%95%B0%E6%8D%AE%E5%BA%93/openGauss/openGauss%E7%9A%84%E4%B8%AD%E6%96%AD%E4%B8%8E%E4%BF%A1%E5%8F%B7/"},{"title":"openGauss的模拟信号机制","text":"从多线程下的信号机制讲起，在Linux下所有线程共享进程的signal action，如何做到每个线程对相同信号有不同处理方式呢？一起看看OpenGauss是如何设计的。 多线程下的信号机制在linux下，每个进程都有自己的signal mask，这个信号掩码指定哪个信号被阻塞，哪个不会被阻塞，通常用调用sigmask来处理。同时一个进程还有自己的signal action，这个行为集合指定了信号在进程内的所有线程该如何处理，通常调用sigaction来处理。 使用了多线程后有以下几个关键问题： 信号发生时，哪个线程会收到？ 每个线程都有自己的mask及action吗？ 每个线程能按自己的方式处理信号吗？ 如果是异常产生的信号（比如程序错误，像SIGPIPE、SIGEGV这些），则只有产生异常的线程收到并处理。 如果是用pthread_kill产生的内部信号，则只有pthread_kill参数中指定的目标线程收到并处理。 如果是外部使用kill命令产生的信号，通常是SIGINT、SIGHUP等job control信号，则会遍历所有线程，直到找到一个不阻塞该信号的线程，然后调用它来处理。(一般从主线程找起)，注意只有一个线程能收到。 第二个问题：每个线程都有自己独立的signal mask，但所有线程共享进程的signal action。这意味着进程内的所有线程共享进程的信号处理函数，当进程内的一个线程为某个信号注册了处理函数，另一个线程可以更改这个处理函数。 第三个问题：由第二点可知，所有线程处理信号的方式都是一样的。 模拟信号的基本思想openGauss是多线程架构，在同一个进程内的不同的线程注册不同的处理函数，则后者会覆盖前者的信号处理。如何做到对于相同信号，不同线程有不同处理方式呢？ 答案是：绕开操作系统，由oG自己实现信号机制。让线程定义“信号”、定义“信号”的处理函数。 信号模拟的基本原理是每个线程注册管理自己的信号处理函数，信号枚举值仍然使用系统的信号值，线程使用自己的变量记录信号和回调函数对应关系。 结构体 具体到代码细节中，我们会有一个保存所有线程对于信号处理和信号的结构体GsSignalSlot的数组：g_instance.signal_base-&gt;slots。 GsSignalSlot中重要的是 GsSignal ，它描述了一个线程怎么处理信号 gs_sigfunc 以及线程要处理的信号 SignalPool。 到这里，我们大致可以猜出信号发送和处理的逻辑流程了。 线程A给线程B发送信号： 遍历g_instance.signal_base-&gt;slots，找到B的slot 构造信号GsNode，然后添加到B的信号池中 线程B接收信号： 遍历自己信号池，取出未处理的信号进行处理 但是线程B怎么知道有信号到来？如何在合适的时机进行信号池的遍历？后续将一一揭晓。 123456789101112131415161718192021222324// 定义一个结构体，用于表示信号槽，即信号与处理线程之间的关联 typedef struct GsSignalSlot { ThreadId thread_id; // 线程ID，表示哪个线程将处理这个信号 char* thread_name; // 线程名称，用于标识或调试 GsSignal* gssignal; // 指向GsSignal结构体的指针，包含信号处理的具体信息 } GsSignalSlot; // 定义一个结构体，用于管理信号相关的信息和处理函数 typedef struct GsSignal { gs_sigfunc handlerList[GS_SIGNAL_COUNT]; // 信号处理函数数组，GS_SIGNAL_COUNT定义了可处理的信号数量 sigset_t masksignal; // 信号掩码，用于阻塞某些信号 SignalPool sig_pool; // 信号池，用于管理信号资源 volatile unsigned int bitmapSigProtectFun;// 位图，用于保护或标记某些信号处理函数的状态 } GsSignal; // 定义一个结构体，用于管理信号池中的信号节点 typedef struct SignalPool { GsNode* free_head; // 指向空闲信号节点链表的头部 GsNode* free_tail; // 指向空闲信号节点链表的尾部 GsNode* used_head; // 指向已使用信号节点链表的头部 GsNode* used_tail; // 指向已使用信号节点链表的尾部 int pool_size; // 信号池的大小，即能容纳的信号节点数量 pthread_mutex_t sigpool_lock; // 信号池访问的互斥锁 } SignalPool; 然后就是具体信号相关的结构体： 12345678910111213141516171819// 信号链表typedef struct GsNode { GsSndSignal sig_data; // 信号数据，包含信号编号、发送信号的线程ID等信息 struct GsNode* next; // 指向下一个节点的指针 } GsNode; // 定义一个结构体，表示需要发送的信号及其相关信息 typedef struct GsSndSignal { unsigned int signo; // 需要处理的信号编号 gs_thread_t thread; // 发送信号的线程ID GsSignalCheck check; // 发送信号时需要检查的信息，如检查类型、调试查询ID、会话ID等 } GsSndSignal; // 定义一个结构体，表示信号发送时需要检查的信息 typedef struct GsSignalCheck { GsSignalCheckType check_type; // 检查类型，可能是一个枚举，定义了不同类型的检查 uint64 debug_query_id; // 调试查询ID，用于调试或跟踪 uint64 session_id; // 会话ID，标识特定的会话或操作 } GsSignalCheck; 基本思想在进程环境中，对信号的处理是异步的：先注册信号处理函数，当信号异步发生时，由信号处理函数来处理信号。 但在多线程中处理信号的原则是：将信号的异步处理转换成同步处理。也就是说用一个线程专门的来“同步等待”信号的到来，而其它的线程可以完全不被该信号中断/打断(interrupt)。这样就在相当程度上简化了在多线程环境中对信号的处理，且可以保证其它的线程不受信号的影响。 模拟信号初始化12345678if (isBoot) { IsInitdb = true; gs_signal_monitor_startup(); // 信号监听线程启动 gs_signal_slots_init(1); // 初始化信号槽 (void)gs_signal_unblock_sigusr2(); // 停止阻塞SIGUSR2信号 gs_signal_startup_siginfo(&quot;AuxiliaryProcessMain&quot;); // 为当前线程分配信号槽位 BootStrapProcessMain(argc, argv);} 在main.cpp的启动流程中，关于信号处理有以下几个步骤： 启动信号监听器线程 初始化信号槽 停止阻塞SIGUSR2信号 为当前线程分配信号槽位 信号监听线程和信号槽前面已经介绍过，这里SIGUSR2是操作系统留给用户的自定义信号。 在oG中，这个信号被用于线程间通讯。也就是说线程互相发“信号”中的“信号”，都是SIGUSR2。线程收到SIGUSR2后的行为，统一都是遍历自己的信号池，对待处理的信号进行处理。 信号监听器线程启动123456void gs_signal_monitor_startup(void){ (void)gs_signal_block_sigusr2(); // 阻塞SIGUSR2信号 (void)gs_signal_install_handler(); // 加载SIGUSR2信号的handler errCode = gs_thread_create(&amp;thread, gs_signal_receiver_thread, 0, NULL); // 启动信号监听线程 return;} 前述在main.cpp中启动了监听线程gs_signal_monitor_startup()，实际上做的事有： 阻塞SIGUSR2信号 加载SIGUSR2信号的处理函数 启动信号监听线程 阻塞SIGUSR2信号是为了让监听线程启动不受该信号影响。 gs_signal_install_handler()在进程级别设置SIGUSR2信号的处理函数为gs_res_signal_handler， RES_SIGNAL 被定义为 SIGUSR2。 1234567891011121314151617181920STATIC gs_sigaction_func gs_signal_install_handler(void){ struct sigaction act, oact; /* * It is important to set SA_NODEFER flag, so this signal is not added * to the signal mask of the calling process on entry to the signal handler. */ sigemptyset(&amp;act.sa_mask); // 设置RES_SIGNAL的处理函数为gs_res_signal_handler act.sa_sigaction = gs_res_signal_handler; act.sa_flags = 0; act.sa_flags |= SA_SIGINFO; act.sa_flags |= SA_RESTART; // 调用sigaction进行信号的注册，`RES_SIGNA`L 被定义为 `SIGUSR2` if (sigaction(RES_SIGNAL, &amp;act, &amp;oact) &lt; 0) { ereport(PANIC, (errcode(ERRCODE_INSUFFICIENT_RESOURCES), errmsg(&quot;not able to set up signal action handler&quot;))); } /* Return previously installed handler */ return oact.sa_sigaction;} 然后启动了信号监听线程：我们看到这个监听线程的作用就是等待信号到来，然后由它将信号发送给具体的线程，将异步的过程改为同步的过程。 1234567891011121314151617181920212223242526272829303132void* gs_signal_receiver_thread(void* args){ /* * Listen on all signals. We explicitely include the list of signals that we * are interested in to reduce exposure. */ sigset_t waitMask; /* wait below signals: SIGINT, SIGTERM, SIGQUIT, SIGHUP */ sigemptyset(&amp;waitMask); sigaddset(&amp;waitMask, SIGINT); sigaddset(&amp;waitMask, SIGTERM); sigaddset(&amp;waitMask, SIGQUIT); sigaddset(&amp;waitMask, SIGHUP); sigaddset(&amp;waitMask, SIGUSR1); sigaddset(&amp;waitMask, SIGURG); gs_signal_block_sigusr2(); /* add just for memcheck */ gs_thread_args_free(); for (;;) { int signo; /* Wait for signals arrival. */ sigwait(&amp;waitMask, &amp;signo); /* send signal to thread */ (void)gs_signal_send(PostmasterPid, signo); } return NULL;} volatile ThreadId PostmasterPid = 0; 这里 gs_signal_send 下面会介绍，目前只要知道它是发送信号的函数。 12345678910/* * standalone backend). IsUnderPostmaster is true in postmaster child * processes. Note that &quot;child process&quot; includes all children, not only * regular backends. These should be set correctly as early as possible * in the execution of a process, so that error handling will do the right * things if an error should occur during process initialization. * * These are initialized for the bootstrap/standalone case. */THR_LOCAL bool IsUnderPostmaster = false; 而这个PostmasterPid在 !IsUnderPostmaster 下，为自身线程的ID。也就是说，Postmaster的子线程的PostmasterPid是固定的，它代表postmaster的线程ID。 这样我们知道，当有外部信号发生时，它被信号监听线程捕获，然后发送给postmaster主线程处理！ 信号槽初始化xx 模拟信号使用信号注册在每一个线程中，都需要单独为信号注册处理函数，比如线程池的监听器组件： 1234567891011void TpoolListenerMain(ThreadPoolListener* listener){ t_thrd.proc_cxt.MyProgName = &quot;ThreadPoolListener&quot;; pgstat_report_appname(&quot;ThreadPoolListener&quot;); (void)gspqsignal(SIGURG, print_stack); (void)gspqsignal(SIGHUP, SIG_IGN); (void)gspqsignal(SIGINT, SIG_IGN); // die with pm (void)gspqsignal(SIGTERM, SIG_IGN); (void)gspqsignal(SIGQUIT, SIG_IGN); (void)gspqsignal(SIGPIPE, SIG_IGN); 注册信号处理函数gspqsignal调用gs_signal_register_handler为信号设置处理函数，其实就是往handlerList里填处理函数的地址。 12345static gs_sigfunc gs_signal_register_handler(GsSignal* gs_signal, int signo, gs_sigfunc fun){ prefun = gs_signal-&gt;handlerList[signo]; gs_signal-&gt;handlerList[signo] = fun; return prefun;} 信号发送gs_signal_send 发送信号主要包括两步： 包装模拟信号 code = gs_signal_set_signal_by_threadid(thread_id, signo); 向线程发送信号 code = gs_signal_thread_kill(thread_id, RES_SIGNAL); gs_signal_set_signal_by_threadid 包装模拟信号的逻辑比较简单，主要为： 根据thread id 找到对应的信号槽slot 在slot的信号池中找到空闲的gsnode 将信号注册到gsnode中 gs_signal_thread_kill 的逻辑也很简单，其实就是对pthread_kill的封装。但是有一点，它遍历了slot，这可能是为了验证线程存在：通过遍历信号槽数组，gs_signal_thread_kill可以验证指定的线程ID是否确实存在于当前进程的上下文中。如果线程ID不存在于数组中，那么可能意味着该线程已经退出或从未被创建，因此发送信号没有意义。 1234567891011121314151617181920212223242526272829static int gs_signal_thread_kill(ThreadId tid, int signo){ unsigned int loop = 0; GsSignalSlot* slots_index = g_instance.signal_base-&gt;slots; int ret = 0; Assert(NULL != g_instance.signal_base-&gt;slots); Assert(g_instance.signal_base-&gt;slots_size &gt; 0); (void)pthread_mutex_lock(&amp;(g_instance.signal_base-&gt;slots_lock)); gs_signal_location_base_signal_lock_info(__func__, 0); for (loop = 0; loop &lt; g_instance.signal_base-&gt;slots_size; loop++) { if (slots_index-&gt;thread_id == tid) { // 发送信号 ret = gs_thread_kill(tid, signo); // pthread_kill的封装 gs_signal_unlocation_base_signal_lock_info(); (void)pthread_mutex_unlock(&amp;(g_instance.signal_base-&gt;slots_lock)); return ret; } slots_index++; } gs_signal_unlocation_base_signal_lock_info(); (void)pthread_mutex_unlock(&amp;(g_instance.signal_base-&gt;slots_lock)); return ESRCH;} 注意：gs_signal_send 发送的信号始终是 RES_SIGNAL 即 SIGUSR2 ，那么对应线程的处理则由gs_signal_handle函数进行！ 信号接收前述oG的模拟信号初始化的过程中阻塞了SIGUSR2信号，等到信号监听线程启动后，又停止阻塞SIGUSR2信号。由于新建的线程都继承了父线程的sigmask，它们都不会阻塞SIGUSR2信号。并且，所有线程共享sigaction，对于SIGUSR2信号处理行为是一致，就是gs_signal_handle函数。 它的行为是： ①遍历信号池使用列表，找到一个需要处理的信号。 ②找到这个信号对应的信号处理函数。把GsNode移到空闲列表中。 ③调用gs_signal_handle_check函数检查当前的条件是否仍然满足。如果仍然有效，回调处理函数。 总结 监听线程同步等待信号，但是对于其他线程来说，处理信号的过程还是异步的（接收SIGUSR2信号，然后在自己的信号池里取出模拟信号处理）。","link":"/2024/08/25/%E6%95%B0%E6%8D%AE%E5%BA%93/openGauss/openGauss%E7%9A%84%E6%A8%A1%E6%8B%9F%E4%BF%A1%E5%8F%B7%E6%9C%BA%E5%88%B6/"},{"title":"最长有效括号","text":"最长有效括号https://leetcode.cn/problems/longest-valid-parentheses/ 暴力法首先是暴力法思路：判断字符串每一个偶数长度的子串是否是有效匹配括号，然后记录最大长度。判断一个子串是否是有效匹配的方式是栈（左括号入栈，右括号出栈，如果为有效匹配，最后栈为空）。 动态规划法dp[i]代表以s[i]为结尾的最长有效括号字符串长度，dp数组的初始值应该为0。 一个字符不能组成有效的括号对，所以为dp[0]为0，然后从s[1]开始往后遍历并同时更新dp数组。 只有右括号才能组成有效括号，注意看下图： 当前遍历到第i位，如果第i-1位是左括号，那么要考虑串连的情况；如果第i-1位是右括号，那么要考虑嵌套+串连的情况。 1234567891011121314151617181920212223class Solution { public int longestValidParentheses(String s) { int ans =0; int[] dp = new int[s.length()]; for(int i=1; i&lt;s.length(); ++i){ if(s.charAt(i)==')'){ if(s.charAt(i)=='('){ dp[i] = 2; // for case ..)() if(i-2&gt;=0) dp[i]+=dp[i-2]; }else{ if(i-dp[i-1]&gt;0 &amp;&amp; s.charAt(i-dp[i-1]-1)=='('){ dp[i] = 2 + dp[i-1]; // for case ..)(...)) if(i-dp[i-1]-2&gt;=0) dp[i]+=dp[i-dp[i-1]-2]; } } ans = Math.max(ans, dp[i]); } } return ans; }} 这里用动态规划的难点是下标难以搞懂。dp数组的含义是长度，位置i的右括号对应的最长有效括号的左括号位置是i-dp[[i]+1。 栈+动态规划这将达到N的立方复杂度，有没有其他方法呢？来分析一下可能的括号匹配例子： （）（）（） 串行括号 （（（））） 嵌套括号 将栈修改为存字符的下标，遇到 ‘）’ 则计算栈顶下标差，然后出栈（如果栈空就跳过）。 这个朴素的想法可以应对嵌套括号，无法应对串行括号。根本原因在于忽略了前面的括号。 因此我们增加一个dp数组，用来记录下标i结尾的有效括号长度。计算栈顶下标差的同时还要加上栈顶前一个字符的有效括号长度。 123456789101112131415161718192021class Solution { public int longestValidParentheses(String s) { Stack&lt;Integer&gt; stk = new Stack&lt;Integer&gt;(); int ans = 0; int[] dp = new int[s.length()]; // dp[i] means s[i] is ')' and its longest valid parentheses for(int i = 0 ,start = 0;i &lt; s.length();i++){ if( s.charAt(i) == '(') stk.add(i); else{ if(stk.isEmpty()) continue; int idx = stk.pop(); if(idx-1&gt;=0) dp[i] = dp[idx-1] + i-idx+1; else dp[i] = i-idx+1; ans = Math.max(ans, dp[i]); } } return ans; }} 双指针贪心法用栈来进行匹配其实就是两个操作：push和pop。我们可以用这两个变量表示对应操作的数量，对于一个有效匹配： 在任意时刻，push的数量大于等于pop的数量 最后时刻，push的数量等于pop的数量 那么我们就可以用一个left表示左括号的数量，right表示右括号的数量，从左向右遍历，遇到相应括号时增加对应数量，然后进行判断： 如果left==right，记录最大数量 如果left&lt;right，将这两者清空 但这无法应对（（（）的例子，因为在我们看来左括号过多并不违法，但有效的括号匹配要求left==right。 换个方向思考，从右到左遍历一遍，此时右括号过多并不违法。结合两者的最大值，就能得到答案了。 12345678910111213141516171819202122232425262728class Solution { public int longestValidParentheses(String s) { int left = 0, right=0, ans=0, ans2=0; int N = s.length(); // 从左往右遍历一次 for(int i=0; i&lt;N; ++i){ if(s.charAt(i) == '(') left++; else right++; if(left == right) ans = Math.max(ans, 2*right); else if (right &gt; left){ left=0; right=0; } } // 从右往左再遍历一次 left = right =0; for(int i=0; i&lt;N; ++i){ if(s.charAt(N-1-i) == '(') left++; else right++; if(right == left) ans2 = Math.max(ans2, 2*left); else if( left &gt; right){ left=0; right=0; } } return Math.max(ans, ans2); }}","link":"/2024/06/05/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E5%8D%95%E9%A2%98%E9%A2%98%E8%A7%A3/%E5%8A%9B%E6%89%A332%20%E6%9C%80%E9%95%BF%E6%9C%89%E6%95%88%E6%8B%AC%E5%8F%B7/"},{"title":"均值为u&#x2F;v的子数组","text":"在介绍这题前，先介绍lc 560 和为K的子数组。 和为K的连续子数组链接：https://leetcode.cn/problems/subarray-sum-equals-k/description/ 给你一个整数数组 nums 和一个整数 k ，请你统计并返回该数组中和为 k 的连续子数组的个数。 暴力解法回溯法遍历每一个连续子数组，计算子数组的和并与K相比。时间复杂度$O(N^3)$ 。 这样做显然不行，有优化的地方吗？有。计算子数组的和。 前缀和优化我们知道前缀和这一技巧，在做一次预处理后，计算某个区间的和只需要O（1）时间。那么题目转化为：求有多少个区间【l，r】和为K，其中l和r范围是0～N-1，且l&lt;r。 具体的解题过程就变成了两层循环： 123456for(int r=0; r&lt;N; ++r){ for(int l=0; l&lt;=r; ++l){ //求l，r区间和 //判断区间和是否与k相等 }} 能不能再优化？ 哈希表优化计算公式：$presum[j] - presum[i] = k$ ，那么 $presum[j] -k = presum[i]$ 转换思路：考虑以$j$为右端点的区间，其区间和为K的个数。这等价于求多少个$i&lt;j$，满足 $presum[i] = presum[j] -k $ 等等，这个公式有点熟悉？力扣梦开始的地方，力扣第一题，两数之和。这里是两数之差。 接下来的思路就很明朗了，空间换时间，利用哈希宝提前存每个presum[i]。 1234567891011121314151617181920class Solution { public int subarraySum(int[] nums, int k) { int N = nums.length; int[] preSum = new int[N]; preSum[0] = nums[0]; for(int i=1; i&lt;N; ++i){ preSum[i] = preSum[i-1]+nums[i]; } Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); map.put(0, 1); // 很重要，对应preSum[-1]=0 int ans = 0; for(int j=0; j&lt;N; ++j){ if(map.containsKey(preSum[j]-k)) { ans += map.get(preSum[j]-k); } map.put(preSum[j], map.getOrDefault(preSum[j], 0)+1); } return ans; }} 细节注意： 以往前缀和下标都是不对应的，比如preSum[i+1] 为从0到i得区间和。 这道题的下标是对应的，原因是 map.put(0, 1); map.put(0, 1); 的作用 其实还是前缀和下标对应的问题。当我们要计算第一个区间，即[0,0]的区间和时，我们采用了preSum[0]-0的实现。 微众银行第三题-平均值微众银行笔试/20230903/第三题赏析 题目详情（1）题目描述 小明有一个数组。他挑选了一个有理数u/v，现在他想知道这个数组有多少个子区间的平均值恰好等于u/v。数组的子区间即是数组中连续的一段区间，如数组[4,2,6]有6个子区间 [4]，[2]，[6]，[4,2]，[2,6]，[4,2,6]。 （2）输入描述 第一行有三个整数 n,u,v (1 ≤ n, v ≤ 100000,1 ≤ u ≤ n *v)，代表数组的长度，小明选择的有理数的分子和分母。 输入保证u和v的最大公因数是1，即u/v是最简分数。 第二行有n个绝对值不超过1000000的整数，代表数组中的元素。 数字间两两有空格隔开。 （3）输出描述 输出一个非负整数，代表所求的答案。 （4）样例 输入 126 5 22 4 1 3 2 3 输出 16 思路分析仔细思考，如果将题目描述的中平均值去除，这不就是和为K的子数组吗？ 条件给的数组平均值与一个真分数，是想要我们干什么呢？回到判断相等的公式。 $\\frac{presum[j]-presum[i]}{j-i]} = \\frac{u}{v}$ 我们将它变形一下： $u\\times i - v \\times presum[i] = u \\times j - v \\times presum[j]$ 等等，这两边的形式好像高度对称啊，我们定义一个新数组 $a[i] = u \\times i - v \\times presum[i]$，上面公式转化为了 $a[i] = a[j] - 0$ 这不就是两数之差为k嘛，只不过k为0。兜兜转转，我们又回到了力扣第一题。 题解1234567891011121314151617181920212223242526import java.util.Scanner;public class Main { public static void main(String[] args) { Scanner scanner = new Scanner(System.in); int n = scanner.nextInt(), u = scanner.nextInt(), v = scanner.nextInt(); int[] a = new int[n]; int[] psum = new int[n + 1]; for (int i = 0; i &lt; n; i++) { a[i] = scanner.nextInt(); psum[i + 1] = psum[i] + a[i]; } long rs = 0; for (int i = 1; i &lt;= n; i++) { for (int j = i; j &lt;= n; j++) { if (1L * (psum[j] - psum[i - 1]) * v == 1L * u * (j - i + 1)) { rs++; } } } System.out.println(rs); }}","link":"/2024/06/05/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E5%8D%95%E9%A2%98%E9%A2%98%E8%A7%A3/%E5%9D%87%E5%80%BC%E4%B8%BAuv%E7%9A%84%E5%AD%90%E6%95%B0%E7%BB%84/"},{"title":"IDEA编辑器配置与快捷键","text":"IntelliJ家的IDE一直很好用，其中IDEA是开发Java的利器。下面介绍一下常用的快捷键。 官方的快捷键表：https://www.jetbrains.com/idea/docs/IntelliJIDEA_ReferenceCard_Mac.pdf Mac 键盘符号和修饰键说明 ⌘ ——&gt; Command ⇧ ——&gt; Shift ⌥ ——&gt; Option ⌃ ——&gt; Control ↩︎ ——&gt; Return/Enter 浏览查找文件或者方法名： 双击shift 全局查找： shift+command+f 查看关键代码： cmmand+鼠标左键 光标跳转回上次地方： command+[ 或者 option+command+左箭头 光标跳转回下次地方： command+] 或者 option+command+右箭头 迅速定位代码报红位置（若无，定位至可改进代码位置） F2 最近查看的文件 command+e （再次按可显示修改过文件） 最近浏览的视图 command+shift+e （同样可再次按） 编辑智能修复 option+Enter 调出修复建议 New 对象后直接.var 就避免前置类型手写 输入/** ,点击“Enter”，自动根据参数和返回值生成注释模板 活模版 （live templates） 活模版：输入几个键就能替代大量重复代码。 设置位置：Settings -&gt; Editor -&gt; Live Templates 代码 对应模版 psvm public static void main(String[] args) { } sout System.out.println(); PostFix机制 更加智能的“活模版”，能够省下大量重复的写代码工作。 设置位置：Settings -&gt; Editor -&gt; General -&gt; Postfix Completion 代码 对应模版 100.fori for (int i = 0; i &lt; 100; i++) { } 100.forr for (int i = 100; i &gt; 0; i–) { } “hello”.sout System.out.println(“hello”); new Date().sout System.out.println(new Date()); 成员变量postfix，后面加field 自动加上字段 public A(String name, String good){ name.field } private final String name; 快速判断非空 good.nn if (good != null) { }","link":"/2023/08/17/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/IDE/IDEA%E7%BC%96%E8%BE%91%E5%99%A8%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%BF%AB%E6%8D%B7%E9%94%AE/"},{"title":"VScode配置与快捷键","text":"个人觉得vscode只是个编辑器，而不是IDE（集成编译环境），很多功能需要搭配插件时间，新手不友好。 内容待更新。 Mac 键盘符号和修饰键说明 ⌘ ——&gt; Command ⇧ ——&gt; Shift ⌥ ——&gt; Option ⌃ ——&gt; Control ↩︎ ——&gt; Return/Enter 开箱设置关闭右侧代码预览图： Settings -&gt; Text Editor -&gt; MiniMap -&gt; Enabled UI缩放，使得字体更大：Zoom 快捷键浏览当前文件内查找： command+f 全局查找： shift+command+f 查找文件并切换： command+p 指定行数跳转： command+g 查看关键代码： cmmand+鼠标左键 文件切换： ctrl+tab 终极奥义：VSCode左下角 “管理 / Manage” -&gt; “键盘快捷方式 / Keyboard Shortcuts” -&gt; 搜索 “前进 / Go Forward 或 后退 / Go Back” 光标跳转回上次地方： command+[ 或者 option+command+左箭头 光标跳转回下次地方： command+] 或者 option+command+右箭头 打开终端： Ctrl + ` 或者 command+j","link":"/2024/06/01/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/IDE/VScode%E8%AE%BE%E7%BD%AE%E4%B8%8E%E5%BF%AB%E6%8D%B7%E9%94%AE/"},{"title":"二分法","text":"二分法好写，但bug颇多。 记住二分法的思想：每次舍弃答案一定不存在的区间，保留答案存在的区间。同时注意二分区间状态转移的一致性。 题单：https://leetcode.cn/studyplan/binary-search/ 有序不重复数组默认中点取法向下取整，则 $left \\le mid &lt;right$，这点的影响在这尚未体现。 简单二分单调递增数组找目标元素下标，元素不重复，目标元素不在其中则返回-1。 https://leetcode.cn/problems/binary-search/description/ 1234567891011121314class Solution { public int search(int[] nums, int target) { int l=0, r=nums.length -1; while(l &lt;= r){ int mid = (l+r)/2; if(nums[mid] == target) return mid; if(nums[mid] &lt; target) l = mid + 1; else r = mid - 1; } return -1; }} 看起来很简单，修改下题目，得到以下这题 搜索插入位置单调递增数组找目标元素下标，元素不重复，如果元素不在其中，返回元素应该在插入的下标。 比如数组【1】，元素0返回下标0，元素1返回下标0，元素2返回下标1。 https://leetcode.cn/problems/search-insert-position/ 12345678910111213class Solution { public int searchInsert(int[] nums, int target) { int l=0, r=nums.length-1; while(l&lt;=r){ int mid=l+(r-l)/2; if(nums[mid]&lt;target) l=mid+1; else r=mid-1; } return l; }} 这题如果沿用上题的左闭右闭区间表示法，就会发现困难重重，其根本原因就在左闭右闭区间无法包括所有答案应在的位置，比如，[1,2,3] 搜索 4 所在位置。仔细揣摩以上代码，虽然写得很精巧，但其中的逻辑转变不是很直观。 我更推荐以下写法： 12345678910111213class Solution { public int searchInsert(int[] nums, int target) { int l = 0, r = nums.length; while(l &lt; r){ int mid = (l+r)/2; if(nums[mid]&gt;=target) r = mid; else l = mid+1; } return l; }} 将每一次缩小区间的过程看成一次状态转移：从一个大区间到一个小区间，其中状态转移的一致性就是指永远保留答案在我的窗口区间内（每次舍弃答案不在的区间）。 那么我们就能对比 while(l &lt;= r) 和 while(l &lt; r)的区别了。由于第一题采用左闭右闭区间表示法，在l==r时仍然能构成小区间，那么答案是可能在这个区间内的，我们还需要继续在这个区间搜索下去。 第二题的while(l &lt; r)同理，在nums[mid]&gt;=target 时，应该往左边缩小区间，r应该为mid-1吗？不应该，因为这样答案可能不在这个区间。举例子[1,3]或[1,2]数组中搜索2所在位置。 这样第一题和第二题就构成了逻辑上的统一。 有序重复数组排序数组寻找元素第一个和最后一个位置https://leetcode.cn/problems/find-first-and-last-position-of-element-in-sorted-array 给你一个按照非递减顺序排列的整数数组 nums，和一个目标值 target。请你找出给定目标值在数组中的开始位置和结束位置。 123456789101112131415161718192021222324252627282930313233class Solution { public int lower_bound(int[] nums, int target){ int l = 0, r = nums.length; while(l&lt;r){ int mid = (l+r)/2; if(nums[mid]&gt;=target) r = mid; else l = mid +1; } return l; } public int upper_bound(int[] nums, int target){ int l = 0, r = nums.length; while(l&lt;r){ int mid = (l+r)/2; if(nums[mid]&gt;target) r = mid; else l = mid +1; } return l; } public int[] searchRange(int[] nums, int target) { int[] ans = {-1, -1}; int l = lower_bound(nums, target); if(l==nums.length || nums[l]!=target) return ans; int r = upper_bound(nums, target); ans[0] = l; ans[1] = r-1; return ans; }} Lower_bound 的语义：有序重复数组寻找目标元素第一次出现的位置，如果不存在，返回应该插入的位置。 Upper_bound 的语义：有序重复数组寻找大于目标元素的数字第一次出现的位置，如果不存在，返回应该插入的位置。 换位思考：先求序列中第一个大于x的元素的位置，然后减1就是x最后出现的位置。 upper bound对于targer极大，只能返回N，所以需要合理使用。或者使用以下思路： 123456789public int[] searchRange(int[] nums, int target) { int[] ans = {-1, -1}; int l = lower_bound(nums, target); if(l==nums.length || nums[l]!=target) return ans; int r = lower_bound(nums, 1+target); ans[0] = l; ans[1] = r-1; return ans;} 泛化通过思考可以发现，lower和upper函数都在解决这样一个问题：在一个有序序列中第一个满足某条件的元素的位置。 lower-bound就是，从左到右，找第一个满足“值大于等于target”的元素。 upper-bound就是，从左到右，找第一个满足“值大于target”的元素。 于是就有了这样一个模版： 1234567891011//从左到右，找第一个满足条件的元素位置int solve(int left, int right){ while(left &lt; right){ int mid = (left+right)/2; if(条件成立) //我们要找条件成立的第一个位置！ right = mid; //所以继续往左区间找 else left = mid+1; } return left;} 这个函数解决在某序列中，从左到右，第一个满足条件的元素下标。 比如求最后一个x&lt;4的元素下标，数组为[1,2,2,2,5]，答案为3 先求第一个满足x&gt;=4的下标，为4，然后减去1，得到答案3 题目keke吃香蕉https://leetcode.cn/problems/koko-eating-bananas/description/ 1234567891011121314151617181920212223242526272829class Solution { public int solve(int[] piles, int speed){ // 以speed的速度解决这堆香蕉需要多久 int time = 0; for(int banana: piles){ //上取整的实现 time += (banana+speed-1)/speed; } return time; } public int minEatingSpeed(int[] piles, int h) { // 最小速度1，最大速度max（piles） // 最大速度解释：piles.length &lt;= h , 最大速度一定可以在length小时吃完 int l =1, r = -1; for(int pile:piles){ r = Math.max(r, pile); } while(l &lt; r){ int mid = (l+r)/2; int time = solve(piles, mid); if(time&lt;=h){ //速度过快，往小的方面搜索 r = mid; }else{ l = mid+1; } } return r; }} 最小速度可以为1，但1不保证能在h小时吃完所有香蕉。最大速度怎么求？无限大？只要找到一个能在h小时吃完所有香蕉的速度speed就行。这个speed是个上界，但不是上确界。 小技巧：上取整的实现 $\\lceil p/s \\rceil = \\lfloor (p+s-1)/s \\rfloor$ 利用带余除法判断，余数是否大于0 1int time = p/s + (p%s&gt;0) ? 1:0; 货物运输https://leetcode.cn/problems/capacity-to-ship-packages-within-d-days/ 123456789101112131415161718192021222324252627282930313233343536373839class Solution { public int transit(int[] weights, int load){ int day = 0; int cur = 0; // 目前载荷 for(int weight:weights){ if(cur+weight &lt;load){ cur += weight; }else if(cur+weight ==load){ ++day; cur = 0; } else{ ++day; cur = weight; } } if(cur&gt;0) ++day; return day; } public int shipWithinDays(int[] weights, int days) { // 最小max(weights)，最大sum（weights） int l =0, r=0; for(int weight:weights){ r += weight; l = Math.max(l , weight); } System.out.println(transit(weights, 5)); while( l &lt; r){ int mid = l + (r-l)/2; int day = transit(weights, mid); if(day &lt;= days){ r = mid; }else{ l = mid+1; } } return r; }} 这题与上面一题几乎一样！注意点： 1、左右边界的确定 左边界是weights的最大，因为船至少能装一个货物。最大就是求和，这样能在一天运完。 2、计算当前负载需要天数的函数 用模拟方式进行，负载装满就出发。 旋转排序数组中的最小值https://leetcode.cn/problems/find-minimum-in-rotated-sorted-array/description/ 123456789101112131415class Solution { public int findMin(int[] nums) { int l=0, r=nums.length-1; if(nums[l]&lt;=nums[r]) return nums[l]; while(l&lt;r &amp;&amp; nums[l]&gt;nums[r]){ int mid = (l+r)&gt;&gt;1; if(nums[mid]&gt;=nums[l]){ l = mid+1; }else{ r = mid; } } return nums[l]; }} 在应用二分法时，每次缩小区间，其实是排除不符合条件的区间过程。 旋转排序数组，其实是分成了两个有序段，左半段和右半段，左半段的值肯定是大于右半段的值。但这题的难点在于左右两段的情况可能不存在，以及应用二分法的过程中，可能从两个段跨越到一个段，导致语义错误。 那么我就应用状态机的思想，维持我left和right的区间始终为两个段的情况（nums[l]&gt;nums[r])，如果跨越到右半段，直接返回右半段的最左边的值。 这道题的难点还在于mid究竟是要和left还是right进行比较？ （1）mid和right比较没问题。如果nums[mid]&gt;nums[right]，那么mid肯定落在左半段。如果nums[mid]&lt;=nums[right]，那么mid是落在右半段。 （2）mid和left比较有风险！left可能越过最高点，整个区间从两个段变成一个段，再也不能通过nums[mid]&gt;=nums[left]来判断mid是落在左半段还是右半段（因为落到单升序区间后，nums[mid]&gt;nums[left]的条件指示我们往右走的行为已经违背了题目初衷）。所以 while(l&lt;r &amp;&amp; nums[l]&gt;nums[r]) 这里条件中nums[l]&gt;nums[r] 必不可少的，这是要保持l，r窗口内是失序的状态，一旦打破，就达到了有序状态，直接返回最左边界的值。 （3）那为什么mid和right比较没问题？因为即使left可能越过最高点，整个区间变成有序状态后，不会再出现nums[mid]&gt;nums[right]的情况。 贴上mid和right比较的代码： 1234567891011121314class Solution { public int findMin(int[] nums) { int l=0, r=nums.length-1; while(l&lt;r){ int mid = (l+r)&gt;&gt;1; if(nums[mid] &lt; nums[r]){ r = mid; }else{ l = mid+1; } } return nums[l]; }} 最后需要注意的一点，mid和left比较的代码是大于等于，和right比较是小于（小于等于也行）。 因为在mid的计算过程中， $left \\le mid &lt;right$，是会出现left！=right，但是mid==left的情况。此时left和mid可能构成一个单独的段，要确保这个段能被捕捉到。 搜索旋转排序数组给你一个target，在旋转排序数组中找它的下标，不存在返回-1。 https://leetcode.cn/problems/search-in-rotated-sorted-array/ 1234567891011121314151617181920212223242526class Solution { public int search(int[] nums, int target) { if(nums==null||nums.length==0) return -1; int l=0, r=nums.length-1; while(l&lt;=r){ int mid = (l+r)&gt;&gt;1; if(nums[mid] == target) return mid; // 先判断mid在左半段还是右半段 if(nums[l] &lt;= nums[mid]){ // 再判断target在段中的左右 if(nums[l] &lt;= target &amp;&amp; target &lt; nums[mid]){ r = mid-1; }else{ l = mid+1; } }else{ if(nums[mid] &lt; target &amp;&amp; target &lt;= nums[r]){ l = mid+1; }else{ r = mid-1; } } } return -1; }} 为什么要用左闭右闭区间表示法？ 为什么 nums[l] &lt;= nums[mid] mid是和left进行比较？ nums数组旋转前就是个升序不重复的数组，然后只需要判断元素是否在这个数组中，用左闭右闭的区间表示正合适。 nums[l] &lt;= nums[mid] 用小于等于比较是为了构成有效区间。也可以和right进行比较，见下方代码，两者语义是一致的。 123456789101112131415161718192021222324class Solution { public int search(int[] nums, int target) { if(nums==null||nums.length==0) return -1; int l=0, r=nums.length-1; while(l&lt;=r){ int mid = (l+r)&gt;&gt;1; if(nums[mid] == target) return mid; if(nums[mid] &lt;= nums[r]){ if(nums[mid] &lt; target &amp;&amp; target &lt;= nums[r]){ l = mid+1; }else{ r = mid-1; } }else{ if(nums[l] &lt;= target &amp;&amp; target &lt; nums[mid]){ r = mid-1; }else{ l = mid+1; } } } return -1; }} 搜索旋转排序数组2给你一个target，在旋转排序数组（这个数组可能含有重复元素）中找它的下标，不存在返回-1。 https://leetcode.cn/problems/search-in-rotated-sorted-array-ii/ 1234567891011121314151617181920212223242526272829class Solution { public boolean search(int[] nums, int target) { if(nums==null||nums.length==0) return false; int l=0, r=nums.length-1; while(l&lt;=r){ int mid = (l+r)&gt;&gt;1; if(nums[mid] == target) return true; // 相等的情况,可能l==mid,也可能l!=mid if(nums[l] == nums[mid]) {l++;continue;} if(nums[l] &lt; nums[mid]){ if(nums[l]&lt;= target &amp;&amp; target &lt; nums[mid]){ // 左半段的左边 r = mid-1; }else{ l = mid+1; } }else{ // nums[mid] &lt; nums[r] if(nums[mid]&lt;target &amp;&amp; target&lt;=nums[r]){ // 右半段的右边 l = mid+1; }else{ r = mid-1; } } } return false; }} 这里比上题就多出了一行代码 1if(nums[l] == nums[mid]) {l++;continue;} 总结在应用二分法，注意左右边界的获取。 根据区间的表示法，选择合适while循环判断条件。 在应用二分法时，每次缩小区间，其实是排除不符合条件的区间过程。 状态转移的一致性就是指永远保留答案在我的窗口区间内（每次舍弃答案不在的区间）。","link":"/2023/12/22/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%95%B0%E7%BB%84%E4%B8%8E%E5%AD%97%E7%AC%A6%E4%B8%B2/JAVA%E4%BA%8C%E5%88%86%E6%B3%95/"},{"title":"前缀和与差分","text":"前缀和与差分都是数组的重要技巧。 前缀和原理介绍（1）是什么？ 前缀和说白了就是数组前N项和。 给定数组 $A_i$ 则前缀和为 $S_i = \\sum\\limits_{k=0}^{i}a_k$ （2）能干什么？ 前缀和能快速计算数组区间和，将线性时间复杂度优化为常数时间复杂度。 记数组第i个元素到第j个元素之间的和为 $f(i,j)$， 则 $f(i,j) = S_{j}-S_{i-1}$ ，其中i从0开始。 为了避免-1的下标，修改前缀和 $S_i = \\sum\\limits_{k=0}^{i-1}a_k，i=1,2,3…$，并令$S_0 = 0$，我们得到$f(i,j) = S_{j+1}-S_{i}$ （3）伪代码 123sum[0] = 0;sum[1] = num[0];sum[k] = num[0]+...+ num[k-1]; 那么从num[i] 到 num[j]的和为sum[j+1] - sum[i] 区域和检索https://leetcode.cn/problems/range-sum-query-immutable/ 123456789101112131415161718class NumArray { public int len; public int[] nums; public NumArray(int[] nums) { len = nums.length; this.nums = nums; } public int sumRange(int left, int right) { int[] sum = new int[1+len]; // sum[k] means a1+...ak-1 sum[0] = 0; for(int i=1; i&lt;=len; ++i){ sum[i] = sum[i-1]+ nums[i-1]; } return sum[right+1]-sum[left]; }} 从此题中就可以看出，前缀和适用于频繁求数组区间和的场景。如果只求一次区间和，那么线性累加反而更快。 和为K的子数组https://leetcode.cn/problems/QTMn0o/description/ （1）暴力遍历 12345678910111213141516class Solution { public int subarraySum(int[] nums, int k) { int N = nums.length; int[] sum = new int[N+1]; for(int i=1; i&lt;=N; ++i) sum[i] = sum[i-1] + nums[i-1]; // 遍历所有的可能区间[i, j] int ans = 0; for(int i=0; i&lt;N; ++i){ for(int j=i; j&lt;N; ++j){ if((sum[j+1]-sum[i]) == k) ans++; } } return ans; }} 题目要求区间和为k的区间个数，那么利用前缀和优化区间和过程，然后遍历每一个区间，时间复杂度$O(N^2)$。 （2）哈希优化 1234567891011121314151617181920class Solution { public int subarraySum(int[] nums, int k) { HashMap&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;(); // 初始化的作用，计算长度为1的子数组 map.put(0,1); // 储存preSum[j] int preSum = 0; int res = 0; // 开始遍历储存前缀和 for (int num : nums) { preSum += num; // 计算是否存在 preSum[i] if (map.containsKey(preSum - k)) res += map.get(preSum - k); // 将这个前缀和存入哈希表 map.put(preSum, map.getOrDefault(preSum, 0)+1); } return res; }} 思路分析：求得前缀和之后，问题其实可以归结为：N个数，求差为定值K的数据对个数。 参考两数之和的思路：N个数，从中找和为定值K的数据对。 一个是两数之和，一个是两数之差，但本质无差。我确定两数之中的一个数之后，由于和/差固定，那么就能确定另外一个数的大小。此时，我只需查表来确定另外一个数的出现次数，就能避免重复运算。 笔试真题：webank—9.3—笔试第三题_牛客网 这题将数组区间和改为了数组平均值，不过经过算式转化后就变成了和为0的子数组个数。 二维区域和搜索https://leetcode.cn/problems/range-sum-query-2d-immutable/ 123456789101112131415161718class NumMatrix { private int[][] preSum; //preSum[i][j] = Sum(matrix[i-1][j-1]) public NumMatrix(int[][] matrix) { int m = matrix.length, n = matrix[0].length; if (m == 0 || n == 0) return; preSum = new int[m + 1][n + 1]; for(int i=1; i&lt;=m; ++i){ for(int j=1; j&lt;=n; ++j){ preSum[i][j] = matrix[i-1][j-1] + preSum[i-1][j] + preSum[i][j-1] - preSum[i-1][j-1]; } } } public int sumRegion(int row1, int col1, int row2, int col2) { return preSum[row2+1][col2+1] - preSum[row2+1][col1] - preSum[row1][col2+1] + preSum[row1][col1]; }} 既然有一维的前缀和，那么就有二维的区域和。固定原点为00，那么就能计算从ij到00形成的区域和。 二叉树路径和https://leetcode.cn/problems/path-sum-iii/description/ （1）普通递归解法 1234567891011121314class Solution { public int dfs(TreeNode root, long target){ // 从root开始的结点路径和为target的数量 if(root==null) return 0; int l = dfs(root.left, target-root.val); int r = dfs(root.right, target-root.val); int mid = (target==root.val)?1:0; return l+r+mid; } public int pathSum(TreeNode root, int targetSum) { if(root==null) return 0; return dfs(root, targetSum)+pathSum(root.left, targetSum)+pathSum(root.right, targetSum); }} 用一个dfs计算从根节点到叶子结点上路径和为target的数量。然后再递归计算左右左右子树上符合条件的数量。 这样做有什么缺点？大量重复计算。 重复计算是怎么出现的？不能简化它吗？回顾现在的思路，针对树的一个根结点，计算从根节点开始的路径和。在DFS的过程中，我们的确是节省了计算（从根节点到当前结点），但是一趟DFS结束后，我们转移到了左右子树的根节点，此时计算清空。 换个思路：从下往上。若记当前结点i到根节点root的路径和为$sum(i, root)$，那么从i节点到j结点的路径和可以为表示$sum(i, root)-sum(j,root)$ ，这不正是区间和的简化计算方式吗？ （2）前缀和解法 123456789101112131415161718class Solution { int ans =0; public void dfs(TreeNode root, Map&lt;Long, Integer&gt; prefixMap, long sum, long targetSum){ if(root==null) return; sum += root.val; ans += prefixMap.getOrDefault(sum-targetSum, 0); prefixMap.put(sum, prefixMap.getOrDefault(sum, 0)+1); dfs(root.left, prefixMap, sum, targetSum); dfs(root.right, prefixMap, sum, targetSum); prefixMap.put(sum, prefixMap.getOrDefault(sum, 0)-1); } public int pathSum(TreeNode root, int targetSum) { Map&lt;Long, Integer&gt; map = new HashMap&lt;&gt;(); map.put(0L, 1); // for zero prefixSum dfs(root, map, 0, targetSum); return ans; }} 这里的前缀和就是从当前结点到root结点的路径和。这样二叉树中的一条路径就可以做到O（1）的计算。 注意： 我们用Map&lt;Long, Integer&gt;来存储相同前缀和的数量，因为二叉树结点有正有负，可能出现相同前缀和。 在结束递归时，减去当前的前缀和。prefixMap.put(sum, prefixMap.getOrDefault(sum, 0)-1); 因为路径不能跨树。 差分原理介绍前缀和适用场景：原始数组不被修改的情况下，区间的累加和的频繁查询。 差分技巧适用场景：频繁对原始数组的某个区间的元素进行增减。 （1）原理 给定数组 $A_i$ 则差分数组表示为 $d_i = a_i - a_{i-1}, i=1,2,3,…, d_0=0$ 差分抓住了相邻元素间差不变的特性，对一个区间内的所有元素加或减某个数，差分总是不变的。 如果你想对区间 nums[i..j] 的元素全部加 3，那么只需要让 diff[i] += 3，然后再让 diff[j+1] -= 3 即可。 如果你想对区间 nums[i..j] 的元素全部减 3，那么只需要让 diff[i] -= 3，然后再让 diff[j+1] -+ 3 即可。 特别地，如果对整个数组进行加减，只需要对首元素加减即可。 （2）代码实现 构造差分数组 12345int[] diff = new int[nums.length];diff[0] = nums[0];for (int i = 1; i &lt; nums.length; i++) { diff[i] = nums[i] - nums[i - 1];} 差分数组反推原数组 12345int[] res = new int[diff.length];res[0] = diff[0];for (int i = 1; i &lt; diff.length; i++) { res[i] = res[i - 1] + diff[i];} 封装工具类 1234567891011121314151617181920212223242526272829303132333435// 差分数组工具类class Difference { // 差分数组 private int[] diff; /* 输入一个初始数组，区间操作将在这个数组上进行 */ public Difference(int[] nums) { assert nums.length &gt; 0; diff = new int[nums.length]; // 根据初始数组构造差分数组 diff[0] = nums[0]; for (int i = 1; i &lt; nums.length; i++) { diff[i] = nums[i] - nums[i - 1]; } } /* 给闭区间 [i, j] 增加 val（可以是负数）*/ public void increment(int i, int j, int val) { diff[i] += val; if (j + 1 &lt; diff.length) { diff[j + 1] -= val; } } /* 返回结果数组 */ public int[] result() { int[] res = new int[diff.length]; // 根据差分数组构造结果数组 res[0] = diff[0]; for (int i = 1; i &lt; diff.length; i++) { res[i] = res[i - 1] + diff[i]; } return res; }} 航班预订统计https://leetcode.cn/problems/corporate-flight-bookings/ 12345678910111213141516class Solution { public int[] corpFlightBookings(int[][] bookings, int n) { int[] diff = new int[n]; // 差分数组 for(int[] book: bookings){ // 注意下标对齐逻辑 diff[book[0]-1] += book[2]; if(book[1]&lt;n) diff[book[1]] -= book[2]; } int[] res = new int[n]; //反推原来数组 res[0] = diff[0]; for(int i=1; i&lt;n; ++i){ res[i] = diff[i] + res[i-1]; } return res; }} 拼车https://leetcode.cn/problems/car-pooling/description/ 1234567891011121314151617181920212223class Solution { public boolean carPooling(int[][] trips, int capacity) { int[] diff = new int[1000]; for(int[] trip:trips){ int n = trip[0]; int l = trip[1]; int r = trip[2]; // 上车 diff[l] += n; if(r&lt;1000) diff[r] -= n; } int[] ans = new int[1000]; ans[0] = diff[0]; for(int i=1; i&lt;1000; ++i){ ans[i] = diff[i] + ans[i-1]; } for(int num: ans) if(num&gt;capacity) return false; return true; }} 差分数组直观应用，事后检查每公里是否超载。","link":"/2024/04/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%95%B0%E7%BB%84%E4%B8%8E%E5%AD%97%E7%AC%A6%E4%B8%B2/Java%E5%89%8D%E7%BC%80%E5%92%8C%E4%B8%8E%E5%B7%AE%E5%88%86/"},{"title":"滑动窗口法","text":"滑动窗口是一种解题技巧，一句话说明就是维护一个窗口，不断滑动，更新答案。 滑动窗口适合的一维情况，比如数组、字符串；同时，拓展到二维也不是不可能。 根据问题求解的特性，可分为最小滑动窗口和最大滑动窗口两种解题模版。 滑动窗口大致逻辑1234567891011121314// 窗口由left和right共同维护，左闭右闭int left = 0, right = 0;while (right &lt; 某个值） { // 增大窗口 right++; // 更新窗口内的性质 window.add(s[right]); //当窗口内满足xx条件时，缩小窗口 while (window needs shrink) { window.remove(s[left]); left++; } //更新答案} 通过双指针维护窗口，right指针扩大窗口，left指针缩小窗口。滑动窗口射击两个过程，扩大窗口以及缩小窗口。需要注意一些细节，比如说如何向窗口中添加新元素，如何缩小窗口，在窗口滑动的哪个阶段更新结果。 （1）窗口内状态收集一般通过容器进行，比如map、queue（单调队列）等。 （2）两种模型 如果在扩大阶段收集答案，那么就是最大窗口模型，但注意同时要满足题目特定条件。背后的思想与贪心类似。 如果在窗口缩小阶段收集答案，那么就是最小窗口模型。 那么这两种模型到底有什么区别？滑动窗口法都有窗口扩张和窗口缩小的过程。最大窗口模型，窗口缩小是使条件满足的过程，然后收集答案；最小窗口模型，只有在满足条件时才能进行窗口缩小，窗口缩小的目的是使得条件不满足，在每一次窗口缩小过程中收集答案。 最小滑动窗口1234567891011121314151617181920void slidingWindow(string s, string t){ int left=0,right=0; int valid = 0; while(right&lt;s.size()){ //取数据 char c = s[right]; // 将数据加入窗口 // your code here while(窗口满足条件){ //记录结果 // your code here //缩小窗口，使之不满足条件 } //此时窗口不满足条件，继续扩大 right++; }} 可以看出来，最小滑动窗口的条件是在while循环内更新的，因为一旦满足了条件就要马上更新，取最小。 最大滑动窗口1234567891011121314151617181920void slidingWindow(string s, string t){ int left=0,right=0; int valid = 0; while(right&lt;s.size()){ //取数据 char c = s[right]; // 将数据加入窗口 // your code here while(窗口不满足条件){ //缩小窗口，使之满足条件 } //记录结果 // your code here //此时窗口满足条件，继续扩大 right++; }} 最大窗口的条件更新是在while外更新的。当我们的窗口满足条件时，我们希望继续扩大窗口，期望得到最大值。一旦窗口内的数据不满足条件了，我们就缩小窗口，调整满足条件。 滑动窗口法实战字符串排列https://leetcode.cn/problems/permutation-in-string/description/ 12345678910111213141516171819class Solution { public boolean checkInclusion(String s1, String s2) { if(s1.length()&gt;s2.length()) return false; // 初始化S1大小的窗口，然后不断向右滑动 int[] winodw = new int[26]; int[] s1_hash = new int[26]; for(int i=0; i&lt;s1.length(); ++i){ s1_hash[s1.charAt(i)-'a'] += 1; winodw[s2.charAt(i)-'a'] += 1; } if(Arrays.equals(s1_hash, winodw)) return true; for(int i=s1.length(); i&lt;s2.length(); ++i){ winodw[s2.charAt(i-s1.length()) -'a']--; winodw[s2.charAt(i)-'a']++; if(Arrays.equals(s1_hash, winodw)) return true; } return false; }} 很简单的思路，用哈希表映射窗口每个字母的个数，然后不断向右滑动。 字符串中的所有字母异位词https://leetcode.cn/problems/find-all-anagrams-in-a-string/ （1）暴力解法 12345678910111213141516171819class Solution { public List&lt;Integer&gt; findAnagrams(String s, String p) { List&lt;Integer&gt; ans = new ArrayList&lt;&gt;(); if (p.length() &gt; s.length() ) return ans; int[] p_map = new int[26]; int[] win_map = new int[26]; for(int i=0; i&lt;p.length(); ++i){ p_map[p.charAt(i)-'a'] +=1; win_map[s.charAt(i)-'a'] +=1; } if (Arrays.equals(p_map, win_map)) ans.add(0); // 这里可优化 for(int i=p.length();i&lt;s.length(); ++i){ win_map[s.charAt(i-p.length())-'a']--; win_map[s.charAt(i) -'a']++; if (Arrays.equals(p_map, win_map)) ans.add(i-p.length()+1);// 这里可优化 } return ans; }} 窗口大小固定，往右滑动。 在比较窗口内字符和p字符时，通过Arrays.equals(p_map, win_map)线性遍历每一个位置是否相同，代价太大。能否优化？ （2）优化比较 12345678910111213141516171819202122232425262728293031323334class Solution { public List&lt;Integer&gt; findAnagrams(String s, String p) { List&lt;Integer&gt; ans = new ArrayList&lt;&gt;(); if (p.length() &gt; s.length() ) return ans; int[] count = new int[26]; // count表示窗口内字母数量减去p的字母数量 int diff = 0; // 表示差异的字母数量 for(int i=0; i&lt;p.length(); ++i){ count[s.charAt(i)-'a'] +=1; count[p.charAt(i)-'a'] -=1; } for(int cnt:count){ if(cnt!=0) diff++; } if (diff==0) ans.add(0); for(int i=p.length();i&lt;s.length(); ++i){ // 处理左端字母减少 if(count[s.charAt(i-p.length())-'a']==1){ diff--; }else if(count[s.charAt(i-p.length())-'a']==0){ diff++; } count[s.charAt(i-p.length())-'a']--; // 处理右端字母增加 if(count[s.charAt(i)-'a']==-1){ diff--; }else if(count[s.charAt(i)-'a']==0){ diff++; } count[s.charAt(i)-'a']++; if (diff==0) ans.add(i-p.length()+1); //比较的优化 } return ans; }} 为了减少比较两个数组的遍历次数，我们维护一个diff变量表示两个数组中的差异数量。当diff为零，表示两个数组一摸一样。此时，可用一个数组count作为两个数组的差值，差值为零自然两个数组相同。 当窗口滑动时，我们知道右侧字母增加，左侧字母减少。右侧字母增加时，如果此位置差值为-1，那么窗口滑动的结果是使得此位置的差值为0，那么diff减少。 在收集答案时，只需判断一次diff是否为零。 最小窗口实战长度最小子数组https://leetcode.cn/problems/minimum-size-subarray-sum/ 1234567891011121314151617class Solution { public int minSubArrayLen(int target, int[] nums) { int windowCount = 0; int ans = Integer.MAX_VALUE; int l =0, r=0; while(r&lt;nums.length){ windowCount += nums[r]; while(windowCount&gt;=target){ ans = Math.min(ans, r-l+1); windowCount -= nums[l]; l++; } r++; } return ans==Integer.MAX_VALUE?0:ans; }} 最小滑动窗口入门题了，窗口内状态只需要用一个变量保存，然后在缩小窗口的过程中更新答案。 最小覆盖子串https://leetcode.cn/problems/minimum-window-substring/ （1）暴力解法 12345678910111213141516171819202122232425262728293031323334class Solution { public boolean isCovered(int[] s1, int[] s2){ for(int i=0; i&lt;s1.length; ++i) { if(s1[i]&lt;s2[i]) return false; } return true; } public int[] initMap(String s, int len){ int[] ret = new int[60]; for(int i=0; i&lt;len; ++i){ ret[s.charAt(i)-'A']++; } return ret; } public String minWindow(String s, String t) { if(s.length()&lt;t.length()) return &quot;&quot;; int l=0, r=0, record_l=0, record_r=s.length()+1; int[] tmap = initMap(t, t.length()); int[] window = new int[60]; while(r&lt;s.length()){ window[s.charAt(r)-'A']++; while(isCovered(window, tmap)){ //可优化 if(record_r-record_l &gt; r-l){ record_l = l; record_r = r; } window[s.charAt(l)-'A']--; l++; } r++; } return record_r==1+s.length()?&quot;&quot;:s.substring(record_l, record_r+1); }} （2）比较优化 12345678910111213141516171819202122232425262728293031class Solution { public int[] initMap(String s, int len){ int[] ret = new int[60]; for(int i=0; i&lt;len; ++i){ ret[s.charAt(i)-'A']--; } return ret; } public String minWindow(String s, String t) { if(s.length()&lt;t.length()) return &quot;&quot;; int l=0, r=0, record_l=0, record_r=s.length()+1; int[] window = initMap(t, t.length()); // window为窗口字母与t差值 int cover=0; // cover为window内字母大于等于0的个数 for(int win:window){if(win&gt;=0) cover++;} while(r&lt;s.length()){ if(window[s.charAt(r)-'A']==-1) cover++; //1.窗口扩张 window[s.charAt(r)-'A']++; while(cover==60){ //优化比较 if(record_r-record_l &gt; r-l){ record_l = l; record_r = r; } if(window[s.charAt(l)-'A']==0) cover--;//2.窗口缩小 window[s.charAt(l)-'A']--; l++; } r++; } return record_r==1+s.length()?&quot;&quot;:s.substring(record_l, record_r+1); }} 利用一个cover表示字母覆盖情况，那么每个位置都需要覆盖到，满足覆盖条件时cover==数组长度。 cover更新：窗口扩张，右侧位置为 -1时，cover增加；窗口缩小，左侧位置为0时，cover减小。 核心思想：维护比较的差异度！而不是每次重新比较，忽略了历史值的利用。 最大窗口实战无重复字符的最长子串 https://leetcode.cn/problems/longest-substring-without-repeating-characters/ 123456789101112131415161718class Solution { public int lengthOfLongestSubstring(String s) { int i=0,j=0,ans=0; Map&lt;Character, Integer&gt; map = new HashMap&lt;&gt;(); while(j&lt;s.length()){ char ch = s.charAt(j); map.put(ch ,map.getOrDefault(ch ,0)+1); while(map.get(ch)&gt;1){ //不满足条件就缩小窗口 char d_ch = s.charAt(i); map.put(d_ch ,map.getOrDefault(d_ch ,0)-1); i++; } ans = Math.max(ans, j-i+1); //满足条件后更新 j++; } return ans; }} 参考： 作者：labuladong链接：https://leetcode.cn/problems/find-all-anagrams-in-a-string/solutions/9749/hua-dong-chuang-kou-tong-yong-si-xiang-jie-jue-zi-/ 作者：HelloPGJC链接：https://leetcode.cn/problems/fruit-into-baskets/solutions/1437444/shen-du-jie-xi-zhe-dao-ti-he-by-linzeyin-6crr/","link":"/2023/12/21/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%95%B0%E7%BB%84%E4%B8%8E%E5%AD%97%E7%AC%A6%E4%B8%B2/Java%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/"},{"title":"动态规划","text":"笔记来自代码随想录，题目加自己题解。 动态规划五部曲 确定dp数组下标含义 确定递推公式（状态转移） dp数组初始化 确定遍历顺序 举例推导 一周目 基础题目 斐波那契数列 爬楼梯 https://leetcode.cn/problems/climbing-stairs/ 最小费爬楼梯 https://leetcode.cn/problems/min-cost-climbing-stairs/ 不同路径（左上角到右下角） https://leetcode.cn/problems/unique-paths/ 不同路径2（网格有障碍物） https://leetcode.cn/problems/unique-paths-ii/ 不同的二叉搜索树 https://leetcode.cn/problems/unique-binary-search-trees/ 二周目 背包问题只讲两个关键问题：01背包和完全背包。 两种dp数组：二维dp和一维dp（滚动数组、空间优化） 两种遍历方式：物品遍历和背包遍历；前向遍历和后向遍历。 01背包问题从最简单的01背包问题讲起。有n件物品和一个最多能背重量为w 的背包。第i件物品的重量是weight[i]，得到的价值是value[i] 。每件物品只能用一次，求解将哪些物品装入背包里物品价值总和最大。 dp[i][v]表示从前i（0～i）件物品中任意选取，装入容量为v的背包，能获得的最大价值。 123456789101112131415161718//第0件物品初始化for (int j = 0 ; j &lt; weight[0]; j++) //小于weight0的装不下 dp[0][j] = 0; for (int j = weight[0]; j &lt;= bagweight; j++) dp[0][j] = value[0];// 递归公式： dp[i][j] = max(dp[i - 1][j], dp[i - 1][j - weight[i]] + value[i]);// 前i件物品，选不选第i件// 先遍历物品再遍历背包for(int i = 1; i &lt; weight.size(); i++) { // 遍历物品，weight数组的大小 就是物品个数 for(int j = 0; j &lt;= bagweight; j++) { // 遍历背包容量 if (j &lt; weight[i]) dp[i][j] = dp[i - 1][j]; else dp[i][j] = max(dp[i - 1][j], dp[i - 1][j - weight[i]] + value[i]); }} 二维数组的空间优化：滚动数组可以从递推公式中看到，第i个物品的状态只与第i-1个物品的状态相关。 1234567891011121314151617181920212223//可以看成两层，上一层是历史状态，计算完dp[i][v]后dp[i-1][v]就再也用不到了，可以被覆盖//从右往左才不会影响到历史状态for (int i = 1; i &lt;= n; i++) { for (int v = V; v &gt;= w[i]; v--) { //必须逆序 dp[v] = max(dp[v],dp[v-w[i]] + c[i]); }}//代码随想录void test_1_wei_bag_problem() { vector&lt;int&gt; weight = {1, 3, 4}; vector&lt;int&gt; value = {15, 20, 30}; int bagWeight = 4; // 初始化 vector&lt;int&gt; dp(bagWeight + 1, 0); for(int i = 0; i &lt; weight.size(); i++) { // 遍历物品 for(int j = bagWeight; j &gt;= weight[i]; j--) { // 遍历背包容量 dp[j] = max(dp[j], dp[j - weight[i]] + value[i]); } } cout &lt;&lt; dp[bagWeight] &lt;&lt; endl;} 思考：能不能先遍历背包容量，再遍历物品呢？即改变两个for循环的位置 答案是不行，改变位置后，每个dp【j】只会放入价值最高的物品，只有一个物品。（j被i重复迭代，只会放入价值最高物品） 相关题目分割等和子集 https://leetcode.cn/problems/partition-equal-subset-sum/ 12345678910111213141516171819202122232425class Solution { public boolean canPartition(int[] nums) { int sum = 0; for(int num: nums) sum+=num; if(sum%2==1) return false; int bagWeight = sum/2; int[][] dp = new int[nums.length][bagWeight+1]; // 初始化 for(int j=0; j&lt;=bagWeight; ++j){ if(j&gt;=nums[0]) dp[0][j] = nums[0]; else dp[0][j] = 0; } for(int i=1; i&lt;nums.length; ++i){ for(int j=0; j&lt;=bagWeight; ++j){ if(j&lt;nums[i]) dp[i][j] = dp[i-1][j]; else dp[i][j] = Math.max(dp[i-1][j], dp[i-1][j-nums[i]]+nums[i]); } } // System.out.println(Arrays.deepToString(dp)); return dp[nums.length-1][bagWeight]==bagWeight? true:false; }} 背包容量为集合总和的一半，每个元素可以选取一次，就相当于01背包 第一次做有点抽象，细想，求背包能装的最大容量，肯定会遍历所有元素 最后一块石头的重量 https://leetcode.cn/problems/last-stone-weight-ii/ 1234567891011121314151617181920lass Solution { public int lastStoneWeightII(int[] stones) { // 分成尽可能相近的两堆 int sum = 0; for(int stone: stones) sum+=stone; int bagWeight = sum/2; int[][] dp = new int[stones.length][bagWeight+1]; for(int j=0; j&lt;=bagWeight; ++j) if(j&gt;=stones[0]) dp[0][j] = stones[0]; for(int i=1; i&lt;stones.length; ++i){ for(int j=0; j&lt;=bagWeight; ++j){ if(j &lt; stones[i]) dp[i][j] = dp[i-1][j]; else dp[i][j] = Math.max(dp[i-1][j], dp[i-1][j-stones[i]]+stones[i]); } } return sum-2*dp[stones.length-1][bagWeight]; }} 这题体现了循序渐进的作用了，如果没做分割等和子集这道题，可能想不到 实际上就是分为重量接近的两堆石头，两个石头相撞后大的石头还是留在原来那一堆 目标和 https://leetcode.cn/problems/target-sum/‘ 12345678910111213141516171819202122class Solution { public int findTargetSumWays(int[] nums, int target) { //dp[i][j] 表示i件东西装满j的背包有多少种装法 int sum = 0; for(int num: nums) sum+=num; if((sum+target)%2==1) return 0; if(sum &lt; Math.abs(target)) return 0; int bagWeight = (sum+target)/2; int[][] dp = new int[1+nums.length][bagWeight+1]; dp[0][0] = 1; //容量0的背包装0件物品，一种装法 for(int i=1; i&lt;= nums.length; ++i){ for(int j=0; j&lt;=bagWeight; ++j){ if(j&gt;=nums[i-1]) dp[i][j] = dp[i-1][j]+dp[i-1][j-nums[i-1]]; else dp[i][j] = dp[i-1][j]; } } System.out.println(Arrays.deepToString(dp)); return dp[nums.length][bagWeight]; }} 还是循序渐进的作用。初看题目？可能没什么思绪。其实还是分成两部分，一部分为+号，另一部分为-号，通过数学运算就能得出背包的容量 这道题不同的地方在于求数目。装满背包有多少种方法。 dp【j】 = dp【j】+dp【j-num【i】】 ，不选物品的方法数+选物品的方法数 一和零 https://leetcode.cn/problems/ones-and-zeroes/ 1234567891011121314151617181920212223242526272829303132class Solution { public int zeros(String s){ int count = 0; for(int i=0; i&lt;s.length(); ++i) if(s.charAt(i) == '0') count++; return count; } public int ones(String s){ int count = 0; for(int i=0; i&lt;s.length(); ++i) if(s.charAt(i) == '1') count++; return count; } public int findMaxForm(String[] strs, int m, int n) { // 三维背包-&gt; 二维做法 int[][] dp = new int[1+m][1+n]; int oneNum = ones(strs[0]); int zeroNum = zeros(strs[0]); // for(int i = zeroNum; i&lt;=m; ++i) // for(int j= oneNum; j&lt;=n; ++j) // dp[i][j] = 1; for(int k=0; k&lt;strs.length; ++k){ int onex = ones(strs[k]); int zerox = zeros(strs[k]); for(int i=m; i&gt;=zerox; --i) for(int j=n; j&gt;=onex; --j) dp[i][j] = Math.max(dp[i][j], 1+dp[i-zerox][j-onex]); } System.out.println(Arrays.deepToString(dp)); return dp[m][n]; }} 这道题相当于两个维度的背包，0的个数是一个维度，1的个数是一个维度 又因为一个字符串是一起放入的，所以状态转移的时候少了很多状态 dp[i][j] = max(dp[i][j], dp[i - zeroNum][j - oneNum] + 1); 完全背包问题在完全背包问题中，每种物品有无限个，可以无限选取。写成二维形式的话，取了i件物品还能再取。求将哪些物品装入背包里物品价值总和最大。 dp[i][v] = max(dp[i-1][v], dp[i][i-w[i]]+c[i]) 简化为 一维形式的话，公式和01背包一摸一样，不同的是正向枚举。 12345for (int i = 1; i &lt;= n; i++) { for (int v = w[i]; v &lt;=V; v++) { dp[v] = max(dp[v], dp[v - w[i]] + c[i]; }} 理解正向枚举： 在完全背包中，对于一维dp数组来说，其实两个for循环嵌套顺序是无所谓的！ 12345678// 先遍历背包，再遍历物品for(int j = 0; j &lt;= bagWeight; j++) { // 遍历背包容量 for(int i = 0; i &lt; weight.size(); i++) { // 遍历物品 if (j - weight[i] &gt;= 0) dp[j] = max(dp[j], dp[j - weight[i]] + value[i]); } cout &lt;&lt; endl;} 相关题目组合总和 https://leetcode.cn/problems/combination-sum-iv/ 完全背包，求装满背包有多少种排列数 不妨换个角度考虑，看看爬楼梯这道题 https://leetcode.cn/problems/climbing-stairs/ 123456for(int i=1; i&lt;target; ++i){ for(int num:nums){ if(i-num&gt;=0) dp[i] = dp[i] + dp[i-num]; }} 初始时，dp[i]为0，dp[i-num]可以看成最后一步跳num步台阶到达第i阶楼梯的方法数，这样就保证了分成的子问题互相不重叠。 零钱兑换 https://leetcode.cn/problems/coin-change-ii/description/ 标准的完全背包，但不同的是求装满背包的组合数 该怎么办呢？先遍历物品再遍历背包！ 先遍历物品保证了背包装入物品的顺序性，怎么理解？ 比如遍历到第i个物品的时候，我们看转移方程 12345for (int i = 0; i &lt; coins.size(); i++) { // 遍历物品 for (int j = coins[i]; j &lt;= amount; j++) { // 遍历背包容量 dp[j] = dp[j] + dp[j - coins[i]]; }} 转移方程的后半部分保证了在背包容量为j时，dp[j] + dp[j - coins[i]] 是由0。。。i-1等物品组成背包方法数。 完全平方数 https://leetcode.cn/problems/perfect-squares/ 给定正整数 n，找到若干个完全平方数（比如 1, 4, 9, 16, …）使得它们的和等于 n。你需要让组成和的完全平方数的个数最少。 完全背包问题，但是要求最少数量，因此要初始化为INT MAX 1234567891011121314class Solution { public int numSquares(int n) { // n 是背包容量， sqrt（n）是物品个数 int[] dp = new int[1+n]; Arrays.fill(dp, Integer.MAX_VALUE); dp[0] = 0; for(int i=1; i&lt;=n; ++i){ for(int j=1; j*j&lt;=i; ++j){ dp[i] = Math.min(dp[i], 1+dp[i-j*j]); } } return dp[n]; }} 单词拆分 https://leetcode.cn/problems/word-break/ 1234567891011121314151617class Solution { public boolean wordBreak(String s, List&lt;String&gt; wordDict) { boolean[] dp = new boolean[s.length()+1]; dp[0] = true; for(int i=1; i&lt;=s.length(); ++i){ for(String word : wordDict){ if(word.length() &lt;= i){ String postfix = s.substring(i-word.length(), i); if(postfix.equals(word)){ dp[i] = dp[i] || dp[i-word.length()]; } } } } return dp[s.length()]; }} 拆分时可以重复使用字典中的单词，说明就是一个完全背包！ 先遍历物品，再遍历背包 回溯法记忆搜索，待做//todo 三周目 打家劫舍+股票问题打家劫舍系列问题打家劫舍1 https://leetcode.cn/problems/house-robber/ 123456789101112class Solution { public int rob(int[] nums) { int[] dp = new int[nums.length]; if(nums.length&lt;=1) return nums[0]; dp[0] = nums[0]; dp[1] = Math.max(nums[0], nums[1]); for(int i=2; i&lt;nums.length; ++i){ dp[i] = Math.max(dp[i-1], dp[i-2]+nums[i]); } return dp[nums.length-1]; }} 只能隔着一家偷，因此 dp[i] = max(dp[i - 2] + nums[i], dp[i - 1]); 打家劫舍2 https://leetcode.cn/problems/house-robber-ii/ 123456789101112131415161718class Solution { public int robRange(int[] nums, int l, int r){ int[] dp = new int[nums.length]; dp[l] = nums[l]; dp[l+1] = Math.max(nums[l], nums[l+1]); for(int i=l+2; i&lt;r; ++i){ dp[i] = Math.max(dp[i-1], dp[i-2]+nums[i]); } return dp[r-1]; } public int rob(int[] nums) { if(nums.length==1) return nums[0]; if(nums.length==2) return Math.max(nums[0], nums[1]); int a1 = robRange(nums, 1, nums.length); // 不偷起始家 int a2 = robRange(nums, 0, nums.length-1); // 不偷最后一家 return Math.max(a1, a2); }} 环形队列，考虑偷的起始点。假设编号为0、1、2..N，那么偷第0家后，第N家必定不能偷，问题可以转为为0到N-1的打家劫舍问题。 同样地，由于第0家可偷可不偷，不偷第0家，问题就是1到N的打家劫舍问题。 打家劫舍3 https://leetcode.cn/problems/house-robber-iii/ （1）记忆化搜索 12345678910111213141516class Solution { public Map&lt;TreeNode, Integer&gt; map = new HashMap&lt;&gt;(); public int rob(TreeNode root) { if(root==null) return 0; if(map.containsKey(root)) return map.get(root); // 取root节点的值 int ans1 = root.val; if(root.left!=null) ans1+= rob(root.left.left)+rob(root.left.right); if(root.right!=null) ans1+= rob(root.right.left)+rob(root.right.right); // 不取root节点的值 int ans2 = rob(root.left) + rob(root.right); int ans = Math.max(ans1, ans2); map.put(root, ans); return ans; }} 基于数组的DP往往是线性的，而树形状的DP还是利用函数递归+记忆化搜索更合适。 （2）优化-树形DP 1234567891011121314151617class Solution { public int[] dpTree(TreeNode root){ int[] ans = new int[2]; // 两种状态，偷与不偷 if(root==null) return new int[]{0,0}; int[] left = dpTree(root.left); int[] right = dpTree(root.right); // 不偷root ans[0] = Math.max(left[0], left[1]) + Math.max(right[0], right[1]); // 偷root ans[1] = left[0]+right[0]+root.val; return ans; } public int rob(TreeNode root) { int[] ans = dpTree(root); return Math.max(ans[0], ans[1]); }} 这种写法将偷与不偷这两种状态合在一个数组中，然后在自底向上的更新。这是树形DP的技巧，见动态规划进阶。 买卖股票问题买卖股票问题引入了状态转移，需要画图辅佐思路。 买卖股票的最佳时机1 https://leetcode.cn/problems/best-time-to-buy-and-sell-stock/ 123456789101112131415class Solution { public int maxProfit(int[] prices) { int[][] dp = new int[prices.length][3]; dp[0][0] = 0; //不持有股票的最大现金 dp[0][1] = -prices[0]; //首次持有股票的最大现金 dp[0][2] = 0; //首次卖出的最大现金 for(int i=1; i&lt;prices.length; ++i){ dp[i][0] = dp[i-1][0]; dp[i][1] = Math.max(dp[i-1][1], dp[i-1][0]-prices[i]); dp[i][2] = Math.max(dp[i-1][2], dp[i-1][1]+prices[i]); } // System.out.println(Arrays.deepToString(dp)); return dp[prices.length-1][2]; }} 本题限制只能买卖股票一次，因此卖出股票后就不能再继续操作。 每一天引入三种状态：不持有股票、持有股票、首次卖出股票。每种状态具有几种操作，每种操作又能把第k天的状态变为第k+1天的状态。 买卖股票的最佳时机2 https://leetcode.cn/problems/best-time-to-buy-and-sell-stock-ii/ （1）动态规划解法 12345678910111213class Solution { public int maxProfit(int[] prices) { int[][] dp = new int[prices.length][2]; dp[0][0] = -prices[0]; //第k天必定持有股票时最大现金，股票可以在前k天买入一次 dp[0][1] = 0; //第k天不持有股票的最大现金 for(int i=1; i&lt;prices.length; ++i){ dp[i][0] = Math.max(dp[i-1][0], dp[i-1][1]-prices[i]); //不做操作、买入操作 dp[i][1] = Math.max(dp[i-1][1], dp[i-1][0]+prices[i]); // 不做操作、卖出操作 } // System.out.println(Arrays.deepToString(dp)); return dp[prices.length-1][1]; }} 只有两种状态：不持有股票、持有股票。 （2）贪心解法 12345678910111213141516class Solution { public int maxProfit(int[] nums) { // 当天买，如果第二天价格高就卖，否则换成第二天买 int hold = nums[0]; int ans = 0; for(int i=1; i&lt;nums.length; ++i){ if(nums[i]&gt;hold){ ans += nums[i]-hold; hold = nums[i]; }else if(nums[i]&lt; hold){ hold = nums[i]; } } return ans; }} 买卖股票的最佳时机3 https://leetcode.cn/problems/best-time-to-buy-and-sell-stock-iii/ 123456789101112131415161718class Solution {public: int maxProfit(vector&lt;int&gt;&amp; prices) { vector&lt;vector&lt;int&gt;&gt; dp(prices.size(), vector&lt;int&gt;(5, 0)); dp[0][1] = -prices[0]; // 一次操作持有股票 dp[0][2] = 0; //一次操作卖出股票 dp[0][3] = dp[0][2] - prices[0]; //二次操作持有股票，注意这里 dp[0][4] = 0; // 二次操作卖出股票 for(int i=1; i&lt;prices.size(); ++i){ dp[i][0] = dp[i-1][0]; dp[i][1] = max(dp[i-1][1], dp[i-1][0] - prices[i]); dp[i][2] = max(dp[i-1][2], dp[i-1][1] + prices[i]); dp[i][3] = max(dp[i-1][3], dp[i-1][2] - prices[i]); dp[i][4] = max(dp[i-1][4], dp[i-1][3] + prices[i]); } return dp[prices.size()-1][4]; }}; 这道题限制最多买卖两次。 五种状态：不持有股票，首次持有股票、首次卖出股票、第二次持有股票、第二次卖出股票； 注意二次持有股票时的初始化与一次持有一样，这是为了收集答案时，获得最大收益时，出售股票不一定恰好是两次。 买卖股票的最佳时机4 https://leetcode.cn/problems/best-time-to-buy-and-sell-stock-iv/ 引入2k+1种状态 买卖股票的最佳时机5 https://leetcode.cn/problems/best-time-to-buy-and-sell-stock-with-cooldown/ 12345678910111213class Solution { public int maxProfit(int[] prices) { int N = prices.length; int[][] dp = new int[N][4]; dp[0][1] = -prices[0]; for(int i=1; i&lt;prices.length; ++i){ dp[i][0] = Math.max(dp[i-1][0], dp[i-1][3]); dp[i][1] = Math.max(dp[i-1][1], Math.max(dp[i-1][0]-prices[i], dp[i-1][3]-prices[i])); dp[i][2] = dp[i-1][1]+prices[i]; dp[i][3] = dp[i-1][2]; } return Math.max(dp[N-1][2], Math.max(dp[N-1][3], dp[N-1][0])); } 有四种状态：不持有股票、持有股票、冷冻期、自由期 每种状态都是自身描述，由当前天的操作转移到第二天的状态。因此持有股票当前天卖出，第二天为冷冻期。冷冻期无操作第二天是自由期。 买卖股票含手续费 https://leetcode.cn/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/ 没啥好说的，同买股票2 画出状态转移图，一切不在话下！ 四周目 字符串dp子串、子序列、编辑距离、回文串 子串和子序列问题kanade算法 求最大子串和 最长递增子序列 https://leetcode.cn/problems/longest-increasing-subsequence/ 最长递增子串 https://leetcode.cn/problems/longest-continuous-increasing-subsequence/ 最长递增子序列的个数 https://leetcode.cn/problems/number-of-longest-increasing-subsequence/ 这题比较难，要利用两个数组，一个记录长度、一个记录个数 最大子串和 https://leetcode.cn/problems/maximum-subarray/ 最大子序列和（就是选正数） 最长公共子序列 https://leetcode.cn/problems/longest-common-subsequence/ 最长公共子数组 https://leetcode.cn/problems/maximum-length-of-repeated-subarray/ 最长公共子串 https://www.nowcoder.com/practice/f33f5adc55f444baa0e0ca87ad8a6aac 1234567891011121314151617181920public class Solution { public String LCS (String str1, String str2) { int[][] dp = new int[1+str1.length()][1+str2.length()]; int len = 0; int start = -1; //dp[0][0] = 1; for(int i=1; i&lt;=str1.length(); ++i){ for(int j=1; j&lt;=str2.length(); ++j){ if(str1.charAt(i-1)==str2.charAt(j-1)){ dp[i][j] = 1 + dp[i-1][j-1]; } if(dp[i][j] &gt; len){ len = dp[i][j]; start = i - len; } } } return str1.substring(start, start+len); }} dpij不能简单的设置为以i，j结尾两个字符串的最长公共子串长度，因为不知道这个公共子串的开始位置和结束位置。所以要设置为公共子串恰好以ij结尾。不匹配的话dpij就是0。 编辑距离系列判断子序列 https://leetcode.cn/problems/is-subsequence/ 给定字符串 s 和 t ，判断 s 是否为 t 的子序列。 1234567891011121314class Solution { public boolean isSubsequence(String s, String t) { int[][] dp = new int[1+s.length()][1+t.length()]; for(int i=1; i&lt;=s.length(); ++i){ for(int j=1; j&lt;=t.length(); ++j){ if(s.charAt(i-1) == t.charAt(j-1)) dp[i][j] = 1 + dp[i-1][j-1]; else dp[i][j] = dp[i][j-1]; } } return dp[s.length()][t.length()]==s.length(); }} 本题最好的解法是双指针，子序列只要求顺序一致，两个指针分别遍历一边s和t，时间复杂度在O（n+m）。 但为了编辑距离的抛砖引玉，确定dp数组的含义：dp[i][j] 表示以下标i-1为结尾的字符串s，和以下标j-1为结尾的字符串t，相同子序列的长度 以及递推公式的含义： if (s[i - 1] == t[j - 1]) t中找到了一个字符在s中也出现了（这相当于从后向前匹配） if (s[i - 1] != t[j - 1]) 相当于t要删除元素，继续匹配 最难理解的就是s[i - 1] == t[j - 1])的情况，其实是从后向前匹配！ 时间复杂度：O(n × m) 空间复杂度：O(n × m) 不同的子序列https://leetcode.cn/problems/distinct-subsequences/ 123456789101112131415161718class Solution { public int numDistinct(String s, String t) { int[][] dp = new int[1+s.length()][1+t.length()]; for(int i=0; i&lt;=s.length(); ++i) dp[i][0] = 1; // for(int j=0; j&lt;=t.length(); ++j) // dp[0][j]=0; for(int i=1; i&lt;=s.length(); ++i){ for(int j=1; j&lt;=t.length(); ++j){ if(s.charAt(i-1) == t.charAt(j-1)) dp[i][j] = dp[i-1][j] + dp[i-1][j-1]; else dp[i][j] = dp[i-1][j]; } } return dp[s.length()][t.length()]; }} dp数组的含义仍然：dp[i][j] 表示以下标i-1为结尾的字符串s，和以下标j-1为结尾的字符串t，相同子序列的长度 不过不同的是si与tj匹配成功后，tj其实有两种匹配方法：匹配最后一个，或者最后一个不匹配，向sj-1匹配。 对应 dp[i][j] = dp[i-1][j] + dp[i-1][j-1];，小例子：s=babgba，t=b 特别要注意的是初始化的过程：dp【i】【0】全都为1，因为0自然匹配成功。 两个字符串的删除https://leetcode.cn/problems/delete-operation-for-two-strings/ 123456789101112131415161718class Solution { public int minDistance(String s, String t) { int[][] dp = new int[1+s.length()][1+t.length()]; for(int i=0; i&lt;=s.length(); ++i) dp[i][0] = i; for(int j=0; j&lt;=t.length(); ++j) dp[0][j] = j; for(int i=1; i&lt;=s.length(); ++i){ for(int j=1; j&lt;=t.length(); ++j){ if(s.charAt(i-1) == t.charAt(j-1)) dp[i][j] = dp[i-1][j-1]; else dp[i][j] = 1 + Math.min(dp[i-1][j], dp[i][j-1]); } } return dp[s.length()][t.length()]; }} dp数组仍然是题目中的含义。让我们想一想失配的含义，自然是删除s中的一个，然后去与t匹配，或者删除t中的一个去与s匹配。对应 dp[i][j] = 1 + Math.min(dp[i-1][j], dp[i][j-1]); 匹配成功时，由于能够删除任意一个字符串的中一个字符，直接忽略这个字符就好了。 编辑距离https://leetcode.cn/problems/edit-distance/ 123456789101112131415161718192021class Solution { public int minDistance(String s, String t) { int[][] dp = new int[1+s.length()][1+t.length()]; for(int i=0; i&lt;=s.length(); ++i) dp[i][0] = i; for(int j=0; j&lt;=t.length(); ++j) dp[0][j] = j; for(int i=1; i&lt;=s.length(); ++i){ for(int j=1; j&lt;=t.length(); ++j){ if(s.charAt(i-1) == t.charAt(j-1)) dp[i][j] = dp[i-1][j-1]; else{ dp[i][j] = Math.min(dp[i-1][j], dp[i][j-1]); dp[i][j] = Math.min(dp[i][j], dp[i-1][j-1]); dp[i][j] ++; // 删除、替换操作 } } } return dp[s.length()][t.length()]; }} 虽然三种操作看着吓人，但仔细想想，增加操作就等价于删除（为什么？） 仍然考虑失配场景：si与tj匹配不成功。 替换操作：将si与tj替换为相同的字母，找下一步s[i-1]和t[i-1] 删除操作：删除si或tj，对应找dp[i-1][j], dp[i][j-1]) 增加操作；我在si处增加一个字母，那么接下来怎么匹配？自然是si与ti-1匹配，因为ti已经匹配了。这不就是相当于删除ti吗？ 明白这点后，题目也就不难了。 回文串回文串就要利用回文串的性质，左右对称，因此可以从中间展开，也有双指针的解法。 回文子串https://leetcode.cn/problems/palindromic-substrings/ 给定一个字符串，你的任务是计算这个字符串中有多少个回文子串。 1234567891011121314151617181920class Solution { public int countSubstrings(String s) { int N = s.length(); int ans = 0; boolean[][] dp = new boolean[N][N]; // dp[i][j] means s[i] to s[j] is phadorme for(int i=0; i&lt;N; ++i){ for(int j=0; j&lt;=i; ++j){ if(s.charAt(i) == s.charAt(j)){ if(i-j&lt;=1) dp[j][i] = true; else dp[j][i] = dp[j+1][i-1]; } if(dp[j][i]) ans++; } } return ans; }} 最长回文子串 https://leetcode.cn/problems/longest-palindromic-substring/description/ 给你一个字符串 s，找到 s 中最长的回文子串。 (1)动态规划（常规写法） 1234567891011121314151617181920212223class Solution { public String longestPalindrome(String s) { int l=0,r=0; int N = s.length(); boolean[][] dp = new boolean[N][N]; //dp[j][i] 表示j, i间为回文字符串 for(int i=0; i&lt;N; ++i){ for(int j=0; j&lt;=i; ++j){ if(s.charAt(i)==s.charAt(j)){ if(i-j&lt;=1) dp[j][i] = true; else dp[j][i] = dp[j+1][i-1]; } if(dp[j][i] &amp;&amp; i- j&gt; r-l){ // 长度大于之前的 l = j; r = i; } } } return s.substring(l, r+1); }} (2)动态规划（以长度遍历，更容易理解的写法） 12345678910111213141516171819class Solution { public String longestPalindrome(String s) { int l=0,r=0; int N = s.length(); boolean[][] dp = new boolean[N][N]; for(int len=1; len&lt;=N; ++len){ for(int i=0; i&lt;N &amp;&amp; i+len-1&lt;N; ++i){ int j = i+len-1; // 从i开始，长度为len的串 if(s.charAt(i) == s.charAt(j)) dp[i][j] = (i==j) || (i+1==j) || dp[i+1][j-1]; if(dp[i][j] &amp;&amp; j-i&gt;r-l){ r = j; l = i; } } } return s.substring(l, r+1); }} (3)双指针（空间效率O（1）的解法） 123456789101112131415161718192021222324252627282930class Solution { public int[] find(String s, int l, int r){ while((l-1&gt;=0) &amp;&amp; (r+1&lt;s.length()) &amp;&amp; (s.charAt(l-1)==s.charAt(r+1))){ --l; ++r; } int r_l = l; int r_r = r; return new int[]{r_l, r_r}; } public String longestPalindrome(String s) { int l=0, r=0; for(int i=0; i&lt;s.length(); ++i){ int[] odd = find(s, i, i); //奇数长度回文串 int[] even = {0,0}; if(i+1&lt; s.length() &amp;&amp; s.charAt(i)==s.charAt(i+1)) even = find(s, i, i+1); // 偶数长度回文串 if(r-l &lt; odd[1]-odd[0]){ l = odd[0]; r = odd[1]; } if(r-l &lt; even[1]-even[0]){ l = even[0]; r = even[1]; } } return s.substring(l, r+1); }} 注意：substring函数是从l到r，最后一个索引不包含。 最长回文子序列 https://leetcode.cn/problems/longest-palindromic-subsequence/ 给定一个字符串 s ，找到其中最长的回文子序列，并返回该序列的长度。 分割回文串的最小次数 https://leetcode.cn/problems/palindrome-partitioning-ii/ 12345678910111213141516171819202122232425262728293031323334class Solution {public: int minCut(string s) { //dp[i] means samllest segment times vector&lt;int&gt; dp(s.size(), 0); for(int i=0; i&lt;s.size(); ++i) dp[i]=i; // precaculate the whole string vector&lt;vector&lt;int&gt;&gt; ispalindromic(s.size(), vector&lt;int&gt;(s.size(), 0)); //打表记录i，j是否是回文子串，也是动态规划的体现 for (int i = s.size()-1; i&gt;=0; --i){ for (int j = i; j &lt; s.size(); ++j){ if(s[i]==s[j]){ if(j-i&lt;=1) ispalindromic[i][j]=1; else ispalindromic[i][j] = ispalindromic[i+1][j-1]; } } } } //递推进行 for(int i=1;i&lt;s.size();++i){ if(ispalindromic[0][i]){ dp[i]=0; continue; }else{ for(int j=0;j&lt;i;j++){ if(ispalindromic[j+1][i]) dp[i] = min(dp[i], 1+dp[j]); } } } return dp[s.size()-1]; }};","link":"/2024/05/30/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/Java%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"title":"动态规划入门","text":"本节内容来自《算法笔记》-胡凡，属于动态规划入门内容。 从斐波那契数列谈起从斐波那契数列的递归图中可以看到重叠子问题被计算多次。 从上图中可以看到，黑色部分被计算多次。我们可以开辟一个数组，记录下第一次计算问题的解，然后再次遇到时，直接查表。这其实就是一种缓存的思想。 动态规划，最重要的是问题可重复利用（重叠子问题，如果子问题互不相交，那么不能重复利用）。 动态规划与记忆化搜索二者本质是一样的，动态规划利用新开辟的数组记录子问题的解，从而达到记忆化的效果。 从数塔问题看起 https://leetcode.cn/problems/triangle/ 自顶向下思路仔细思考，数塔的形状是否和斐波那契递归图很像？如果令dp[i][j]表示从第i行第j列数字到最底部的最小路径，那么就有dp[i][j] = min(dp[i+1][j], dp[i+1][j+1]) + triangle[i][j]。 第i层的状态依赖于i+1层，这样就引出来状态转移这个名词。 同时容易想到dp数组的初始化边界，最后一层当然是它自己。最后求解的问题答案就是dp[1][1] 12345678910111213141516class Solution { public int minimumTotal(List&lt;List&lt;Integer&gt;&gt; triangle) { //自下而上的自顶向下计算 //dp[i][j] 表示从i，j到根部的最短距离 int N = triangle.size(); int[][] dp = new int[N][N]; for(int i=0; i&lt;triangle.get(N-1).size(); ++i) dp[N-1][i] = triangle.get(N-1).get(i); for(int i=N-2; i&gt;=0; --i){ for(int j=0; j&lt;triangle.get(i).size(); ++j){ dp[i][j] = Math.min(dp[i+1][j], dp[i+1][j+1]) + triangle.get(i).get(j); } } return dp[0][0]; }} 自底向上思路分治+递归。 此时dp[i][j]不能直接求解答案，而是子问题的解。 注意：这里的分治并不是严格意义上的分治，分治法要求子问题不重叠，我这里只是借助分治的意思。 最后要经历诸如 $min(dp[0], dp[1], …, dp[N])$ 的步骤，即收集子问题的解来解决原问题。 123456789101112131415161718192021222324class Solution { public int minimumTotal(List&lt;List&lt;Integer&gt;&gt; triangle) { //dp[i][j] 表示从00到ij的最小路径和 int N = triangle.size(); int[][] dp = new int[N][N]; dp[0][0] = triangle.get(0).get(0); for(int i=1; i&lt;N; ++i){ int i_length = triangle.get(i).size()-1; int i_minus_length = triangle.get(i-1).size()-1; dp[i][0] = dp[i-1][0] + triangle.get(i).get(0); dp[i][i_length] = dp[i-1][i_minus_length] + triangle.get(i).get(i_length); } for(int i=1; i&lt;N; ++i){ for(int j=1; j&lt;triangle.get(i).size()-1; ++j){ dp[i][j] = Math.min(dp[i-1][j], dp[i-1][j-1])+triangle.get(i).get(j); // 这里j=1，i=1时存疑，其实是恰好没计算，j=1不满足判断条件 } } int ans = dp[N-1][0]; for(int j=1; j&lt;triangle.get(N-1).size(); ++j){ ans = Math.min(ans, dp[N-1][j]); } return ans; }} 最优子结构通过这个问题再次引出一个名词 最优子结构， 即原问题的最优解可以由子问题的最优解推导出来。 动态规划解决的问题必须是拥有重叠子问题和最优子结构。分治法解决的问题是不重叠的。 123456总结：动态规划的主要步骤1. 设计dp数组含义2. 找到递推公式3. 初始化4. 递推，并找出答案 例题最大连续子序列和 https://leetcode.cn/problems/lian-xu-zi-shu-zu-de-zui-da-he-lcof/ https://leetcode.cn/problems/maximum-subarray/description/ 12345678910111213class Solution { public int maxSubArray(int[] nums) { int[] dp = new int[nums.length]; dp[0] = nums[0]; int ans = dp[0]; for(int i=1; i&lt;nums.length; ++i){ // dp[i] = Math.max(dp[i-1]+nums[i], nums[i]); dp[i] = Math.max(dp[i-1], 0) + nums[i]; ans = Math.max(ans, dp[i]); } return ans; }} 这道题属于连续子串的问题。还是上面的思路：分治+动规。 dp[i]表示以i结尾的连续子数组的最大和。 那么dp[i]就有两种思路：要么和前面一起组成连续子串，要么自己单独成立连续子串。 123dp[i] = max{A[i], dp[i-1] + A[i]};//初始化也很容易dp[0] = A[0]; 最后还要收集子问题的解。 1max(dp[0], dp[1], ..., dp[N]) 最长不下降子序列 https://leetcode.cn/problems/longest-continuous-increasing-subsequence/ 123456789101112class Solution { public int findLengthOfLCIS(int[] nums) { int[] dp = new int[nums.length]; dp[0] = 1; int ans = 1; for(int i=1; i&lt;nums.length; ++i){ dp[i] = nums[i]&gt;nums[i-1]?(dp[i-1]+1):1; ans = Math.max(ans, dp[i]); } return ans; }} 这道题属于子序列的问题。还是上面的思路：分治+动规。 dp[i]表示以i结尾的最长不下降子序列。由于是子序列，不要求连续，那么第i个元素就可以和先前i-1个元素进行比较，整体复杂度$O(N^2)$ 对比，最长连续不下降子序列 https://leetcode.cn/problems/longest-continuous-increasing-subsequence/description/ 最长公共子序列 https://leetcode.cn/problems/longest-common-subsequence/ 123456789101112class Solution { public int findLengthOfLCIS(int[] nums) { int[] dp = new int[nums.length]; dp[0] = 1; int ans = 1; for(int i=1; i&lt;nums.length; ++i){ dp[i] = nums[i]&gt;nums[i-1]?(dp[i-1]+1):1; ans = Math.max(ans, dp[i]); } return ans; }} 求两个字符串的最长公共部分。两个字符串，容易想到二维dp数组。 dp[i][j]表示的是以第i个字符结尾的第一个字符串和以第j个字符结尾的第二个字符串之间的最长公共子序列的长度。 类似：最长重复子数组 https://leetcode.cn/problems/maximum-length-of-repeated-subarray/ 最长回文子串 https://leetcode.cn/problems/longest-palindromic-substring/description/ 这道题有些不一样了，虽然是单个字符串，但是用一维dp数组反而不好解题。 考虑dp[i][j],表示第i个字符到第j个字符之间表示的字符串是否为回文串。 注意：这里经过两层抽象，一层是二维dp，另一层二维dp不是直接求解问题（它表示的区间字符串是否是回文串，而不是说当前区间的最长的回文串的长度），相当于前述的分治+动规 通过考虑区间长度的问题进行遍历，这其实又是一层抽象，不容易想到。 123456789101112131415161718192021222324252627282930313233343536373839class Solution { public String longestPalindrome(String s) { //dp[i][j] 表示i，j之间为回文字符串 int l=-1,r=-1,maxLen=-1; int N = s.length(); int[][] dp = new int[N][N]; for(int i=0; i&lt;N; ++i){ //长度1的回文串初始化 dp[i][i] = 1; l = i; r = i; }s for(int i=0; i&lt;N-1; ++i){ //长度2回文串初始化 if(s.charAt(i) == s.charAt(i+1)){ dp[i][i+1] = 1; l = i; r = i+1; } } for(int len=2; len&lt;N; ++len){ for(int i=0; i&lt;N-len; ++i){ if(s.charAt(i) == s.charAt(i+len)){ dp[i][i+len] = dp[i+1][i+len-1]==1? 1:0; } else{ dp[i][i+len] = 0; } if(dp[i][i+len]==1){ if(len+1 &gt; maxLen){ maxLen = len+1; l = i; r = i+len; } } } } // System.out.println(Arrays.deepToString(dp)); return s.substring(l, r+1); }} 对比，最长回文子序列 https://leetcode.cn/problems/longest-palindromic-subsequence/ 背包问题背包和完全背包，重中之重。见动态规划进阶。 总结字符串dp的套路 字符串问题涉及两个概念：子串和子序列一般来说，子串是连续的，子序列是不连续的。如此，一种题可以出两道。 最大子串和 最大子序列和（其实就是选正数） 最长不下降子串 最长不下将子序列 最长公共子串 最长公共子序列 最长回文子串 最长回文子序列 字符串dp设计的套路当题目与子序列或子串相关时，可以考虑一下dp的设计 （1）一维dp 令dp[i]表示以s[i]结尾或开头的xxxx dp[i]表示字符串前i个的性质 前者限定问题求解必须包含第i个元素，后面不作限定，只需要利用前i个元素求解即可。 （2）二维dp涉及两个字符串 令dp[i][j]表示以s[i]结尾，以t[j]结尾的xxx （3）二维dp只涉及一个字符串，比如求回文串 令dp[i][j]表示s[i]至s[j]区间的xxx","link":"/2024/05/30/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/Java%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E5%85%A5%E9%97%A8/"}],"tags":[{"name":"分布式系统","slug":"分布式系统","link":"/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"},{"name":"数据库","slug":"数据库","link":"/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"双指针","slug":"双指针","link":"/tags/%E5%8F%8C%E6%8C%87%E9%92%88/"},{"name":"转载","slug":"转载","link":"/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"CSAPP","slug":"CSAPP","link":"/tags/CSAPP/"},{"name":"动态规划","slug":"动态规划","link":"/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"贪心","slug":"贪心","link":"/tags/%E8%B4%AA%E5%BF%83/"},{"name":"前缀和","slug":"前缀和","link":"/tags/%E5%89%8D%E7%BC%80%E5%92%8C/"},{"name":"哈希","slug":"哈希","link":"/tags/%E5%93%88%E5%B8%8C/"},{"name":"二分法","slug":"二分法","link":"/tags/%E4%BA%8C%E5%88%86%E6%B3%95/"},{"name":"滑动窗口","slug":"滑动窗口","link":"/tags/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/"}],"categories":[{"name":"C++","slug":"C","link":"/categories/C/"},{"name":"MIT6.824","slug":"MIT6-824","link":"/categories/MIT6-824/"},{"name":"cmu15445","slug":"cmu15445","link":"/categories/cmu15445/"},{"name":"后端开发","slug":"后端开发","link":"/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"},{"name":"工具学习","slug":"工具学习","link":"/categories/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/"},{"name":"数据结构与算法","slug":"数据结构与算法","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"生活哲学","slug":"生活哲学","link":"/categories/%E7%94%9F%E6%B4%BB%E5%93%B2%E5%AD%A6/"},{"name":"网站搭建","slug":"网站搭建","link":"/categories/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/"},{"name":"计算机工程","slug":"计算机工程","link":"/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%B7%A5%E7%A8%8B/"},{"name":"操作系统","slug":"操作系统","link":"/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"MIT6.S081","slug":"MIT6-S081","link":"/categories/MIT6-S081/"},{"name":"数组与字符串","slug":"数据结构与算法/数组与字符串","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%95%B0%E7%BB%84%E4%B8%8E%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"name":"lab","slug":"cmu15445/lab","link":"/categories/cmu15445/lab/"},{"name":"Redis","slug":"后端开发/Redis","link":"/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/Redis/"},{"name":"muduo网络库","slug":"后端开发/muduo网络库","link":"/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/muduo%E7%BD%91%E7%BB%9C%E5%BA%93/"},{"name":"设计模式","slug":"后端开发/设计模式","link":"/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"GDB","slug":"工具学习/GDB","link":"/categories/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/GDB/"},{"name":"Git","slug":"工具学习/Git","link":"/categories/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/Git/"},{"name":"Vim","slug":"工具学习/Vim","link":"/categories/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/Vim/"},{"name":"xv6book","slug":"MIT6-S081/xv6book","link":"/categories/MIT6-S081/xv6book/"},{"name":"命令行","slug":"工具学习/命令行","link":"/categories/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/%E5%91%BD%E4%BB%A4%E8%A1%8C/"},{"name":"数据库","slug":"数据库","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"单题题解","slug":"数据结构与算法/单题题解","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E5%8D%95%E9%A2%98%E9%A2%98%E8%A7%A3/"},{"name":"lab","slug":"MIT6-S081/lab","link":"/categories/MIT6-S081/lab/"},{"name":"IDE","slug":"工具学习/IDE","link":"/categories/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/IDE/"},{"name":"动态规划","slug":"数据结构与算法/动态规划","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"PostgreSQL","slug":"数据库/PostgreSQL","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/PostgreSQL/"},{"name":"openGauss","slug":"数据库/openGauss","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/openGauss/"}],"pages":[{"title":"","text":"this is test file","link":"/test.html"},{"title":"about","text":".intro { text-align: center; font-weight: bold } .intro a { color:var(--font-color)!important } .intro p { line-height: 1.75 } .head1 { font-weight: bold; font-size: 1.2em; } .head2 { font-weight: bold; } (｡･∀･)ﾉﾞ Desirer | BJTU |","link":"/about/index.html"},{"title":"about","text":".intro { text-align: center; font-weight: bold } .intro a { color:var(--font-color)!important } .intro p { line-height: 1.75 } .head1 { font-weight: bold; font-size: 1.2em; } .head2 { font-weight: bold; } (｡･∀･)ﾉﾞ Desirer | BJTU |","link":"/about/index_2.html"}]}