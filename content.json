{"posts":[{"title":"Learn Vim Efficiently 1","text":"前言：学linux时接触了vim这个编辑器，当时只知道三种模式转换，并不觉得vim有多好用。看南大蒋炎岩操作系统课程时，jyy在shell上键指如飞，我就思考为什么他能够编辑得这么快。我想到的一个点就是光标的移动。在没有接触vim之前，我都是通过键盘右下角的上下左右键进行光标的移动，这意味着右手需要移动一段距离。而接触vim之后，hjkl的移动映射只能说真香。现在我恨不得接触到的每个文本编辑器都有vim工作模式。 推荐阅读： https://github.com/iggredible/Learn-Vim https://missing.csail.mit.edu/2020/editors/ 快速体验：力扣刷题设置绑定vim键位，快速体验vim。 0 三种工作模式知道vim的三种工作模式 ：编辑模式（insert mode）、命令行模式（command line mode）、正常模式（normal mode） 编辑模式：最一般的文本编辑 按i进入，&lt;Esc&gt;退出 命令行模式：保存文件，离开，读入文件，显示行号等 按:显示，&lt;Esc&gt;退出 正常模式：光标移动、删除、复制粘贴、查找替换 初始模式，&lt;Esc&gt;总能返回normal mode 推荐将&lt;Esc&gt;键位映射至&lt;Caps&gt;键位。 1 hjkl光标移动与插入模式在normal mode下，可以通过hjkl键进行光标的移动，练会以后很香。 光标移动： 123456h Leftj Downk Upl Rightw 移动到下一个单词（挖坑、w和W区别）b 反向移动到下一个单词 插入模式： i 光标之前 I 本行开头 a 光标之后 A 本行结尾 o 本行之后新增一行插入 O 本行之前新增一行插入 s 删除当前字符插入 S 删除当前行插入 2 复制粘贴撤销删除在normal mode下可以进行以下操作： yy 复制当前行 （y代表 yank） dd 剪切当前行 p 粘贴 paste u 撤销 undo （挖坑，u撤销的到底是什么？） &lt;ctrl-r&gt; 重做 redo 3 可视化编辑 v 文本块编辑 V 行块编辑 Ctrl-v 块编辑 123y Yank text (copy)d Delete text and save to registerc Delete text, save to register, and start insert mode 后序： 本文以学windows文本编辑器的逻辑介绍了vim。学vim重要的是提高效率，如何快速入门vim？我想是掌握最常用的操作，抛弃那些看起来效率很高但是使用频率低的操作（比如e、E、ge、gE），这些只会徒增记忆的烦恼。待到使用这些命令成为肌肉记忆时，再学习也不迟。 好了，学会以上这些就算简单入门了，实际上vim还有更多命令，能带来效率质的提高。看不如动手，去力扣刷题吧，感受vim的魅力。 更多材料： vim-commands-cheat-sheet vim-cheet-sheet","link":"/2023/11/22/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/Vim/Vim-1/"},{"title":"Learn Vim Efficiently 2","text":"这里将介绍vim的语法和光标浏览，这几乎是vim最重要的部分。 一、语法强烈推荐阅读： https://github.com/iggredible/Learn-Vim/blob/master/ch04_vim_grammar.md 不同于其他文本编辑器的快捷键（需要同时按下两个键或者三个键），vim的命令更像是编程，有一套特定的语法。 在vim中只有一个语法规则： 1动词+名词 1.1 动词所谓动词就是Operator，操作符。 用:h operator可以查看16种操作符，这里列举三种最常用的操作符。 123y Yank text (copy)d Delete text and save to registerc Delete text, save to register, and start insert mode 1.2 名词所谓名词就是motions，你用来在vim中移动的符号。这里是一些motions。 1234567h Leftj Downk Upl Rightw 移动到下一个单词b 反向移动到下一个单词$ 移动到本行末尾 1.3 动词+名词的语法体现假设你有如下文本： 1cosnt string learn = “vim”; 在正常模式下，你的光标在字母c上。 复制一整行:y$ y是复制，$是移动到一行末尾 删除const：dw d删除w一个单词 向左拷贝3个字母：y3h 删除2个单词：d2w 所以vim的命令不需要刻意记忆，就像自然语言。 以行为单位的操作很频繁，所以vim将准备了一些行操作的快捷方式：yy,dd和cc 1.4 更加快捷的操作假设你有如下文本： 1234int print(){ console.log(&quot;hello vim&quot;); int a[15];} 快速删除括号内的内容di( 快速删除双引号里的内容di&quot; 快速删除中括号内的内容di[ 这将是vim的必杀技。di代表着delete inner。对于结构化的文本，特别是代码。 12i + object Inner text objecta + object Outer text object da(将会连括号一起删除。 1234567891011w A wordp A paragraphs A sentence( or ) A pair of ( ){ or } A pair of { }[ or ] A pair of [ ]&lt; or &gt; A pair of &lt; &gt;t XML tags&quot; A pair of &quot; &quot;' A Pair of ' '` A pair of ` ` 二、光标移动强烈推荐阅读： https://github.com/iggredible/Learn-Vim/blob/master/ch05_moving_in_file.md 光标移动是很基础且重要的内容，一般我们退出编辑模式就是进行光标的移动。 2.1 字符移动12345hjklN + Motion 比如说5H向左移动5个字符。 2.2 单词间移动顾名思义，在单词间移动。 12345w Move forward to the beginning of the next worde Move forward one word to the end of the next wordb Move backward to beginning of the previous word 一般命令都会有大写和小写两个版本，或者代表着两个方向，或者代表着两个不同的意思。 123456W Move forward to the beginning of the next WORDE Move forward one word to the end of the next WORDB Move backward to beginning of the previous WORDge Move backward to end of the previous wordgE Move backward to end of the previous WORD 那么大写的单词和小写的单词有什么区别呢？单词都是被空白字符分隔的字符串。 小写单词只包括字母和数字 大写单词包括任何字符除了空格、制表符和 EOL 2.3 行间移动或者叫行内水平移动更佳。 1230 Go to the first character in the current line$ Go to the last char in the current linen| Go the column n in the current line 值得说是n|，在代码的报警信息中经常能看到第几行第几列报错，使用这个命令能快速定位到出错列。n代表任意数字。 快捷的操作：行内搜索。我认为这是vim的第二个必杀技。 12f Search forward for a match in the same linet Search forward for a match in the same line, stopping before match 利用f可以快速到达你想要的字符面前。比如说fa，快速将光标定位到第一个a的位置。 快速记住f和t的区别：f代表find，找到。t代表till，直到。 同样大小写两个版本代表着两个方向。 12345F Search backward for a match in the same lineT Search backward for a match in the same line, stopping before match; Repeat the last search in the same line using the same direction, Repeat the last search in the same line using the opposite direction 使用;和.能避免重复劳动。记住上次的 行内查找操作。 2.4 行号移动这才是名副其实的行间移动。比如说你想到第7行，命令7G 1234gg Go to the first lineG Go to the last linenG Go to line nn% Go to n% in file 2.5 搜索与替换终于来了，全文搜索与替换。 1234/ Search forward for a match? Search backward for a matchn Repeat last search in same direction of previous searchN Repeat last search in opposite direction of previous search 比如说，现在我们有这样一段文本： 123const int a = 1;const int b = 2;int c = 3; 现在我们想要将所有的int都替换为float： \\int&lt;Enter&gt; 这时你将定位到第一个int cwfloat&lt;Esc&gt; change word改变一个单词，然后输入float n. 继续下一个搜索，然后用点命令重复改变 这时你就能发现vim的快捷了。 还有一些快捷命令： 1234* Search for whole word under cursor forward# Search for whole word under cursor backwardg* Search for word under cursor forwardg# Search for word under cursor backward g*和*的作用，客观自行搜索。 2.6 窗口与浏览To scroll, you have 3 speed increments: full-screen (Ctrl-F/Ctrl-B), half-screen (Ctrl-D/Ctrl-U), and line (Ctrl-E/Ctrl-Y). 123456* Ctrl-E Scroll down a lineCtrl-D Scroll down half screenCtrl-F Scroll down whole screen* Ctrl-Y Scroll up a lineCtrl-U Scroll up half screenCtrl-B Scroll up whole screen You can also scroll relatively to the current line (zoom screen sight): 123zt Bring the current line near the top of your screen* zz Bring the current line to the middle of your screenzb Bring the current line near the bottom of your screen 这里留下作者的话： Finally, realize that you do not need to know every single Vim command to be productive. Most Vim users don’t. I don’t. Learn the commands that will help you accomplish your task at that moment. Take your time. Navigation skill is a very important skill in Vim. Learn one small thing every day and learn it well. 三、Vimrc3.1 是什么？vimrc是vim的配置文件。 3.2 有什么用？它能将某些设置永久保存。什么意思呢？比如说，你现在打开vim设置了行号:set number，当你下一次打开vim时，这个设置就失效了。通过vimrc就能永久保存设置。 一般vimrc在用户目录下， ~/.vimrc. 3.3 它有哪些内容？一般来说，vimrc主要配置以下内容： Plugins Settings Custom Funcitons Custom Commands Mappings 我们只挑常用的讲，设置settings和映射mappings。 当你改变vimrc时，记得source it。 Save it (:w), then source it (:source %). 3.4 设置你可以准备一些常用的设置： 12set numberset nocompatible Since we are learning about Vim and not Vi, a setting that you must have is the nocompatible option. Add set nocompatible in your vimrc. Many Vim-specific features are disabled when it is running on compatible option. 3.5 映射你可以将一些键位映射成一系列命令的组合。这是个非常有用的功能。比方说，你如果不习惯vim的hjkl你可以映射为类似方向键布局的jkli。 语法为： 1nnoremap &lt;key&gt; &lt;key&gt; n意味着normal模式 nore意味着non-recursive，不递归的 map就是映射 如何理解non-recursive呢？让我们来看一个例子： 你现在想要实现这样一个功能：按B就能在每一行的末尾加一个分号，然后退回到上一个单词。你写出这样： 1nmap B A;&lt;esc&gt;B 注意，A行末尾插入，分号，esc退回到normal模式，B回退一个单词。 这看起来很美好，但实际上这个命令会加无限多的分号。除非你按Ctrl-C停止。 为什么？因为没有设置不递归，最后一个B也被解释为映射后的B，而不是映射前的B（回退单词）。 所以，最好在平常中都使用不递归的映射。 好了，现在你可以实现一些快捷的功能了。 1inoremap jk &lt;esc&gt; 这个命令在插入模式下，同时按住jk就能退出插入模式。 map命令的首字母对应不同的模式，这里留给大家探索。 四、后序多用，多折腾。 这里留下作者的话： Vimrc is an important component of Vim customization. A good way to start building your vimrc is by reading other people’s vimrcs and gradually build it over time. The best vimrc is not the one that developer X uses, but the one that is tailored exactly to fit your thinking framework and editing style.","link":"/2023/11/22/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/Vim/VIm-2/"},{"title":"Learn Vim Efficiently 3","text":"这里介绍点命令、寄存器和宏。点命令比较有用，寄存器和宏比较鸡肋。 一、 点命令点命令 . 可以重复你在vim中的改变。 1.1 change in vim在vim中，究竟什么被视为一个改变？ 简单的来说，从进入插入模式到退出之间的所有操作！ 1.2 一个点命令的快捷使用方式比如说，现在我们有这样一段文本： 123const int a = 1;const int b = 2;int c = 3; 现在我们想要将所有的int都替换为float： \\int&lt;Enter&gt; 这时你将定位到第一个int cwfloat&lt;Esc&gt; change word改变一个单词，然后输入float n. 继续下一个搜索，然后用点命令重复改变 点命令的最佳使用场景就是变量更名，当你修改完一个变量的名字，移动光标到下一个变量，然后应用点命令。 二、寄存器在vim中有10种类型的寄存器，不过我并不打算全部介绍它们。 关于寄存器，我们要知道： 有哪些？ 怎么往寄存器里存值？ 怎么从寄存器里取值？ 2.1 start by 4 types register 匿名寄存器：&quot;&quot; 拷贝寄存器：&quot;0 数字寄存器：&quot;1-9 和字母寄存器：&quot;a-z small delete register：&quot;- 寄存器总是以双引号开头，后面跟着一个符号。 匿名寄存器，是我们最常用的寄存器。这里的常用，是它被vim使用，而不是我们主动显式地调用。之前讲的dd,yy,p快捷方式都是往匿名寄存器里存值或取值。 拷贝寄存器，是我们使用y操作符时关联的寄存器。注意yy命令会同时拷贝匿名寄存器和拷贝寄存器，利用这点我们就能得到一个缓存。比如说先用yy再用dd，此时匿名寄存器被更新，如果想用第一次复制的内容，需要从拷贝寄存器拉值&quot;0p。 数字寄存器和字母寄存器都是常规寄存器，主要是往里面存值和取值。 samll ddelete register主要用于小单词的存取。当你diw一个单词的时候，这个单词就会存在这个寄存器中。 2.2 寄存器存取值对寄存器的操作都很简单，用双引号来调用一个寄存器，后面跟上你的命令。 比如，现在你有以下文本： 1const int a = 1; &quot;ad3l&lt;esc&gt; 向左删除3个字符，存在寄存器a中 j 移动到下一行 &quot;ap 从寄存器a中取值 三、宏3.1 是什么？宏可以看作一系列操作的录制，它能帮助你避免许多的重复劳动，在你需要的时候自动执行预先录制好的操作。 3.2 录制宏如果要录制宏，当然需要一个能存储的宏的容器，在vim中，自然就是寄存器了。 录制宏 1q&lt;寄存器名&gt; 结束录制 1q 比如说，录制宏到寄存器4 1q4 之后，寄存器4会记录下你的每一个按键操作。 记得结束录制。 3.3 使用宏使用宏也很简单，用@调用存在寄存器里的宏。 1@&lt;寄存器名&gt; 或者 1@@ Execute the last executed macros 这个命令直接执行上一次录制的宏。 举一个例子：我们想要大写每一个单词 12345hellovimmacrosareawesome With your cursor at the start of the line “hello”, run: 1qa0gU$jq The breakdown: qa starts recording a macro in the a register. 0 goes to beginning of the line. gU$ uppercases the text from your current location to the end of the line. j goes down one line. q stops recording. To replay it, run @a. Just like many other Vim commands, you can pass a count argument to macros. For example, running 3@a executes the macro three times.","link":"/2023/11/22/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/Vim/vim-3/"},{"title":"Git快速入门","text":"Git是一个版本控制工具，通常配合远程代码仓库多人协作开发。上手Git并不难，用过之后就会觉得真香。我入门的方式就是给一个项目提Pull Request。 git学习思路：单链 -&gt; 树 -&gt; 多棵树 本地版本控制（利用状态机的思想学习Git） 分支版本控制（利用树的思想） 远程仓库控制（两颗树之间的对应！） 最后学习学习git相关的配置文件，git就算简单入门了。 推荐阅读：https://www.progit.cn/#_pro_git 在线Git闯关-图形化学GIt：https://learngitbranching.js.org/?locale=zh_CN 一、git基础工作目录下的每一个文件都不外乎这两种状态：已跟踪或未跟踪 已跟踪的文件是指那些被纳入了版本控制的文件，在上一次快照中有它们的记录。 未跟踪文件是工作目录中除已跟踪文件以外的所有其它文件，它们既不存在于上次快照的记录中，也没有放入暂存区。 经过Git追踪的文件，在工作一段时间后，它们可能处于其中之一的状态： committed 已经提交，数据在本地仓库中 modified 已经修改，没有保存在数据库中 staged 已经暂存，包含在下次提交的快照中 引入Git项目三个工作区域的概念：Git仓库、工作目录、暂存区域 基本的 Git 工作流程如下： 在工作目录中修改文件。 暂存文件，将文件的快照放入暂存区域。 提交更新，找到暂存区域的文件，将快照永久性存储到 Git 仓库目录。 如果 Git 目录中保存着的特定版本文件，就属于已提交状态。 如果作了修改并已放入暂存区域，就属于已暂存状态。 如果自上次取出后，作了修改但还没有放到暂存区域，就是已修改状态。 二、本地版本控制2.1 获取仓库获取仓库的方法： 现有目录初始化仓库 克隆仓库 （1）现有目录初始化仓库 1234git init git add your_filegit add LISCENSEgit commit -m 'initial project version' （2）克隆仓库 1git clone [url] 比如 1git clone https://github.com/libgit2/libgit2 这会在当前目录下创建一个名为 “libgit2” 的目录，并在这个目录下初始化一个 .git 文件夹。 如果你想在克隆远程仓库的时候自定义本地仓库的名字， 在上条命令后面跟着你自定义的名字： 1git clone https://github.com/libgit2/libgit2 your_local_name 2.2 git状态工作目录下的每一个文件都不外乎这两种状态：已跟踪或未跟踪 已跟踪的文件是指那些被纳入了版本控制的文件，在上一次快照中有它们的记录，在工作一段时间后，它们的状态可能处于未修改，已修改或已放入暂存区。 未跟踪文件是工作目录中除已跟踪文件以外的所有其它文件，它们既不存在于上次快照的记录中，也没有放入暂存区。 初次克隆某个仓库的时候，工作目录中的所有文件都属于已跟踪文件，并处于未修改状态。 编辑过某些文件之后，由于自上次提交后你对它们做了修改，Git 将它们标记为已修改文件。 我们逐步将这些修改过的文件放入暂存区，然后提交所有暂存了的修改，如此反复。这就是Git本地工作的思想。 2.3 git操作（1）查看文件状态1$ git status （2）跟踪新文件（untracked -&gt; staged)1$ git add yourfile 这是个多功能命令：可以用它开始跟踪新文件，或者把已跟踪的文件放到暂存区，还能用于合并时把有冲突的文件标记为已解决状态等。 （3）暂存已修改文件 (modified -&gt; staged)1$ git add yourfile （4）忽略文件在这种情况下，我们可以创建一个名为 .gitignore 的文件，列出要忽略的文件模式。这些文件不会被提交。 （5）提交更新12$ git commit//另外，你也可以在 commit 命令后添加 -m 选项，将提交信息与命令放在同一行 可以看到，提交后它会告诉你，当前是在哪个分支（master）提交的，本次提交的完整 SHA-1 校验和是什么（463dc4f），以及在本次提交中，有多少文件修订过，多少行添加和删改过。 在提交前，请一定要确认还有什么修改过的或新建的文件还没有 git add 过，否则提交的时候不会记录这些还没暂存起来的变化。 这些修改过的文件只保留在本地磁盘。 每次准备提交前用 git status 看下，是不是都已暂存起来了。 （6）跳过暂存1git commit -a 跳过暂存步骤，将已跟踪的文件（若已经修改）提交。 （7）移除文件xx （8）版本回滚首先查看提交的各个版本提交的 SHA-1 标识符。两个命令都行，不过第二个显示的信息更加简洁。 12$ git log --pretty=oneline$ git log --oneline 使用 git revert 命令可以创建一个新的提交，它撤销了指定的提交内容，但是保留了原来的提交记录。 1git revert SHA-1 使用 git reset 命令可以回滚提交，但这种方式是破坏性的，因为它会更改 Git 历史记录，从而删除要回滚的提交以及回滚之后的提交。 1git reset --hard SHA-1 使用reset后就不能恢复了！ （9）放弃暂存区的修改，回到上次提交要放弃本次代码修改并将工作区回到上次提交的状态，可以使用命令： 1git checkout -- . 该命令会将工作区中所有文件的修改全部还原到上次提交的状态，注意命令中的点号”.”表示当前目录，也可以替换成具体的文件或目录名。 此外，如果你只是想还原某个特定文件的修改，可以使用： 1git checkout -- 文件名 注意，这个命令并不会从版本库中删除已经提交的修改记录，只是还原到上次提交。 如果需要完全撤销某个提交，使用 git reset 命令。 三、分支版本控制3.0 查看分支1git branch 这个命令可以查看当前的所有分支。 1234$ git branch iss53* master testing 注意 master 分支前的 * 字符：它代表现在位于的分支（当前 HEAD 指针所指向的分支）。 3.1 查看分支指向的对象分支指向的对象指commit的文件对象。 123git log --oneline --decorategit log --decorate git log --oneline --decorate 输出效果： 123位于分支 master2348425 (HEAD -&gt; master, testing) v265cd212 initial commit!# 当前 HEAD 指针所指向的分支是master，代表当前所在分支。 3.2 创建分支1git branch your_name 这会在当前提交对象上创建your_name的一个指针，代表创建了一个分支。 3.3 切换分支1git checkout branch_name 切换到branch_name这条分支。实际上会将head指针指向branch_name上。输出效果： 122348425 (HEAD -&gt; testing, master) v265cd212 initial commit!# （1）当你在testing分支提交时，会像现在这样： 123dcd85fe (HEAD -&gt; testing) add file a.c2348425 (master) v265cd212 initial commit!# （2）当你切换回mater分支时,head指针会指向master。 注意：你的工作目录恢复成 master 分支所指向的快照内容。 也就是说，你现在做修改的话，项目将始于一个较旧的版本。 本质上来讲，这就是忽略 testing 分支所做的修改，以便于向另一个方向进行开发。 （3）当你在master分支上再次提交修改时，你的项目就会产生分叉！ 1git log --oneline --decorate --graph --all 它会输出你的提交历史、各个分支的指向以及项目的分支分叉情况。 12345* c8f77ad (HEAD -&gt; master) somethign fixed| * dcd85fe (testing) add file a.c|/* 2348425 v2* 65cd212 initial commit!# Git 的分支实质上仅是包含所指对象校验和（长度为 40 的 SHA-1 值字符串）的文件，所以它的创建和销毁都异常高效。 3.3 分支工作流（1）创建并切换到新分支 1git checkout -b issue54 （2）删除分支 1git branch -d hostfix （3）合并分支 12345678//先切换到master分支$ git checkout masterSwitched to branch 'master'//然后将iss53分支合并到master分支$ git merge iss53Merge made by the 'recursive' strategy.index.html | 1 +1 file changed, 1 insertion(+) 和之前将分支指针向前推进所不同的是，Git 将此次三方合并的结果做了一个新的快照并且自动创建一个新的提交指向它。 这个被称作一次合并提交，它的特别之处在于他有不止一个父提交。 3.4 遇到冲突时的合并如果两次合并都涉及同一个文件的同一处修改，在合并它们的时候就会产生冲突。 此时需要手动排除冲突。步骤： git status 查看冲突的文件 逐一打开冲突文件修改 git add将修改完的文件放入暂存区 git commit提交修改 3.5 放弃合并1git merge --abort 有时候冲突太多了，直接放弃合并吧。 3.6 分支开发工作流比如只在 master 分支上保留完全稳定的代码——有可能仅仅是已经发布或即将发布的代码。 他们还有一些名为 develop 或者 next 的平行分支，被用来做后续开发或者测试稳定性——这些分支不必保持绝对稳定，但是一旦达到稳定状态，它们就可以被合并入 master 分支。 稳定分支的指针总是在提交历史中落后一大截，而前沿分支的指针往往比较靠前。 四、远程仓库控制4.1 查看远程仓库12$ git remoteorigin 它会列出你指定的每一个远程服务器的简写。默认情况下就只有一个origin。 使用选项 -v，会显示远程仓库使用的 Git 保存的简写与其对应的 URL。 123$ git remote -vorigin https://github.com/schacon/ticgit (fetch)origin https://github.com/schacon/ticgit (push) 4.2 添加远程仓库1git remote add &lt;shortname&gt; &lt;url&gt; 添加一个新的远程 Git 仓库，同时指定一个你可以引用的简写。 比如： 12345678$ git remoteorigin$ git remote add pb https://github.com/paulboone/ticgit$ git remote -vorigin https://github.com/schacon/ticgit (fetch)origin https://github.com/schacon/ticgit (push)pb https://github.com/paulboone/ticgit (fetch)pb https://github.com/paulboone/ticgit (push) 先查看现在有远程仓库，只有一个origin。然后添加一个简写为pb的远程仓库。再此查看对应的远程仓库，发现pb已经添加上了。 4.3 从远程仓库抓取fetch1$ git fetch [remote-name] 这个命令会访问远程仓库，拉取所有你还没有的数据（包括新的分支）。 git fetch 命令会将数据拉取到你的本地仓库 - 它并不会自动合并或修改你当前的工作。 如果你使用 clone 命令克隆了一个仓库，命令会自动将其添加为远程仓库并默认以 “origin” 为简写。 所以，git fetch origin 会抓取克隆（或上一次抓取）后新推送的所有工作。 4.4 推送到远程仓库push1git push &lt;远程仓库名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt; 将你本地的某个分支推送到远程的某个分支。两个分支名可以不相同。 如果一个本地分支和远程分支建立了联系（下节会讲，所谓联系就是一一对应），直接 git push就能推送到对应的远程分支。 4.5 跟踪分支track跟踪实际上意味着将本地分支与远程分支建立联系。 (1) 查看本地分支与远程分支之间的关系1git branch -vv 样例输出： 123 develop 3e7f1c3 [origin/develop: ahead 2] Fix bug #123 feature-abc 12a8ee2 [origin/feature-abc] New feature implementation* main 4d59b46 [origin/main: ahead 1, behind 2] Merge pull request #456 这个输出列出了本地仓库中的三个分支：develop、feature-abc和main。其中，星号(*)表示当前所在的分支是main。 对于每个分支，输出显示了以下信息： 分支名称 分支所依据的提交哈希值 与之对应的远程分支名称及其状态信息 在这个示例中，develop分支有两个本地提交尚未推送到远程，而feature-abc分支只有与远程分支同步的提交。同时，main分支有一个本地提交，需要将其推送给远程，并且还需要从远程拉取两个提交。 1、当克隆一个仓库时，git通常会自动地创建一个跟踪 origin/master 的 master 分支。 2、需要重点注意的是这个命令并没有连接服务器，它只会告诉你关于本地缓存的服务器数据。 如果想要统计最新的领先与落后数字，需要在运行此命令前抓取所有的远程仓库。 git fetch --all (2) 跟踪一个远程分支（重要）1git checkout -b [local_branch] [remote_name]/[remote_branch] 这个命令会自动创建一个本地分支并跟踪远程分支。 这是一个十分常用的操作，所以 Git 提供了 --track 快捷方式： 1$ git checkout --track origin/[remote_branch] 直接创建本地的同名分支，跟踪远程分支。比如： 1git checkout --track origin/bugfix-update-v1.1 这会建立一个本地分支origin/bugfix-update-v1.1，它会自动与远程同名分支建立联系。 (3) 修改本地分支跟踪的远程分支1$ git branch -u [remotename]/[remote_branch] 这条命令将设置当前分支跟踪的远程分支。 或者这条命令也有同样效果。 1$ git branch --set-upstream-to=[remotename]/[branch] 4.6 拉取分支pull1git pull git pull是指将远程仓库的代码更新到本地仓库，并合并到本地分支上。 具体来说，git pull命令相当于执行了两个命令： git fetch：从远程仓库拉取最新的代码，并将其存放在本地的“FETCH_HEAD”引用中，但不会修改本地分支。 git merge：将“FETCH_HEAD”引用合并到当前分支上，从而将最新的代码更新到本地仓库。 当执行git pull命令时，会自动执行以上两个步骤，从远程仓库拉取最新的代码，并合并到本地分支上，以使本地代码与远程仓库保持同步。 4.6 查看远程仓库查看某一个远程仓库的更多信息 1git remote show [remote-name] 重命名引用的名字 1git remote rename [old_name] [new_name] 比如将pb远程引用的仓库名称改为paul 1234$ git remote rename pb paul$ git remoteoriginpaul 五、打标签Git 可以给历史中的某一个提交打上标签，以示重要。 比较有代表性的是人们会使用这个功能来标记发布结点（v1.0 等等）。 5.0 为什么要打标签（1）A tag is immutable！ Tag是不可变的，在合入主分支与发布的期间，不必担心任何非预期的改变。 （2）便于管理 标签可比提交带有更多的信息。 5.1 列出标签123$ git tagv0.1v1.3 也可以使用特定的模式查找标签。 1$ git tag -l 'v1.8.5*' 六、git的配置6.1 gitconifg文件（1）是什么？ .gitconfig 文件是 Git 的配置文件，在系统上一般位于用户主目录下。这个文件包含了 Git 的一些全局配置，例如 Git 用户名、邮箱地址、文本编辑器等。 （2）怎么用？ 通过修改 .gitconfig 文件，可以定制 Git 的行为。下面是一些可以在 .gitconfig 文件中设置的常用配置： user.name：设置 Git 的用户名，例如git config --global user.name &quot;Your Name&quot;。 user.email： 设置 Git 的邮箱地址，例如 git config --global user.email &quot;youremail@example.com&quot;。 core.editor：设置 Git 使用的文本编辑器，例如 git config --global core.editor &quot;vim&quot;。 core.autocrlf：将文本文件在 Windows 和 Unix 之间自动进行换行符转换，以便在不同平台之间协作，例如git config --global core.autocrlf true。 alias：自定义 Git 命令别名，例如 git config --global alias.st status 将 git status 命令设置为 git st 命令的别名。 可以通过运行以下命令打开 .gitconfig 文件： 1git config --global --edit 这将在系统中打开 Git 配置文件，可以进行编辑。在 .gitconfig 文件中进行修改后，新的设置会对所有 Git 仓库生效。 6.2 gitignore_global文件（1）是什么？ .gitignore_global 文件是 Git 的全局忽略文件。在这个文件中写入的文件或文件夹将不会被 Git 追踪或提交到远程仓库中。这个文件不同于普通的 .gitignore 文件，它适用于所有的 Git 仓库，而不仅仅是单个项目。 .gitignore_global 文件的作用是防止 Git 追踪某些类型的文件或目录。例如，Windows 系统自动生成的 Thumbs.db 文件、macOS 下的 .DS_Store 文件以及 Python 等语言生成的 .pyc、.pyo 文件等都可以在这个文件中被忽略。当对多个 Git 仓库工作时，这是非常有用的，可以避免在未意识到的情况下提交不必要的文件，从而节省仓库的空间和管理工作。 （2）怎么用？ 要在 Git 中启用全局忽略文件，请在命令行中运行以下命令： 1git config --global core.excludesfile ~/.gitignore_global 其中 ~/.gitignore_global 是 .gitignore_global 文件的路径，可以根据实际情况修改路径。运行此命令后，Git 将不再追踪或提交 .gitignore_global 文件中列出的任何文件或目录。 （3）文件怎么配置？ 在 ~/.gitignore_global 文件中，您可以放置您希望在所有 Git 仓库中忽略的文件或文件夹的模式（通配符格式）。这将使 Git 忽略这些文件或文件夹，即使它们没有被放入 .gitignore 文件中。 例如，如果您希望 Git 在所有仓库中忽略 .DS_Store 文件和 __pycache__ 文件夹，可以创建一个 ~/.gitignore_global 文件，并在其中添加以下内容： 1234# Ignore all .DS_Store files.DS_Store# Ignore pycache directory__pycache__/ 然后，使用 git config 命令将路径添加到 Git 全局配置中，使其生效： 1git config --global core.excludesfile ~/.gitignore_global 这样，在任何 Git 仓库中，都将忽略 .DS_Store 文件和 __pycache__ 文件夹。","link":"/2023/12/01/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/Git/Git-fast-learning/"},{"title":"Missing Semmster Learning 学习笔记","text":"计算机教学中缺失的一课 ：https://missing.csail.mit.edu/ 笔记很丑，不想再改。 一、Course overview + the shell认识shell。shell直译为壳，比喻为操作系统内核外面的一层，是我们同内核对话的一个界面。 推荐阅读：https://wangdoc.com/bash/intro bash是最常用的shell，可以把它当作一种编程语言，命令解释器。以下学习的就是bash的相关命令。 1.1 shell命令入门123echo &quot;hello world&quot;echo 'hello world'echo hello\\ world echo的字符用双引号或单引号包含。也可以不用它们，但遇到空格时要用反斜杠转译空格。（因为空格默认为分隔符） 1.2 how system can find echo?123echo $PATHwhich echo/bin/echo &quot;hello world&quot; echo其实是一段小程序，它也有自己的代码。通过$PATH这个系统变量，就能知道操作系统在哪里寻找echo的可执行文件。 也可以通过指定可执行文件的路径的方式来执行特定的可执行文件。 1.3 navigting in the shell1234cdpwdls和ls -l绝对路径和相对路径 理解linux的路径是一颗树，根路径从/开始。绝对路径从根开始，相对路径是相对于当前目录。 1.4 connecting programsprograms always associated with tow stream: input stream and output streamredirection &lt; file and &gt; filewhen cat is not given any arguments, it prints contents from its input stream to its output stream 12cat &lt; hello.txt| pipe command unix系统设计的哲学： 程序默认从键盘接受输入，输出到屏幕。（即每个程序关联标准输入流，标准输出流） 通过左右箭头符号可以重定向输入输出 管道可以将上一个程序的输出导入到下一个程序的输入 二、Shell Tools and Scriptingshell scripting, about learning a new language: basic data type Control flow If case while for syntax shell编程就是学新的编程语言，你需要知道： 数据类型 程序控制流 具体语法 2.1 variable如何定义变量？直接写出变量名，紧跟着等于号，最后是值。注意中间不能有空格。 1foo=bar # foo = bar is wrong 双引号和单引号在shell程序中的区别在于里面的变量是否会被解释。单引号不会解释变量。 12echo &quot;$foo&quot; # this print barecho '$foo' # this print $foo 2.2 function1234mcd () { mkdir -p &quot;$1&quot; cd &quot;$1&quot;} $0 name of program $1-9 arguments to the script $# number of arguments $$ pid $@ all the arguments $? the last command’s exit status 定义函数也非常简单，xxx。 2.3 Logical command123|| &amp;&amp;; # simplely seperate current command and the next command 或逻辑、与逻辑、单纯的分隔符。在命令行环境中也能使用。 2.4 command substitution1echo &quot;start program at $(date)&quot; 这就是先前讲的，双引号内的命令会被解释执行。前提是用$()包围。 2.5 Process substitution1234&lt;(cmd) # this will execute cmd and place the output in a temporary file and substitute the# &lt;() with that file's name 在Bash中，”&lt;(cmd)”是一种称为”Process Substitution”的特殊语法，它允许将命令的输出作为文件传递给另一个命令。 具体来说，”&lt;(cmd)”会将命令cmd的输出作为一个临时文件，并将该文件的路径作为参数传递给当前命令。 这个临时文件只存在于命令执行期间，并在命令执行完毕后自动删除。 2.6 wildcards and curly braces Wildcards - Whenever you want to perform some sort of wildcard matching, you can use ? and * to match one or any amount of characters respectively. For instance, given files foo, foo1, foo2, foo10 and bar, the command rm foo? will delete foo1 and foo2 whereas rm foo* will delete all but bar. Curly braces {} - Whenever you have a common substring in a series of commands, you can use curly braces for bash to expand this automatically. This comes in very handy when moving or converting files. 1234567891011121314151617181920212223convert image.{png,jpg}# Will expand toconvert image.png image.jpgcp /path/to/project/{foo,bar,baz}.sh /newpath# Will expand tocp /path/to/project/foo.sh /path/to/project/bar.sh /path/to/project/baz.sh /newpath# Globbing techniques can also be combinedmv *{.py,.sh} folder# Will move all *.py and *.sh filesmkdir foo bar# This creates files foo/a, foo/b, ... foo/h, bar/a, bar/b, ... bar/htouch {foo,bar}/{a..h}touch foo/x bar/y# Show differences between files in foo and bardiff &lt;(ls foo) &lt;(ls bar)# Outputs# &lt; x# ---# &gt; y 通配符的概念无需多言。？表示任意一个字符，*表示任意多个字符。 大括号的作用比较微妙。有点像for循环遍历列表，然后自动展开。 这三个符号能极大的拓展匹配，实现自动化操作。 2.7 shebang line1#!/bin/bash Shebang line是指在脚本文件的第一行中使用特定格式的注释来指定解释器的路径。Shebang（也称为 Hashbang ）是一个由井号和叹号构成的字符串行 *#!*。 Shebang line的作用是告诉系统应该使用哪个解释器来执行脚本，从而使脚本能够正确地运行。 Some differences between shell functions and scripts that you should keep in mind are: Functions have to be in the same language as the shell, while scripts can be written in any language. This is why including a shebang for scripts is important. Functions are loaded once when their definition is read. Scripts are loaded every time they are executed. This makes functions slightly faster to load, but whenever you change them you will have to reload their definition. Functions are executed in the current shell environment whereas scripts execute in their own process. Thus, functions can modify environment variables, e.g. change your current directory, whereas scripts can’t. Scripts will be passed by value environment variables that have been exported using export As with any programming language, functions are a powerful construct to achieve modularity, code reuse, and clarity of shell code. Often shell scripts will include their own function definitions. differences between shell functions and scripts functions are executed in the current shell environment scripts execute in their own process 执行shell脚本其实是另外开了一个进程执行，所以当前环境不受影响。 1source xx.sh 而source一个shell脚本其实是加载脚本内的变量，这会影响当前环境变量。 2.8 shell tools123456find grepuniqsortwcawk 一些好用的小工具： TLDR pages Tree fasd autojump nnn 五、Command-line Environment提升你的shell工作流。 5.1 job control你的shell使用一种叫做信号的机制在进程间沟通。信号是一种软中断机制。 123ctrl-c 传递SIGINT信号ctrl-\\ 传递SIGQUIT信号ctrl-z 传递SIGTSTP信号，short for Terminal Stop SIGTERM signal ask a process to exit. Using kill command to send it. kill jobs fg bg nohup 5.2 terminal multiplexerstmux教学 leading key &lt;C-b&gt; x means you press ctrl and b, then release them together, and then press x panes 123竖直分裂一个窗口 &lt;C-b&gt; %水平分裂一个窗口 &lt;C-b&gt; &quot;关闭当前窗口 exit or ctrl-d windows - equivalent to tabs in browsers(threads in process) 123&lt;C-b&gt; c 创建一个虚拟桌面&lt;C-b&gt; p 切换上一个&lt;C-b&gt; n 切换下一个 sessions - a session is an independent workspace with one or more windows 12345tmux # start a new sessiontmux new -s NAME # start a new session with nametmux ls #ls current sessionsdetach a session with &lt;C-b&gt; dattach a session `tmux a` , with -t to specify which 5.3 Aliases1alias name=&quot;command arg1 arg2&quot; 为你的常用命令设置别名，减少重复劳动。 使用alias可以查看设置的别名。 常见的别名设置： 1todo 5.4 Dotfiles隐藏文件，通常是各种程序的配置文件。 bash ~/.bashrc or~/.bash_profile git ~/.gitconfig vim ~/.vimrc tmux ~/.tmux.conf ssh~/.ssh/config 关于隐藏文件，我们需要知道三件事： 内容 位置 管理 5.5 Remote Machines（1）ssh远程登录 1ssh user@remote_server_name ssh远程登录十分重要。 1ssh user@remote_server_name command 如果只执行一条命令，不想登录远程主机。 1ls | ssh user@remote_server_name grep PATTERN 这条命令会先将本地ls的输出通过管道传送到远程机器的grep上。是不是很神奇。这就是Unix的设计哲学。 （2）如果你不想每次都输入密码，利用非对称加密算法中的公钥和私钥，就能免去麻烦。 Key generationTo generate a pair you can run ssh-keygen. 1ssh-keygen -o -a 100 -t ed25519 -f ~/.ssh/id_ed25519 You should choose a passphrase, to avoid someone who gets hold of your private key to access authorized servers. Use ssh-agent or gpg-agent so you do not have to type your passphrase every time. If you have ever configured pushing to GitHub using SSH keys, then you have probably done the steps outlined here and have a valid key pair already. To check if you have a passphrase and validate it you can run ssh-keygen -y -f /path/to/key. Key based authenticationssh will look into .ssh/authorized_keys to determine which clients it should let in. To copy a public key over you can use: 1cat .ssh/id_ed25519.pub | ssh foobar@remote 'cat &gt;&gt; ~/.ssh/authorized_keys' A simpler solution can be achieved with ssh-copy-id where available: 1ssh-copy-id -i .ssh/id_ed25519 foobar@remote （3）文件传输 ssh+tee 1cat localfile | ssh remote_server tee serverfile tee命令读标准输入到一个文件中。 scp 1scp path/local_file remote_host:path/remote_file scp可以像cp一样，将本地文件cp到远程路径 rsync 增强的scp，不过多深入。 （4）端口转发 本地端口转发：发送给本地端口的请求发送到远程机器上 远程端口转发：远程机器监听请求，将请求转发给本地机器 1ssh -L local_ip:local_port:remote_ip:remote_port user@remote_seerver 这是本地端口转发的语法，L表示本地端口转发。本地网卡端口是可以省略的，这时表示local port绑定了本地主机所有的网卡。 比如： 1$ ssh -L 9999:localhost:8888 user@remote_server 通过访问本地localhost:9999就能访问远程服务器的localhost:8888服务。 了解跳板机的概念：https://developer.aliyun.com/article/1035160 5.6 Shells &amp; FrameworksOn-my-zsh Syntax-highlighting History-substring-search 框架是件美好的事情。","link":"/2023/12/01/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/%E7%BB%88%E7%AB%AF/missing-semester-note/"},{"title":"终端基础知识","text":"命令行、终端、Shell、Promt的基础认知。 操作系统自带的终端都很丑且难用，好用的终端需要一番折腾配置（特别是国内环境网络问题），新手往往望而生畏。 【在学校没有人教你的终端基础知识】 https://www.bilibili.com/video/BV1rk4y1W7dZ 一、CLICLI is the abbreviation of Command Line Interface. It’s a text-based way of interacting with a computer. 相比于图像界面提供的按钮，你可以使用一行命令来实现你想要的功能，比如说打开、关闭文件，从而实现与计算机的交互。 那么，你在哪里输入这种文本命令？ 二、TerminalTerminal直译为终端，什么是终端？你可以理解为计算机与人们之间沟通的桥梁。通常它是一个全黑的窗口，可以输入命令并提供反馈。 终端是一款软件，许多系统都有自带的终端。也可以使用其他的终端软件。 三、ShellShell直译为壳，这里不必纠结翻译问题。 Shell运行在终端中，解释你的输入并执行它们。可以简单理解为一个命令解释器，不同的shell有不同的语法。 你输入的文本就好比日常生活中人与人沟通的话，计算机有自己的二进制语言，你有自己的一套语言，比如汉语、英语、法语、日语，Shell就在其中充当翻译官的角色。 四、Prompt命令提示符。在终端中，命令提示符用来提示你输入。比如说提示你当前所在的路径等等","link":"/2023/12/01/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/%E7%BB%88%E7%AB%AF/%E7%BB%88%E7%AB%AF%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"title":"协程理论认识","text":"笔记取自： 【协程革命】理论篇 https://www.bilibili.com/video/BV1K14y1v7cw 主旨协程是可以暂停和恢复的函数。 在一个地方暂停后，又在同样的地方恢复。 为什么需要暂停？一些场景 等待资源就绪（网络IO） UI渲染时处理业务逻辑 游戏技能计算，每一帧计算飞行轨迹然后处理其他逻辑 可以归纳为有其他优先级更高的事件发生时，交处执行权。但这不是线程的切换，协程只是一个函数，协程的切换是函数间的切换（可能切换到另一个线程内的协程）。 暂停与恢复协程暂停了，然后恢复的是哪个协程？ 普遍来说，有一个调度器控制协程切换的整个行为，它负责挑选合适的协程进行运行。 一个协程暂停，它可能返回上层调用它的函数，可能直接返回调度器，也可能切换到另一个协程。 回到调度器，协程调用链得到保存 回到上层调用，比如说python的yield产生一个数据 直接恢复其他协程而不通知调用器，这个最危险（对称式协程） 协程与线程 调度器存放了许多被暂停的协程，多线程争抢协程运行。 实现协程一个协程要做到再恢复，就必须有个地方存上次离开的信息（上下文信息），根据地方的不同，分为有栈协程和无栈协程。 无栈协程对应一个结构体，这个结构体保存了所有协程必要的信息。有栈协程对应了一个2000字节的内存空间，这2000字节的空间可以当作栈使用。 两者优缺点： 有栈申请空间浪费，空间大小不好确定。无栈内存紧凑 有栈递归快，无栈慢 协程切换为什么比线程快在用户级线程中，线程由程序通过线程库实现，线程管理由应用负责，线程切换只需要在用户态完成。 1）协程切换完全在用户空间进行，线程切换涉及特权模式切换，需要在内核空间完成； 2）协程切换相比线程切换做的事情更少。 当前协程的 CPU 寄存器状态，称之为CPU上下文 除了和协程相同基本的 CPU 上下文，还有线程私有的栈和寄存器等，说白了就是上下文比协程多一些。","link":"/2023/12/02/%E5%8D%8F%E7%A8%8B%E7%90%86%E8%AE%BA%E8%AE%A4%E8%AF%86/"},{"title":"Redis入门","text":"Redis是一款用C编写的基于内存的非关系数据库，实际开发中，Redis用作缓存数据库，用来减轻后端数据库的压力。Redis全称为：Remote Dictionary Server（远程数据服务）。 Redis官网:：http://redis.io/ 在线尝试：https://try.redis.io/ 咱认为，学习Redis的最佳方式是从项目开始。先学一点数据结构Redis的终端命令，然后再接入SpringBoot快速上手项目使用。学完基本数据使用后，再探究其原理。 基本数据类型Reids的基本数据类型是value的类型，而不是键的类型。 string类型基本读写 12set key value [EX seconds|PX milliseconds] [NX|XX] get key EX|PX 设置过期时间，单位不同； NX （Not Exist），表示键不存在才进行操作，XX相反； 多字符串存取 12mset key value [key2 value2 ...]mget key [key2 ...] 值的加减 1234incr keydecr keyincrby key numberdecrby key number key对应的数据不是字符串类型吗？怎么能进行加减操作？这里埋个坑。 hash类型redis hash 是 字符 filed 和 value 之间的映射表，所以非常适合用于存储对象。比如说key作为对象名，Field作为对象的属性字段，value则是属性字段的值。 基本读写 123hset key field value [field value ...]hget key fieldhdel key field 查看哈希表的所有field： hkeys key 查看哈希表的所有value：hvals key 查看哈希表的所有field value对：hgetall key 判断一个Key是否存在：hexists key field 应用场景hash类型一般适合用来存对象，能够独立存储每个字段，如果需要修改某个字段的值，可针对性修改。适合对象字段频繁改变的情况。 string类型也能用来存储对象，首先将对象序列化为Json字符串，再存入Redis。这样的坏处是修改字段麻烦。适合对象字段不怎么改变的情况。 List类型redis的list相当于Java中的LinkedList，是一个双向链表，可以在头部或者尾部添加元素，当列表弹出最后一个元素后，该结构自动删除。 （1）基本读写 1234lpush key element [element2]lindex key indexrpush key element [element2]rindex key index lpush 可以将一个或多个值依次插入列表的头部，rpush则将一个或多个值依次插入列表的尾部。 lindex获取指定index的值（注意index从0开始） （2）删除元素 12lpop keyrpop key （3）获取区间元素，注意区间是左闭右闭。 1lrange start stop （4）插入元素 1linsert list BEFORE|AFTER target_element new element Set类型set就是集合，集合的元素不重复无序。Redise的Set底层由哈希表实现，查询复杂度为$O(1)$。 添加一个或多个元素 1SADD key element [element2 ...] 移除一个或多个元素 1SREM key element [element2 ..] 获取集合的所有元素 1SMEMBERS key 判断是否是成员 1SISMEMBER key member 集合应用场景（1）用户点赞 用户对某条评论点赞。偶数次点赞会取消赞。这就要求用户是否对某条评论点赞的判断。 利用set的是否是成员快速判断用户是否点赞。如果点赞，就将用户id添加到评论的点赞set里。 （2）共同关注 利用集合取交集的命令，就能实现共同关注的功能。 Zset类型Set是无序集合，ZSet则是有序集合。有序性是因为ZSet中的每个元素关联了一个Score分数，依据分数进行排序。 ZSet的终端命令与Set大体相同，前缀从S换成了Z，并且额外要求一个Score参数。 有序集合应用场景（1）点赞好友显示 朋友圈点赞头像显示。利用时间戳作为Zset的score，就能以时间排序。 （2）朋友圈滚动分页 用户查看朋友圈其实是查看它的收件箱。如果有新动态发布，那一定是在最顶上。以时间戳作为排序就能实现这种情况。 通用命令（1）exists 存在命令 1exists key 判断指定的key是否存在 （2）keys 查找命令 1keys pattern 查找指定模式的键，模式匹配（通配符、正则表达式） （3）rename 重命令 1rename key newKeyName （4）del 删除key 1del key （5）ttl 获取键的生存时间 1ttl key 值得注意：在多个键时，可以用冒号为键分隔，达到更好可视化效果 底层数据结构 简单动态字符串12345struct sdshdr{ int len; //当前保存字符串长度 int free; //当前未使用字符数量 char buf[]; } SDS类似Java的ArrayList、cpp的vector，动态扩容。虽然底层使用字符数组存储字符，但配合了两个整数变量控制存储空间，这两个变量就是实际所占空间大小和剩余空间大小。 SDS采取预先分配冗余空间策略减少内存的频繁分配。当字符串所占空间小于1M时，成倍扩容。超过1M时，每次只扩容1MB，最多512MB。 压缩链表 ZipList1234567struct ziplist&lt;T&gt; { int32 zlbytes; // 全部占用字节数 int32 zltail_offset; // 最后一个元素距离压缩列表起始位置的偏移量，用于快速定位到最后一个节点 int16 zllength; // 元素个数 T[] entries; // 元素内容列表 int8 zlend; // 标志压缩列表的结束，值恒为 0xFF} ZipList与SDS结构相差无几，由连续内存块组成的顺序型数据结构，它有多个entry节点，每个entry节点可以存放整数或者字符串。另外多了几个标志符，字节数、偏移量、长度、结尾标志符。 List 使用压缩链表的情况：List中元素的数量小于或等于16个时，Redis会使用压缩链表进行存储。 hash对象只有同时满足以下条件，才会采用ziplist编码： hash对象保存的键和值字符串长度都小于64字节 hash对象保存的键值对数量小于512 当Zset中元素的数量小于或等于256个时，Redis会使用压缩列表进行存储。 当ziplist作为zset的底层存储结构时候，每个集合元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员，第二个元素保存元素的分值。 哈希表 Redis的哈希表实现其实是字典，一个字典中包含了两个哈希表。一个哈希表里面可以有多个槽，而每个槽保存了一个键值对（或者多个，取决于是否有哈希冲突）。 采用开链法解决哈希冲突，当不同key映射到同一个哈希槽时，Redis会采用链表的方式，将后来的节点链接到上一节点。 双哈希表设计：这是一种以空间换时间的技术。特别是应对ReHash过程（哈希表扩容或收缩）。 当哈希表的负载因子超过一定阈值时，就会将0号哈希表上的键值对转移到1号哈希表上。具体过程为：为1号哈希表申请空间，然后重新计算哈希值和索引，并重新插入到 ht[1] 中，插入一个删除一个。当0号哈希表所有元素转移完成时，释放0的空间，然后将1号设为0号。 注意这个数据转移过程可以是一次性操作、也可以是分批次操作（渐进式rehash）。另外因为有两个哈希表，查询时如果0号哈希表查不到，还需要在1号哈希表再查一次，牺牲了一点查询性能。 整数集合12345typedef struct intset{ uint32_t encoding; //编码方式 uint32_t length; //集合包含的元素数量 int8_t contents[]; //保存元素的数组}intset; 当set存的都是整数，且个数小于512个时，底层使用整数集合。 跳跃链表 SkipList跳表 = 单链表+随机化的多级索引。 它的基本思想是在链表的基础上，增加多级索引，从而提高数据的查找效率。在一般情况下，它的查找、插入、删除等操作的时间复杂度都为O(log n)。 跳表的核心是索引，它通过维护多级有序链表来实现。每一级索引是原始链表的一部分节点组成，每一级索引的元素数量都比它下一级索引的元素数量少一半。最上面一级索引只有两个节点，第二级索引有四个节点，以此类推。通过这种方式，跳表在空间复杂度和时间复杂度之间做到了平衡。 跳表的查找过程与二分查找类似，先在最高级的索引中查找目标节点，然后通过下降到更低一级的索引再次查找，直到在最底层的索引中找到目标节点或者查找到整个跳表中都没有这个节点。由于跳表的结构不依赖于节点的分布情况，所以它可以用来代替平衡树，实现更高效的查找操作。","link":"/2023/12/06/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/Redis%E5%AD%A6%E4%B9%A0/"},{"title":"设计模式学习","text":"设计模式大致分为三类。 创建者模式：提供一种创建对象的方式，同时隐藏了创建对象的逻辑。而不是直接使用new创建对象。 结构型模式：结构型模式更加关注对象与对象之间的关系与组合，旨在构建灵活可复用的类和对象结构。 行为型模式：关注类或对象之间的通信、协作、职责分配。旨在对象间的责任分配和算法封装。 记住所有的设计模式是愚蠢的，关注自己所在领域常用设计模式，语言框架中默认使用的设计模式。 创建型模式创建者模式封装了创建对象的逻辑，将复杂对象的构建过程与其表示（使用）分离。代替手动用new操作符调用构造函数繁琐的过程。 优点：对象构造与表示分离，隐藏对象的内部结构。 工厂模式工厂模式提供了一种将对象的实例化过程封装在工厂类中的方式。 分类： 简单工厂模式 工厂方法模式 抽象工厂模式 缺点： 增加了系统中的类和对象的个数，复杂度增加。 需要额外工作量创建和维护工厂类和产品类，增加开发成本。 应用场景： 日志配置器：日志记录层次、记录格式、记录的存放路径 123456789101112131415public class ShapeFactory { public Shape getShape(String shapeType){ //使用 getShape 方法获取形状类型的对象 if(shapeType == null){ return null; } if(shapeType.equalsIgnoreCase(&quot;CIRCLE&quot;)){ return new Circle(); } else if(shapeType.equalsIgnoreCase(&quot;RECTANGLE&quot;)){ return new Rectangle(); } else if(shapeType.equalsIgnoreCase(&quot;SQUARE&quot;)){ return new Square(); } return null; }} 自己的应用： 深度学习中，经常需要对比不同学习模型的在相同任务上的效果。而不同的模型的创建逻辑大体相同，但部分细节不同。我自己写了一个模型工厂，根据传入的模型名称、模型层数、模块机制来自动构建模型。这样，每当我要改变一个模型训练，我就修改相应参数。 其实，这么说，整个深度学习任务的过程都可以看成工厂模式，只不过我没有做整个大任务的抽象封装。在Python代码中，我调用了一个argparse这么一个模块，它的作用就是解析命令行的参数。我训练一个任务，大体有数据集、模型、学习率、迭代次数这些个参数，每一次任务可以用参数组合表示。那么就是说我用参数组合来定义任务，这与工厂模式的思想是不谋而合的，我把要改变的地方全部提取出来，放到一起。 单例模式单例模式也就说保证一个类只有一个实例存在，整个系统中只有一个全局对象。 应用场景：当系统只需要一个实例来协调整个系统的行为时 日志记录器 配置管理器 windos中的任务管理器 单线程下实现方式： 私有化构造函数，使得构造函数无法通过外部调用； 创建一个持有字段hold，类型为对象的引用； 创建一个静态方法get，用于获得对象实例的引用。首先检查hold是否为空，为空才创建对象，否则返回引用。 多线程下实现注意点： 线程安全性，get方法得加锁 双重检查：在单例模式中，通常需要进行双重检查锁定，即先检查单例对象是否已经被创建，然后再加锁并再次检查。 饿汉式和懒汉式的选择：饿汉式在类加载时就完成了初始化，而懒汉式则在第一次调用getInstance方法时才进行初始化。 12345678910111213141516public class Singleton { private static volatile Singleton instance; private Singleton() {} public static Singleton getInstance() { if (instance == null) { synchronized (Singleton.class) { if (instance == null) { instance = new Singleton(); } } } return instance; } } 建造者模式建造者模式将一个复杂对象分解成多个简单部分，对复杂对象分模块构建，一步步构建最终对象。 一般适合创建实例有多个步骤的复杂对象，比如说汽车有各个零件，每种零件的厂商是不固定的，但汽车的组装步骤是一定的。再提炼来说：一个复杂对象由各个部分的子对象组成，子对象可能会经常变化，而各个子对象的组合逻辑却不怎么变化。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class Computer { private final String cpu;//必须 private final String ram;//必须 private final int usbCount;//可选 private final String keyboard;//可选 private final String display;//可选 private Computer(Builder builder){ this.cpu=builder.cpu; this.ram=builder.ram; this.usbCount=builder.usbCount; this.keyboard=builder.keyboard; this.display=builder.display; } public static class Builder{ private String cpu;//必须 private String ram;//必须 private int usbCount;//可选 private String keyboard;//可选 private String display;//可选 public Builder(String cup,String ram){ this.cpu=cup; this.ram=ram; } public Builder setUsbCount(int usbCount) { this.usbCount = usbCount; return this; } public Builder setKeyboard(String keyboard) { this.keyboard = keyboard; return this; } public Builder setDisplay(String display) { this.display = display; return this; } public Computer build(){ return new Computer(this); } } //省略getter方法}---// 使用方式Computer computer=new Computer.Builder(&quot;因特尔&quot;,&quot;三星&quot;) .setDisplay(&quot;三星24寸&quot;) .setKeyboard(&quot;罗技&quot;) .setUsbCount(2) .build(); 结构型模式类与类之间的关系与组合，关注的是类间的布局。 装饰器模式装饰器模式允许向一个对象添加新的功能，同时却不改变其原有代码。 应用： Java中的注解 python里装饰器 Spring框架的注解AOP Java中可以自定义注解，然后通过反射的方式获取注解（注解拦截），然后进行功能增强。 适配器模式适配器模式允许你将不兼容的对象包装成一个适配器类，使它们能够与其他对象一起工作。适配器模式通常用于处理与现有类库或框架不兼容的类或接口。 在STL里，栈和队列都是适配器，它们底层使用Deque作为容器存储，对外却表现为栈或队列的特性。 代理模式unix系统调用中，错误包装函数。 我们需要从概念上了解代理和装饰的区别： 代理是全权代理，目标根本不对外，全部由代理类来完成。 装饰是增强，是辅助，目标仍然可以自行对外提供服务，装饰器只起增强作用。 三、行为型模式行为型模式关注的是对象间的通信、写作、职责分配等。 责任链模式将处理对象连成一条链，请求沿着链传递，直到有一个对象处理为止。 状态模式对象的行为跟随着状态而改变。【状态机】 迭代器模式提供一个方法顺序访问对象的各个元素，但不暴露对象的内部表示。 CPP的STL库里的迭代器就很好体现这一点。原生指针不足以支持元素的顺序访问，譬如链表节点、树的节点。迭代器的出现使得容器和算法分离，算法通过迭代器访问容器元素却不用知晓其实现，换句话说，算法更加通用。","link":"/2023/12/01/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"title":"链表总结","text":"链表的题目多涉及指针操作，需要画图显示步骤，不然容易搞混。 常用的套路有： 双指针（前驱后继指针、快慢指针、奇偶指针） 虚拟头节点（好处：需要前驱节点时，总能找到前驱节点。比如在删除头节点时，我们可以找到头节点的前驱。） 设计链表 https://leetcode.cn/problems/design-linked-list/description/ 从0开始设计一个链表，实现get、add、delete方法 链表首先要声明链表节点 123456789class ListNode { int val; ListNode next; ListNode(){} ListNode(int val) { this.val = val; this.next = null; }} 再设计链表类 123456789101112131415161718192021class MyLinkedList { int size; //长度 ListNode head; //虚拟头节点 public MyLinkedList() { //假设链表中的所有节点下标从 0 开始。 size = 0; head = new ListNode(-1); } public int get(int index) { //如果下标无效，则返回 -1 } public void addAtIndex(int index, int val) { //将一个值为 val 的节点插入到链表中下标为 index 的节点之前 } public void deleteAtIndex(int index) { //如果下标有效，则删除链表中下标为 index 的节点 }} 我们首先实现get方法。 123456789public int get(int index) { //如果下标无效，则返回 -1 if(index&lt;0 || index&gt;=size) return -1; ListNode cur = head; //链表下标从0开始计算 for(int i=0; i&lt;=index; ++i) cur = cur.next; return cur.val;} 再看delete方法，这里就能看到虚拟头节点的好处了。删除一个节点需要知道它的前驱节点，让它的前驱指向它的后继；如果要删除0号节点即头节点，没有虚拟头节需要额外判断； 12345678910111213public void deleteAtIndex(int index) { //如果下标有效，则删除链表中下标为 index 的节点 if (index &lt; 0 || index &gt;= size) return; ListNode cur = head; //注意要让cur指向index的前驱 //所以判断i&lt;index for(int i=0; i&lt;index; ++i) cur = cur.next; //跳过cur的next cur.next = cur.next.next; //这里需要注意java的自动回收机制，不需要delete --size;} 最后看add方法。 1234567891011121314public void addAtIndex(int index, int val) { //将一个值为 val 的节点插入到链表中下标为 index 的节点之前 if (index &gt; size) return; if (index &lt; 0) index = 0; ListNode cur = head; //注意要让cur指向index的前驱 for(int i=0; i&lt;index; ++i){ cur = cur.next; } ListNode tmp = new ListNode(val); tmp.next = cur.next; cur.next = tmp; ++size;} 双指针应用移除特定链表元素 https://leetcode.cn/problems/remove-linked-list-elements/ 1234567891011121314151617181920class Solution { public ListNode removeElements(ListNode head, int val) { ListNode dummyNode = new ListNode(-1); dummyNode.next = head; ListNode pre = dummyNode; ListNode cur = dummyNode.next; while(cur != null){ // 对cur进行 遍历 if(cur.val == val){ pre.next = cur.next; cur = pre.next; continue; //找下一个 } //找下一个 pre = cur; cur = cur.next; } return dummyNode.next; }} 移除链表中某个特定节点需要知道它的前驱和后继，所以设立前后指针；虚拟头节点方便删除。 删除链表的倒数第N个节点 https://leetcode.cn/problems/remove-nth-node-from-end-of-list/ 123456789101112131415161718class Solution { public ListNode removeNthFromEnd(ListNode head, int n) { ListNode dummyNode = new ListNode(-1); dummyNode.next = head; ListNode first = dummyNode; ListNode second = dummyNode; // second run n step for(int i=0; i&lt;n; ++i){ second = second.next; } while(second != null &amp;&amp; second.next !=null) { //删除节点需要找到它的前驱 second = second.next; first = first.next; } first.next = first.next.next; return dummyNode.next; }} 快慢指针应用，快指针先走N步，然后再走到底。 相交链表https://leetcode.cn/problems/intersection-of-two-linked-lists/ 12345678910111213public class Solution { public ListNode getIntersectionNode(ListNode headA, ListNode headB) { if(headA==null || headB==null) return null; ListNode x=headA, y =headB; while(x!=y) { if (x==null) x = headB; else x = x.next; if (y==null) y = headA; else y = y.next; } return x; }} 双指针的比较巧妙应用，利用 $x+y = y+x $的思想，走到底之后还可以重头再走一遍。 环形链表https://assets.leetcode-cn.com/aliyun-lc-upload/uploads/2018/12/14/160_statement.png 123456789101112public class Solution { public boolean hasCycle(ListNode head) { if(head==null||head.next==null)return false; ListNode slow=head, fast=head; while(fast!=null){ fast = (fast.next==null)?fast.next:fast.next.next; slow = slow.next; if(fast==slow)return true; } return false; }} 快慢指针的典型应用，判断链表中是否有环。 环形链表入口节点https://leetcode.cn/problems/linked-list-cycle-ii/ 1234567891011121314151617181920212223public class Solution { public ListNode detectCycle(ListNode head) { if(head == null) return head; ListNode slow = head; ListNode fast = head; while(fast!=null){ if(fast.next != null) fast = fast.next.next; else fast = fast.next; slow = slow.next; if(fast == slow) break; } if(fast == null) return null; //相遇点 fast = head; while(fast != slow){ fast = fast.next; slow = slow.next; } return fast; }} 这道题难点在于找出环入口节点。解体的关键在于两个点： 假设head到环入口节点的长度为a，环的长度为len，相遇时距离环入口的偏移为offset 当一个指针走 a + k*len步时，它一定在环入口处 推理： f = 2*s s = a + offset + k1*len f = a + offset + k2*len 得到 f-s = k3*len = s 即 s 走了整数倍len，f走了整数倍len。 因此只要相遇后，将fast移到头节点，一步一步走再走a步，一定和slow碰面在入口之处。 迭代法（复杂指针操作）翻转链表 https://leetcode.cn/problems/reverse-linked-list/ (1) 迭代方式反转 123456789101112131415class Solution { public ListNode reverseList(ListNode head) { // 迭代法 ListNode prev = null; ListNode cur = head; ListNode tmp = null; while(cur != null){ tmp = cur.next; cur.next = prev; prev = cur; cur = tmp; } return prev; }} 迭代方式翻转，自然需要两个指针; 需要注意的是翻转前后的尾巴null处理 pre指向已经翻转的链表头节点，初始为null； cur指向下一个要翻转的节点，初始为head （2）递归方式反转 1234567891011121314class Solution { public ListNode reverseList(ListNode head) { //空链表和单个链表无需反转，直接返回 if(head==null) return null; if(head.next==null) return head; //这里假设head.next的开头的链表完成了反转，返回反转后的头节点 ListNode prev = reverseList(head.next); //now we have to do is //reverse head.next and head head.next.next = head; head.next = null; return prev; }} 翻转部分链表 https://leetcode.cn/problems/reverse-linked-list-ii/ 123456789101112131415161718192021222324252627class Solution { public ListNode reverseBetween(ListNode head, int left, int right) { //o(n)的算法 ListNode dummyHead = new ListNode(-1); dummyHead.next = head; ListNode pre = dummyHead; //1 找到left的前驱 for(int i=0; i&lt;left-1; ++i){ pre = pre.next; } ListNode tmp1 = pre; ListNode tmp2 = pre.next; // 2 反转部分 ListNode prev = null; ListNode curr = pre.next; //注意这里多反转一单位长度 for(int i=0; i&lt;= right-left; ++i){ ListNode tmp = curr.next; curr.next = prev; prev = curr; curr = tmp; } tmp1.next = prev; tmp2.next = curr; return dummyHead.next; }} 反转特定范围内的链表，需要注意边界条件。 两两交换链表节点 迭代方式自然需要保存多个指针，修改互相的引用，然后顺序遍历下去。 为了使得处理更加顺畅，引入虚拟头节点 如果被指针指向的顺序搞懵，不如多声明几个变量，保存节点 两两反转需要两个变量 迭代处理，需要前驱和后继，又要两个变量 总共四个变量 12345678910111213141516171819202122232425class Solution { public ListNode swapPairs(ListNode head) { ListNode dummyHead = new ListNode(-1); dummyHead.next = head; ListNode prev = dummyHead; ListNode curr = prev.next; if(curr==null || curr.next==null) return head; ListNode nest = curr.next; ListNode tmp = nest.next; while(curr!=null){ // reverse nest.next = curr; curr.next = tmp; prev.next = nest; // iteration prev = curr; if(prev.next==null) break; curr = prev.next; if(curr==null||curr.next==null) break; nest = curr.next; tmp = nest.next; } return dummyHead.next; }} 简洁写法 12345678910111213141516171819class Solution { public ListNode swapPairs(ListNode head) { ListNode dummyHead = new ListNode(-1); dummyHead.next = head; ListNode prev = dummyHead; while(prev.next!=null &amp;&amp; prev.next.next!=null){ ListNode curr = prev.next; ListNode nest = curr.next; ListNode tmp = nest.next; // reverse nest.next = curr; curr.next = tmp; prev.next = nest; // iteration prev = curr; } return dummyHead.next; }} 巧妙递归翻转部分链表 https://leetcode.cn/problems/reverse-linked-list-ii/ 12345678910111213141516171819class Solution { // 反转head开头的N个节点 ListNode reverseN(ListNode head, int N){ if(head==null || N==1) return head; ListNode rHead = reverseN(head.next, N-1); ListNode tmp = head.next.next; head.next.next = head; head.next = tmp; return rHead; } public ListNode reverseBetween(ListNode head, int left, int right) { if(left == 1){ return reverseN(head, right); } // 索引减1 ListNode rHead = reverseBetween(head.next, left-1, right-1); head.next = rHead; return head; } 主要思想：将left和right堪称相对于头节点的索引。当left为1时，题目归化为反转开头N个节点。 K个一组翻转链表 https://leetcode.cn/problems/reverse-nodes-in-k-group/description/ 123456789101112131415161718192021222324class Solution { // 反转开头N个节点，并返回反转后的头节点 public ListNode reverseN(ListNode head, int N){ if(N==1) return head; ListNode rHead = reverseN(head.next, N-1); ListNode tmp = head.next.next; head.next.next = head; head.next = tmp; return rHead; } public ListNode reverseKGroup(ListNode head, int k) { // 不足N个直接返回 ListNode count = head; for(int i=0; i&lt;k; ++i){ if(count!=null) count = count.next; else return head; } // 先反转开头N个 ListNode rHead = reverseN(head, k); // 递归反转 head.next = reverseKGroup(head.next, k); return rHead; }} 思想：反转前K个后，第K+1个节点还是一样处理。 两两交换链表中的节点 https://leetcode.cn/problems/swap-nodes-in-pairs/ 1234567891011class Solution { public ListNode swapPairs(ListNode head) { if(head==null||head.next==null) return head; ListNode headNext = head.next; ListNode tmp = swapPairs(headNext.next); headNext.next = head; head.next = tmp; return headNext; }} 其实就是K一组翻转链表，K=2的情形。 判断回文链表123456789101112131415class Solution { public ListNode left; public boolean isPalindrome(ListNode head) { left = head; return traverse(head); } public boolean traverse(ListNode head){ if(head == null) return true; boolean res = traverse(head.next); if(left.val != head.val) return false; left = left.next; return res; }} 这个写法比较邪门，将链表想象成一颗退化的树，借助left存储最左端的点，递归一直到最右端，然后判断左右是否相等。 合并链表合并两个有序链表https://leetcode.cn/problems/merge-two-sorted-lists 1234567891011121314151617181920212223class Solution { public ListNode mergeTwoLists(ListNode list1, ListNode list2) { if(list1==null) return list2; if(list2==null) return list1; ListNode dummyHead = new ListNode(-1); ListNode op = dummyHead; while(list1!=null &amp;&amp; list2!=null){ ListNode tmp = new ListNode(-1); if(list1.val &lt; list2.val){ tmp.val = list1.val; list1 = list1.next; }else{ tmp.val = list2.val; list2 = list2.next; } op.next = tmp; op = op.next; } if(list1!=null) op.next =list1; if(list2!=null) op.next =list2; return dummyHead.next; }} 合并K个有序链表https://leetcode.cn/problems/vvXgSW/ 1234567891011121314151617181920212223242526272829303132class Solution { public ListNode meregeTowListInplace(ListNode head1, ListNode head2){ ListNode op1 = head1; ListNode op2 = head2; ListNode dummyHead = new ListNode(-1); ListNode op3 = dummyHead; while(op1!=null &amp;&amp; op2!=null){ if(op1.val &lt; op2.val){ op3.next = op1; op1=op1.next; }else{ op3.next = op2; op2=op2.next; } op3 = op3.next; } if(op1!=null) op3.next = op1; if(op2!=null) op3.next = op2; return dummyHead.next; } public ListNode MergeSort(ListNode[] lists, int start, int end){ if(start&gt;=end) return lists[start]; int mid = (end-start)/2 + start; ListNode head1 = MergeSort(lists, start, mid); ListNode head2 = MergeSort(lists, mid+1, end); return meregeTowListInplace(head1, head2); } public ListNode mergeKLists(ListNode[] lists) { if(lists.length==0) return null; return MergeSort(lists, 0, lists.length-1); }} 链表合并，天然适合二路归并算法。合并两条链表算法很简单，并且原地操作。合并2条链表后，可以再合并4条链表，8条链条，最终合并全部链表！ 解法二：堆 12345678910111213141516171819202122232425class Solution { public ListNode mergeKLists(ListNode[] lists) { if (lists == null || lists.length == 0) return null; PriorityQueue&lt;ListNode&gt; pq = new PriorityQueue&lt;&gt;(lists.length, new Comparator&lt;ListNode&gt;() { @Override public int compare(ListNode o1, ListNode o2) { if (o1.val &lt; o2.val) return -1; else if (o1.val == o2.val) return 0; else return 1; } }); for(ListNode node: lists){ if(node!=null) pq.offer(node); } ListNode dummyHead = new ListNode(-1); ListNode op = dummyHead; while(!pq.isEmpty()){ op.next = pq.poll(); op = op.next; if(op.next!=null) pq.add(op.next); } return dummyHead.next; }} 想清楚操作的顺序，再写代码，不然逻辑混乱，越改越错！ 算法思想：K个升序链表，每次我们都要取最小的。利用升序的特性，我们可以知道最小元素只在每个链表的头部产生。 这个过程抽象为从一个候选集合中取最小值，自然想到堆数据结构。 算法步骤： 1、先取K个链表头部元素建立堆； 2、从堆中取一个，那下一个最小的元素，只可能从取中节点所在的链表产生。所以从那个链表头部取一个节点。 3、不断取一个补一个，最后再将堆中的元素全部取出的即可。 排序链表https://leetcode.cn/problems/sort-list 1234567891011121314151617181920212223242526272829303132333435363738394041class Solution { public ListNode meregeTowListInplace(ListNode head1, ListNode head2){ ListNode op1 = head1; ListNode op2 = head2; ListNode dummyHead = new ListNode(-1); ListNode op3 = dummyHead; while(op1!=null &amp;&amp; op2!=null){ if(op1.val &lt; op2.val){ op3.next = op1; op1=op1.next; }else{ op3.next = op2; op2=op2.next; } op3 = op3.next; } if(op1!=null) op3.next = op1; if(op2!=null) op3.next = op2; return dummyHead.next; } public ListNode mergeSort(ListNode head){ if(head==null||head.next==null) return head; // 首先将一条链表分为前后两半链表 // 偶数长度链表的中间节点在后一半的第一个节点上 ListNode slow =head, fast =head.next; while(fast!=null &amp;&amp; fast.next!=null){ fast = fast.next.next; slow = slow.next; } // 此时slow指向前一半的最后个节点 // 根据slow将链表分为两半 ListNode secondHead = slow.next; slow.next=null; ListNode head1 = mergeSort(head); ListNode head2 = mergeSort(secondHead); return meregeTowListInplace(head1, head2); } public ListNode sortList(ListNode head) { return mergeSort(head); }} 重排链表https://leetcode.cn/problems/reorder-list/description/ 123456789101112131415161718192021222324252627282930313233class Solution { public ListNode reverse(ListNode head){ if(head==null || head.next ==null) return head; ListNode tmp = reverse(head.next); head.next.next = head; head.next =null; return tmp; } public void reorderList(ListNode head) { // 获取后一半链表 if(head==null || head.next ==null) return ; ListNode slow = head; ListNode fast = head.next; while(fast!=null &amp;&amp; fast.next!=null){ slow = slow.next; fast = fast.next.next; } // 反转后一半 ListNode head2 = reverse(slow.next); slow.next =null; // 合并两条链表 ListNode head1 = head; while(head2!=null){ ListNode tmp1 = head1.next; ListNode tmp2 = head2.next; head1.next = head2; head2.next = tmp1; head1 = tmp1; head2 = tmp2; } return ; }} 技术细节：快慢指针+反转链表 其他判断回文链表 https://leetcode.cn/problems/palindrome-linked-list/ 123456789101112131415161718192021222324252627class Solution { public ListNode reverseList(ListNode head){ if(head==null || head.next==null) return head; ListNode tmp = reverseList(head.next); head.next.next = head; head.next =null; return tmp; } public boolean isPalindrome(ListNode head) { if(head==null || head.next==null) return true; ListNode slow =head, fast = head; // 排除了空节点和单节点的情况后，剩下至少两个节点 while(fast!=null &amp;&amp; fast.next!=null){ fast = (fast.next==null)? fast.next:fast.next.next; slow = slow.next; } ListNode LastHalfNode = reverseList(slow); while(LastHalfNode!=null &amp;&amp; head!=null){ if (LastHalfNode.val != head.val){ return false; } LastHalfNode = LastHalfNode.next; head = head.next; } return true; }} 暴力的做法是开辟额外空间存储遍历后数组的值，再用双指针前后夹击判断。思考空间复杂读O（1）的算法，自然的想法是翻转一半的链表，然后比较两条链表。 （1）获取中间节点 方法是快慢指针。问题来了，奇数长度中间节点是确定的，偶数长度链表的中间节点是哪一个？答案是取决于快慢指针的具体实现，有可能是前一半的最后一个节点，也有可能是后一半的第一个节点。 12345ListNode slow =head, fast = head;while(fast!=null &amp;&amp; fast.next!=null){ fast = (fast.next==null)? fast.next:fast.next.next; slow = slow.next;} （2）偷懒的一个技巧 直接比较两条链表，不比较长度，奇数长度情况下最后一个节点不会被比较。 升序矩阵寻找第K个大小的元素https://leetcode.cn/problems/kth-smallest-element-in-a-sorted-matrix/description/ 12345678910111213141516171819202122232425262728293031323334353637class Solution { class Status implements Comparable&lt;Status&gt;{ public int val; public int x; public int y; Status(int val, int x, int y){ this.val = val; this.x = x; this.y = y; } @Override public int compareTo(Status st){ if(this.val &lt; st.val) return -1; if(this.val &gt; st.val) return 1; return 0; } } public int kthSmallest(int[][] matrix, int k) { PriorityQueue&lt;Status&gt; pq = new PriorityQueue&lt;&gt;(); int N = matrix.length; //添加第一列 for(int i=0; i&lt;N; ++i) pq.offer(new Status(matrix[i][0], i, 0)); //然后每次取一个，加一个 while(k&gt;1){ Status st = pq.poll(); if(st.y &lt; N-1){ // 如果这一行还没取完，就继续取 int new_x = st.x; int new_y = st.y+1; pq.offer(new Status(matrix[new_x][new_y], new_x, new_y)); } k--; } Status st = pq.poll(); return st.val; }} 这道题的思想和合并K个升序链表一摸一样。但是忽略了列间的单调上升关系。","link":"/2023/12/12/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/Java%E9%93%BE%E8%A1%A8%E6%80%BB%E7%BB%93/"},{"title":"MIT6.824笔记一 绪论与MapReduce","text":"MIT 6.824 课程第一节笔记，主要介绍了分布式系统的驱动力、难点、类型等，还介绍了MapReduce。 分布式系统介绍（1）驱动力 更高的计算性能（并行计算、大CPU、大内存、大磁盘） 容错机制（两台计算机运行相同的任务，一台失败可到另外一台） 问题的分布特性（比如说银行转账） RPC与代码隔离，只通过网络通信 这门课程主要研究性能与容错。 （2）困难 并行 容错 兼顾性能 （3）分布式系统的类型 基础架构的类型主要是存储，通信（网络）和计算。 实际上我们最关注的是存储，构建一种多副本，容错的，高性能分布式存储实现。 会讨论一些计算系统，比如MapReduce。 也会说一些关于通信的问题，但是主要的出发点是通信是我们建立分布式系统所用的工具。 对于存储和计算，我们的目标是为了能够设计一些简单接口，让第三方应用能够使用这些分布式的存储和计算，这样才能简单的在这些基础架构之上，构建第三方应用程序。 （4）工具 RPC（Remote Procedure Call）。RPC的目标就是掩盖我们正在不可靠网络上通信的事实。 线程。这是一种编程技术，使得我们可以利用多核心计算机。对于本课程而言，更重要的是，线程提供了一种结构化的并发操作方式，这样，从程序员角度来说可以简化并发操作。 并发控制，比如锁。 （5）其他特性 可拓展性：N倍的机器能否带来N倍的性能提升？ 可用性：容错、故障应对 一致性：读写一致性，系统正确的行为 Map Reduce背景Google （2003 年左右）面对巨量（数十 T）的索引数据和全网结构的数据，需要找到最重要的网页。这可以简化为一个排序问题，但如此数量级的排序，单机不是一个可选项。 MapReduce的思想是，应用程序设计人员和分布式运算的使用者，只需要写简单的Map函数和Reduce函数，而不需要知道任何有关分布式的事情，MapReduce框架会处理剩下的事情。 工作原理 两类任务：Map和Reduce一个主节点分配任务，若干个worker节点干活。 看起来很简单的架构，但在分布式环境下，需要考虑： worker节点崩溃，需要任务完成确认机制以及崩溃后临时文件的清理 网络通信不可靠，发送任务和确认任务的消息均可能丢失","link":"/2023/11/25/MIT6.824/%E7%AC%94%E8%AE%B01%E7%BB%AA%E8%AE%BA/"},{"title":"MIT6.824笔记二 Go与RPC","text":"这节课主要介绍Go语言以及用Go实现爬虫的例子。 GOGO的优势 语法层面支持线程和管道 垃圾回收机制，不需要手动管理内存 类型安全（内存安全） //关于内存安全还需要再深刻认识 线程协调方式 channels：go 中比较推荐的方式，分阻塞和带缓冲。 sync.Cond：信号机制。 waitGroup：阻塞知道一组 goroutine 执行完毕，后面还会提到。 爬虫例子 从一个种子网页 URL 开始 通过 HTTP 请求，获取其内容文本 解析其内容包含的所有 URL，针对所有 URL 重复过程 2，3 为了避免重复抓取，需要记下所有抓取过的 URL。 串行爬取（1）串行爬取的主要逻辑 12fmt.Printf(&quot;=== Serial===\\n&quot;)Serial(&quot;http://golang.org/&quot;, fetcher, make(map[string]bool)) 1234567891011121314func Serial(url string, fetcher Fetcher, fetched map[string]bool) { if fetched[url] { return } fetched[url] = true urls, err := fetcher.Fetch(url) if err != nil { return } for _, u := range urls { Serial(u, fetcher, fetched) } return} 深度优先遍历（DFS ）全部网页构成的图结构，利用一个名为 fetched 的 set 来保存所有已经抓取过的 URL。 （2）爬取函数的主要逻辑 Fetcher接口，里面定义了一个Fetch方法 fakeFetcher自定义类型，是一个string到fakeResult的map fakeResult结构体，包括body和urls 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859//// Fetcher//type Fetcher interface { // Fetch returns a slice of URLs found on the page. Fetch(url string) (urls []string, err error)}// fakeFetcher is Fetcher that returns canned results.type fakeFetcher map[string]*fakeResult //自定义类型type fakeResult struct { body string urls []string}func (f fakeFetcher) Fetch(url string) ([]string, error) { if res, ok := f[url]; ok { fmt.Printf(&quot;found: %s\\n&quot;, url) return res.urls, nil } fmt.Printf(&quot;missing: %s\\n&quot;, url) return nil, fmt.Errorf(&quot;not found: %s&quot;, url)}// fetcher is a populated fakeFetcher.var fetcher = fakeFetcher{ &quot;http://golang.org/&quot;: &amp;fakeResult{ &quot;The Go Programming Language&quot;, []string{ &quot;http://golang.org/pkg/&quot;, &quot;http://golang.org/cmd/&quot;, }, }, &quot;http://golang.org/pkg/&quot;: &amp;fakeResult{ &quot;Packages&quot;, []string{ &quot;http://golang.org/&quot;, &quot;http://golang.org/cmd/&quot;, &quot;http://golang.org/pkg/fmt/&quot;, &quot;http://golang.org/pkg/os/&quot;, }, }, &quot;http://golang.org/pkg/fmt/&quot;: &amp;fakeResult{ &quot;Package fmt&quot;, []string{ &quot;http://golang.org/&quot;, &quot;http://golang.org/pkg/&quot;, }, }, &quot;http://golang.org/pkg/os/&quot;: &amp;fakeResult{ &quot;Package os&quot;, []string{ &quot;http://golang.org/&quot;, &quot;http://golang.org/pkg/&quot;, }, },} 并行爬取（1）思考并行的方法 简单将抓取部分用go关键并行。 但如果仅这么改造，不利用某些手段（sync.WaitGroup）等待子 goroutine，而直接返回，那么可能只会抓取到种子 URL，同时造成子 goroutine 的泄露。 如果访问已经抓取的 URL 集合 fetched 不加锁，很可能造成多次拉取同一个网页（两个线程都访问fetched，这个url访问过了吗，结果都是未访问） （2）并行实现——利用锁和共享变量 12fmt.Printf(&quot;=== ConcurrentMutex ===\\n&quot;)ConcurrentMutex(&quot;http://golang.org/&quot;, fetcher, makeState()) 1234567891011121314151617181920212223242526272829303132333435363738394041//// Concurrent crawler with shared state and Mutex//type fetchState struct { mu sync.Mutex fetched map[string]bool}func makeState() *fetchState { return &amp;fetchState{fetched: make(map[string]bool)}}func (fs *fetchState) testAndSet(url string) bool { fs.mu.Lock() defer fs.mu.Unlock() r := fs.fetched[url] fs.fetched[url] = true //已经访问过 return r}func ConcurrentMutex(url string, fetcher Fetcher, fs *fetchState) { if fs.testAndSet(url) { //这里其实就是用锁保护map的更新 return } urls, err := fetcher.Fetch(url) if err != nil { return } var done sync.WaitGroup for _, u := range urls { done.Add(1) go func(u string) { defer done.Done() ConcurrentMutex(u, fetcher, fs) }(u) } done.Wait() return} 其中，关键部分为：sync.WaitGroup 123456789var done sync.WaitGroupfor _, u := range urls { done.Add(1) go func(u string) { defer done.Done() ConcurrentMutex(u, fetcher, fs) }(u)}done.Wait() WaitGroup 内部维护了一个计数器：调用 wg.Add(n) 时候会增加 n；调用 wait.Done() 时候会减少 1。调用 wg.Wait() 会一直阻塞直到当计数器变为 0 所以 WaitGroup 适合等待一组 goroutine 都结束的场景。 利用channel实现并行爬取我们可以实现一个新的爬虫版本，不用锁 + 共享变量，而用 go 中内置的语法：channel 来通信。具体做法类似实现一个生产者消费者模型，使用 channel 做消息队列。 初始将种子 url 塞进 channel。 消费者：master 不断从 channel 中取出 urls，判断是否抓取过，然后启动新的 worker goroutine 去抓取。 生产者：worker goroutine 抓取到给定的任务 url，并将解析出的结果 urls 塞回 channel。 master 使用一个变量 n 来追踪发出的任务数；往发出一份任务增加一；从 channel 中获取并处理完一份结果（即将其再安排给 worker）减掉一；当所有任务都处理完时，退出程序。 12fmt.Printf(&quot;=== ConcurrentChannel ===\\n&quot;)ConcurrentChannel(&quot;http://golang.org/&quot;, fetcher) 1234567891011121314151617181920212223242526272829303132333435363738//// Concurrent crawler with channels//func worker(url string, ch chan []string, fetcher Fetcher) { urls, err := fetcher.Fetch(url) if err != nil { ch &lt;- []string{} } else { ch &lt;- urls }}func coordinator(ch chan []string, fetcher Fetcher) { n := 1 fetched := make(map[string]bool) for urls := range ch { for _, u := range urls { if fetched[u] == false { fetched[u] = true n += 1 go worker(u, ch, fetcher) } } n -= 1 if n == 0 { break } }}func ConcurrentChannel(url string, fetcher Fetcher) { ch := make(chan []string) go func() { ch &lt;- []string{url} }() coordinator(ch, fetcher)} Q&amp;A: master 读 channel，多 worker 写 channel，不会有竞争问题吗？channel 是线程安全的。 channel 不需要最后 close 吗？我们用 n 追踪了所有执行中的任务数，因此当 n 为 0 退出时，channel 中不存在任何任务 / 结果，因此 master/worker 都不会对 channel 存在引用，稍后 gc collector 会将其回收。 为什么在 ConcurrentChannel 需要用 goroutine 往 channel 中写一个 url？否则 master 在读取的时候会一直阻塞。并且 channel 是一个非缓冲 channel，如果不用 goroutine，将会永远阻塞在写的时候。第3个问题，如果不用goroutine，并且是非缓冲管道情况下，发送方会阻塞在发送代码，直到有接收放接收消息。","link":"/2023/11/25/MIT6.824/%E7%AC%94%E8%AE%B02RPC%E4%B8%8E%E7%BA%BF%E7%A8%8B/"},{"title":"MIT6.824笔记三 分布式存储系统GFS","text":"这节课主要介绍分布式存储系统的难点以及论文GFS。 分布式系统出现的原因是人们想要利用更多的机器实现更好的性能，但更多的机器意味着故障的期望上升。解决单台机器故障最简单的办法就是多副本的容错机制，但多副本间需要时间同步。一致性难题意味着牺牲性能，这是个闭环，人们必须在性能和一致性上做取舍。 对于GFS的学习，我觉得首先要明白GFS应对的需求，整体的架构设计，然后就是读写过程，数据一致性，这是从使用层面上来说的。在高可用方面，GFS的备份管理、文件快照、崩溃恢复等细节需要再深入研究。 分布式存储系统的难点从一种角度出发理解分布式储存的难点： 性能 一开始，人们想用大量机器提供更高的性能，这称之为分片（sharding）。但分片一多，故障率就上来了。 故障 故障：单台计算机出错概率小，多台计算机出错的期望就上来了。上千台计算机总有一台失效停机。我们需要一种容错机制（fault torlance）。 容错 实现容错机制最简单的办法就是提供多个副本（replication、backup），一旦一个副本失败，就马上用另一个副本顶替。 副本 有了复制，也还需要注意副本之间的同步，或者说一致型。 一致性 维护一致性通常需要精心设计的手段，比如说主从之间定期通信，传快照或者状态改变。但无论如何设计，一致性的存在或多或少会损害性能。这就是分布式存储系统/分布式系统的难点所在。 如果构建强一致系统会付出相应代价，如果不想付出很多代价，就得忍受不确定的行为。在实践中，要根据场景设计合理的系统，适当取舍。 尽管我们会通过数百台计算机构建一个系统，但是对于一个理想的强一致模型，你看到的就像是只有一台服务器，一份数据，并且系统一次只做一件事情。这是一种直观的理解强一致的方式。 Google File SystemGFS 是谷歌最早开发应用的分布式存储框架。GFS的可贵之处在于它的应用性，尽管学界研究了数十年的分布式系统，但GFS是第一个应用到上千台计算机的分布式系统。论文写得很棒，推荐读英文原文。 论文中的一些思想在当时都不是特别新颖，比如分布式，分片，容错这些在当时已经知道如何实现了。这篇论文的特点是，它描述了一个真正运行在成百上千台计算机上的系统，这个规模远远超过了学术界建立的系统。并且由于GFS被用于工业界，它反映了现实世界的经验，例如对于一个系统来说，怎样才能正常工作，怎样才能节省成本，这些内容也极其有价值。 GFS 可贵之处是经过实践检验、部署过上千台机器的工业级系统，颠覆了之前学术界中很多的经典设计认知，比如： 为了保证数据访问不出错，需要提供强一致性保证（GFS 仅提供某种弱一致性） 为了系统的可靠性，用多机来保证主节点的可靠性（GFS 使用了单点 Master） GFS的设计场景对于任何一种分布式系统，都要明确它应用的场景需求，然后才能对此作出相应设计保障。 大文件存储，GB级别大小 大量顺序读和少量随机读 大量追加写和少量随机写 能够应对多客户端并发写入 部署在普通计算机上，有较高故障率，需要好的容错机制 GFS的总体设计 一个GFS集群包括若干个客户端、一个主节点、若干个从节点（分片服务器成，chunkserver）。 文件被分为64MB大小的块，每个块对应一个唯一64bit的块标识（chunk handle）并分散存储在从节点上。从节点就只是个运行LInux系统的普通机器。 主节点维护命名空间（文件系统的路径）、访问控制信息、文件与块的对应信息、块的存储信息（每个块存储在哪个从节点上）。 客户端与主节点的交互只有文件的元信息。客户端得到它想要的文件存储的真实信息后，就直接向从节点索要数据。 GFS读过程// 略 GFS写过程// 略 GFS的一致性GFS 把自己的一致性称为松弛的一致性模型（relaxed consistency model）。 元数据（命名空间）的操作都是由单一的 master 处理的，并且操作通过锁来保护，保证了原子性，也保证了正确性。 文件的数据修改则相对复杂。在讲述接下来的内容前，首先我们先明确，在文件的某一部分被修改后，它可能进入以下三种状态的其中之一： 客户端读取不同的 Replica 时可能会读取到不同的内容，那这部分文件是不一致的（Inconsistent） 所有客户端无论读取哪个 Replica 都会读取到相同的内容，那这部分文件就是一致的（Consistent） 所有客户端都能看到上一次修改的所有完整内容，且这部分文件是一致的，那么我们说这部分文件是确定的（Defined） 在修改后，一个文件的当前状态将取决于此次修改的类型以及修改是否成功。具体来说： 如果一次写入操作成功且没有与其他并发的写入操作发生重叠，那这部分的文件是确定的（同时也是一致的） 如果有若干个写入操作并发地执行成功，那么这部分文件会是一致的但会是不确定的：在这种情况下，客户端所能看到的数据通常不能直接体现出其中的任何一次修改 失败的写入操作会让文件进入不一致的状态 适应 GFS 的松弛一致性GFS 的松弛一致性模型，实际上是一种不一致的模型，或者更准确地说，在一致的数据中间夹杂着不一致的数据。这就要求上层应用在使用 GFS 时能够适应 GFS 所提供的一致性语义。 论文中给出了几条使用 GFS 的建议：依赖追加（append）而不是依赖覆盖（overwrite）、设立检查点（checkpoint）、写入自校验（write self-validating）、自记录标识（self-identifying record）。 简单来讲，上层应用可以通过两种方式来做到这一点：更多使用追加操作而不是覆写操作；写入包含校验信息的数据。 青睐追加操作而不是覆写操作的原因是明显的：GFS 针对追加操作做出了显著的优化，这使得这种数据写入方式的性能更高，而且也能提供更强的一致性语义。 对于不一致的数据，为每条记录添加校验数，读取方通过校验数识别出不一致的数据，并且丢弃不一致的数据。 对于重复数据，可以采用数据幂等处理。具体来说，可以采用两种方式处理。第一种，对于同一份数据处理多次，这并无负面影响；第二种，如果执行多次处理带来不同的结果，那么应用就需要过滤掉不一致的数据。写入方写入记录时额外写入一个唯一的标识（identifier），读取方读取数据后，通过标识辨别之前是否已经处理过该数据。 GFS的设计哲学前面讲解了基于GFS的应用，需要通过一些特殊手段来应对GFS的松弛一致性模型带来的各种问题。对于使用者来说，GFS的一致性保证是非常不友好的，很多人第一次看到这样的一致性保证都是比较吃惊的。 GFS在架构上选择这样的设计，有它自己的设计哲学。GFS追求的是简单、够用的原则。GFS主要解决的问题是如何使用廉价的服务器存储海量的数据，且达到非常高的吞吐量（GFS非常好地做到了这两点，但这不是本书的主题，这里就不展开介绍了），并且文件系统本身要简单，能够快速地实现出来（GFS的开发者在开发完GFS之后，很快就去开发BigTable了[2]）。 GFS很好地完成了这样的目标，但是留下了一致性问题，给使用者带来了负担。这个问题在GFS推广应用的初期阶段不明显，因为GFS的主要使用者（BigTable系统是GFS系统的主要调用方）就是GFS的开发者，他们深知应该如何使用GFS。这种不一致性在BigTable中被屏蔽掉（采用上面所说的方法），BigTable提供了很好的一致性保证。 但是随着GFS推广应用的不断深入，GFS简单、够用的架构开始带来很多问题，一致性问题仅仅是其中之一。Sean Quinlan作为Leader主导GFS的研发很长时间，在一次采访中，他详细说明了在GFS渡过推广应用的初期阶段之后，这种简单的架构带来的各种问题[2]。 在清晰地看到GFS的一致性模型给使用者带来的不便后，开源的HDFS（Hadoop分布式文件系统）坚定地摒弃了GFS的一致性模型，提供了更好的一致性保证（第3章将介绍HDFS的实现方式）。 参考资料： Google File System 论文详析 https://zhuanlan.zhihu.com/p/33944479 GFS的分布式哲学 https://mp.weixin.qq.com/s/ut8Q7vXa5Lm0auNaN2_Emg [1] Ghemawat S, Gobioff H, Leung S T. The Google File System. ACM SIGOPS Operating Systems Review, 2003. [2] Marshall, Kirk, McKusick, et al. GFS: Evolution on Fast-forward. Communications of the ACM, 2009.","link":"/2023/11/25/MIT6.824/%E7%AC%94%E8%AE%B03GFS/"},{"title":"MIT6.824笔记四 容错与FTVM","text":"这节课主要介绍容错的主要手段——复制以及相应的论文：Fautl-Tolerant Virtual Machines。 复制与容错关系容错本身是为了提供高可用性。例如，当你想构建一个服务时，尽管计算机硬件总是有可能故障，但是我们还是希望能稳定的提供服务。 容错的简单手段就是复制。复制能应对什么样的故障？ 最简单的描述就是单台计算机的fail-stop故障。Fail-stop是一种容错领域的通用术语。它是指，如果某些东西出了故障，比如说计算机，那么它会单纯的停止运行。当任何地方出现故障时，就停止运行，而不是运算出错误结果。 但是复制不能处理软件中的bug和硬件设计中的缺陷，关联性错误（同一批次产品的生产设计缺陷）。 Fautl-Tolerant Virtual MachinesINTRODUCTION论文的introduction写得很简练，直接放原文。 A common approach to implementing fault-tolerant servers is the primary / backup approach [1], where a backup server is always available to take over if the primary server fails. The state of the backup server must be kept nearly identical to the primary server at all times, so that the backup server can take over immediately when the primary fails, and in such a way that the failure is hidden to external clients and no data is lost. 应对容错的主要方式就是主从复制。主节点崩溃时，从节点能够马上接管，并且从节点的状态要与主节点尽可能一致。 One way of replicating the state on the backup server is to ship changes to all state of the primary, including CPU, memory, and I/O devices, to the backup nearly continuously. However, the bandwidth needed to send this state, particular changes in memory, can be very large. 在备份服务器上复制状态的一种方法是将对主服务器的所有状态（包括 CPU、内存和 I/O 设备）的更改几乎连续地传送到备份中。但是，发送此状态所需的带宽（特别是内存中的更改）可能非常大。 A different method for replicating servers that can use much less bandwidth is sometimes referred to as the state-machine approach [13]. The idea is to model the servers as deterministic state machines that are kept in sync by starting them from the same initial state and ensuring that they receive the same input requests in the same order. Since most servers or services have some operations that are not deterministic, extra coordination must be used to ensure that a primary and backup are kept in sync. However, the amount of extra information need to keep the primary and backup in sync is far less than the amount of state (mainly memory updates) that is changing in the primary. 另一种方法基于状态机。这个想法是通过从相同的初始状态启动服务器并确保它们以相同的顺序接收相同的输入请求来将服务器建模为保持同步的确定性状态机。由于大多数服务器或服务都具有一些不确定的操作，因此必须使用额外的协调来确保主服务器和备份服务器保持同步。但是，保持主数据库和备份数据库同步所需的额外信息量远远小于主数据库中更改的状态（主要是内存更新）量。 BASIC FT DESIGN 所有的输入（网络输入、鼠标键盘输入）由主节点接收。主节点和从节点间通过网络的方式通信，称之为logging channel。主节点将它看见的所有输入都通过logging channel 发给从节点。另外，logging channel还传输一些其他包括非确定性行为的信息。 这样从节点就和主节点执行一模一样的的操作，但是从节点的输出被抛弃，只有主节点才能回复客户端。 非确定性事件非确定性事件：不由当前内存和寄存器直接决定的指令 比如随机数生成、事件日期、唯一ID，这些统称为Weird Instructions 客户端的网络输入：包中的数据和包到达的中断触发位置。 FT Protocoloutput requirement if the backup VM ever takes over after a failure of the primary, the backup VM will continue executing in a way that is entirely consistent with all outputs that the primary VM has sent to the external world. 如果备份虚拟机在主虚拟机发生故障后接管，则备份虚拟机将继续以与主虚拟机发送到外部世界的所有输出完全一致的方式执行。 感觉这句话就是脱裤子放屁，多此一举。从状态机肯定要与主状态机状态一致，这样才能在故障时进行主从切换。可以通过延迟任何外部输出（通常是网络数据包）来确保输出要求，直到备份 VM 收到所有信息，使其至少可以重播到该输出操作的点。这就引出来第二个点 output rule the primary VM may not send an out put to the external world, until the backup VM has received and acknowledged the log entry associated with the operation producing the output. 只有主节点收到日志复制完成的回复，它才向外部输出。这意味着从节点收到了日志（此时日志可能堆在缓冲区，尚未执行） Test-and-Set服务一种常见的场景就是主从间网络不可用，此时它们都以为对方挂了，从而各自掌权回复客户端，也就是脑裂问题。 这篇论文解决这个问题的方法是，向一个外部的第三方权威机构求证，来决定Primary还是Backup允许上线。这里的第三方就是Test-and-Set服务。 VM通过网络请求Test-and-Set服务，这个服务会在内存中保留一些标志位，当你向它发送一个Test-and-Set请求，它会设置标志位，并且返回旧的值。这有点像锁，保证了原子操作。任何情况下，想要上线掌权的副本都需要获取Test-and-Set服务。 持有锁的服务挂了怎么办？一般锁都是设置一个租约，有一些心跳机制来续约。","link":"/2023/11/25/MIT6.824/%E7%AC%94%E8%AE%B04VMwareFT/"},{"title":"MIT6.824笔记五 Raft","text":"Raft是一个分布式共识算法/协议，即让多台机器达成一致的算法。 Raft将共识问题分解为三部分：Leader选举、Log复制以及安全性设置(一致性设置）。 由于实验2完整复现了Raft协议，这里只挑一些重点讲。复现时应该着重考虑：节点崩溃又上线、不可靠网络。 Leader选举角色转变 server有三种状态：follower、candidate、leader。分别经过如图所示的过程进行状态转变。 follower和candidate的任务就是等定时器过期发起投票，leader则是发起心跳请求。 当followers选举时间间隔到期后转变为candidate，增加自己的任期号，发起一轮投票； 当leader时，心跳时间间隔开启，选举时间间隔关闭，每隔一段时间向所有node发送空的AppendEntry。 任期机制 发送和回复RPC都要带上自己的任期。任何时刻（收到请求和处理回复）发现自己的任期旧，都要转变身份为follower。 一期一票制度：一个机器在一个任期只能投一票，投票对象VotedFor应该作持久化，避免节点崩溃再次上线重新投票。 投票过程想明白几个问题： 什么时候才能发起投票？ 发起投票的步骤？ 收到过半选票后的处理？ 什么条件下才能为candidate投出自己的选票？ 选举定时器重置的时间点？ 过半票决的好处： 在一机一票的场景下，只会产生一个leader节点 出现网络分区的时候，只可能有一个分区会有超过一半的服务器互相通信 旧leader的过半服务器必然与新leader的过半服务器有重叠，那么就有一个服务器经历过两个任期，它收集了完整的log信息 响应投票： 收到投票RPC消息后，需要比较任期号，驳回旧的任期号投票请求； 如果任期号校验通过，重置选举时间； 当且仅当自己的votedFor为空或为消息中的candidateId时，并且比较自己的log与RPC中的lastLog信息后，才同意投票，并设置自己的votedFor为candidateId。 日志复制想明白几个问题： nextIndex和matchIndex的作用？ 日志不一致时的回退算法？ 什么时候日志能提交？怎么避免日志重复提交？ leader只能提交当前任期内的日志。","link":"/2023/12/13/MIT6.824/%E7%AC%94%E8%AE%B05Raft/"},{"title":"MIT6.824笔记六 线性一致与Zookeeper","text":"这节课主要介绍了线性一致的概念与Zookeeper论文。 线性一致描述的是系统的行为，正确的行为是客户端发送了一个写请求并且收到服务端答复后，这个写请求能被之后的读请求看到。每个读请求看到的都是最新的写请求所作的更改。 Zookeeper论文是我接触到的最抽象的一篇论文。首先它的功能就很抽象：分布式协调内核。它提供的两个保证：线性写和FIFO客户端请求也费时间理解。最后则是它的API调用以及具体实现。 读这篇论文的原因我想一是Zookeeper的广泛使用，证明了其实用性；二是其“线性一致”的设计，契合课程。收获就是其API的设计、Watch模式。 线性一致（1）例子 12345example history 1: |-Wx1-| |-Wx2-| |---Rx2---| |-Rx1-|is this history linearizable? 满足以下两个要求： 线性后的序列要与实际请求时间相匹配（一个请求的结束时间在另一个请求的开启时间之前，那么线性序列也必须遵守） 每个读请求看到都是序列中前一个写请求的值 （2）线性一致 线性一致更多描述的是关于系统行为的定义，我们只能通过一系列请求以及返回值来推测一个系统是否是线性一致的。 在一个线性一致的系统中，读请求不允许返回旧的数据。也就是说，如果我发起了一个写请求，然后再读，如果读到的不是上次写的值，那这个系统就不是线性一致的。 ZooKeeper 参考了个人笔记：https://zhuanlan.zhihu.com/p/363396366 介绍ZookeeperZookeeper是一个通用的分布式协调服务（General-Purpose Coordination Service），通过提供协调内核/客户端API的形式，让开发者自己实现诸多原语/功能，包括统一命名、配置管理、成员管理、分布式锁、双重屏障等。 Zookeeper基于Zab（类似Raft的基于领导者的原子广播协议）实现了多副本容错机制，但不同于Raft，Zookper的所有副本都能接受读请求。这得益于Zookeeper的两个设计：线性写和FIFO客户端请求。 Zookeeper为客户端提供了一组数据节点（称之为Znode），Znode根据分层名称空间进行组织，记法上类似于Unix的文件系统。客户端通过Zookeeper提供的API能对数据节点进行创建、删除、读取、写入、获取目录下所有文件等操作。Zookeeper还实现了一种Watch机制，通过此机制，客户端能够监听某个Znode的变化（更新、删除），Zookeeper会在Znode发生变化时向客户端发送一条通知消息。 Zookeeper API Zookeeper的API某种程度上来说像是一个文件系统。它有一个层级化的目录结构，有一个根目录（root），之后每个应用程序有自己的子目录。文件和目录都被称为znodes。 1234567891011`CREATE(PATH，DATA，FLAG)`。入参分别是文件的全路径名PATH，数据DATA，和表明znode类型的FLAG。这里有意思的是，CREATE的语义是排他的。`DELETE(PATH，VERSION)`。入参分别是文件的全路径名PATH，和版本号VERSION。有一件事情我之前没有提到，每一个znode都有一个表示当前版本号的version，当znode有更新时，version也会随之增加`EXIST(PATH，WATCH)`。入参分别是文件的全路径名PATH，和一个有趣的额外参数WATCH。通过指定watch，你可以监听对应文件的变化。`GETDATA(PATH，WATCH)`。入参分别是文件的全路径名PATH，和WATCH标志位。这里的watch监听的是文件的内容的变化。`SETDATA(PATH，DATA，VERSION)`。入参分别是文件的全路径名PATH，数据DATA，和版本号VERSION。如果你传入了version，那么Zookeeper当且仅当文件的版本号与传入的version一致时，才会更新文件。`LIST(PATH)`。入参是目录的路径名，返回的是路径下的所有文件。 Znode有两种基本类型：Regular和Ephemeral。创建的api还包括一个sequential flag。 Znode还关联了时间戳、版本信息。 更新方法都带有一个版本号，只有版本号与Znode的版本号一致时，更新操作才能成功。 配置管理如何利用Zookeeper实现动态配置管理？非常简单。 配置管理器将配置写在一个Znode中，其他进程读这个Znode，同时设置Watch标志位。如果Znode中的配置改变了，那么其他进程将会收到通知，并且会再次读取最新配置。 集合点Rendezvous我理解为进程同步。客户端创建Znode，然后将Zode的full path作为参数传递给master process和worker process。如果master process先创建完成，那么它就将它的信息（addresses and ports）写入到Znode中；如果是worker process先创建完成，它照样读取Znode并设置Watch标志位，后续mater改变Znode后，worker就能读取信息。 组成员管理利用一个Znode 表示组。当组成员创建时，只需创建一个对应的Znode的Child Znode。如果需要唯一的对应，可设置Sequentail标志位。如果需要获取一个Group的信息，只需要简单调用list api查看Znode的所有Child。如果一个进程要监视组信息的变化，为每一个组成员设置Watch标志位即可。 ephemeral node有一个好处是能代表会话的状态，当进程失败或结束时，ephemeral node会自动移除。 分布式锁1234WHILE TRUE: IF CREATE(&quot;f&quot;, data, ephemeral=TRUE): RETURN IF EXIST(&quot;f&quot;, watch=TRUE): WAIT 总的来说，先是通过CREATE创建锁文件，或许可以直接成功。如果失败了，我们需要等待持有锁的客户端释放锁。通过Zookeeper的watch机制，我们会在锁文件删除的时候得到一个watch通知。收到通知之后，我们回到最开始，尝试重新创建锁文件，如果运气足够好，那么这次是能创建成功的。 Herd Effect如果有1000个客户端同时要获得锁文件，为1000个客户端分发锁所需要的时间也是N方。因为每一次锁文件的释放，所有剩下的客户端都会收到WATCH的通知，并且回到循环的开始，再次尝试创建锁文件。 为了获得锁，要通知一大群的线程，也就是惊群，最会只有一个线程能获得锁。 123456CREATE(&quot;f&quot;, data, sequential=TRUE, ephemeral=TRUE)WHILE TRUE: LIST(&quot;f*&quot;) IF NO LOWER #FILE: RETURN IF EXIST(NEXT LOWER #FILE, watch=TRUE): WAIT 代码第4行，如果现存的Sequential文件的序列号都不小于我们在代码第1行得到的序列号，那么表明我们在并发竞争中赢了，我们获得了锁。所以当我们的Sequential文件对应的序列号在所有序列号中最小时，我们获得了锁，直接RETURN。序列号代表了不同客户端创建Sequential文件的顺序。在这种锁方案中，会使用这个顺序来向客户端分发锁。当存在更低序列号的Sequential文件时，我们要做的是等待拥有更低序列号的客户端释放锁。在这个方案中，释放锁的方式是删除文件。所以接下来，我们需要做的是等待序列号更低的锁文件删除，之后我们才能获得锁。 所以，在代码的第5行，我们调用EXIST，并设置WATCH，等待比自己序列号更小的下一个锁文件删除。如果等到了，我们回到循环的最开始。但是这次，我们不会再创建锁文件，代码从LIST开始执行。这是获得锁的过程，释放就是删除创建的锁文件。 学生提问：为什么这种锁不会受羊群效应（Herd Effect）的影响？ Robert教授：假设我们有1000个客户端在等待获取锁，每个客户端都会在代码的第6行等待锁释放。但是每个客户端等待的锁文件都不一样，比如序列号为500的锁只会被序列号为501的客户端等待，而序列号500的客户端只会等待序列号499的锁文件。 每个客户端只会等待一个锁文件，当一个锁文件被释放，只有下一个序列号对应的客户端才会收到通知，也只有这一个客户端会回到循环的开始，也就是代码的第3行，之后这个客户端会获得锁。所以，不管有多少个客户端在等待锁，每一次锁释放再被其他客户端获取的代价是一个常数。而在非扩展锁中，锁释放时，每个等待的客户端都会被通知到，之后，每个等待的客户端都会发送CREATE请求给Zookeeper，所以每一次锁释放再被其他客户端获取的代价与客户端数量成正比。 双重屏障// todo 计数器第一个很简单的例子是计数器，假设我们在Zookeeper中有一个文件，我们想要在那个文件存储一个统计数字，例如，统计客户端的请求次数，当收到了一个来自客户端的请求时，我们需要增加存储的数字。 1234WHILE TRUE: X, V = GETDATA(&quot;F&quot;) IF SETDATA(&quot;f&quot;, X + 1, V): BREAK 这个例子，其实就是大家常说的mini-transaction。这里之所以是事务的，是因为一旦我们操作成功了，我们对计数器达成了_读-更改-写_的原子操作。 之所以称之为mini-transaction，是因为这里并不是一个完整的数据库事务（transaction）。一个真正的数据库可以使用完整的通用的事务，你可以指定事务的开始，然后执行任意的数据读写，之后结束事务。一个真实的事务可能会非常复杂，而Zookeeper支持这种非常简单的事务，使得我们可以对于一份数据实现原子操作。这对于计数器或者其他的一些简单功能足够了。所以，这里的事务并不通用，但是的确也提供了原子性，所以它被称为mini-transaction。 Zookeeper的保证Zookeeper基于Raft框架，是容错的，在发生网络分区的时候，也能有正确的行为。Zookeeper有一些性能增强，使得读请求可以在任何副本被处理，因此，可能会返回旧数据。 为什么Zookeeper在允许多副本读的情况下还能保证正确的行为？ 这得益于ZooKeeper 两个基本的一致性保证：线性写和先进先出(FIFO)的客户端请求。 写请求是线性一致的 All requests that update the state of ZooKeeper are serializable and respect precedence. Leader 保证写操作的顺序，并且该顺序在所有 Follower 上保持一致。 客户端可以并发的发送写请求，然后Zookeeper表现的就像以某种顺序，一次只执行一个写请求，并且也符合写请求的实际时间。所以如果一个写请求在另一个写请求开始前就结束了，那么Zookeeper实际上也会先执行第一个写请求，再执行第二个写请求。 所有更改Zookeeper状态的请求都是线性的，那么这就保证了主从状态一致性。 先进先出的客户端请求 All requests from a given client are executed in the order that they were sent by the client. 每个客户端可以为其操指定一个顺序，ZooKeeper 会按照客户端指定的顺序来执行。即zookeeper为每个单独的客户端提供了线性一致性。 这里的线性一致性只对于单个客户端的请求。比如说，客户端先发了一个写请求，然后再发读请求到落后的副本，那么这个读请求得看到它自己之前的写更新。 所以，如果我发送一个写请求给Leader，在Leader commit这个请求之前需要消耗一些时间，所以我现在给Leader发了一个写请求，而Leader还没有处理完它，或者commit它。之后，我发送了一个读请求给某个副本。这个读请求需要暂缓一下，以确保FIFO客户端请求序列。读请求需要暂缓，直到这个副本发现之前的写请求已经执行了。这是FIFO客户端请求序列的必然结果，（对于某个特定的客户端）读写请求是线性一致的。 ZooKeeper 通过 zxid 来实现，zxid 是最后一个事务的标记，当客户端发出一个请求到一个相同或者不同的副本时，会在请求带上 zxid 标记，副本通过检查客户端的 zxid 和自己的 zxid，保证读到的是更新的 zxid 的数据(没有具体说怎么处理，是阻塞等待还是拒绝请求) 更进一步，如果同一个客户端发送一个写请求&lt;X, 17&gt;，然后立即去某个副本服务器读 X，这里会暂缓一下读请求，直到这个副本发现写请求的 zxid 已经执行了，即客户端将会读到 &lt;X, 17&gt;，不会读到过期的数据。 同步操作 sync尽管有了Zookeeper的两个保证，但这还不是线性一致性。Zookeeper提供了另外一种弥补线性一致的方法：sync。 To handle this scenario more efficiently ZooKeeper provides the sync request: when followed by a read, constitutes a slow read. sync causes a server to apply all pending write requests before processing the read without the overhead of a full write. This primitive is similar in idea to the flush primitive of ISIS。 可以简单认为sync操作等于原子的写+读。这样客户端的读操作一定能看到最新的写入操作。因为FIFO的客户端请求使得它看到了自己的写请求，而写请求又是线性的，于是之前的写请求一定也被看见。 Zookeeper的实现//todo","link":"/2023/11/27/MIT6.824/%E7%AC%94%E8%AE%B06Zookeeper/"},{"title":"MIT6.824笔记七 链式复制","text":"这节课主要介绍了链复制的基本思想。CRAQ将读操作分散到各个节点，提升了读性能。 链复制基本方法![image-20231213135524616](/Users/mac/Library/Application Support/typora-user-images/image-20231213135524616.png) 为了保持线性一致的语义，链复制的基本思想是将服务器组成链表，请求从头部开始，一直链式传递到尾部。 写请求发往头部，读请求发往尾部。不同的是，写请求要经过完整的链传递复制，读请求不需要。 具体而言，当链表头部的服务器收到写请求时，它应用写请求，然后传递给下一个服务器。下一个服务器同样应用写请求，再传递下一个服务器。当尾部服务器应用完写请求时，它才回复客户端写请求已经完成。 读请求则十分简单，直接根据尾部服务器的状态读取。没有完成的写请求要么没有传递到尾服务器，要么就是回复丢失。而链复制一次只处理一个请求。所以读请求能看到最新的写请求状态，自然就是线性一致。 故障恢复链复制的写请求出现故障只有两种情况：要么写请求被所有服务器看到（commited），要么写请求只传递到中间某个服务器。 （1）Head故障 写请求在Head转发前，Head就故障了。那么没有服务器能看到这个写请求，第二个节点成为新的Head。 写请求在Head转发后，Head故障了，那么这个写请求还是会被持续转发下去，所有live服务器都看到这个写请求。 （2）Tail故障 如果TAIL出现故障，处理流程也非常相似，TAIL的前一个节点可以接手成为新的TAIL。所有TAIL知道的信息，TAIL的前一个节点必然都知道，因为TAIL的所有信息都是其前一个节点告知的。 （3）中间节点故障 或许有一些写请求被故障节点接收了，但是还没有被故障节点之后的节点接收，所以，当我们将其从链中移除时，故障节点的前一个节点或许需要重发最近的一些写请求给它的新后继节点。这是恢复中间节点流程的简单版本。 对比Raft（1）性能 对于Raft，如果我们有一个Leader和一些Follower。Leader需要直接将数据发送给所有的Follower 然而在Chain Replication中，HEAD只需要将写请求发送到一个其他节点。 所以Raft Leader的负担会比Chain Replication中HEAD的负担更高。当客户端请求变多时，Raft Leader会到达一个瓶颈，而不能在单位时间内处理更多的请求。 （2）读写分离 另一个与Raft相比的有趣的差别是，Raft中读请求同样也需要在Raft Leader中处理，所以Raft Leader可以看到所有的请求。而在Chain Replication中，每一个节点都可以看到写请求，但是只有TAIL可以看到读请求。所以负载在一定程度上，在HEAD和TAIL之间分担了，而不是集中在单个Leader节点。 （3）故障恢复 Chain Replication故障恢复更加简单。 配置管理器Chain Replication并不能抵御网络分区，也不能抵御脑裂。在实际场景中，这意味它不能单独使用。总是会有一个外部的权威（External Authority）来决定谁是活的，谁挂了，并确保所有参与者都认可由哪些节点组成一条链，这样在链的组成上就不会有分歧。这个外部的权威通常称为Configuration Manager。 Configuration Manager的工作就是监测节点存活性，一旦Configuration Manager认为一个节点挂了，它会生成并送出一个新的配置，在这个新的配置中，描述了链的新的定义，包含了链中所有的节点，HEAD和TAIL。Configuration Manager认为挂了的节点，或许真的挂了也或许没有，但是我们并不关心。因为所有节点都会遵从新的配置内容，所以现在不存在分歧了。 现在只有一个角色（Configuration Manager）在做决定，它不可能否认自己，所以可以解决脑裂的问题。 当然，你是如何使得一个服务是容错的，不否认自己，同时当有网络分区时不会出现脑裂呢？答案是，Configuration Manager通常会基于Raft或者Paxos。在CRAQ的场景下，它会基于Zookeeper。而Zookeeper本身又是基于类似Raft的方案。 所以，你的数据中心内的设置通常是，你有一个基于Raft或者Paxos的Configuration Manager，它是容错的，也不会受脑裂的影响。之后，通过一系列的配置更新通知，Configuration Manager将数据中心内的服务器分成多个链。 CRAQ论文：https://pdos.csail.mit.edu/6.824/papers/craq.pdf // todo","link":"/2023/12/13/MIT6.824/%E7%AC%94%E8%AE%B07CRAQ/"},{"title":"滑动窗口法","text":"滑动窗口是一种解题技巧，一句话说明就是维护一个窗口，不断滑动，更新答案。 滑动窗口适合的一维情况，比如数组、字符串；同时，拓展到二维也不是不可能。 根据问题求解的特性，可分为最小滑动窗口和最大滑动窗口两种解题模版。 滑动窗口大致逻辑1234567891011121314// 窗口由left和right共同维护，左闭右闭int left = 0, right = 0;while (right &lt; 某个值） { // 增大窗口 right++; // 更新窗口内的性质 window.add(s[right]); //当窗口内满足xx条件时，缩小窗口 while (window needs shrink) { window.remove(s[left]); left++; } //更新答案} 通过双指针维护窗口，right指针扩大窗口，left指针缩小窗口。滑动窗口射击两个过程，扩大窗口以及缩小窗口。需要注意一些细节，比如说如何向窗口中添加新元素，如何缩小窗口，在窗口滑动的哪个阶段更新结果。 （1）窗口内状态收集一般通过容器进行，比如map、queue（单调队列）等。 （2）两种模型 如果在扩大阶段收集答案，那么就是最大窗口模型，但注意同时要满足题目特定条件。背后的思想与贪心类似。 如果在窗口缩小阶段收集答案，那么就是最小窗口模型。 那么这两种模型到底有什么区别？滑动窗口法都有窗口扩张和窗口缩小的过程。最大窗口模型，窗口缩小是使条件满足的过程，然后收集答案；最小窗口模型，只有在满足条件时才能进行窗口缩小，窗口缩小的目的是使得条件不满足，在每一次窗口缩小过程中收集答案。 最小滑动窗口1234567891011121314151617181920void slidingWindow(string s, string t){ int left=0,right=0; int valid = 0; while(right&lt;s.size()){ //取数据 char c = s[right]; // 将数据加入窗口 // your code here while(窗口满足条件){ //记录结果 // your code here //缩小窗口，使之不满足条件 } //此时窗口不满足条件，继续扩大 right++; }} 可以看出来，最小滑动窗口的条件是在while循环内更新的，因为一旦满足了条件就要马上更新，取最小。 最大滑动窗口1234567891011121314151617181920void slidingWindow(string s, string t){ int left=0,right=0; int valid = 0; while(right&lt;s.size()){ //取数据 char c = s[right]; // 将数据加入窗口 // your code here while(窗口不满足条件){ //缩小窗口，使之满足条件 } //记录结果 // your code here //此时窗口满足条件，继续扩大 right++; }} 最大窗口的条件更新是在while外更新的。当我们的窗口满足条件时，我们希望继续扩大窗口，期望得到最大值。一旦窗口内的数据不满足条件了，我们就缩小窗口，调整满足条件。 滑动窗口法实战字符串排列https://leetcode.cn/problems/permutation-in-string/description/ 12345678910111213141516171819class Solution { public boolean checkInclusion(String s1, String s2) { if(s1.length()&gt;s2.length()) return false; // 初始化S1大小的窗口，然后不断向右滑动 int[] winodw = new int[26]; int[] s1_hash = new int[26]; for(int i=0; i&lt;s1.length(); ++i){ s1_hash[s1.charAt(i)-'a'] += 1; winodw[s2.charAt(i)-'a'] += 1; } if(Arrays.equals(s1_hash, winodw)) return true; for(int i=s1.length(); i&lt;s2.length(); ++i){ winodw[s2.charAt(i-s1.length()) -'a']--; winodw[s2.charAt(i)-'a']++; if(Arrays.equals(s1_hash, winodw)) return true; } return false; }} 很简单的思路，用哈希表映射窗口每个字母的个数，然后不断向右滑动。 字符串中的所有字母异位词https://leetcode.cn/problems/find-all-anagrams-in-a-string/ 12345678910111213141516171819class Solution { public List&lt;Integer&gt; findAnagrams(String s, String p) { List&lt;Integer&gt; ans = new ArrayList&lt;&gt;(); if (p.length() &gt; s.length() ) return ans; int[] p_map = new int[26]; int[] win_map = new int[26]; for(int i=0; i&lt;p.length(); ++i){ p_map[p.charAt(i)-'a'] +=1; win_map[s.charAt(i)-'a'] +=1; } if (Arrays.equals(p_map, win_map)) ans.add(0); for(int i=p.length();i&lt;s.length(); ++i){ win_map[s.charAt(i-p.length())-'a']--; win_map[s.charAt(i) -'a']++; if (Arrays.equals(p_map, win_map)) ans.add(i-p.length()+1); } return ans; }} 简单改变上一题的模版，增加一个容器收集答案。 最小窗口实战长度最小子数组https://leetcode.cn/problems/minimum-size-subarray-sum/ 1234567891011121314151617class Solution { public int minSubArrayLen(int target, int[] nums) { int windowCount = 0; int ans = Integer.MAX_VALUE; int l =0, r=0; while(r&lt;nums.length){ windowCount += nums[r]; while(windowCount&gt;=target){ ans = Math.min(ans, r-l+1); windowCount -= nums[l]; l++; } r++; } return ans==Integer.MAX_VALUE?0:ans; }} 最小滑动窗口入门题了，窗口内状态只需要用一个变量保存，然后在缩小窗口的过程中更新答案。 最小覆盖子串https://leetcode.cn/problems/minimum-window-substring/ 12345678910111213141516171819202122232425262728293031323334class Solution { public boolean isCovered(int[] s1, int[] s2){ for(int i=0; i&lt;s1.length; ++i) { if(s1[i]&lt;s2[i]) return false; } return true; } public int[] initMap(String s, int len){ int[] ret = new int[60]; for(int i=0; i&lt;len; ++i){ ret[s.charAt(i)-'A']++; } return ret; } public String minWindow(String s, String t) { if(s.length()&lt;t.length()) return &quot;&quot;; int l=0, r=0, record_l=0, record_r=s.length()+1; int[] tmap = initMap(t, t.length()); int[] window = new int[60]; while(r&lt;s.length()){ window[s.charAt(r)-'A']++; while(isCovered(window, tmap)){ if(record_r-record_l &gt; r-l){ record_l = l; record_r = r; } window[s.charAt(l)-'A']--; l++; } r++; } return record_r==1+s.length()?&quot;&quot;:s.substring(record_l, record_r+1); }} 有模版之后一切不再难。 最大窗口实战无重复字符的最长子串 https://leetcode.cn/problems/longest-substring-without-repeating-characters/ 123456789101112131415161718class Solution { public int lengthOfLongestSubstring(String s) { int i=0,j=0,ans=0; Map&lt;Character, Integer&gt; map = new HashMap&lt;&gt;(); while(j&lt;s.length()){ char ch = s.charAt(j); map.put(ch ,map.getOrDefault(ch ,0)+1); while(map.get(ch)&gt;1){ //不满足条件就缩小窗口 char d_ch = s.charAt(i); map.put(d_ch ,map.getOrDefault(d_ch ,0)-1); i++; } ans = Math.max(ans, j-i+1); //满足条件后更新 j++; } return ans; }} 参考： 作者：labuladong链接：https://leetcode.cn/problems/find-all-anagrams-in-a-string/solutions/9749/hua-dong-chuang-kou-tong-yong-si-xiang-jie-jue-zi-/ 作者：HelloPGJC链接：https://leetcode.cn/problems/fruit-into-baskets/solutions/1437444/shen-du-jie-xi-zhe-dao-ti-he-by-linzeyin-6crr/","link":"/2023/12/21/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%95%B0%E7%BB%84%E4%B8%8E%E5%AD%97%E7%AC%A6%E4%B8%B2/Java%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/"}],"tags":[{"name":"分布式系统","slug":"分布式系统","link":"/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"},{"name":"双指针","slug":"双指针","link":"/tags/%E5%8F%8C%E6%8C%87%E9%92%88/"},{"name":"滑动窗口","slug":"滑动窗口","link":"/tags/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/"}],"categories":[{"name":"工具学习","slug":"工具学习","link":"/categories/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/"},{"name":"Vim","slug":"工具学习/Vim","link":"/categories/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/Vim/"},{"name":"Git","slug":"工具学习/Git","link":"/categories/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/Git/"},{"name":"终端","slug":"工具学习/终端","link":"/categories/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/%E7%BB%88%E7%AB%AF/"},{"name":"操作系统","slug":"操作系统","link":"/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"后端开发","slug":"后端开发","link":"/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"},{"name":"设计模式","slug":"设计模式","link":"/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"数据结构与算法","slug":"数据结构与算法","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"MIT6.824","slug":"MIT6-824","link":"/categories/MIT6-824/"},{"name":"数组与字符串","slug":"数据结构与算法/数组与字符串","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%95%B0%E7%BB%84%E4%B8%8E%E5%AD%97%E7%AC%A6%E4%B8%B2/"}],"pages":[{"title":"","text":"this is test file","link":"/test.html"}]}